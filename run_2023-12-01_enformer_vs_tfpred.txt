KeyError in file /project2/haky/temi/projects/TFPred-snakemake/snakefile.smk, line 206:
'scratch'
  File "/project2/haky/temi/projects/TFPred-snakemake/snakefile.smk", line 206, in <module>
186 valid TF-tissue pairs were found.
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 100
Provided resources: load=50
Job stats:
job                              count    min threads    max threads
-----------------------------  -------  -------------  -------------
aggregate_predictions              186              1              1
all                                  1              1              1
create_enformer_configuration      186              1              1
create_training_set                186              8              8
evaluate_TFPred                    186              1              1
find_homer_motifs                   51              1              1
merge_homer_motifs                  40              1              1
predict_with_enformer              186              1              1
prepare_training_data              186              1              1
train_TFPred_weights               186              1              1
total                             1394              1              8

Select jobs to execute...

[Fri Dec  1 23:47:41 2023]
Job 34: working on motif_file=runx1,tf=RUNX1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/RUNX1/runx1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/RUNX1/scanMotifsGenomeWide_runx1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 34 with external jobid 'Submitted batch job 11024350'.

[Fri Dec  1 23:47:42 2023]
Job 20: working on motif_file=ets1,tf=ETS1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ETS1/ets1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ETS1/scanMotifsGenomeWide_ets1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 20 with external jobid 'Submitted batch job 11024351'.

[Fri Dec  1 23:47:42 2023]
Job 19: working on motif_file=znf382,tf=ZNF382
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ZNF382/znf382.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ZNF382/scanMotifsGenomeWide_znf382.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 19 with external jobid 'Submitted batch job 11024352'.

[Fri Dec  1 23:47:42 2023]
Job 48: working on motif_file=jun-cre,tf=JUN
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/JUN/jun-cre.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/JUN/scanMotifsGenomeWide_jun-cre.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 48 with external jobid 'Submitted batch job 11024353'.

[Fri Dec  1 23:47:42 2023]
Job 28: working on motif_file=tcf4,tf=TCF4
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/TCF4/tcf4.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/TCF4/scanMotifsGenomeWide_tcf4.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 28 with external jobid 'Submitted batch job 11024354'.

[Fri Dec  1 23:47:42 2023]
Job 42: working on motif_file=gata3.ir3,tf=GATA3
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GATA3/gata3.ir3.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GATA3/scanMotifsGenomeWide_gata3.ir3.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 42 with external jobid 'Submitted batch job 11024355'.

[Fri Dec  1 23:47:43 2023]
Job 11: working on motif_file=stat3,tf=STAT3
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT3/stat3.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT3/scanMotifsGenomeWide_stat3.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 11 with external jobid 'Submitted batch job 11024356'.

[Fri Dec  1 23:47:43 2023]
Job 41: working on motif_file=gata3.dr8,tf=GATA3
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GATA3/gata3.dr8.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GATA3/scanMotifsGenomeWide_gata3.dr8.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 41 with external jobid 'Submitted batch job 11024357'.

[Fri Dec  1 23:47:43 2023]
Job 21: working on motif_file=foxo1,tf=FOXO1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FOXO1/foxo1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FOXO1/scanMotifsGenomeWide_foxo1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 21 with external jobid 'Submitted batch job 11024358'.

[Fri Dec  1 23:47:43 2023]
Job 35: working on motif_file=otx2,tf=OTX2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/OTX2/otx2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/OTX2/scanMotifsGenomeWide_otx2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 35 with external jobid 'Submitted batch job 11024359'.

[Fri Dec  1 23:47:43 2023]
Job 49: working on motif_file=jun-ap1,tf=JUN
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/JUN/jun-ap1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/JUN/scanMotifsGenomeWide_jun-ap1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 49 with external jobid 'Submitted batch job 11024360'.

[Fri Dec  1 23:47:43 2023]
Job 18: working on motif_file=ar-half,tf=AR
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/AR/ar-half.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/AR/scanMotifsGenomeWide_ar-half.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 18 with external jobid 'Submitted batch job 11024361'.

[Fri Dec  1 23:47:43 2023]
Job 43: working on motif_file=gata3.dr4,tf=GATA3
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GATA3/gata3.dr4.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GATA3/scanMotifsGenomeWide_gata3.dr4.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 43 with external jobid 'Submitted batch job 11024362'.

[Fri Dec  1 23:47:43 2023]
Job 5: working on motif_file=foxa1.lncap,tf=FOXA1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FOXA1/foxa1.lncap.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FOXA1/scanMotifsGenomeWide_foxa1.lncap.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 5 with external jobid 'Submitted batch job 11024363'.

[Fri Dec  1 23:47:43 2023]
Job 10: working on motif_file=snai2,tf=SNAI2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/SNAI2/snai2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/SNAI2/scanMotifsGenomeWide_snai2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 10 with external jobid 'Submitted batch job 11024364'.

[Fri Dec  1 23:47:44 2023]
Job 29: working on motif_file=e2f1,tf=E2F1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/E2F1/e2f1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/E2F1/scanMotifsGenomeWide_e2f1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 29 with external jobid 'Submitted batch job 11024365'.

[Fri Dec  1 23:47:44 2023]
Job 22: working on motif_file=foxa2,tf=FOXA2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FOXA2/foxa2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FOXA2/scanMotifsGenomeWide_foxa2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 22 with external jobid 'Submitted batch job 11024366'.

[Fri Dec  1 23:47:44 2023]
Job 36: working on motif_file=p53-myc,tf=MYC
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/MYC/p53-myc.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/MYC/scanMotifsGenomeWide_p53-myc.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 36 with external jobid 'Submitted batch job 11024367'.

[Fri Dec  1 23:47:44 2023]
Job 50: working on motif_file=vdr,tf=VDR
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/VDR/vdr.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/VDR/scanMotifsGenomeWide_vdr.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 50 with external jobid 'Submitted batch job 11024368'.

[Fri Dec  1 23:47:44 2023]
Job 17: working on motif_file=ews-fli1,tf=FLI1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FLI1/ews-fli1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FLI1/scanMotifsGenomeWide_ews-fli1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 17 with external jobid 'Submitted batch job 11024369'.

[Fri Dec  1 23:47:44 2023]
Job 6: working on motif_file=hif1a,tf=HIF1A
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/HIF1A/hif1a.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/HIF1A/scanMotifsGenomeWide_hif1a.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 6 with external jobid 'Submitted batch job 11024370'.

[Fri Dec  1 23:47:45 2023]
Job 30: working on motif_file=rest,tf=REST
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/REST/rest.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/REST/scanMotifsGenomeWide_rest.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 30 with external jobid 'Submitted batch job 11024371'.

[Fri Dec  1 23:47:45 2023]
Job 44: working on motif_file=pr,tf=PR
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/PR/pr.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/PR/scanMotifsGenomeWide_pr.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 44 with external jobid 'Submitted batch job 11024372'.

[Fri Dec  1 23:47:45 2023]
Job 9: working on motif_file=gata2,tf=GATA2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GATA2/gata2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GATA2/scanMotifsGenomeWide_gata2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 9 with external jobid 'Submitted batch job 11024373'.

[Fri Dec  1 23:47:45 2023]
Job 4: working on motif_file=foxa1.mcf7,tf=FOXA1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FOXA1/foxa1.mcf7.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FOXA1/scanMotifsGenomeWide_foxa1.mcf7.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 4 with external jobid 'Submitted batch job 11024374'.

[Fri Dec  1 23:47:45 2023]
Job 23: working on motif_file=stat1,tf=STAT1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT1/stat1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT1/scanMotifsGenomeWide_stat1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 23 with external jobid 'Submitted batch job 11024375'.

[Fri Dec  1 23:47:45 2023]
Job 37: working on motif_file=hoxb13,tf=HOXB13
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/HOXB13/hoxb13.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/HOXB13/scanMotifsGenomeWide_hoxb13.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 37 with external jobid 'Submitted batch job 11024376'.

[Fri Dec  1 23:47:45 2023]
Job 51: working on motif_file=hsf1,tf=HSF1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/HSF1/hsf1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/HSF1/scanMotifsGenomeWide_hsf1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 51 with external jobid 'Submitted batch job 11024377'.

[Fri Dec  1 23:47:45 2023]
Job 16: working on motif_file=sp1,tf=SP1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/SP1/sp1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/SP1/scanMotifsGenomeWide_sp1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 16 with external jobid 'Submitted batch job 11024378'.

[Fri Dec  1 23:47:45 2023]
Job 12: working on motif_file=stat3.il23,tf=STAT3
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT3/stat3.il23.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT3/scanMotifsGenomeWide_stat3.il23.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 12 with external jobid 'Submitted batch job 11024379'.

[Fri Dec  1 23:47:45 2023]
Job 31: working on motif_file=grhl2,tf=GRHL2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GRHL2/grhl2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GRHL2/scanMotifsGenomeWide_grhl2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 31 with external jobid 'Submitted batch job 11024380'.

[Fri Dec  1 23:47:46 2023]
Job 45: working on motif_file=sox2,tf=SOX2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/SOX2/sox2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/SOX2/scanMotifsGenomeWide_sox2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 45 with external jobid 'Submitted batch job 11024381'.

[Fri Dec  1 23:47:46 2023]
Job 8: working on motif_file=ctcf,tf=CTCF
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/CTCF/ctcf.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/CTCF/scanMotifsGenomeWide_ctcf.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 8 with external jobid 'Submitted batch job 11024382'.

[Fri Dec  1 23:47:46 2023]
Job 2: working on motif_file=ews-erg,tf=ERG
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ERG/ews-erg.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ERG/scanMotifsGenomeWide_ews-erg.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 2 with external jobid 'Submitted batch job 11024383'.

[Fri Dec  1 23:47:46 2023]
Job 24: working on motif_file=neurog2,tf=NEUROG2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/NEUROG2/neurog2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/NEUROG2/scanMotifsGenomeWide_neurog2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 24 with external jobid 'Submitted batch job 11024384'.

[Fri Dec  1 23:47:46 2023]
Job 38: working on motif_file=ascl1,tf=ASCL1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ASCL1/ascl1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ASCL1/scanMotifsGenomeWide_ascl1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 38 with external jobid 'Submitted batch job 11024385'.

[Fri Dec  1 23:47:47 2023]
Job 15: working on motif_file=pparg,tf=PPARG
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/PPARG/pparg.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/PPARG/scanMotifsGenomeWide_pparg.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 15 with external jobid 'Submitted batch job 11024386'.

[Fri Dec  1 23:47:47 2023]
Job 32: working on motif_file=stat6,tf=STAT6
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT6/stat6.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT6/scanMotifsGenomeWide_stat6.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 32 with external jobid 'Submitted batch job 11024387'.

[Fri Dec  1 23:47:47 2023]
Job 46: working on motif_file=oct4-sox2,tf=SOX2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/SOX2/oct4-sox2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/SOX2/scanMotifsGenomeWide_oct4-sox2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 46 with external jobid 'Submitted batch job 11024388'.

[Fri Dec  1 23:47:47 2023]
Job 1: working on motif_file=erg,tf=ERG
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ERG/erg.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ERG/scanMotifsGenomeWide_erg.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1 with external jobid 'Submitted batch job 11024389'.

[Fri Dec  1 23:47:47 2023]
Job 25: working on motif_file=gata4,tf=GATA4
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GATA4/gata4.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GATA4/scanMotifsGenomeWide_gata4.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 25 with external jobid 'Submitted batch job 11024390'.

[Fri Dec  1 23:47:47 2023]
Job 39: working on motif_file=gata3,tf=GATA3
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GATA3/gata3.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GATA3/scanMotifsGenomeWide_gata3.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 39 with external jobid 'Submitted batch job 11024391'.

[Fri Dec  1 23:47:47 2023]
Job 14: working on motif_file=yy1,tf=YY1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/YY1/yy1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/YY1/scanMotifsGenomeWide_yy1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 14 with external jobid 'Submitted batch job 11024392'.

[Fri Dec  1 23:47:47 2023]
Job 33: working on motif_file=stat6.2,tf=STAT6
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT6/stat6.2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT6/scanMotifsGenomeWide_stat6.2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 33 with external jobid 'Submitted batch job 11024393'.

[Fri Dec  1 23:47:47 2023]
Job 47: working on motif_file=cdx2,tf=CDX2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/CDX2/cdx2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/CDX2/scanMotifsGenomeWide_cdx2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 47 with external jobid 'Submitted batch job 11024394'.

[Fri Dec  1 23:47:47 2023]
Job 7: working on motif_file=ctcf-mys,tf=CTCF
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/CTCF/ctcf-mys.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/CTCF/scanMotifsGenomeWide_ctcf-mys.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 7 with external jobid 'Submitted batch job 11024395'.

[Fri Dec  1 23:47:48 2023]
Job 3: working on motif_file=max,tf=MAX
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/MAX/max.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/MAX/scanMotifsGenomeWide_max.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 3 with external jobid 'Submitted batch job 11024396'.

[Fri Dec  1 23:47:48 2023]
Job 26: working on motif_file=stat4,tf=STAT4
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT4/stat4.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT4/scanMotifsGenomeWide_stat4.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 26 with external jobid 'Submitted batch job 11024397'.

[Fri Dec  1 23:47:48 2023]
Job 40: working on motif_file=gata3.ir4,tf=GATA3
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GATA3/gata3.ir4.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GATA3/scanMotifsGenomeWide_gata3.ir4.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 40 with external jobid 'Submitted batch job 11024398'.

[Fri Dec  1 23:47:48 2023]
Job 13: working on motif_file=fosl2,tf=FOSL2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FOSL2/fosl2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FOSL2/scanMotifsGenomeWide_fosl2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 13 with external jobid 'Submitted batch job 11024399'.

[Fri Dec  1 23:47:48 2023]
Job 27: working on motif_file=foxm1,tf=FOXM1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FOXM1/foxm1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FOXM1/scanMotifsGenomeWide_foxm1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 27 with external jobid 'Submitted batch job 11024400'.
[Fri Dec  1 23:48:51 2023]
Error in rule find_homer_motifs:
    jobid: 34
    input: data/homer_files/RUNX1/runx1.motif
    output: data/homer_files/RUNX1/scanMotifsGenomeWide_runx1.txt
    shell:
        
        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/RUNX1/runx1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/RUNX1/scanMotifsGenomeWide_runx1.txt
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11024350

Error executing rule find_homer_motifs on cluster (jobid: 34, external: Submitted batch job 11024350, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.find_homer_motifs.34.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 34.
Select jobs to execute...

[Fri Dec  1 23:48:51 2023]
Job 34: working on motif_file=runx1,tf=RUNX1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/RUNX1/runx1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/RUNX1/scanMotifsGenomeWide_runx1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 34 with external jobid 'Submitted batch job 11024440'.
[Fri Dec  1 23:59:12 2023]
Finished job 6.
1 of 1394 steps (0.1%) done
Select jobs to execute...

[Fri Dec  1 23:59:12 2023]
Job 82: working on tf=HIF1A data/homer_files/HIF1A/scanMotifsGenomeWide_hif1a.txt
Reason: Input files updated by another job: data/homer_files/HIF1A/scanMotifsGenomeWide_hif1a.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 82 with external jobid 'Submitted batch job 11024597'.
[Fri Dec  1 23:59:52 2023]
Finished job 82.
2 of 1394 steps (0.1%) done
[Fri Dec  1 23:59:54 2023]
Finished job 20.
3 of 1394 steps (0.2%) done
Select jobs to execute...

[Fri Dec  1 23:59:54 2023]
Job 70: working on tf=ETS1 data/homer_files/ETS1/scanMotifsGenomeWide_ets1.txt
Reason: Input files updated by another job: data/homer_files/ETS1/scanMotifsGenomeWide_ets1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 70 with external jobid 'Submitted batch job 11024622'.
[Fri Dec  1 23:59:57 2023]
Finished job 28.
4 of 1394 steps (0.3%) done
Select jobs to execute...

[Fri Dec  1 23:59:57 2023]
Job 81: working on tf=TCF4 data/homer_files/TCF4/scanMotifsGenomeWide_tcf4.txt
Reason: Input files updated by another job: data/homer_files/TCF4/scanMotifsGenomeWide_tcf4.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 81 with external jobid 'Submitted batch job 11024623'.
[Fri Dec  1 23:59:59 2023]
Finished job 11.
5 of 1394 steps (0.4%) done
[Sat Dec  2 00:00:01 2023]
Finished job 21.
6 of 1394 steps (0.4%) done
Select jobs to execute...

[Sat Dec  2 00:00:01 2023]
Job 85: working on tf=FOXO1 data/homer_files/FOXO1/scanMotifsGenomeWide_foxo1.txt
Reason: Input files updated by another job: data/homer_files/FOXO1/scanMotifsGenomeWide_foxo1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 85 with external jobid 'Submitted batch job 11024654'.
[Sat Dec  2 00:00:02 2023]
Finished job 35.
7 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:02 2023]
Job 76: working on tf=OTX2 data/homer_files/OTX2/scanMotifsGenomeWide_otx2.txt
Reason: Input files updated by another job: data/homer_files/OTX2/scanMotifsGenomeWide_otx2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 76 with external jobid 'Submitted batch job 11024658'.
[Sat Dec  2 00:00:08 2023]
Finished job 29.
8 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:08 2023]
Job 64: working on tf=E2F1 data/homer_files/E2F1/scanMotifsGenomeWide_e2f1.txt
Reason: Input files updated by another job: data/homer_files/E2F1/scanMotifsGenomeWide_e2f1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 64 with external jobid 'Submitted batch job 11024659'.
[Sat Dec  2 00:00:12 2023]
Finished job 17.
9 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:12 2023]
Job 73: working on tf=FLI1 data/homer_files/FLI1/scanMotifsGenomeWide_ews-fli1.txt
Reason: Input files updated by another job: data/homer_files/FLI1/scanMotifsGenomeWide_ews-fli1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 73 with external jobid 'Submitted batch job 11024660'.
[Sat Dec  2 00:00:15 2023]
Finished job 9.
10 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:15 2023]
Job 54: working on tf=GATA2 data/homer_files/GATA2/scanMotifsGenomeWide_gata2.txt
Reason: Input files updated by another job: data/homer_files/GATA2/scanMotifsGenomeWide_gata2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 54 with external jobid 'Submitted batch job 11024661'.
[Sat Dec  2 00:00:16 2023]
Finished job 4.
11 of 1394 steps (1%) done
[Sat Dec  2 00:00:18 2023]
Finished job 37.
12 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:18 2023]
Job 91: working on tf=HOXB13 data/homer_files/HOXB13/scanMotifsGenomeWide_hoxb13.txt
Reason: Input files updated by another job: data/homer_files/HOXB13/scanMotifsGenomeWide_hoxb13.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 91 with external jobid 'Submitted batch job 11024662'.
[Sat Dec  2 00:00:20 2023]
Finished job 16.
13 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:20 2023]
Job 67: working on tf=SP1 data/homer_files/SP1/scanMotifsGenomeWide_sp1.txt
Reason: Input files updated by another job: data/homer_files/SP1/scanMotifsGenomeWide_sp1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 67 with external jobid 'Submitted batch job 11024663'.
[Sat Dec  2 00:00:23 2023]
Finished job 45.
14 of 1394 steps (1%) done
[Sat Dec  2 00:00:25 2023]
Finished job 2.
15 of 1394 steps (1%) done
[Sat Dec  2 00:00:26 2023]
Finished job 24.
16 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:26 2023]
Job 79: working on tf=NEUROG2 data/homer_files/NEUROG2/scanMotifsGenomeWide_neurog2.txt
Reason: Input files updated by another job: data/homer_files/NEUROG2/scanMotifsGenomeWide_neurog2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 79 with external jobid 'Submitted batch job 11024664'.
[Sat Dec  2 00:00:31 2023]
Finished job 1.
17 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:31 2023]
Job 66: working on tf=ERG data/homer_files/ERG/scanMotifsGenomeWide_erg.txt data/homer_files/ERG/scanMotifsGenomeWide_ews-erg.txt
Reason: Input files updated by another job: data/homer_files/ERG/scanMotifsGenomeWide_ews-erg.txt, data/homer_files/ERG/scanMotifsGenomeWide_erg.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 66 with external jobid 'Submitted batch job 11024672'.
[Sat Dec  2 00:00:32 2023]
Finished job 25.
18 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:32 2023]
Job 60: working on tf=GATA4 data/homer_files/GATA4/scanMotifsGenomeWide_gata4.txt
Reason: Input files updated by another job: data/homer_files/GATA4/scanMotifsGenomeWide_gata4.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 60 with external jobid 'Submitted batch job 11024673'.
[Sat Dec  2 00:00:36 2023]
Finished job 47.
19 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:36 2023]
Job 71: working on tf=CDX2 data/homer_files/CDX2/scanMotifsGenomeWide_cdx2.txt
Reason: Input files updated by another job: data/homer_files/CDX2/scanMotifsGenomeWide_cdx2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 71 with external jobid 'Submitted batch job 11024674'.
[Sat Dec  2 00:00:41 2023]
Finished job 13.
20 of 1394 steps (1%) done
Select jobs to execute...

[Sat Dec  2 00:00:41 2023]
Job 56: working on tf=FOSL2 data/homer_files/FOSL2/scanMotifsGenomeWide_fosl2.txt
Reason: Input files updated by another job: data/homer_files/FOSL2/scanMotifsGenomeWide_fosl2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 56 with external jobid 'Submitted batch job 11024675'.
[Sat Dec  2 00:00:42 2023]
Finished job 27.
21 of 1394 steps (2%) done
Select jobs to execute...

[Sat Dec  2 00:00:42 2023]
Job 61: working on tf=FOXM1 data/homer_files/FOXM1/scanMotifsGenomeWide_foxm1.txt
Reason: Input files updated by another job: data/homer_files/FOXM1/scanMotifsGenomeWide_foxm1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 61 with external jobid 'Submitted batch job 11024676'.
[Sat Dec  2 00:00:52 2023]
Finished job 70.
22 of 1394 steps (2%) done
Select jobs to execute...

[Sat Dec  2 00:00:52 2023]
Job 124: working on tf=ETS1,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/ETS1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ETS1 --tissue Prostate --predicted_motif_file data/homer_files/ETS1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ETS1_Prostate --predictors_file data/predictor_files/ETS1_Prostate.predictors.txt --ground_truth_file data/predictor_files/ETS1_Prostate.ground_truth.txt --info_file data/predictor_files/ETS1_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 124 with external jobid 'Submitted batch job 11024677'.

[Sat Dec  2 00:00:54 2023]
Job 208: working on tf=ETS1,tissue=Lung
Reason: Input files updated by another job: data/homer_files/ETS1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ETS1 --tissue Lung --predicted_motif_file data/homer_files/ETS1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ETS1_Lung --predictors_file data/predictor_files/ETS1_Lung.predictors.txt --ground_truth_file data/predictor_files/ETS1_Lung.ground_truth.txt --info_file data/predictor_files/ETS1_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 208 with external jobid 'Submitted batch job 11024678'.

[Sat Dec  2 00:00:54 2023]
Job 226: working on tf=ETS1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/ETS1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ETS1 --tissue Bone-Marrow --predicted_motif_file data/homer_files/ETS1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ETS1_Bone-Marrow --predictors_file data/predictor_files/ETS1_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/ETS1_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/ETS1_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 226 with external jobid 'Submitted batch job 11024679'.

[Sat Dec  2 00:00:54 2023]
Job 151: working on tf=ETS1,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/ETS1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ETS1 --tissue Umbilical-Vein --predicted_motif_file data/homer_files/ETS1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ETS1_Umbilical-Vein --predictors_file data/predictor_files/ETS1_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/ETS1_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/ETS1_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 151 with external jobid 'Submitted batch job 11024680'.

[Sat Dec  2 00:00:54 2023]
Job 239: working on tf=ETS1,tissue=Pancreas
Reason: Input files updated by another job: data/homer_files/ETS1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ETS1 --tissue Pancreas --predicted_motif_file data/homer_files/ETS1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ETS1_Pancreas --predictors_file data/predictor_files/ETS1_Pancreas.predictors.txt --ground_truth_file data/predictor_files/ETS1_Pancreas.ground_truth.txt --info_file data/predictor_files/ETS1_Pancreas.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 239 with external jobid 'Submitted batch job 11024681'.

[Sat Dec  2 00:00:57 2023]
Job 101: working on tf=ETS1,tissue=Blood
Reason: Input files updated by another job: data/homer_files/ETS1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ETS1 --tissue Blood --predicted_motif_file data/homer_files/ETS1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ETS1_Blood --predictors_file data/predictor_files/ETS1_Blood.predictors.txt --ground_truth_file data/predictor_files/ETS1_Blood.ground_truth.txt --info_file data/predictor_files/ETS1_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 101 with external jobid 'Submitted batch job 11024682'.
[Sat Dec  2 00:00:57 2023]
Finished job 81.
23 of 1394 steps (2%) done
[Sat Dec  2 00:00:57 2023]
Finished job 85.
24 of 1394 steps (2%) done
[Sat Dec  2 00:00:57 2023]
Finished job 76.
25 of 1394 steps (2%) done
[Sat Dec  2 00:00:57 2023]
Finished job 64.
26 of 1394 steps (2%) done
Select jobs to execute...

[Sat Dec  2 00:00:57 2023]
Job 260: working on tf=E2F1,tissue=Umbilical-Cord
Reason: Input files updated by another job: data/homer_files/E2F1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor E2F1 --tissue Umbilical-Cord --predicted_motif_file data/homer_files/E2F1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/E2F1_Umbilical-Cord --predictors_file data/predictor_files/E2F1_Umbilical-Cord.predictors.txt --ground_truth_file data/predictor_files/E2F1_Umbilical-Cord.ground_truth.txt --info_file data/predictor_files/E2F1_Umbilical-Cord.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 260 with external jobid 'Submitted batch job 11024683'.

[Sat Dec  2 00:00:57 2023]
Job 96: working on tf=E2F1,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/E2F1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor E2F1 --tissue Cervix --predicted_motif_file data/homer_files/E2F1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/E2F1_Cervix --predictors_file data/predictor_files/E2F1_Cervix.predictors.txt --ground_truth_file data/predictor_files/E2F1_Cervix.ground_truth.txt --info_file data/predictor_files/E2F1_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 96 with external jobid 'Submitted batch job 11024684'.

[Sat Dec  2 00:00:57 2023]
Job 250: working on tf=E2F1,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/E2F1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor E2F1 --tissue Mammary-Gland --predicted_motif_file data/homer_files/E2F1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/E2F1_Mammary-Gland --predictors_file data/predictor_files/E2F1_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/E2F1_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/E2F1_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 250 with external jobid 'Submitted batch job 11024685'.

[Sat Dec  2 00:00:59 2023]
Job 265: working on tf=E2F1,tissue=Blood
Reason: Input files updated by another job: data/homer_files/E2F1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor E2F1 --tissue Blood --predicted_motif_file data/homer_files/E2F1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/E2F1_Blood --predictors_file data/predictor_files/E2F1_Blood.predictors.txt --ground_truth_file data/predictor_files/E2F1_Blood.ground_truth.txt --info_file data/predictor_files/E2F1_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 265 with external jobid 'Submitted batch job 11024686'.

[Sat Dec  2 00:00:59 2023]
Job 107: working on tf=E2F1,tissue=Breast
Reason: Input files updated by another job: data/homer_files/E2F1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor E2F1 --tissue Breast --predicted_motif_file data/homer_files/E2F1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/E2F1_Breast --predictors_file data/predictor_files/E2F1_Breast.predictors.txt --ground_truth_file data/predictor_files/E2F1_Breast.ground_truth.txt --info_file data/predictor_files/E2F1_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 107 with external jobid 'Submitted batch job 11024687'.

[Sat Dec  2 00:00:59 2023]
Job 179: working on tf=E2F1,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/E2F1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor E2F1 --tissue Prostate --predicted_motif_file data/homer_files/E2F1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/E2F1_Prostate --predictors_file data/predictor_files/E2F1_Prostate.predictors.txt --ground_truth_file data/predictor_files/E2F1_Prostate.ground_truth.txt --info_file data/predictor_files/E2F1_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 179 with external jobid 'Submitted batch job 11024688'.

[Sat Dec  2 00:00:59 2023]
Job 165: working on tf=E2F1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/E2F1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor E2F1 --tissue Colon --predicted_motif_file data/homer_files/E2F1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/E2F1_Colon --predictors_file data/predictor_files/E2F1_Colon.predictors.txt --ground_truth_file data/predictor_files/E2F1_Colon.ground_truth.txt --info_file data/predictor_files/E2F1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 165 with external jobid 'Submitted batch job 11024689'.

[Sat Dec  2 00:00:59 2023]
Job 167: working on tf=E2F1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/E2F1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor E2F1 --tissue Bone-Marrow --predicted_motif_file data/homer_files/E2F1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/E2F1_Bone-Marrow --predictors_file data/predictor_files/E2F1_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/E2F1_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/E2F1_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 167 with external jobid 'Submitted batch job 11024690'.
[Sat Dec  2 00:00:59 2023]
Finished job 73.
27 of 1394 steps (2%) done
[Sat Dec  2 00:00:59 2023]
Finished job 54.
28 of 1394 steps (2%) done
[Sat Dec  2 00:00:59 2023]
Finished job 91.
29 of 1394 steps (2%) done
Select jobs to execute...

[Sat Dec  2 00:00:59 2023]
Job 128: working on tf=GATA2,tissue=Blood
Reason: Input files updated by another job: data/homer_files/GATA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA2 --tissue Blood --predicted_motif_file data/homer_files/GATA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA2_Blood --predictors_file data/predictor_files/GATA2_Blood.predictors.txt --ground_truth_file data/predictor_files/GATA2_Blood.ground_truth.txt --info_file data/predictor_files/GATA2_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 128 with external jobid 'Submitted batch job 11024691'.

[Sat Dec  2 00:00:59 2023]
Job 102: working on tf=GATA2,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/GATA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA2 --tissue Bone-Marrow --predicted_motif_file data/homer_files/GATA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA2_Bone-Marrow --predictors_file data/predictor_files/GATA2_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/GATA2_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/GATA2_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 102 with external jobid 'Submitted batch job 11024692'.

[Sat Dec  2 00:01:00 2023]
Job 158: working on tf=GATA2,tissue=Colon
Reason: Input files updated by another job: data/homer_files/GATA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA2 --tissue Colon --predicted_motif_file data/homer_files/GATA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA2_Colon --predictors_file data/predictor_files/GATA2_Colon.predictors.txt --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --info_file data/predictor_files/GATA2_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 158 with external jobid 'Submitted batch job 11024693'.

[Sat Dec  2 00:01:00 2023]
Job 245: working on tf=GATA2,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/GATA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA2 --tissue Prostate --predicted_motif_file data/homer_files/GATA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA2_Prostate --predictors_file data/predictor_files/GATA2_Prostate.predictors.txt --ground_truth_file data/predictor_files/GATA2_Prostate.ground_truth.txt --info_file data/predictor_files/GATA2_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 245 with external jobid 'Submitted batch job 11024694'.

[Sat Dec  2 00:01:00 2023]
Job 99: working on tf=GATA2,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/GATA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA2 --tissue Umbilical-Vein --predicted_motif_file data/homer_files/GATA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA2_Umbilical-Vein --predictors_file data/predictor_files/GATA2_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/GATA2_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/GATA2_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 99 with external jobid 'Submitted batch job 11024695'.

[Sat Dec  2 00:01:00 2023]
Job 115: working on tf=GATA2,tissue=Cord-blood
Reason: Input files updated by another job: data/homer_files/GATA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA2 --tissue Cord-blood --predicted_motif_file data/homer_files/GATA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA2_Cord-blood --predictors_file data/predictor_files/GATA2_Cord-blood.predictors.txt --ground_truth_file data/predictor_files/GATA2_Cord-blood.ground_truth.txt --info_file data/predictor_files/GATA2_Cord-blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 115 with external jobid 'Submitted batch job 11024696'.
[Sat Dec  2 00:01:00 2023]
Finished job 67.
30 of 1394 steps (2%) done
Select jobs to execute...

[Sat Dec  2 00:01:00 2023]
Job 258: working on tf=SP1,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/homer_files/SP1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SP1 --tissue Embryonic-Kidney --predicted_motif_file data/homer_files/SP1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SP1_Embryonic-Kidney --predictors_file data/predictor_files/SP1_Embryonic-Kidney.predictors.txt --ground_truth_file data/predictor_files/SP1_Embryonic-Kidney.ground_truth.txt --info_file data/predictor_files/SP1_Embryonic-Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 258 with external jobid 'Submitted batch job 11024697'.

[Sat Dec  2 00:01:00 2023]
Job 218: working on tf=SP1,tissue=Blood
Reason: Input files updated by another job: data/homer_files/SP1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SP1 --tissue Blood --predicted_motif_file data/homer_files/SP1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SP1_Blood --predictors_file data/predictor_files/SP1_Blood.predictors.txt --ground_truth_file data/predictor_files/SP1_Blood.ground_truth.txt --info_file data/predictor_files/SP1_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 218 with external jobid 'Submitted batch job 11024698'.

[Sat Dec  2 00:01:00 2023]
Job 122: working on tf=SP1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/SP1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SP1 --tissue Colon --predicted_motif_file data/homer_files/SP1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SP1_Colon --predictors_file data/predictor_files/SP1_Colon.predictors.txt --ground_truth_file data/predictor_files/SP1_Colon.ground_truth.txt --info_file data/predictor_files/SP1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 122 with external jobid 'Submitted batch job 11024699'.

[Sat Dec  2 00:01:01 2023]
Job 206: working on tf=SP1,tissue=Lung
Reason: Input files updated by another job: data/homer_files/SP1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SP1 --tissue Lung --predicted_motif_file data/homer_files/SP1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SP1_Lung --predictors_file data/predictor_files/SP1_Lung.predictors.txt --ground_truth_file data/predictor_files/SP1_Lung.ground_truth.txt --info_file data/predictor_files/SP1_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 206 with external jobid 'Submitted batch job 11024700'.

[Sat Dec  2 00:01:01 2023]
Job 220: working on tf=SP1,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/SP1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SP1 --tissue Embryo --predicted_motif_file data/homer_files/SP1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SP1_Embryo --predictors_file data/predictor_files/SP1_Embryo.predictors.txt --ground_truth_file data/predictor_files/SP1_Embryo.ground_truth.txt --info_file data/predictor_files/SP1_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 220 with external jobid 'Submitted batch job 11024701'.

[Sat Dec  2 00:01:01 2023]
Job 256: working on tf=SP1,tissue=Breast
Reason: Input files updated by another job: data/homer_files/SP1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SP1 --tissue Breast --predicted_motif_file data/homer_files/SP1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SP1_Breast --predictors_file data/predictor_files/SP1_Breast.predictors.txt --ground_truth_file data/predictor_files/SP1_Breast.ground_truth.txt --info_file data/predictor_files/SP1_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 256 with external jobid 'Submitted batch job 11024702'.

[Sat Dec  2 00:01:01 2023]
Job 223: working on tf=SP1,tissue=Liver
Reason: Input files updated by another job: data/homer_files/SP1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SP1 --tissue Liver --predicted_motif_file data/homer_files/SP1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SP1_Liver --predictors_file data/predictor_files/SP1_Liver.predictors.txt --ground_truth_file data/predictor_files/SP1_Liver.ground_truth.txt --info_file data/predictor_files/SP1_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 223 with external jobid 'Submitted batch job 11024703'.

[Sat Dec  2 00:01:01 2023]
Job 227: working on tf=SP1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/SP1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SP1 --tissue Bone-Marrow --predicted_motif_file data/homer_files/SP1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SP1_Bone-Marrow --predictors_file data/predictor_files/SP1_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/SP1_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/SP1_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 227 with external jobid 'Submitted batch job 11024704'.
[Sat Dec  2 00:01:01 2023]
Finished job 79.
31 of 1394 steps (2%) done
[Sat Dec  2 00:01:02 2023]
Finished job 66.
32 of 1394 steps (2%) done
[Sat Dec  2 00:01:03 2023]
Finished job 60.
33 of 1394 steps (2%) done
Select jobs to execute...

[Sat Dec  2 00:01:03 2023]
Job 159: working on tf=GATA4,tissue=Colon
Reason: Input files updated by another job: data/homer_files/GATA4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA4 --tissue Colon --predicted_motif_file data/homer_files/GATA4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA4_Colon --predictors_file data/predictor_files/GATA4_Colon.predictors.txt --ground_truth_file data/predictor_files/GATA4_Colon.ground_truth.txt --info_file data/predictor_files/GATA4_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 159 with external jobid 'Submitted batch job 11024705'.

[Sat Dec  2 00:01:03 2023]
Job 243: working on tf=GATA4,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/GATA4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA4 --tissue Embryo --predicted_motif_file data/homer_files/GATA4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA4_Embryo --predictors_file data/predictor_files/GATA4_Embryo.predictors.txt --ground_truth_file data/predictor_files/GATA4_Embryo.ground_truth.txt --info_file data/predictor_files/GATA4_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 243 with external jobid 'Submitted batch job 11024706'.

[Sat Dec  2 00:01:03 2023]
Job 274: working on tf=GATA4,tissue=Skin
Reason: Input files updated by another job: data/homer_files/GATA4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA4 --tissue Skin --predicted_motif_file data/homer_files/GATA4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA4_Skin --predictors_file data/predictor_files/GATA4_Skin.predictors.txt --ground_truth_file data/predictor_files/GATA4_Skin.ground_truth.txt --info_file data/predictor_files/GATA4_Skin.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 274 with external jobid 'Submitted batch job 11024707'.

[Sat Dec  2 00:01:04 2023]
Job 277: working on tf=GATA4,tissue=Lung
Reason: Input files updated by another job: data/homer_files/GATA4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA4 --tissue Lung --predicted_motif_file data/homer_files/GATA4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA4_Lung --predictors_file data/predictor_files/GATA4_Lung.predictors.txt --ground_truth_file data/predictor_files/GATA4_Lung.ground_truth.txt --info_file data/predictor_files/GATA4_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 277 with external jobid 'Submitted batch job 11024708'.

[Sat Dec  2 00:01:04 2023]
Job 237: working on tf=GATA4,tissue=Stomach
Reason: Input files updated by another job: data/homer_files/GATA4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA4 --tissue Stomach --predicted_motif_file data/homer_files/GATA4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA4_Stomach --predictors_file data/predictor_files/GATA4_Stomach.predictors.txt --ground_truth_file data/predictor_files/GATA4_Stomach.ground_truth.txt --info_file data/predictor_files/GATA4_Stomach.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 237 with external jobid 'Submitted batch job 11024709'.

[Sat Dec  2 00:01:04 2023]
Job 255: working on tf=GATA4,tissue=Liver
Reason: Input files updated by another job: data/homer_files/GATA4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA4 --tissue Liver --predicted_motif_file data/homer_files/GATA4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA4_Liver --predictors_file data/predictor_files/GATA4_Liver.predictors.txt --ground_truth_file data/predictor_files/GATA4_Liver.ground_truth.txt --info_file data/predictor_files/GATA4_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 11024710'.
[Sat Dec  2 00:01:04 2023]
Finished job 71.
34 of 1394 steps (2%) done
[Sat Dec  2 00:01:05 2023]
Finished job 56.
35 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:05 2023]
Job 229: working on tf=FOSL2,tissue=Breast
Reason: Input files updated by another job: data/homer_files/FOSL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOSL2 --tissue Breast --predicted_motif_file data/homer_files/FOSL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOSL2_Breast --predictors_file data/predictor_files/FOSL2_Breast.predictors.txt --ground_truth_file data/predictor_files/FOSL2_Breast.ground_truth.txt --info_file data/predictor_files/FOSL2_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 229 with external jobid 'Submitted batch job 11024711'.

[Sat Dec  2 00:01:05 2023]
Job 234: working on tf=FOSL2,tissue=Brain
Reason: Input files updated by another job: data/homer_files/FOSL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOSL2 --tissue Brain --predicted_motif_file data/homer_files/FOSL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOSL2_Brain --predictors_file data/predictor_files/FOSL2_Brain.predictors.txt --ground_truth_file data/predictor_files/FOSL2_Brain.ground_truth.txt --info_file data/predictor_files/FOSL2_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 234 with external jobid 'Submitted batch job 11024712'.

[Sat Dec  2 00:01:05 2023]
Job 210: working on tf=FOSL2,tissue=Lung
Reason: Input files updated by another job: data/homer_files/FOSL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOSL2 --tissue Lung --predicted_motif_file data/homer_files/FOSL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOSL2_Lung --predictors_file data/predictor_files/FOSL2_Lung.predictors.txt --ground_truth_file data/predictor_files/FOSL2_Lung.ground_truth.txt --info_file data/predictor_files/FOSL2_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 210 with external jobid 'Submitted batch job 11024713'.

[Sat Dec  2 00:01:06 2023]
Job 224: working on tf=FOSL2,tissue=Liver
Reason: Input files updated by another job: data/homer_files/FOSL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOSL2 --tissue Liver --predicted_motif_file data/homer_files/FOSL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOSL2_Liver --predictors_file data/predictor_files/FOSL2_Liver.predictors.txt --ground_truth_file data/predictor_files/FOSL2_Liver.ground_truth.txt --info_file data/predictor_files/FOSL2_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 224 with external jobid 'Submitted batch job 11024714'.

[Sat Dec  2 00:01:06 2023]
Job 247: working on tf=FOSL2,tissue=Endometrium
Reason: Input files updated by another job: data/homer_files/FOSL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOSL2 --tissue Endometrium --predicted_motif_file data/homer_files/FOSL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOSL2_Endometrium --predictors_file data/predictor_files/FOSL2_Endometrium.predictors.txt --ground_truth_file data/predictor_files/FOSL2_Endometrium.ground_truth.txt --info_file data/predictor_files/FOSL2_Endometrium.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 247 with external jobid 'Submitted batch job 11024715'.
[Sat Dec  2 00:01:06 2023]
Finished job 34.
36 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:06 2023]
Job 63: working on tf=RUNX1 data/homer_files/RUNX1/scanMotifsGenomeWide_runx1.txt
Reason: Input files updated by another job: data/homer_files/RUNX1/scanMotifsGenomeWide_runx1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 63 with external jobid 'Submitted batch job 11024716'.
[Sat Dec  2 00:01:08 2023]
Finished job 48.
37 of 1394 steps (3%) done
[Sat Dec  2 00:01:11 2023]
Finished job 49.
38 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:11 2023]
Job 74: working on tf=JUN data/homer_files/JUN/scanMotifsGenomeWide_jun-cre.txt data/homer_files/JUN/scanMotifsGenomeWide_jun-ap1.txt
Reason: Input files updated by another job: data/homer_files/JUN/scanMotifsGenomeWide_jun-cre.txt, data/homer_files/JUN/scanMotifsGenomeWide_jun-ap1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 74 with external jobid 'Submitted batch job 11024717'.
[Sat Dec  2 00:01:12 2023]
Finished job 18.
39 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:12 2023]
Job 72: working on tf=AR data/homer_files/AR/scanMotifsGenomeWide_ar-half.txt
Reason: Input files updated by another job: data/homer_files/AR/scanMotifsGenomeWide_ar-half.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 72 with external jobid 'Submitted batch job 11024723'.
[Sat Dec  2 00:01:14 2023]
Finished job 5.
40 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:14 2023]
Job 90: working on tf=FOXA1 data/homer_files/FOXA1/scanMotifsGenomeWide_foxa1.mcf7.txt data/homer_files/FOXA1/scanMotifsGenomeWide_foxa1.lncap.txt
Reason: Input files updated by another job: data/homer_files/FOXA1/scanMotifsGenomeWide_foxa1.mcf7.txt, data/homer_files/FOXA1/scanMotifsGenomeWide_foxa1.lncap.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 90 with external jobid 'Submitted batch job 11024730'.
[Sat Dec  2 00:01:16 2023]
Finished job 10.
41 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:16 2023]
Job 88: working on tf=SNAI2 data/homer_files/SNAI2/scanMotifsGenomeWide_snai2.txt
Reason: Input files updated by another job: data/homer_files/SNAI2/scanMotifsGenomeWide_snai2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 88 with external jobid 'Submitted batch job 11024731'.
[Sat Dec  2 00:01:16 2023]
Finished job 22.
42 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:16 2023]
Job 75: working on tf=FOXA2 data/homer_files/FOXA2/scanMotifsGenomeWide_foxa2.txt
Reason: Input files updated by another job: data/homer_files/FOXA2/scanMotifsGenomeWide_foxa2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 75 with external jobid 'Submitted batch job 11024732'.
[Sat Dec  2 00:01:18 2023]
Finished job 36.
43 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:18 2023]
Job 84: working on tf=MYC data/homer_files/MYC/scanMotifsGenomeWide_p53-myc.txt
Reason: Input files updated by another job: data/homer_files/MYC/scanMotifsGenomeWide_p53-myc.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 84 with external jobid 'Submitted batch job 11024733'.
[Sat Dec  2 00:01:26 2023]
Finished job 38.
44 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:26 2023]
Job 77: working on tf=ASCL1 data/homer_files/ASCL1/scanMotifsGenomeWide_ascl1.txt
Reason: Input files updated by another job: data/homer_files/ASCL1/scanMotifsGenomeWide_ascl1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 77 with external jobid 'Submitted batch job 11024734'.
[Sat Dec  2 00:01:27 2023]
Finished job 15.
45 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:27 2023]
Job 87: working on tf=PPARG data/homer_files/PPARG/scanMotifsGenomeWide_pparg.txt
Reason: Input files updated by another job: data/homer_files/PPARG/scanMotifsGenomeWide_pparg.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 87 with external jobid 'Submitted batch job 11024735'.
[Sat Dec  2 00:01:28 2023]
Finished job 32.
46 of 1394 steps (3%) done
[Sat Dec  2 00:01:30 2023]
Finished job 39.
47 of 1394 steps (3%) done
[Sat Dec  2 00:01:31 2023]
Finished job 14.
48 of 1394 steps (3%) done
Select jobs to execute...

[Sat Dec  2 00:01:31 2023]
Job 58: working on tf=YY1 data/homer_files/YY1/scanMotifsGenomeWide_yy1.txt
Reason: Input files updated by another job: data/homer_files/YY1/scanMotifsGenomeWide_yy1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 58 with external jobid 'Submitted batch job 11024736'.
[Sat Dec  2 00:01:32 2023]
Finished job 33.
49 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:32 2023]
Job 83: working on tf=STAT6 data/homer_files/STAT6/scanMotifsGenomeWide_stat6.txt data/homer_files/STAT6/scanMotifsGenomeWide_stat6.2.txt
Reason: Input files updated by another job: data/homer_files/STAT6/scanMotifsGenomeWide_stat6.2.txt, data/homer_files/STAT6/scanMotifsGenomeWide_stat6.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 83 with external jobid 'Submitted batch job 11024737'.
[Sat Dec  2 00:01:37 2023]
Finished job 61.
50 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:37 2023]
Job 132: working on tf=FOXM1,tissue=Bone
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Bone --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Bone --predictors_file data/predictor_files/FOXM1_Bone.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Bone.ground_truth.txt --info_file data/predictor_files/FOXM1_Bone.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 132 with external jobid 'Submitted batch job 11024738'.

[Sat Dec  2 00:01:37 2023]
Job 246: working on tf=FOXM1,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Embryonic-Kidney --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Embryonic-Kidney --predictors_file data/predictor_files/FOXM1_Embryonic-Kidney.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Embryonic-Kidney.ground_truth.txt --info_file data/predictor_files/FOXM1_Embryonic-Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 11024739'.

[Sat Dec  2 00:01:38 2023]
Job 176: working on tf=FOXM1,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Cervix --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Cervix --predictors_file data/predictor_files/FOXM1_Cervix.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Cervix.ground_truth.txt --info_file data/predictor_files/FOXM1_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 176 with external jobid 'Submitted batch job 11024740'.

[Sat Dec  2 00:01:38 2023]
Job 162: working on tf=FOXM1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Colon --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Colon --predictors_file data/predictor_files/FOXM1_Colon.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Colon.ground_truth.txt --info_file data/predictor_files/FOXM1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 162 with external jobid 'Submitted batch job 11024741'.

[Sat Dec  2 00:01:38 2023]
Job 138: working on tf=FOXM1,tissue=Breast
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Breast --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Breast --predictors_file data/predictor_files/FOXM1_Breast.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Breast.ground_truth.txt --info_file data/predictor_files/FOXM1_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 138 with external jobid 'Submitted batch job 11024742'.

[Sat Dec  2 00:01:38 2023]
Job 249: working on tf=FOXM1,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Mammary-Gland --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Mammary-Gland --predictors_file data/predictor_files/FOXM1_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/FOXM1_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 11024743'.

[Sat Dec  2 00:01:38 2023]
Job 217: working on tf=FOXM1,tissue=Blood
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Blood --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Blood --predictors_file data/predictor_files/FOXM1_Blood.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Blood.ground_truth.txt --info_file data/predictor_files/FOXM1_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 217 with external jobid 'Submitted batch job 11024744'.

[Sat Dec  2 00:01:38 2023]
Job 235: working on tf=FOXM1,tissue=Brain
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Brain --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Brain --predictors_file data/predictor_files/FOXM1_Brain.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Brain.ground_truth.txt --info_file data/predictor_files/FOXM1_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 235 with external jobid 'Submitted batch job 11024745'.

[Sat Dec  2 00:01:38 2023]
Job 213: working on tf=FOXM1,tissue=Endometrium
Reason: Input files updated by another job: data/homer_files/FOXM1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXM1 --tissue Endometrium --predicted_motif_file data/homer_files/FOXM1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXM1_Endometrium --predictors_file data/predictor_files/FOXM1_Endometrium.predictors.txt --ground_truth_file data/predictor_files/FOXM1_Endometrium.ground_truth.txt --info_file data/predictor_files/FOXM1_Endometrium.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 213 with external jobid 'Submitted batch job 11024746'.
[Sat Dec  2 00:01:47 2023]
Finished job 124.
51 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:47 2023]
Job 310: working on tf=ETS1,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/ETS1_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ETS1 --tissue Prostate --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/ETS1_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ETS1_Prostate.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 310 with external jobid 'Submitted batch job 11024747'.
[Sat Dec  2 00:01:48 2023]
Finished job 208.
52 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:48 2023]
Job 394: working on tf=ETS1,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/ETS1_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ETS1 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/ETS1_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ETS1_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 394 with external jobid 'Submitted batch job 11024752'.
[Sat Dec  2 00:01:49 2023]
Finished job 226.
53 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:49 2023]
Job 412: working on tf=ETS1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/ETS1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ETS1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/ETS1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ETS1_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 412 with external jobid 'Submitted batch job 11024753'.
[Sat Dec  2 00:01:50 2023]
Finished job 151.
54 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:50 2023]
Job 337: working on tf=ETS1,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/ETS1_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ETS1 --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/ETS1_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ETS1_Umbilical-Vein.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 337 with external jobid 'Submitted batch job 11024754'.
[Sat Dec  2 00:01:51 2023]
Finished job 239.
55 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:51 2023]
Job 425: working on tf=ETS1,tissue=Pancreas
Reason: Input files updated by another job: data/predictor_files/ETS1_Pancreas.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ETS1 --tissue Pancreas --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/ETS1_Pancreas.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ETS1_Pancreas.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 425 with external jobid 'Submitted batch job 11024755'.
[Sat Dec  2 00:01:52 2023]
Finished job 101.
56 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:52 2023]
Job 287: working on tf=ETS1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/ETS1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ETS1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/ETS1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ETS1_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 287 with external jobid 'Submitted batch job 11024756'.
[Sat Dec  2 00:01:54 2023]
Finished job 260.
57 of 1394 steps (4%) done
[Sat Dec  2 00:01:55 2023]
Finished job 96.
58 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:55 2023]
Job 446: working on tf=E2F1,tissue=Umbilical-Cord
Reason: Input files updated by another job: data/predictor_files/E2F1_Umbilical-Cord.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor E2F1 --tissue Umbilical-Cord --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/E2F1_Umbilical-Cord.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_E2F1_Umbilical-Cord.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 446 with external jobid 'Submitted batch job 11024757'.

[Sat Dec  2 00:01:55 2023]
Job 282: working on tf=E2F1,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/E2F1_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor E2F1 --tissue Cervix --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/E2F1_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_E2F1_Cervix.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 282 with external jobid 'Submitted batch job 11024758'.
[Sat Dec  2 00:01:55 2023]
Finished job 250.
59 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:55 2023]
Job 436: working on tf=E2F1,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/E2F1_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor E2F1 --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/E2F1_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_E2F1_Mammary-Gland.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 436 with external jobid 'Submitted batch job 11024759'.
[Sat Dec  2 00:01:57 2023]
Finished job 265.
60 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:57 2023]
Job 451: working on tf=E2F1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/E2F1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor E2F1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/E2F1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_E2F1_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 451 with external jobid 'Submitted batch job 11024760'.
[Sat Dec  2 00:01:57 2023]
Finished job 107.
61 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:57 2023]
Job 293: working on tf=E2F1,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/E2F1_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor E2F1 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/E2F1_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_E2F1_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 293 with external jobid 'Submitted batch job 11024761'.
[Sat Dec  2 00:01:58 2023]
Finished job 179.
62 of 1394 steps (4%) done
Select jobs to execute...

[Sat Dec  2 00:01:58 2023]
Job 365: working on tf=E2F1,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/E2F1_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor E2F1 --tissue Prostate --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/E2F1_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_E2F1_Prostate.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 365 with external jobid 'Submitted batch job 11024762'.
[Sat Dec  2 00:01:59 2023]
Finished job 165.
63 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:01:59 2023]
Job 351: working on tf=E2F1,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/E2F1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor E2F1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/E2F1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 351 with external jobid 'Submitted batch job 11024763'.
[Sat Dec  2 00:02:00 2023]
Finished job 167.
64 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:00 2023]
Job 353: working on tf=E2F1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/E2F1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor E2F1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/E2F1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_E2F1_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 353 with external jobid 'Submitted batch job 11024764'.
[Sat Dec  2 00:02:01 2023]
Finished job 128.
65 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:01 2023]
Job 314: working on tf=GATA2,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/GATA2_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA2 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA2_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA2_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 314 with external jobid 'Submitted batch job 11024765'.
[Sat Dec  2 00:02:02 2023]
Finished job 102.
66 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:02 2023]
Job 288: working on tf=GATA2,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/GATA2_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA2 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA2_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA2_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 288 with external jobid 'Submitted batch job 11024766'.
[Sat Dec  2 00:02:03 2023]
Finished job 158.
67 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:03 2023]
Job 344: working on tf=GATA2,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/GATA2_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA2 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA2_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA2_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 344 with external jobid 'Submitted batch job 11024767'.
[Sat Dec  2 00:02:04 2023]
Finished job 245.
68 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:04 2023]
Job 431: working on tf=GATA2,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/GATA2_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA2 --tissue Prostate --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA2_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA2_Prostate.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 431 with external jobid 'Submitted batch job 11024768'.
[Sat Dec  2 00:02:05 2023]
Finished job 99.
69 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:05 2023]
Job 285: working on tf=GATA2,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/GATA2_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA2 --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA2_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA2_Umbilical-Vein.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 285 with external jobid 'Submitted batch job 11024769'.
[Sat Dec  2 00:02:06 2023]
Finished job 115.
70 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:06 2023]
Job 301: working on tf=GATA2,tissue=Cord-blood
Reason: Input files updated by another job: data/predictor_files/GATA2_Cord-blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA2 --tissue Cord-blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA2_Cord-blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA2_Cord-blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 301 with external jobid 'Submitted batch job 11024770'.
[Sat Dec  2 00:02:08 2023]
Finished job 258.
71 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:08 2023]
Job 444: working on tf=SP1,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/predictor_files/SP1_Embryonic-Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SP1 --tissue Embryonic-Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SP1_Embryonic-Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SP1_Embryonic-Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 444 with external jobid 'Submitted batch job 11024771'.
[Sat Dec  2 00:02:09 2023]
Finished job 218.
72 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:09 2023]
Job 404: working on tf=SP1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/SP1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SP1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SP1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SP1_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 404 with external jobid 'Submitted batch job 11024772'.
[Sat Dec  2 00:02:09 2023]
Finished job 122.
73 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:09 2023]
Job 308: working on tf=SP1,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/SP1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SP1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SP1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SP1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 308 with external jobid 'Submitted batch job 11024773'.
[Sat Dec  2 00:02:10 2023]
Finished job 206.
74 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:10 2023]
Job 392: working on tf=SP1,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/SP1_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SP1 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SP1_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SP1_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 392 with external jobid 'Submitted batch job 11024774'.
[Sat Dec  2 00:02:11 2023]
Finished job 220.
75 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:11 2023]
Job 406: working on tf=SP1,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/SP1_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SP1 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SP1_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SP1_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 406 with external jobid 'Submitted batch job 11024775'.
[Sat Dec  2 00:02:12 2023]
Finished job 256.
76 of 1394 steps (5%) done
Select jobs to execute...

[Sat Dec  2 00:02:12 2023]
Job 442: working on tf=SP1,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/SP1_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SP1 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SP1_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SP1_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 442 with external jobid 'Submitted batch job 11024776'.
[Sat Dec  2 00:02:13 2023]
Finished job 223.
77 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:13 2023]
Job 409: working on tf=SP1,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/SP1_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SP1 --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SP1_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SP1_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 409 with external jobid 'Submitted batch job 11024777'.
[Sat Dec  2 00:02:15 2023]
Finished job 227.
78 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:15 2023]
Job 413: working on tf=SP1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/SP1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SP1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SP1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SP1_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 413 with external jobid 'Submitted batch job 11024778'.
[Sat Dec  2 00:02:15 2023]
Finished job 159.
79 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:15 2023]
Job 345: working on tf=GATA4,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/GATA4_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA4 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA4_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA4_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 345 with external jobid 'Submitted batch job 11024779'.
[Sat Dec  2 00:02:17 2023]
Finished job 243.
80 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:17 2023]
Job 429: working on tf=GATA4,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/GATA4_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA4 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA4_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA4_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 429 with external jobid 'Submitted batch job 11024780'.
[Sat Dec  2 00:02:17 2023]
Finished job 274.
81 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:17 2023]
Job 460: working on tf=GATA4,tissue=Skin
Reason: Input files updated by another job: data/predictor_files/GATA4_Skin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA4 --tissue Skin --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA4_Skin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA4_Skin.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 460 with external jobid 'Submitted batch job 11024781'.
[Sat Dec  2 00:02:18 2023]
Finished job 277.
82 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:18 2023]
Job 463: working on tf=GATA4,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/GATA4_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA4 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA4_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA4_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 463 with external jobid 'Submitted batch job 11024782'.
[Sat Dec  2 00:02:19 2023]
Finished job 237.
83 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:19 2023]
Job 423: working on tf=GATA4,tissue=Stomach
Reason: Input files updated by another job: data/predictor_files/GATA4_Stomach.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA4 --tissue Stomach --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA4_Stomach.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA4_Stomach.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 423 with external jobid 'Submitted batch job 11024783'.
[Sat Dec  2 00:02:20 2023]
Finished job 255.
84 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:20 2023]
Job 441: working on tf=GATA4,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/GATA4_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA4 --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA4_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA4_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 441 with external jobid 'Submitted batch job 11024784'.
[Sat Dec  2 00:02:21 2023]
Finished job 229.
85 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:21 2023]
Job 415: working on tf=FOSL2,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/FOSL2_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOSL2 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOSL2_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 415 with external jobid 'Submitted batch job 11024785'.
[Sat Dec  2 00:02:22 2023]
Finished job 234.
86 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:22 2023]
Job 420: working on tf=FOSL2,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/FOSL2_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOSL2 --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOSL2_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 420 with external jobid 'Submitted batch job 11024786'.
[Sat Dec  2 00:02:23 2023]
Finished job 210.
87 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:23 2023]
Job 396: working on tf=FOSL2,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/FOSL2_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOSL2 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOSL2_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 396 with external jobid 'Submitted batch job 11024787'.
[Sat Dec  2 00:02:25 2023]
Finished job 224.
88 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:25 2023]
Job 410: working on tf=FOSL2,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/FOSL2_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOSL2 --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOSL2_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 410 with external jobid 'Submitted batch job 11024788'.
[Sat Dec  2 00:02:25 2023]
Finished job 247.
89 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:25 2023]
Job 433: working on tf=FOSL2,tissue=Endometrium
Reason: Input files updated by another job: data/predictor_files/FOSL2_Endometrium.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOSL2 --tissue Endometrium --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOSL2_Endometrium.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Endometrium.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 433 with external jobid 'Submitted batch job 11024789'.
[Sat Dec  2 00:02:26 2023]
Finished job 63.
90 of 1394 steps (6%) done
Select jobs to execute...

[Sat Dec  2 00:02:26 2023]
Job 103: working on tf=RUNX1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Bone-Marrow --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Bone-Marrow --predictors_file data/predictor_files/RUNX1_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/RUNX1_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 103 with external jobid 'Submitted batch job 11024790'.

[Sat Dec  2 00:02:27 2023]
Job 118: working on tf=RUNX1,tissue=Cord-blood
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Cord-blood --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Cord-blood --predictors_file data/predictor_files/RUNX1_Cord-blood.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Cord-blood.ground_truth.txt --info_file data/predictor_files/RUNX1_Cord-blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 118 with external jobid 'Submitted batch job 11024791'.

[Sat Dec  2 00:02:27 2023]
Job 272: working on tf=RUNX1,tissue=Kidney
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Kidney --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Kidney --predictors_file data/predictor_files/RUNX1_Kidney.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Kidney.ground_truth.txt --info_file data/predictor_files/RUNX1_Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 272 with external jobid 'Submitted batch job 11024792'.

[Sat Dec  2 00:02:27 2023]
Job 174: working on tf=RUNX1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Colon --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Colon --predictors_file data/predictor_files/RUNX1_Colon.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Colon.ground_truth.txt --info_file data/predictor_files/RUNX1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 174 with external jobid 'Submitted batch job 11024793'.

[Sat Dec  2 00:02:27 2023]
Job 92: working on tf=RUNX1,tissue=Blood
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Blood --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Blood --predictors_file data/predictor_files/RUNX1_Blood.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Blood.ground_truth.txt --info_file data/predictor_files/RUNX1_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 92 with external jobid 'Submitted batch job 11024794'.

[Sat Dec  2 00:02:27 2023]
Job 262: working on tf=RUNX1,tissue=Fetal-Liver
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Fetal-Liver --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Fetal-Liver --predictors_file data/predictor_files/RUNX1_Fetal-Liver.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Fetal-Liver.ground_truth.txt --info_file data/predictor_files/RUNX1_Fetal-Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 262 with external jobid 'Submitted batch job 11024795'.

[Sat Dec  2 00:02:27 2023]
Job 266: working on tf=RUNX1,tissue=Breast
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Breast --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Breast --predictors_file data/predictor_files/RUNX1_Breast.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Breast.ground_truth.txt --info_file data/predictor_files/RUNX1_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 266 with external jobid 'Submitted batch job 11024796'.

[Sat Dec  2 00:02:27 2023]
Job 240: working on tf=RUNX1,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Prostate --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Prostate --predictors_file data/predictor_files/RUNX1_Prostate.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Prostate.ground_truth.txt --info_file data/predictor_files/RUNX1_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 240 with external jobid 'Submitted batch job 11024797'.

[Sat Dec  2 00:02:27 2023]
Job 251: working on tf=RUNX1,tissue=Pleura
Reason: Input files updated by another job: data/homer_files/RUNX1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor RUNX1 --tissue Pleura --predicted_motif_file data/homer_files/RUNX1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/RUNX1_Pleura --predictors_file data/predictor_files/RUNX1_Pleura.predictors.txt --ground_truth_file data/predictor_files/RUNX1_Pleura.ground_truth.txt --info_file data/predictor_files/RUNX1_Pleura.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 251 with external jobid 'Submitted batch job 11024798'.
[Sat Dec  2 00:02:28 2023]
Finished job 74.
91 of 1394 steps (7%) done
[Sat Dec  2 00:02:28 2023]
Finished job 72.
92 of 1394 steps (7%) done
[Sat Dec  2 00:02:29 2023]
Finished job 90.
93 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:29 2023]
Job 108: working on tf=FOXA1,tissue=Breast
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Breast --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Breast --predictors_file data/predictor_files/FOXA1_Breast.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Breast.ground_truth.txt --info_file data/predictor_files/FOXA1_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 108 with external jobid 'Submitted batch job 11024799'.

[Sat Dec  2 00:02:30 2023]
Job 110: working on tf=FOXA1,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Mammary-Gland --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Mammary-Gland --predictors_file data/predictor_files/FOXA1_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/FOXA1_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 110 with external jobid 'Submitted batch job 11024800'.

[Sat Dec  2 00:02:30 2023]
Job 264: working on tf=FOXA1,tissue=endometrioid-adenocarcinoma
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue endometrioid-adenocarcinoma --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_endometrioid-adenocarcinoma --predictors_file data/predictor_files/FOXA1_endometrioid-adenocarcinoma.predictors.txt --ground_truth_file data/predictor_files/FOXA1_endometrioid-adenocarcinoma.ground_truth.txt --info_file data/predictor_files/FOXA1_endometrioid-adenocarcinoma.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 264 with external jobid 'Submitted batch job 11024801'.

[Sat Dec  2 00:02:30 2023]
Job 142: working on tf=FOXA1,tissue=Lung
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Lung --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Lung --predictors_file data/predictor_files/FOXA1_Lung.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Lung.ground_truth.txt --info_file data/predictor_files/FOXA1_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 142 with external jobid 'Submitted batch job 11024802'.

[Sat Dec  2 00:02:30 2023]
Job 156: working on tf=FOXA1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Colon --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Colon --predictors_file data/predictor_files/FOXA1_Colon.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Colon.ground_truth.txt --info_file data/predictor_files/FOXA1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 156 with external jobid 'Submitted batch job 11024803'.

[Sat Dec  2 00:02:30 2023]
Job 105: working on tf=FOXA1,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Prostate --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Prostate --predictors_file data/predictor_files/FOXA1_Prostate.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Prostate.ground_truth.txt --info_file data/predictor_files/FOXA1_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 105 with external jobid 'Submitted batch job 11024804'.

[Sat Dec  2 00:02:30 2023]
Job 261: working on tf=FOXA1,tissue=Pancreatic-ductal
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Pancreatic-ductal --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Pancreatic-ductal --predictors_file data/predictor_files/FOXA1_Pancreatic-ductal.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Pancreatic-ductal.ground_truth.txt --info_file data/predictor_files/FOXA1_Pancreatic-ductal.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 261 with external jobid 'Submitted batch job 11024805'.

[Sat Dec  2 00:02:30 2023]
Job 125: working on tf=FOXA1,tissue=Liver
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Liver --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Liver --predictors_file data/predictor_files/FOXA1_Liver.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Liver.ground_truth.txt --info_file data/predictor_files/FOXA1_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 125 with external jobid 'Submitted batch job 11024806'.

[Sat Dec  2 00:02:30 2023]
Job 211: working on tf=FOXA1,tissue=Endometrium
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Endometrium --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Endometrium --predictors_file data/predictor_files/FOXA1_Endometrium.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Endometrium.ground_truth.txt --info_file data/predictor_files/FOXA1_Endometrium.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 211 with external jobid 'Submitted batch job 11024807'.

[Sat Dec  2 00:02:31 2023]
Job 241: working on tf=FOXA1,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/FOXA1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA1 --tissue Embryo --predicted_motif_file data/homer_files/FOXA1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA1_Embryo --predictors_file data/predictor_files/FOXA1_Embryo.predictors.txt --ground_truth_file data/predictor_files/FOXA1_Embryo.ground_truth.txt --info_file data/predictor_files/FOXA1_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 241 with external jobid 'Submitted batch job 11024808'.
[Sat Dec  2 00:02:31 2023]
Finished job 88.
94 of 1394 steps (7%) done
[Sat Dec  2 00:02:31 2023]
Finished job 75.
95 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:31 2023]
Job 271: working on tf=FOXA2,tissue=Endoderm
Reason: Input files updated by another job: data/homer_files/FOXA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA2 --tissue Endoderm --predicted_motif_file data/homer_files/FOXA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA2_Endoderm --predictors_file data/predictor_files/FOXA2_Endoderm.predictors.txt --ground_truth_file data/predictor_files/FOXA2_Endoderm.ground_truth.txt --info_file data/predictor_files/FOXA2_Endoderm.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 271 with external jobid 'Submitted batch job 11024809'.

[Sat Dec  2 00:02:31 2023]
Job 150: working on tf=FOXA2,tissue=Lung
Reason: Input files updated by another job: data/homer_files/FOXA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA2 --tissue Lung --predicted_motif_file data/homer_files/FOXA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA2_Lung --predictors_file data/predictor_files/FOXA2_Lung.predictors.txt --ground_truth_file data/predictor_files/FOXA2_Lung.ground_truth.txt --info_file data/predictor_files/FOXA2_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 150 with external jobid 'Submitted batch job 11024810'.

[Sat Dec  2 00:02:32 2023]
Job 114: working on tf=FOXA2,tissue=Liver
Reason: Input files updated by another job: data/homer_files/FOXA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA2 --tissue Liver --predicted_motif_file data/homer_files/FOXA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA2_Liver --predictors_file data/predictor_files/FOXA2_Liver.predictors.txt --ground_truth_file data/predictor_files/FOXA2_Liver.ground_truth.txt --info_file data/predictor_files/FOXA2_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 114 with external jobid 'Submitted batch job 11024811'.

[Sat Dec  2 00:02:32 2023]
Job 242: working on tf=FOXA2,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/FOXA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA2 --tissue Embryo --predicted_motif_file data/homer_files/FOXA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA2_Embryo --predictors_file data/predictor_files/FOXA2_Embryo.predictors.txt --ground_truth_file data/predictor_files/FOXA2_Embryo.ground_truth.txt --info_file data/predictor_files/FOXA2_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 242 with external jobid 'Submitted batch job 11024812'.

[Sat Dec  2 00:02:32 2023]
Job 172: working on tf=FOXA2,tissue=Colon
Reason: Input files updated by another job: data/homer_files/FOXA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA2 --tissue Colon --predicted_motif_file data/homer_files/FOXA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA2_Colon --predictors_file data/predictor_files/FOXA2_Colon.predictors.txt --ground_truth_file data/predictor_files/FOXA2_Colon.ground_truth.txt --info_file data/predictor_files/FOXA2_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 172 with external jobid 'Submitted batch job 11024813'.

[Sat Dec  2 00:02:32 2023]
Job 269: working on tf=FOXA2,tissue=Skin
Reason: Input files updated by another job: data/homer_files/FOXA2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXA2 --tissue Skin --predicted_motif_file data/homer_files/FOXA2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXA2_Skin --predictors_file data/predictor_files/FOXA2_Skin.predictors.txt --ground_truth_file data/predictor_files/FOXA2_Skin.ground_truth.txt --info_file data/predictor_files/FOXA2_Skin.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 269 with external jobid 'Submitted batch job 11024814'.
[Sat Dec  2 00:02:32 2023]
Finished job 84.
96 of 1394 steps (7%) done
[Sat Dec  2 00:02:33 2023]
Finished job 77.
97 of 1394 steps (7%) done
[Sat Dec  2 00:02:34 2023]
Finished job 87.
98 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:34 2023]
Job 123: working on tf=PPARG,tissue=Blood
Reason: Input files updated by another job: data/homer_files/PPARG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor PPARG --tissue Blood --predicted_motif_file data/homer_files/PPARG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/PPARG_Blood --predictors_file data/predictor_files/PPARG_Blood.predictors.txt --ground_truth_file data/predictor_files/PPARG_Blood.ground_truth.txt --info_file data/predictor_files/PPARG_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 123 with external jobid 'Submitted batch job 11024815'.

[Sat Dec  2 00:02:35 2023]
Job 173: working on tf=PPARG,tissue=Colon
Reason: Input files updated by another job: data/homer_files/PPARG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor PPARG --tissue Colon --predicted_motif_file data/homer_files/PPARG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/PPARG_Colon --predictors_file data/predictor_files/PPARG_Colon.predictors.txt --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --info_file data/predictor_files/PPARG_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 173 with external jobid 'Submitted batch job 11024816'.

[Sat Dec  2 00:02:35 2023]
Job 238: working on tf=PPARG,tissue=Lung
Reason: Input files updated by another job: data/homer_files/PPARG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor PPARG --tissue Lung --predicted_motif_file data/homer_files/PPARG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/PPARG_Lung --predictors_file data/predictor_files/PPARG_Lung.predictors.txt --ground_truth_file data/predictor_files/PPARG_Lung.ground_truth.txt --info_file data/predictor_files/PPARG_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 238 with external jobid 'Submitted batch job 11024817'.

[Sat Dec  2 00:02:35 2023]
Job 117: working on tf=PPARG,tissue=Adipose
Reason: Input files updated by another job: data/homer_files/PPARG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor PPARG --tissue Adipose --predicted_motif_file data/homer_files/PPARG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/PPARG_Adipose --predictors_file data/predictor_files/PPARG_Adipose.predictors.txt --ground_truth_file data/predictor_files/PPARG_Adipose.ground_truth.txt --info_file data/predictor_files/PPARG_Adipose.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 117 with external jobid 'Submitted batch job 11024818'.
[Sat Dec  2 00:02:35 2023]
Finished job 58.
99 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:35 2023]
Job 131: working on tf=YY1,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Cervix --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Cervix --predictors_file data/predictor_files/YY1_Cervix.predictors.txt --ground_truth_file data/predictor_files/YY1_Cervix.ground_truth.txt --info_file data/predictor_files/YY1_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 131 with external jobid 'Submitted batch job 11024819'.

[Sat Dec  2 00:02:38 2023]
Job 216: working on tf=YY1,tissue=Endometrium
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Endometrium --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Endometrium --predictors_file data/predictor_files/YY1_Endometrium.predictors.txt --ground_truth_file data/predictor_files/YY1_Endometrium.ground_truth.txt --info_file data/predictor_files/YY1_Endometrium.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 216 with external jobid 'Submitted batch job 11024820'.

[Sat Dec  2 00:02:38 2023]
Job 222: working on tf=YY1,tissue=Liver
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Liver --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Liver --predictors_file data/predictor_files/YY1_Liver.predictors.txt --ground_truth_file data/predictor_files/YY1_Liver.ground_truth.txt --info_file data/predictor_files/YY1_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 222 with external jobid 'Submitted batch job 11024821'.

[Sat Dec  2 00:02:38 2023]
Job 144: working on tf=YY1,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Embryo --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Embryo --predictors_file data/predictor_files/YY1_Embryo.predictors.txt --ground_truth_file data/predictor_files/YY1_Embryo.ground_truth.txt --info_file data/predictor_files/YY1_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 144 with external jobid 'Submitted batch job 11024822'.

[Sat Dec  2 00:02:38 2023]
Job 199: working on tf=YY1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Bone-Marrow --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Bone-Marrow --predictors_file data/predictor_files/YY1_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/YY1_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/YY1_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 199 with external jobid 'Submitted batch job 11024823'.
[Sat Dec  2 00:02:38 2023]
Finished job 83.
100 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:38 2023]
Job 233: working on tf=YY1,tissue=Brain
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Brain --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Brain --predictors_file data/predictor_files/YY1_Brain.predictors.txt --ground_truth_file data/predictor_files/YY1_Brain.ground_truth.txt --info_file data/predictor_files/YY1_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 233 with external jobid 'Submitted batch job 11024824'.
[Sat Dec  2 00:02:40 2023]
Finished job 43.
101 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:40 2023]
Job 207: working on tf=YY1,tissue=Lung
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Lung --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Lung --predictors_file data/predictor_files/YY1_Lung.predictors.txt --ground_truth_file data/predictor_files/YY1_Lung.ground_truth.txt --info_file data/predictor_files/YY1_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 207 with external jobid 'Submitted batch job 11024825'.
[Sat Dec  2 00:02:44 2023]
Finished job 23.
102 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:44 2023]
Job 78: working on tf=STAT1 data/homer_files/STAT1/scanMotifsGenomeWide_stat1.txt
Reason: Input files updated by another job: data/homer_files/STAT1/scanMotifsGenomeWide_stat1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 78 with external jobid 'Submitted batch job 11024826'.
[Sat Dec  2 00:02:46 2023]
Finished job 12.
103 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:46 2023]
Job 86: working on tf=STAT3 data/homer_files/STAT3/scanMotifsGenomeWide_stat3.txt data/homer_files/STAT3/scanMotifsGenomeWide_stat3.il23.txt
Reason: Input files updated by another job: data/homer_files/STAT3/scanMotifsGenomeWide_stat3.il23.txt, data/homer_files/STAT3/scanMotifsGenomeWide_stat3.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 86 with external jobid 'Submitted batch job 11024827'.
[Sat Dec  2 00:02:49 2023]
Finished job 46.
104 of 1394 steps (7%) done
Select jobs to execute...

[Sat Dec  2 00:02:49 2023]
Job 52: working on tf=SOX2 data/homer_files/SOX2/scanMotifsGenomeWide_sox2.txt data/homer_files/SOX2/scanMotifsGenomeWide_oct4-sox2.txt
Reason: Input files updated by another job: data/homer_files/SOX2/scanMotifsGenomeWide_oct4-sox2.txt, data/homer_files/SOX2/scanMotifsGenomeWide_sox2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 52 with external jobid 'Submitted batch job 11024828'.
[Sat Dec  2 00:02:52 2023]
Finished job 3.
105 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:02:52 2023]
Job 80: working on tf=MAX data/homer_files/MAX/scanMotifsGenomeWide_max.txt
Reason: Input files updated by another job: data/homer_files/MAX/scanMotifsGenomeWide_max.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 80 with external jobid 'Submitted batch job 11024829'.
[Sat Dec  2 00:02:52 2023]
Finished job 26.
106 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:02:52 2023]
Job 57: working on tf=STAT4 data/homer_files/STAT4/scanMotifsGenomeWide_stat4.txt
Reason: Input files updated by another job: data/homer_files/STAT4/scanMotifsGenomeWide_stat4.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 57 with external jobid 'Submitted batch job 11024833'.
[Sat Dec  2 00:02:54 2023]
Finished job 132.
107 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:02:54 2023]
Job 157: working on tf=YY1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Colon --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Colon --predictors_file data/predictor_files/YY1_Colon.predictors.txt --ground_truth_file data/predictor_files/YY1_Colon.ground_truth.txt --info_file data/predictor_files/YY1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 157 with external jobid 'Submitted batch job 11024855'.
[Sat Dec  2 00:02:55 2023]
Finished job 246.
108 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:02:56 2023]
Job 259: working on tf=YY1,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Embryonic-Kidney --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Embryonic-Kidney --predictors_file data/predictor_files/YY1_Embryonic-Kidney.predictors.txt --ground_truth_file data/predictor_files/YY1_Embryonic-Kidney.ground_truth.txt --info_file data/predictor_files/YY1_Embryonic-Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 259 with external jobid 'Submitted batch job 11024857'.
[Sat Dec  2 00:02:57 2023]
Finished job 176.
109 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:02:57 2023]
Job 121: working on tf=YY1,tissue=Blood
Reason: Input files updated by another job: data/homer_files/YY1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor YY1 --tissue Blood --predicted_motif_file data/homer_files/YY1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/YY1_Blood --predictors_file data/predictor_files/YY1_Blood.predictors.txt --ground_truth_file data/predictor_files/YY1_Blood.ground_truth.txt --info_file data/predictor_files/YY1_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 121 with external jobid 'Submitted batch job 11024859'.
[Sat Dec  2 00:02:57 2023]
Finished job 162.
110 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:02:57 2023]
Job 432: working on tf=FOXM1,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/predictor_files/FOXM1_Embryonic-Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Embryonic-Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Embryonic-Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Embryonic-Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 432 with external jobid 'Submitted batch job 11024860'.
[Sat Dec  2 00:02:59 2023]
Finished job 138.
111 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:02:59 2023]
Job 324: working on tf=FOXM1,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/FOXM1_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 324 with external jobid 'Submitted batch job 11024861'.
[Sat Dec  2 00:03:00 2023]
Finished job 249.
112 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:03:00 2023]
Job 362: working on tf=FOXM1,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/FOXM1_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Cervix --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Cervix.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 362 with external jobid 'Submitted batch job 11024862'.
[Sat Dec  2 00:03:02 2023]
Finished job 217.
113 of 1394 steps (8%) done
[Sat Dec  2 00:03:02 2023]
Finished job 235.
114 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:03:02 2023]
Job 403: working on tf=FOXM1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/FOXM1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 403 with external jobid 'Submitted batch job 11024865'.

[Sat Dec  2 00:03:02 2023]
Job 421: working on tf=FOXM1,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/FOXM1_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 421 with external jobid 'Submitted batch job 11024866'.
Select jobs to execute...
[Sat Dec  2 00:03:03 2023]
Finished job 213.
115 of 1394 steps (8%) done

[Sat Dec  2 00:03:03 2023]
Job 399: working on tf=FOXM1,tissue=Endometrium
Reason: Input files updated by another job: data/predictor_files/FOXM1_Endometrium.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Endometrium --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Endometrium.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Endometrium.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 399 with external jobid 'Submitted batch job 11024874'.
[Sat Dec  2 00:03:12 2023]
Finished job 310.
116 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:03:12 2023]
Job 318: working on tf=FOXM1,tissue=Bone
Reason: Input files updated by another job: data/predictor_files/FOXM1_Bone.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Bone --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Bone.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Bone.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 318 with external jobid 'Submitted batch job 11024876'.
[Sat Dec  2 00:03:13 2023]
Finished job 394.
117 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:03:13 2023]
Job 496: working on ETS1_Prostate
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ETS1_Prostate.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ETS1_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ETS1_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 496 with external jobid 'Submitted batch job 11024877'.
[Sat Dec  2 00:03:14 2023]
Finished job 412.
118 of 1394 steps (8%) done
Select jobs to execute...

[Sat Dec  2 00:03:14 2023]
Job 598: working on ETS1_Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ETS1_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ETS1_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 598 with external jobid 'Submitted batch job 11024878'.
[Sat Dec  2 00:03:15 2023]
Finished job 337.
119 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:15 2023]
Job 523: working on ETS1_Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ETS1_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ETS1_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 523 with external jobid 'Submitted batch job 11024879'.
[Sat Dec  2 00:03:16 2023]
Finished job 425.
120 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:16 2023]
Job 611: working on ETS1_Pancreas
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ETS1_Pancreas.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ETS1_Pancreas.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 611 with external jobid 'Submitted batch job 11024880'.
[Sat Dec  2 00:03:19 2023]
Finished job 287.
121 of 1394 steps (9%) done
[Sat Dec  2 00:03:19 2023]
Finished job 446.
122 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:19 2023]
Job 632: working on E2F1_Umbilical-Cord
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Umbilical-Cord.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Umbilical-Cord.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 632 with external jobid 'Submitted batch job 11024881'.

[Sat Dec  2 00:03:19 2023]
Job 473: working on ETS1_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ETS1_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ETS1_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ETS1_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 473 with external jobid 'Submitted batch job 11024882'.
Select jobs to execute...
[Sat Dec  2 00:03:20 2023]
Finished job 282.
123 of 1394 steps (9%) done

[Sat Dec  2 00:03:20 2023]
Job 468: working on E2F1_Cervix
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Cervix.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 468 with external jobid 'Submitted batch job 11024883'.
[Sat Dec  2 00:03:21 2023]
Finished job 436.
124 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:21 2023]
Job 622: working on E2F1_Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 622 with external jobid 'Submitted batch job 11024884'.
[Sat Dec  2 00:03:21 2023]
Finished job 451.
125 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:21 2023]
Job 637: working on E2F1_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 637 with external jobid 'Submitted batch job 11024885'.
[Sat Dec  2 00:03:23 2023]
Finished job 293.
126 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:23 2023]
Job 479: working on E2F1_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 479 with external jobid 'Submitted batch job 11024886'.
[Sat Dec  2 00:03:23 2023]
Finished job 365.
127 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:23 2023]
Job 551: working on E2F1_Prostate
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Prostate.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 551 with external jobid 'Submitted batch job 11024887'.
[Sat Dec  2 00:03:24 2023]
Finished job 351.
128 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:24 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11024888'.
[Sat Dec  2 00:03:26 2023]
Finished job 353.
129 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:26 2023]
Job 539: working on E2F1_Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 539 with external jobid 'Submitted batch job 11024889'.
[Sat Dec  2 00:03:26 2023]
Error in rule create_enformer_configuration:
    jobid: 314
    input: data/predictor_files/GATA2_Blood.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_GATA2_Blood.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA2 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA2_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA2_Blood.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11024765

Error executing rule create_enformer_configuration on cluster (jobid: 314, external: Submitted batch job 11024765, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.314.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 314.
Select jobs to execute...

[Sat Dec  2 00:03:26 2023]
Job 314: working on tf=GATA2,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/GATA2_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA2 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA2_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA2_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 314 with external jobid 'Submitted batch job 11024890'.
[Sat Dec  2 00:03:28 2023]
Finished job 288.
130 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:28 2023]
Job 474: working on GATA2_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA2_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA2_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA2_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 474 with external jobid 'Submitted batch job 11024891'.
[Sat Dec  2 00:03:28 2023]
Finished job 344.
131 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:28 2023]
Job 530: working on GATA2_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA2_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA2_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA2_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 530 with external jobid 'Submitted batch job 11024892'.
[Sat Dec  2 00:03:30 2023]
Finished job 431.
132 of 1394 steps (9%) done
Select jobs to execute...

[Sat Dec  2 00:03:30 2023]
Job 617: working on GATA2_Prostate
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA2_Prostate.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA2_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA2_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 617 with external jobid 'Submitted batch job 11024893'.
[Sat Dec  2 00:03:31 2023]
Finished job 285.
133 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:31 2023]
Job 471: working on GATA2_Umbilical-Vein
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA2_Umbilical-Vein.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA2_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA2_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 471 with external jobid 'Submitted batch job 11024894'.
[Sat Dec  2 00:03:31 2023]
Finished job 301.
134 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:31 2023]
Job 487: working on GATA2_Cord-blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA2_Cord-blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA2_Cord-blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA2_Cord-blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 487 with external jobid 'Submitted batch job 11024895'.
[Sat Dec  2 00:03:33 2023]
Finished job 444.
135 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:33 2023]
Job 630: working on SP1_Embryonic-Kidney
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SP1_Embryonic-Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SP1_Embryonic-Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 630 with external jobid 'Submitted batch job 11024896'.
[Sat Dec  2 00:03:34 2023]
Finished job 404.
136 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:34 2023]
Job 590: working on SP1_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SP1_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SP1_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SP1_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 590 with external jobid 'Submitted batch job 11024897'.
[Sat Dec  2 00:03:34 2023]
Finished job 308.
137 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:34 2023]
Job 494: working on SP1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SP1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SP1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SP1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 494 with external jobid 'Submitted batch job 11024898'.
[Sat Dec  2 00:03:35 2023]
Finished job 392.
138 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:35 2023]
Job 580: working on ETS1_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ETS1_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ETS1_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ETS1_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 580 with external jobid 'Submitted batch job 11024899'.
[Sat Dec  2 00:03:37 2023]
Finished job 406.
139 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:37 2023]
Job 592: working on SP1_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SP1_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SP1_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SP1_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 592 with external jobid 'Submitted batch job 11024900'.
[Sat Dec  2 00:03:38 2023]
Finished job 442.
140 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:38 2023]
Job 628: working on SP1_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SP1_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SP1_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SP1_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 628 with external jobid 'Submitted batch job 11024901'.
[Sat Dec  2 00:03:40 2023]
Finished job 409.
141 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:40 2023]
Job 595: working on SP1_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SP1_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SP1_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SP1_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 595 with external jobid 'Submitted batch job 11024902'.
[Sat Dec  2 00:03:41 2023]
Finished job 413.
142 of 1394 steps (10%) done
[Sat Dec  2 00:03:41 2023]
Finished job 345.
143 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:42 2023]
Job 599: working on SP1_Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SP1_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SP1_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 599 with external jobid 'Submitted batch job 11024903'.

[Sat Dec  2 00:03:42 2023]
Job 531: working on GATA4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 531 with external jobid 'Submitted batch job 11024904'.
[Sat Dec  2 00:03:42 2023]
Finished job 429.
144 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:42 2023]
Job 615: working on GATA4_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA4_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA4_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA4_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 615 with external jobid 'Submitted batch job 11024905'.
Select jobs to execute...
[Sat Dec  2 00:03:43 2023]
Finished job 460.
145 of 1394 steps (10%) done

[Sat Dec  2 00:03:43 2023]
Job 646: working on GATA4_Skin
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA4_Skin.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA4_Skin.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA4_Skin.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 646 with external jobid 'Submitted batch job 11024906'.
[Sat Dec  2 00:03:44 2023]
Finished job 463.
146 of 1394 steps (10%) done
Select jobs to execute...

[Sat Dec  2 00:03:44 2023]
Job 649: working on GATA4_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA4_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA4_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA4_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 649 with external jobid 'Submitted batch job 11024907'.
[Sat Dec  2 00:03:45 2023]
Finished job 423.
147 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:45 2023]
Job 609: working on GATA4_Stomach
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA4_Stomach.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA4_Stomach.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA4_Stomach.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 11024908'.
[Sat Dec  2 00:03:45 2023]
Finished job 441.
148 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:45 2023]
Job 627: working on GATA4_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA4_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA4_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA4_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 627 with external jobid 'Submitted batch job 11024909'.
[Sat Dec  2 00:03:47 2023]
Finished job 415.
149 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:47 2023]
Job 601: working on FOSL2_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 601 with external jobid 'Submitted batch job 11024910'.
[Sat Dec  2 00:03:48 2023]
Finished job 420.
150 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:48 2023]
Job 606: working on FOSL2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 606 with external jobid 'Submitted batch job 11024911'.
[Sat Dec  2 00:03:49 2023]
Finished job 396.
151 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:49 2023]
Job 582: working on FOSL2_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 582 with external jobid 'Submitted batch job 11024912'.
[Sat Dec  2 00:03:49 2023]
Finished job 410.
152 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:49 2023]
Job 596: working on FOSL2_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 596 with external jobid 'Submitted batch job 11024913'.
[Sat Dec  2 00:03:51 2023]
Finished job 433.
153 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:51 2023]
Job 619: working on FOSL2_Endometrium
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Endometrium.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Endometrium.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOSL2_Endometrium.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 619 with external jobid 'Submitted batch job 11024914'.
[Sat Dec  2 00:03:52 2023]
Finished job 103.
154 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:52 2023]
Job 289: working on tf=RUNX1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/RUNX1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 289 with external jobid 'Submitted batch job 11024915'.
[Sat Dec  2 00:03:53 2023]
Finished job 118.
155 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:53 2023]
Job 304: working on tf=RUNX1,tissue=Cord-blood
Reason: Input files updated by another job: data/predictor_files/RUNX1_Cord-blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Cord-blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Cord-blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Cord-blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 304 with external jobid 'Submitted batch job 11024916'.
[Sat Dec  2 00:03:54 2023]
Finished job 272.
156 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:54 2023]
Job 458: working on tf=RUNX1,tissue=Kidney
Reason: Input files updated by another job: data/predictor_files/RUNX1_Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 458 with external jobid 'Submitted batch job 11024917'.
[Sat Dec  2 00:03:55 2023]
Finished job 174.
157 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:55 2023]
Job 578: working on SP1_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SP1_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SP1_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SP1_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 578 with external jobid 'Submitted batch job 11024918'.
[Sat Dec  2 00:03:56 2023]
Finished job 92.
158 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:56 2023]
Job 278: working on tf=RUNX1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/RUNX1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 278 with external jobid 'Submitted batch job 11024919'.
[Sat Dec  2 00:03:57 2023]
Finished job 262.
159 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:57 2023]
Job 448: working on tf=RUNX1,tissue=Fetal-Liver
Reason: Input files updated by another job: data/predictor_files/RUNX1_Fetal-Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Fetal-Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Fetal-Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Fetal-Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 448 with external jobid 'Submitted batch job 11024920'.
[Sat Dec  2 00:03:59 2023]
Finished job 266.
160 of 1394 steps (11%) done
Select jobs to execute...

[Sat Dec  2 00:03:59 2023]
Job 452: working on tf=RUNX1,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/RUNX1_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 452 with external jobid 'Submitted batch job 11024921'.
[Sat Dec  2 00:03:59 2023]
Finished job 240.
161 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:03:59 2023]
Job 426: working on tf=RUNX1,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/RUNX1_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Prostate --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Prostate.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 426 with external jobid 'Submitted batch job 11024922'.
[Sat Dec  2 00:04:00 2023]
Finished job 251.
162 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:00 2023]
Job 437: working on tf=RUNX1,tissue=Pleura
Reason: Input files updated by another job: data/predictor_files/RUNX1_Pleura.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Pleura --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Pleura.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Pleura.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 437 with external jobid 'Submitted batch job 11024923'.
[Sat Dec  2 00:04:02 2023]
Finished job 110.
163 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:02 2023]
Job 296: working on tf=FOXA1,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/FOXA1_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Mammary-Gland.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 296 with external jobid 'Submitted batch job 11024924'.
[Sat Dec  2 00:04:03 2023]
Finished job 264.
164 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:03 2023]
Job 450: working on tf=FOXA1,tissue=endometrioid-adenocarcinoma
Reason: Input files updated by another job: data/predictor_files/FOXA1_endometrioid-adenocarcinoma.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue endometrioid-adenocarcinoma --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_endometrioid-adenocarcinoma.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_endometrioid-adenocarcinoma.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 450 with external jobid 'Submitted batch job 11024925'.
[Sat Dec  2 00:04:04 2023]
Finished job 142.
165 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:04 2023]
Job 328: working on tf=FOXA1,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/FOXA1_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 328 with external jobid 'Submitted batch job 11024926'.
[Sat Dec  2 00:04:05 2023]
Finished job 156.
166 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:05 2023]
Job 342: working on tf=FOXA1,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/FOXA1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 342 with external jobid 'Submitted batch job 11024927'.
[Sat Dec  2 00:04:07 2023]
Finished job 261.
167 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:07 2023]
Job 447: working on tf=FOXA1,tissue=Pancreatic-ductal
Reason: Input files updated by another job: data/predictor_files/FOXA1_Pancreatic-ductal.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Pancreatic-ductal --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Pancreatic-ductal.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Pancreatic-ductal.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 447 with external jobid 'Submitted batch job 11024928'.
[Sat Dec  2 00:04:08 2023]
Finished job 125.
168 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:08 2023]
Job 311: working on tf=FOXA1,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/FOXA1_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 311 with external jobid 'Submitted batch job 11024929'.
[Sat Dec  2 00:04:09 2023]
Finished job 211.
169 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:09 2023]
Job 397: working on tf=FOXA1,tissue=Endometrium
Reason: Input files updated by another job: data/predictor_files/FOXA1_Endometrium.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Endometrium --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Endometrium.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Endometrium.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 397 with external jobid 'Submitted batch job 11024930'.
[Sat Dec  2 00:04:10 2023]
Finished job 241.
170 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:10 2023]
Job 427: working on tf=FOXA1,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/FOXA1_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 427 with external jobid 'Submitted batch job 11024931'.
[Sat Dec  2 00:04:11 2023]
Finished job 271.
171 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:11 2023]
Job 360: working on tf=RUNX1,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/RUNX1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 360 with external jobid 'Submitted batch job 11024932'.
[Sat Dec  2 00:04:12 2023]
Finished job 150.
172 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:12 2023]
Job 336: working on tf=FOXA2,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/FOXA2_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA2 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA2_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 336 with external jobid 'Submitted batch job 11024933'.
[Sat Dec  2 00:04:13 2023]
Finished job 114.
173 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:13 2023]
Job 300: working on tf=FOXA2,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/FOXA2_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA2 --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA2_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 300 with external jobid 'Submitted batch job 11024934'.
[Sat Dec  2 00:04:14 2023]
Finished job 242.
174 of 1394 steps (12%) done
Select jobs to execute...

[Sat Dec  2 00:04:14 2023]
Job 428: working on tf=FOXA2,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/FOXA2_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA2 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA2_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 428 with external jobid 'Submitted batch job 11024935'.
[Sat Dec  2 00:04:15 2023]
Finished job 172.
175 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:15 2023]
Job 358: working on tf=FOXA2,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/FOXA2_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA2 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA2_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 358 with external jobid 'Submitted batch job 11024936'.
[Sat Dec  2 00:04:16 2023]
Finished job 269.
176 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:16 2023]
Job 455: working on tf=FOXA2,tissue=Skin
Reason: Input files updated by another job: data/predictor_files/FOXA2_Skin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA2 --tissue Skin --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA2_Skin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Skin.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 455 with external jobid 'Submitted batch job 11024937'.
[Sat Dec  2 00:04:17 2023]
Finished job 123.
177 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:17 2023]
Job 309: working on tf=PPARG,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/PPARG_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor PPARG --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/PPARG_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_PPARG_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 309 with external jobid 'Submitted batch job 11024938'.
[Sat Dec  2 00:04:18 2023]
Finished job 173.
178 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:18 2023]
Job 457: working on tf=FOXA2,tissue=Endoderm
Reason: Input files updated by another job: data/predictor_files/FOXA2_Endoderm.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA2 --tissue Endoderm --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA2_Endoderm.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Endoderm.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 457 with external jobid 'Submitted batch job 11024939'.
[Sat Dec  2 00:04:19 2023]
Finished job 238.
179 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:19 2023]
Job 424: working on tf=PPARG,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/PPARG_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor PPARG --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/PPARG_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_PPARG_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 11024940'.
[Sat Dec  2 00:04:20 2023]
Finished job 117.
180 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:20 2023]
Job 303: working on tf=PPARG,tissue=Adipose
Reason: Input files updated by another job: data/predictor_files/PPARG_Adipose.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor PPARG --tissue Adipose --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/PPARG_Adipose.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_PPARG_Adipose.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 303 with external jobid 'Submitted batch job 11024941'.
[Sat Dec  2 00:04:21 2023]
Finished job 131.
181 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:21 2023]
Job 317: working on tf=YY1,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/YY1_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Cervix --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Cervix.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 317 with external jobid 'Submitted batch job 11024942'.
[Sat Dec  2 00:04:22 2023]
Finished job 216.
182 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:22 2023]
Job 402: working on tf=YY1,tissue=Endometrium
Reason: Input files updated by another job: data/predictor_files/YY1_Endometrium.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Endometrium --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Endometrium.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Endometrium.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 402 with external jobid 'Submitted batch job 11024945'.
[Sat Dec  2 00:04:23 2023]
Finished job 222.
183 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:23 2023]
Job 408: working on tf=YY1,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/YY1_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 408 with external jobid 'Submitted batch job 11024946'.
[Sat Dec  2 00:04:24 2023]
Finished job 144.
184 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:24 2023]
Job 330: working on tf=YY1,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/YY1_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 330 with external jobid 'Submitted batch job 11024947'.
[Sat Dec  2 00:04:25 2023]
Finished job 199.
185 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:25 2023]
Job 385: working on tf=YY1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/YY1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 385 with external jobid 'Submitted batch job 11024948'.
[Sat Dec  2 00:04:26 2023]
Finished job 233.
186 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:26 2023]
Job 419: working on tf=YY1,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/YY1_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 419 with external jobid 'Submitted batch job 11024949'.
[Sat Dec  2 00:04:27 2023]
Finished job 207.
187 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:27 2023]
Job 393: working on tf=YY1,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/YY1_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 393 with external jobid 'Submitted batch job 11024950'.
[Sat Dec  2 00:04:28 2023]
Finished job 78.
188 of 1394 steps (13%) done
Select jobs to execute...

[Sat Dec  2 00:04:28 2023]
Job 276: working on tf=STAT1,tissue=Lung
Reason: Input files updated by another job: data/homer_files/STAT1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT1 --tissue Lung --predicted_motif_file data/homer_files/STAT1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT1_Lung --predictors_file data/predictor_files/STAT1_Lung.predictors.txt --ground_truth_file data/predictor_files/STAT1_Lung.ground_truth.txt --info_file data/predictor_files/STAT1_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 276 with external jobid 'Submitted batch job 11024951'.
[Sat Dec  2 00:04:29 2023]
Finished job 86.
189 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:29 2023]
Job 244: working on tf=STAT3,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Embryo --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Embryo --predictors_file data/predictor_files/STAT3_Embryo.predictors.txt --ground_truth_file data/predictor_files/STAT3_Embryo.ground_truth.txt --info_file data/predictor_files/STAT3_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 244 with external jobid 'Submitted batch job 11024952'.
[Sat Dec  2 00:04:30 2023]
Finished job 52.
190 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:30 2023]
Job 104: working on tf=SOX2,tissue=Brain
Reason: Input files updated by another job: data/homer_files/SOX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SOX2 --tissue Brain --predicted_motif_file data/homer_files/SOX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SOX2_Brain --predictors_file data/predictor_files/SOX2_Brain.predictors.txt --ground_truth_file data/predictor_files/SOX2_Brain.ground_truth.txt --info_file data/predictor_files/SOX2_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 104 with external jobid 'Submitted batch job 11024953'.
[Sat Dec  2 00:04:31 2023]
Finished job 80.
191 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:31 2023]
Job 155: working on tf=SOX2,tissue=Colon
Reason: Input files updated by another job: data/homer_files/SOX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SOX2 --tissue Colon --predicted_motif_file data/homer_files/SOX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SOX2_Colon --predictors_file data/predictor_files/SOX2_Colon.predictors.txt --ground_truth_file data/predictor_files/SOX2_Colon.ground_truth.txt --info_file data/predictor_files/SOX2_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 155 with external jobid 'Submitted batch job 11024954'.
[Sat Dec  2 00:04:32 2023]
Finished job 57.
192 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:32 2023]
Job 120: working on tf=SOX2,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/SOX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SOX2 --tissue Embryo --predicted_motif_file data/homer_files/SOX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SOX2_Embryo --predictors_file data/predictor_files/SOX2_Embryo.predictors.txt --ground_truth_file data/predictor_files/SOX2_Embryo.ground_truth.txt --info_file data/predictor_files/SOX2_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 120 with external jobid 'Submitted batch job 11024955'.
[Sat Dec  2 00:04:33 2023]
Finished job 157.
193 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:33 2023]
Job 177: working on tf=SOX2,tissue=Thyroid
Reason: Input files updated by another job: data/homer_files/SOX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SOX2 --tissue Thyroid --predicted_motif_file data/homer_files/SOX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SOX2_Thyroid --predictors_file data/predictor_files/SOX2_Thyroid.predictors.txt --ground_truth_file data/predictor_files/SOX2_Thyroid.ground_truth.txt --info_file data/predictor_files/SOX2_Thyroid.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 177 with external jobid 'Submitted batch job 11024956'.
[Sat Dec  2 00:04:34 2023]
Finished job 259.
194 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:34 2023]
Job 136: working on tf=SOX2,tissue=Skin
Reason: Input files updated by another job: data/homer_files/SOX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SOX2 --tissue Skin --predicted_motif_file data/homer_files/SOX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SOX2_Skin --predictors_file data/predictor_files/SOX2_Skin.predictors.txt --ground_truth_file data/predictor_files/SOX2_Skin.ground_truth.txt --info_file data/predictor_files/SOX2_Skin.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 136 with external jobid 'Submitted batch job 11024957'.
[Sat Dec  2 00:04:35 2023]
Finished job 121.
195 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:35 2023]
Job 178: working on tf=SOX2,tissue=Lung
Reason: Input files updated by another job: data/homer_files/SOX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SOX2 --tissue Lung --predicted_motif_file data/homer_files/SOX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SOX2_Lung --predictors_file data/predictor_files/SOX2_Lung.predictors.txt --ground_truth_file data/predictor_files/SOX2_Lung.ground_truth.txt --info_file data/predictor_files/SOX2_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 178 with external jobid 'Submitted batch job 11024958'.
[Sat Dec  2 00:04:36 2023]
Finished job 432.
196 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:36 2023]
Job 168: working on tf=STAT3,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Bone-Marrow --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Bone-Marrow --predictors_file data/predictor_files/STAT3_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/STAT3_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/STAT3_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 168 with external jobid 'Submitted batch job 11024959'.
[Sat Dec  2 00:04:37 2023]
Finished job 324.
197 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:37 2023]
Job 169: working on tf=STAT3,tissue=Blood
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Blood --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Blood --predictors_file data/predictor_files/STAT3_Blood.predictors.txt --ground_truth_file data/predictor_files/STAT3_Blood.ground_truth.txt --info_file data/predictor_files/STAT3_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 169 with external jobid 'Submitted batch job 11024960'.
[Sat Dec  2 00:04:38 2023]
Finished job 362.
198 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:38 2023]
Job 190: working on tf=STAT3,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Cervix --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Cervix --predictors_file data/predictor_files/STAT3_Cervix.predictors.txt --ground_truth_file data/predictor_files/STAT3_Cervix.ground_truth.txt --info_file data/predictor_files/STAT3_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 190 with external jobid 'Submitted batch job 11024961'.
[Sat Dec  2 00:04:39 2023]
Finished job 403.
199 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:39 2023]
Job 170: working on tf=STAT3,tissue=Peritoneal-Effusion
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Peritoneal-Effusion --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Peritoneal-Effusion --predictors_file data/predictor_files/STAT3_Peritoneal-Effusion.predictors.txt --ground_truth_file data/predictor_files/STAT3_Peritoneal-Effusion.ground_truth.txt --info_file data/predictor_files/STAT3_Peritoneal-Effusion.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 170 with external jobid 'Submitted batch job 11024962'.
[Sat Dec  2 00:04:40 2023]
Finished job 421.
200 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:40 2023]
Job 268: working on tf=STAT3,tissue=Umbilical-Cord
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Umbilical-Cord --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Umbilical-Cord --predictors_file data/predictor_files/STAT3_Umbilical-Cord.predictors.txt --ground_truth_file data/predictor_files/STAT3_Umbilical-Cord.ground_truth.txt --info_file data/predictor_files/STAT3_Umbilical-Cord.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 268 with external jobid 'Submitted batch job 11024963'.
[Sat Dec  2 00:04:41 2023]
Finished job 19.
201 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:41 2023]
Job 275: working on tf=STAT3,tissue=Lung
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Lung --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Lung --predictors_file data/predictor_files/STAT3_Lung.predictors.txt --ground_truth_file data/predictor_files/STAT3_Lung.ground_truth.txt --info_file data/predictor_files/STAT3_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 275 with external jobid 'Submitted batch job 11024964'.
[Sat Dec  2 00:04:43 2023]
Finished job 42.
202 of 1394 steps (14%) done
Select jobs to execute...

[Sat Dec  2 00:04:43 2023]
Job 171: working on tf=STAT3,tissue=Lymph-Node
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Lymph-Node --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Lymph-Node --predictors_file data/predictor_files/STAT3_Lymph-Node.predictors.txt --ground_truth_file data/predictor_files/STAT3_Lymph-Node.ground_truth.txt --info_file data/predictor_files/STAT3_Lymph-Node.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 171 with external jobid 'Submitted batch job 11024965'.
[Sat Dec  2 00:04:43 2023]
Finished job 41.
203 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:43 2023]
Job 164: working on tf=STAT3,tissue=Colon
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Colon --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Colon --predictors_file data/predictor_files/STAT3_Colon.predictors.txt --ground_truth_file data/predictor_files/STAT3_Colon.ground_truth.txt --info_file data/predictor_files/STAT3_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 164 with external jobid 'Submitted batch job 11024966'.
[Sat Dec  2 00:04:44 2023]
Finished job 50.
204 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:44 2023]
Job 137: working on tf=STAT3,tissue=Breast
Reason: Input files updated by another job: data/homer_files/STAT3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT3 --tissue Breast --predicted_motif_file data/homer_files/STAT3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT3_Breast --predictors_file data/predictor_files/STAT3_Breast.predictors.txt --ground_truth_file data/predictor_files/STAT3_Breast.ground_truth.txt --info_file data/predictor_files/STAT3_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 137 with external jobid 'Submitted batch job 11024967'.
[Sat Dec  2 00:04:45 2023]
Finished job 30.
205 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:45 2023]
Job 160: working on tf=MAX,tissue=Colon
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Colon --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Colon --predictors_file data/predictor_files/MAX_Colon.predictors.txt --ground_truth_file data/predictor_files/MAX_Colon.ground_truth.txt --info_file data/predictor_files/MAX_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 160 with external jobid 'Submitted batch job 11024968'.
[Sat Dec  2 00:04:46 2023]
Finished job 44.
206 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:46 2023]
Job 68: working on tf=PR data/homer_files/PR/scanMotifsGenomeWide_pr.txt
Reason: Input files updated by another job: data/homer_files/PR/scanMotifsGenomeWide_pr.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 68 with external jobid 'Submitted batch job 11024969'.
[Sat Dec  2 00:04:47 2023]
Finished job 51.
207 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:47 2023]
Job 230: working on tf=MAX,tissue=Breast
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Breast --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Breast --predictors_file data/predictor_files/MAX_Breast.predictors.txt --ground_truth_file data/predictor_files/MAX_Breast.ground_truth.txt --info_file data/predictor_files/MAX_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 230 with external jobid 'Submitted batch job 11024970'.
[Sat Dec  2 00:04:48 2023]
Finished job 31.
208 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:48 2023]
Job 133: working on tf=MAX,tissue=Lung
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Lung --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Lung --predictors_file data/predictor_files/MAX_Lung.predictors.txt --ground_truth_file data/predictor_files/MAX_Lung.ground_truth.txt --info_file data/predictor_files/MAX_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 133 with external jobid 'Submitted batch job 11024971'.
[Sat Dec  2 00:04:49 2023]
Finished job 8.
209 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:49 2023]
Job 134: working on tf=MAX,tissue=Brain
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Brain --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Brain --predictors_file data/predictor_files/MAX_Brain.predictors.txt --ground_truth_file data/predictor_files/MAX_Brain.ground_truth.txt --info_file data/predictor_files/MAX_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 134 with external jobid 'Submitted batch job 11024972'.
[Sat Dec  2 00:04:50 2023]
Finished job 7.
210 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:50 2023]
Job 184: working on tf=MAX,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Embryo --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Embryo --predictors_file data/predictor_files/MAX_Embryo.predictors.txt --ground_truth_file data/predictor_files/MAX_Embryo.ground_truth.txt --info_file data/predictor_files/MAX_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 184 with external jobid 'Submitted batch job 11024974'.
[Sat Dec  2 00:04:51 2023]
Finished job 40.
211 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:51 2023]
Job 59: working on tf=GATA3 data/homer_files/GATA3/scanMotifsGenomeWide_gata3.txt data/homer_files/GATA3/scanMotifsGenomeWide_gata3.ir4.txt data/homer_files/GATA3/scanMotifsGenomeWide_gata3.dr8.txt data/homer_files/GATA3/scanMotifsGenomeWide_gata3.ir3.txt data/homer_files/GATA3/scanMotifsGenomeWide_gata3.dr4.txt
Reason: Input files updated by another job: data/homer_files/GATA3/scanMotifsGenomeWide_gata3.ir4.txt, data/homer_files/GATA3/scanMotifsGenomeWide_gata3.dr4.txt, data/homer_files/GATA3/scanMotifsGenomeWide_gata3.ir3.txt, data/homer_files/GATA3/scanMotifsGenomeWide_gata3.dr8.txt, data/homer_files/GATA3/scanMotifsGenomeWide_gata3.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 59 with external jobid 'Submitted batch job 11024982'.
[Sat Dec  2 00:04:52 2023]
Finished job 399.
212 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:04:52 2023]
Job 198: working on tf=MAX,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Bone-Marrow --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Bone-Marrow --predictors_file data/predictor_files/MAX_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/MAX_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/MAX_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 198 with external jobid 'Submitted batch job 11024983'.
[Sat Dec  2 00:05:02 2023]
Finished job 318.
213 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:05:02 2023]
Job 93: working on tf=MAX,tissue=Blood
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Blood --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Blood --predictors_file data/predictor_files/MAX_Blood.predictors.txt --ground_truth_file data/predictor_files/MAX_Blood.ground_truth.txt --info_file data/predictor_files/MAX_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 93 with external jobid 'Submitted batch job 11024984'.
[Sat Dec  2 00:05:16 2023]
Finished job 314.
214 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:05:16 2023]
Job 191: working on tf=MAX,tissue=Liver
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Liver --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Liver --predictors_file data/predictor_files/MAX_Liver.predictors.txt --ground_truth_file data/predictor_files/MAX_Liver.ground_truth.txt --info_file data/predictor_files/MAX_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 191 with external jobid 'Submitted batch job 11024991'.
[Sat Dec  2 00:05:41 2023]
Finished job 289.
215 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:05:41 2023]
Job 214: working on tf=MAX,tissue=Endometrium
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Endometrium --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Endometrium --predictors_file data/predictor_files/MAX_Endometrium.predictors.txt --ground_truth_file data/predictor_files/MAX_Endometrium.ground_truth.txt --info_file data/predictor_files/MAX_Endometrium.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 214 with external jobid 'Submitted batch job 11024996'.
[Sat Dec  2 00:05:42 2023]
Finished job 304.
216 of 1394 steps (15%) done
Select jobs to execute...

[Sat Dec  2 00:05:42 2023]
Job 152: working on tf=MAX,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Cervix --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Cervix --predictors_file data/predictor_files/MAX_Cervix.predictors.txt --ground_truth_file data/predictor_files/MAX_Cervix.ground_truth.txt --info_file data/predictor_files/MAX_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 152 with external jobid 'Submitted batch job 11024997'.
[Sat Dec  2 00:05:43 2023]
Finished job 458.
217 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:43 2023]
Job 195: working on tf=MAX,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/MAX/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MAX --tissue Umbilical-Vein --predicted_motif_file data/homer_files/MAX/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MAX_Umbilical-Vein --predictors_file data/predictor_files/MAX_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/MAX_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/MAX_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 195 with external jobid 'Submitted batch job 11024998'.
[Sat Dec  2 00:05:45 2023]
Error in rule create_enformer_configuration:
    jobid: 278
    input: data/predictor_files/RUNX1_Blood.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Blood.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Blood.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11024919

Error executing rule create_enformer_configuration on cluster (jobid: 278, external: Submitted batch job 11024919, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.278.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 278.
Select jobs to execute...

[Sat Dec  2 00:05:45 2023]
Job 55: working on tf=GRHL2 data/homer_files/GRHL2/scanMotifsGenomeWide_grhl2.txt
Reason: Input files updated by another job: data/homer_files/GRHL2/scanMotifsGenomeWide_grhl2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 55 with external jobid 'Submitted batch job 11024999'.
[Sat Dec  2 00:05:46 2023]
Finished job 448.
218 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:46 2023]
Job 119: working on tf=STAT1,tissue=Blood
Reason: Input files updated by another job: data/homer_files/STAT1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT1 --tissue Blood --predicted_motif_file data/homer_files/STAT1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT1_Blood --predictors_file data/predictor_files/STAT1_Blood.predictors.txt --ground_truth_file data/predictor_files/STAT1_Blood.ground_truth.txt --info_file data/predictor_files/STAT1_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 119 with external jobid 'Submitted batch job 11025000'.
[Sat Dec  2 00:05:47 2023]
Finished job 452.
219 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:47 2023]
Job 175: working on tf=STAT1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/STAT1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT1 --tissue Colon --predicted_motif_file data/homer_files/STAT1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT1_Colon --predictors_file data/predictor_files/STAT1_Colon.predictors.txt --ground_truth_file data/predictor_files/STAT1_Colon.ground_truth.txt --info_file data/predictor_files/STAT1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 175 with external jobid 'Submitted batch job 11025001'.
[Sat Dec  2 00:05:48 2023]
Finished job 426.
220 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:48 2023]
Job 197: working on tf=STAT1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/STAT1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT1 --tissue Bone-Marrow --predicted_motif_file data/homer_files/STAT1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT1_Bone-Marrow --predictors_file data/predictor_files/STAT1_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/STAT1_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/STAT1_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 197 with external jobid 'Submitted batch job 11025002'.
[Sat Dec  2 00:05:49 2023]
Finished job 437.
221 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:49 2023]
Job 97: working on tf=STAT1,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/STAT1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT1 --tissue Cervix --predicted_motif_file data/homer_files/STAT1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT1_Cervix --predictors_file data/predictor_files/STAT1_Cervix.predictors.txt --ground_truth_file data/predictor_files/STAT1_Cervix.ground_truth.txt --info_file data/predictor_files/STAT1_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 97 with external jobid 'Submitted batch job 11025003'.
[Sat Dec  2 00:05:50 2023]
Finished job 296.
222 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:50 2023]
Job 62: working on tf=VDR data/homer_files/VDR/scanMotifsGenomeWide_vdr.txt
Reason: Input files updated by another job: data/homer_files/VDR/scanMotifsGenomeWide_vdr.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 62 with external jobid 'Submitted batch job 11025004'.
[Sat Dec  2 00:05:51 2023]
Finished job 450.
223 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:51 2023]
Job 89: working on tf=HSF1 data/homer_files/HSF1/scanMotifsGenomeWide_hsf1.txt
Reason: Input files updated by another job: data/homer_files/HSF1/scanMotifsGenomeWide_hsf1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 89 with external jobid 'Submitted batch job 11025005'.
[Sat Dec  2 00:05:52 2023]
Finished job 328.
224 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:52 2023]
Job 69: working on tf=CTCF data/homer_files/CTCF/scanMotifsGenomeWide_ctcf-mys.txt data/homer_files/CTCF/scanMotifsGenomeWide_ctcf.txt
Reason: Input files updated by another job: data/homer_files/CTCF/scanMotifsGenomeWide_ctcf.txt, data/homer_files/CTCF/scanMotifsGenomeWide_ctcf-mys.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 69 with external jobid 'Submitted batch job 11025014'.
[Sat Dec  2 00:05:53 2023]
Finished job 342.
225 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:53 2023]
Job 65: working on tf=ZNF382 data/homer_files/ZNF382/scanMotifsGenomeWide_znf382.txt
Reason: Input files updated by another job: data/homer_files/ZNF382/scanMotifsGenomeWide_znf382.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 65 with external jobid 'Submitted batch job 11025025'.
[Sat Dec  2 00:05:54 2023]
Finished job 447.
226 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:54 2023]
Job 278: working on tf=RUNX1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/RUNX1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor RUNX1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/RUNX1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 278 with external jobid 'Submitted batch job 11025033'.
[Sat Dec  2 00:05:55 2023]
Finished job 311.
227 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:55 2023]
Job 53: working on tf=REST data/homer_files/REST/scanMotifsGenomeWide_rest.txt
Reason: Input files updated by another job: data/homer_files/REST/scanMotifsGenomeWide_rest.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 53 with external jobid 'Submitted batch job 11025034'.
[Sat Dec  2 00:05:56 2023]
Finished job 397.
228 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:56 2023]
Job 307: working on tf=YY1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/YY1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 307 with external jobid 'Submitted batch job 11025035'.
[Sat Dec  2 00:05:57 2023]
Finished job 427.
229 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:57 2023]
Job 445: working on tf=YY1,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/predictor_files/YY1_Embryonic-Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Embryonic-Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Embryonic-Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Embryonic-Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 445 with external jobid 'Submitted batch job 11025036'.
[Sat Dec  2 00:05:58 2023]
Finished job 360.
230 of 1394 steps (16%) done
Select jobs to execute...

[Sat Dec  2 00:05:58 2023]
Job 343: working on tf=YY1,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/YY1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 343 with external jobid 'Submitted batch job 11025037'.
[Sat Dec  2 00:05:59 2023]
Error in rule create_enformer_configuration:
    jobid: 336
    input: data/predictor_files/FOXA2_Lung.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Lung.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA2 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA2_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Lung.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11024933

Error executing rule create_enformer_configuration on cluster (jobid: 336, external: Submitted batch job 11024933, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.336.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 336.
Select jobs to execute...

[Sat Dec  2 00:05:59 2023]
Job 336: working on tf=FOXA2,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/FOXA2_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA2 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA2_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 336 with external jobid 'Submitted batch job 11025038'.
[Sat Dec  2 00:06:00 2023]
Finished job 300.
231 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:00 2023]
Job 636: working on FOXA1_endometrioid-adenocarcinoma
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_endometrioid-adenocarcinoma.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_endometrioid-adenocarcinoma.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_endometrioid-adenocarcinoma.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 636 with external jobid 'Submitted batch job 11025039'.
[Sat Dec  2 00:06:02 2023]
Finished job 428.
232 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:02 2023]
Job 633: working on FOXA1_Pancreatic-ductal
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Pancreatic-ductal.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Pancreatic-ductal.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Pancreatic-ductal.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 633 with external jobid 'Submitted batch job 11025040'.
[Sat Dec  2 00:06:02 2023]
Finished job 358.
233 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:02 2023]
Job 618: working on FOXM1_Embryonic-Kidney
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Embryonic-Kidney.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Embryonic-Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Embryonic-Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 618 with external jobid 'Submitted batch job 11025041'.
[Sat Dec  2 00:06:03 2023]
Finished job 455.
234 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:03 2023]
Job 482: working on FOXA1_Mammary-Gland
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Mammary-Gland.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 482 with external jobid 'Submitted batch job 11025042'.
[Sat Dec  2 00:06:04 2023]
Finished job 309.
235 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:04 2023]
Job 634: working on RUNX1_Fetal-Liver
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Fetal-Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Fetal-Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 634 with external jobid 'Submitted batch job 11025043'.
[Sat Dec  2 00:06:05 2023]
Finished job 457.
236 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:05 2023]
Job 475: working on RUNX1_Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 475 with external jobid 'Submitted batch job 11025044'.
[Sat Dec  2 00:06:06 2023]
Finished job 424.
237 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:06 2023]
Job 585: working on FOXM1_Endometrium
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Endometrium.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Endometrium.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Endometrium.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 585 with external jobid 'Submitted batch job 11025045'.
[Sat Dec  2 00:06:07 2023]
Finished job 303.
238 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:07 2023]
Job 583: working on FOXA1_Endometrium
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Endometrium.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Endometrium.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Endometrium.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 583 with external jobid 'Submitted batch job 11025046'.
[Sat Dec  2 00:06:08 2023]
Finished job 317.
239 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:08 2023]
Job 490: working on RUNX1_Cord-blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Cord-blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Cord-blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 490 with external jobid 'Submitted batch job 11025047'.
[Sat Dec  2 00:06:09 2023]
Finished job 402.
240 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:09 2023]
Job 588: working on YY1_Endometrium
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Endometrium.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Endometrium.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Endometrium.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 588 with external jobid 'Submitted batch job 11025048'.
[Sat Dec  2 00:06:10 2023]
Finished job 408.
241 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:10 2023]
Job 643: working on FOXA2_Endoderm
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Endoderm.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Endoderm.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 643 with external jobid 'Submitted batch job 11025049'.
[Sat Dec  2 00:06:11 2023]
Finished job 330.
242 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:11 2023]
Job 612: working on RUNX1_Prostate
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Prostate.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 612 with external jobid 'Submitted batch job 11025050'.
[Sat Dec  2 00:06:12 2023]
Finished job 385.
243 of 1394 steps (17%) done
Select jobs to execute...

[Sat Dec  2 00:06:12 2023]
Job 571: working on YY1_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 571 with external jobid 'Submitted batch job 11025051'.
[Sat Dec  2 00:06:13 2023]
Finished job 419.
244 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:13 2023]
Job 489: working on PPARG_Adipose
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_PPARG_Adipose.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_PPARG_Adipose.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_PPARG_Adipose.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 489 with external jobid 'Submitted batch job 11025052'.
[Sat Dec  2 00:06:14 2023]
Finished job 393.
245 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:14 2023]
Job 613: working on FOXA1_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 613 with external jobid 'Submitted batch job 11025053'.
[Sat Dec  2 00:06:15 2023]
Finished job 276.
246 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:15 2023]
Job 462: working on tf=STAT1,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/STAT1_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT1 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT1_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT1_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 462 with external jobid 'Submitted batch job 11025054'.
[Sat Dec  2 00:06:16 2023]
Finished job 244.
247 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:16 2023]
Job 430: working on tf=STAT3,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/STAT3_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 430 with external jobid 'Submitted batch job 11025055'.
[Sat Dec  2 00:06:17 2023]
Finished job 104.
248 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:17 2023]
Job 614: working on FOXA2_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA2_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 614 with external jobid 'Submitted batch job 11025056'.
[Sat Dec  2 00:06:18 2023]
Finished job 155.
249 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:18 2023]
Job 341: working on tf=SOX2,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/SOX2_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SOX2 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SOX2_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SOX2_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 341 with external jobid 'Submitted batch job 11025057'.
[Sat Dec  2 00:06:19 2023]
Finished job 120.
250 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:19 2023]
Job 306: working on tf=SOX2,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/SOX2_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SOX2 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SOX2_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SOX2_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 306 with external jobid 'Submitted batch job 11025058'.
[Sat Dec  2 00:06:20 2023]
Finished job 177.
251 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:20 2023]
Job 363: working on tf=SOX2,tissue=Thyroid
Reason: Input files updated by another job: data/predictor_files/SOX2_Thyroid.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SOX2 --tissue Thyroid --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SOX2_Thyroid.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SOX2_Thyroid.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 363 with external jobid 'Submitted batch job 11025059'.
[Sat Dec  2 00:06:21 2023]
Finished job 136.
252 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:21 2023]
Job 322: working on tf=SOX2,tissue=Skin
Reason: Input files updated by another job: data/predictor_files/SOX2_Skin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SOX2 --tissue Skin --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SOX2_Skin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SOX2_Skin.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 322 with external jobid 'Submitted batch job 11025060'.
[Sat Dec  2 00:06:22 2023]
Finished job 178.
253 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:22 2023]
Job 364: working on tf=SOX2,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/SOX2_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SOX2 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SOX2_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SOX2_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 364 with external jobid 'Submitted batch job 11025061'.
[Sat Dec  2 00:06:23 2023]
Finished job 168.
254 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:23 2023]
Job 354: working on tf=STAT3,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/STAT3_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 354 with external jobid 'Submitted batch job 11025062'.
[Sat Dec  2 00:06:25 2023]
Finished job 169.
255 of 1394 steps (18%) done
[Sat Dec  2 00:06:25 2023]
Finished job 190.
256 of 1394 steps (18%) done
Select jobs to execute...

[Sat Dec  2 00:06:25 2023]
Job 376: working on tf=STAT3,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/STAT3_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Cervix --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Cervix.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 376 with external jobid 'Submitted batch job 11025063'.

[Sat Dec  2 00:06:25 2023]
Job 355: working on tf=STAT3,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/STAT3_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 355 with external jobid 'Submitted batch job 11025064'.
Select jobs to execute...
[Sat Dec  2 00:06:26 2023]
Finished job 170.
257 of 1394 steps (18%) done

[Sat Dec  2 00:06:26 2023]
Job 356: working on tf=STAT3,tissue=Peritoneal-Effusion
Reason: Input files updated by another job: data/predictor_files/STAT3_Peritoneal-Effusion.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Peritoneal-Effusion --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Peritoneal-Effusion.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Peritoneal-Effusion.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 356 with external jobid 'Submitted batch job 11025065'.
[Sat Dec  2 00:06:27 2023]
Finished job 268.
258 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:27 2023]
Job 454: working on tf=STAT3,tissue=Umbilical-Cord
Reason: Input files updated by another job: data/predictor_files/STAT3_Umbilical-Cord.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Umbilical-Cord --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Umbilical-Cord.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Umbilical-Cord.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 454 with external jobid 'Submitted batch job 11025066'.
[Sat Dec  2 00:06:28 2023]
Finished job 275.
259 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:28 2023]
Job 461: working on tf=STAT3,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/STAT3_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 461 with external jobid 'Submitted batch job 11025067'.
[Sat Dec  2 00:06:29 2023]
Finished job 171.
260 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:29 2023]
Job 357: working on tf=STAT3,tissue=Lymph-Node
Reason: Input files updated by another job: data/predictor_files/STAT3_Lymph-Node.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Lymph-Node --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Lymph-Node.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Lymph-Node.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 357 with external jobid 'Submitted batch job 11025068'.
[Sat Dec  2 00:06:30 2023]
Finished job 164.
261 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:30 2023]
Job 510: working on FOXM1_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 510 with external jobid 'Submitted batch job 11025069'.
[Sat Dec  2 00:06:31 2023]
Finished job 137.
262 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:31 2023]
Job 323: working on tf=STAT3,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/STAT3_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 323 with external jobid 'Submitted batch job 11025070'.
[Sat Dec  2 00:06:32 2023]
Finished job 160.
263 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:32 2023]
Job 346: working on tf=MAX,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/MAX_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 346 with external jobid 'Submitted batch job 11025071'.
[Sat Dec  2 00:06:33 2023]
Finished job 68.
264 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:33 2023]
Job 644: working on RUNX1_Kidney
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Kidney.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 644 with external jobid 'Submitted batch job 11025072'.
[Sat Dec  2 00:06:34 2023]
Finished job 230.
265 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:34 2023]
Job 416: working on tf=MAX,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/MAX_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 416 with external jobid 'Submitted batch job 11025073'.
[Sat Dec  2 00:06:35 2023]
Finished job 133.
266 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:35 2023]
Job 319: working on tf=MAX,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/MAX_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 319 with external jobid 'Submitted batch job 11025074'.
[Sat Dec  2 00:06:36 2023]
Finished job 134.
267 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:36 2023]
Job 320: working on tf=MAX,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/MAX_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 320 with external jobid 'Submitted batch job 11025075'.
[Sat Dec  2 00:06:37 2023]
Finished job 184.
268 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:37 2023]
Job 370: working on tf=MAX,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/MAX_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 370 with external jobid 'Submitted batch job 11025076'.
[Sat Dec  2 00:06:38 2023]
Finished job 59.
269 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:38 2023]
Job 202: working on tf=GATA3,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/GATA3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA3 --tissue Bone-Marrow --predicted_motif_file data/homer_files/GATA3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA3_Bone-Marrow --predictors_file data/predictor_files/GATA3_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/GATA3_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/GATA3_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 202 with external jobid 'Submitted batch job 11025077'.
[Sat Dec  2 00:06:39 2023]
Finished job 108.
270 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:39 2023]
Job 205: working on tf=GATA3,tissue=Lung
Reason: Input files updated by another job: data/homer_files/GATA3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA3 --tissue Lung --predicted_motif_file data/homer_files/GATA3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA3_Lung --predictors_file data/predictor_files/GATA3_Lung.predictors.txt --ground_truth_file data/predictor_files/GATA3_Lung.ground_truth.txt --info_file data/predictor_files/GATA3_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 205 with external jobid 'Submitted batch job 11025086'.
[Sat Dec  2 00:06:40 2023]
Finished job 105.
271 of 1394 steps (19%) done
Select jobs to execute...

[Sat Dec  2 00:06:40 2023]
Job 130: working on tf=GATA3,tissue=Blood
Reason: Input files updated by another job: data/homer_files/GATA3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA3 --tissue Blood --predicted_motif_file data/homer_files/GATA3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA3_Blood --predictors_file data/predictor_files/GATA3_Blood.predictors.txt --ground_truth_file data/predictor_files/GATA3_Blood.ground_truth.txt --info_file data/predictor_files/GATA3_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 130 with external jobid 'Submitted batch job 11025093'.
[Sat Dec  2 00:06:41 2023]
Finished job 198.
272 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:41 2023]
Job 270: working on tf=GATA3,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/GATA3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA3 --tissue Embryo --predicted_motif_file data/homer_files/GATA3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA3_Embryo --predictors_file data/predictor_files/GATA3_Embryo.predictors.txt --ground_truth_file data/predictor_files/GATA3_Embryo.ground_truth.txt --info_file data/predictor_files/GATA3_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 270 with external jobid 'Submitted batch job 11025094'.
[Sat Dec  2 00:06:51 2023]
Finished job 93.
273 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:51 2023]
Job 109: working on tf=GATA3,tissue=Breast
Reason: Input files updated by another job: data/homer_files/GATA3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA3 --tissue Breast --predicted_motif_file data/homer_files/GATA3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA3_Breast --predictors_file data/predictor_files/GATA3_Breast.predictors.txt --ground_truth_file data/predictor_files/GATA3_Breast.ground_truth.txt --info_file data/predictor_files/GATA3_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 109 with external jobid 'Submitted batch job 11025095'.
[Sat Dec  2 00:06:52 2023]
Finished job 191.
274 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:52 2023]
Job 263: working on tf=GATA3,tissue=Thymus
Reason: Input files updated by another job: data/homer_files/GATA3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA3 --tissue Thymus --predicted_motif_file data/homer_files/GATA3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA3_Thymus --predictors_file data/predictor_files/GATA3_Thymus.predictors.txt --ground_truth_file data/predictor_files/GATA3_Thymus.ground_truth.txt --info_file data/predictor_files/GATA3_Thymus.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 263 with external jobid 'Submitted batch job 11025096'.
[Sat Dec  2 00:06:53 2023]
Finished job 214.
275 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:53 2023]
Job 180: working on tf=GATA3,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/GATA3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA3 --tissue Mammary-Gland --predicted_motif_file data/homer_files/GATA3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA3_Mammary-Gland --predictors_file data/predictor_files/GATA3_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/GATA3_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/GATA3_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 180 with external jobid 'Submitted batch job 11025097'.
[Sat Dec  2 00:06:54 2023]
Finished job 152.
276 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:54 2023]
Job 236: working on tf=GATA3,tissue=Brain
Reason: Input files updated by another job: data/homer_files/GATA3/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GATA3 --tissue Brain --predicted_motif_file data/homer_files/GATA3/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GATA3_Brain --predictors_file data/predictor_files/GATA3_Brain.predictors.txt --ground_truth_file data/predictor_files/GATA3_Brain.ground_truth.txt --info_file data/predictor_files/GATA3_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 236 with external jobid 'Submitted batch job 11025098'.
[Sat Dec  2 00:06:55 2023]
Finished job 195.
277 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:55 2023]
Job 294: working on tf=FOXA1,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/FOXA1_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 294 with external jobid 'Submitted batch job 11025100'.
[Sat Dec  2 00:06:56 2023]
Finished job 55.
278 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:56 2023]
Job 291: working on tf=FOXA1,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/FOXA1_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXA1 --tissue Prostate --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXA1_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Prostate.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 291 with external jobid 'Submitted batch job 11025101'.
[Sat Dec  2 00:06:57 2023]
Finished job 119.
279 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:57 2023]
Job 384: working on tf=MAX,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/MAX_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 384 with external jobid 'Submitted batch job 11025102'.
[Sat Dec  2 00:06:58 2023]
Finished job 175.
280 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:58 2023]
Job 279: working on tf=MAX,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/MAX_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 279 with external jobid 'Submitted batch job 11025103'.
[Sat Dec  2 00:06:59 2023]
Finished job 197.
281 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:06:59 2023]
Job 377: working on tf=MAX,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/MAX_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 377 with external jobid 'Submitted batch job 11025104'.
[Sat Dec  2 00:07:00 2023]
Finished job 97.
282 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:07:00 2023]
Job 400: working on tf=MAX,tissue=Endometrium
Reason: Input files updated by another job: data/predictor_files/MAX_Endometrium.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Endometrium --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Endometrium.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Endometrium.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 400 with external jobid 'Submitted batch job 11025105'.
[Sat Dec  2 00:07:01 2023]
Finished job 62.
283 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:07:01 2023]
Job 381: working on tf=MAX,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/MAX_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Umbilical-Vein.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 381 with external jobid 'Submitted batch job 11025106'.
[Sat Dec  2 00:07:03 2023]
Finished job 89.
284 of 1394 steps (20%) done
[Sat Dec  2 00:07:03 2023]
Finished job 69.
285 of 1394 steps (20%) done
Select jobs to execute...

[Sat Dec  2 00:07:03 2023]
Job 147: working on tf=HSF1,tissue=Lung
Reason: Input files updated by another job: data/homer_files/HSF1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HSF1 --tissue Lung --predicted_motif_file data/homer_files/HSF1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HSF1_Lung --predictors_file data/predictor_files/HSF1_Lung.predictors.txt --ground_truth_file data/predictor_files/HSF1_Lung.ground_truth.txt --info_file data/predictor_files/HSF1_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 147 with external jobid 'Submitted batch job 11025107'.

[Sat Dec  2 00:07:03 2023]
Job 148: working on tf=HSF1,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/HSF1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HSF1 --tissue Mammary-Gland --predicted_motif_file data/homer_files/HSF1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HSF1_Mammary-Gland --predictors_file data/predictor_files/HSF1_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/HSF1_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/HSF1_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 148 with external jobid 'Submitted batch job 11025108'.
Select jobs to execute...
[Sat Dec  2 00:07:04 2023]
Finished job 65.
286 of 1394 steps (21%) done

[Sat Dec  2 00:07:04 2023]
Job 140: working on tf=HSF1,tissue=Breast
Reason: Input files updated by another job: data/homer_files/HSF1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HSF1 --tissue Breast --predicted_motif_file data/homer_files/HSF1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HSF1_Breast --predictors_file data/predictor_files/HSF1_Breast.predictors.txt --ground_truth_file data/predictor_files/HSF1_Breast.ground_truth.txt --info_file data/predictor_files/HSF1_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 140 with external jobid 'Submitted batch job 11025109'.
[Sat Dec  2 00:07:06 2023]
Finished job 278.
287 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:06 2023]
Job 154: working on tf=HSF1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/HSF1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HSF1 --tissue Bone-Marrow --predicted_motif_file data/homer_files/HSF1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HSF1_Bone-Marrow --predictors_file data/predictor_files/HSF1_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/HSF1_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/HSF1_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 154 with external jobid 'Submitted batch job 11025110'.
[Sat Dec  2 00:07:06 2023]
Finished job 53.
288 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:06 2023]
Job 192: working on tf=HSF1,tissue=Liver
Reason: Input files updated by another job: data/homer_files/HSF1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HSF1 --tissue Liver --predicted_motif_file data/homer_files/HSF1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HSF1_Liver --predictors_file data/predictor_files/HSF1_Liver.predictors.txt --ground_truth_file data/predictor_files/HSF1_Liver.ground_truth.txt --info_file data/predictor_files/HSF1_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 192 with external jobid 'Submitted batch job 11025111'.
[Sat Dec  2 00:07:07 2023]
Finished job 307.
289 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:07 2023]
Job 248: working on tf=HSF1,tissue=Bone
Reason: Input files updated by another job: data/homer_files/HSF1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HSF1 --tissue Bone --predicted_motif_file data/homer_files/HSF1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HSF1_Bone --predictors_file data/predictor_files/HSF1_Bone.predictors.txt --ground_truth_file data/predictor_files/HSF1_Bone.ground_truth.txt --info_file data/predictor_files/HSF1_Bone.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 248 with external jobid 'Submitted batch job 11025112'.
[Sat Dec  2 00:07:08 2023]
Finished job 445.
290 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:08 2023]
Job 139: working on tf=HSF1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/HSF1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HSF1 --tissue Colon --predicted_motif_file data/homer_files/HSF1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HSF1_Colon --predictors_file data/predictor_files/HSF1_Colon.predictors.txt --ground_truth_file data/predictor_files/HSF1_Colon.ground_truth.txt --info_file data/predictor_files/HSF1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 139 with external jobid 'Submitted batch job 11025113'.
[Sat Dec  2 00:07:09 2023]
Error in rule create_enformer_configuration:
    jobid: 343
    input: data/predictor_files/YY1_Colon.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025037

Error executing rule create_enformer_configuration on cluster (jobid: 343, external: Submitted batch job 11025037, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.343.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 343.
Select jobs to execute...

[Sat Dec  2 00:07:09 2023]
Job 116: working on tf=HSF1,tissue=Adipose
Reason: Input files updated by another job: data/homer_files/HSF1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HSF1 --tissue Adipose --predicted_motif_file data/homer_files/HSF1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HSF1_Adipose --predictors_file data/predictor_files/HSF1_Adipose.predictors.txt --ground_truth_file data/predictor_files/HSF1_Adipose.ground_truth.txt --info_file data/predictor_files/HSF1_Adipose.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 116 with external jobid 'Submitted batch job 11025114'.
[Sat Dec  2 00:07:10 2023]
Finished job 336.
291 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:10 2023]
Job 146: working on tf=CTCF,tissue=Skeletal-Muscle
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Skeletal-Muscle --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Skeletal-Muscle --predictors_file data/predictor_files/CTCF_Skeletal-Muscle.predictors.txt --ground_truth_file data/predictor_files/CTCF_Skeletal-Muscle.ground_truth.txt --info_file data/predictor_files/CTCF_Skeletal-Muscle.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 146 with external jobid 'Submitted batch job 11025115'.
[Sat Dec  2 00:07:26 2023]
Finished job 462.
292 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:26 2023]
Job 188: working on tf=CTCF,tissue=Esophagus
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Esophagus --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Esophagus --predictors_file data/predictor_files/CTCF_Esophagus.predictors.txt --ground_truth_file data/predictor_files/CTCF_Esophagus.ground_truth.txt --info_file data/predictor_files/CTCF_Esophagus.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 188 with external jobid 'Submitted batch job 11025116'.
[Sat Dec  2 00:07:27 2023]
Finished job 430.
293 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:27 2023]
Job 203: working on tf=CTCF,tissue=Spleen
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Spleen --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Spleen --predictors_file data/predictor_files/CTCF_Spleen.predictors.txt --ground_truth_file data/predictor_files/CTCF_Spleen.ground_truth.txt --info_file data/predictor_files/CTCF_Spleen.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 203 with external jobid 'Submitted batch job 11025117'.
[Sat Dec  2 00:07:29 2023]
Finished job 341.
294 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:29 2023]
Job 273: working on tf=CTCF,tissue=Cord-blood
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Cord-blood --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Cord-blood --predictors_file data/predictor_files/CTCF_Cord-blood.predictors.txt --ground_truth_file data/predictor_files/CTCF_Cord-blood.ground_truth.txt --info_file data/predictor_files/CTCF_Cord-blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 273 with external jobid 'Submitted batch job 11025118'.
[Sat Dec  2 00:07:30 2023]
Finished job 306.
295 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:30 2023]
Job 189: working on tf=CTCF,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Embryonic-Kidney --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Embryonic-Kidney --predictors_file data/predictor_files/CTCF_Embryonic-Kidney.predictors.txt --ground_truth_file data/predictor_files/CTCF_Embryonic-Kidney.ground_truth.txt --info_file data/predictor_files/CTCF_Embryonic-Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 189 with external jobid 'Submitted batch job 11025119'.
[Sat Dec  2 00:07:31 2023]
Finished job 363.
296 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:31 2023]
Job 106: working on tf=CTCF,tissue=Breast
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Breast --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Breast --predictors_file data/predictor_files/CTCF_Breast.predictors.txt --ground_truth_file data/predictor_files/CTCF_Breast.ground_truth.txt --info_file data/predictor_files/CTCF_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 106 with external jobid 'Submitted batch job 11025120'.
[Sat Dec  2 00:07:32 2023]
Finished job 322.
297 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:32 2023]
Job 204: working on tf=CTCF,tissue=Eye
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Eye --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Eye --predictors_file data/predictor_files/CTCF_Eye.predictors.txt --ground_truth_file data/predictor_files/CTCF_Eye.ground_truth.txt --info_file data/predictor_files/CTCF_Eye.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 204 with external jobid 'Submitted batch job 11025121'.
[Sat Dec  2 00:07:33 2023]
Finished job 364.
298 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:33 2023]
Job 135: working on tf=CTCF,tissue=Fetal-Liver
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Fetal-Liver --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Fetal-Liver --predictors_file data/predictor_files/CTCF_Fetal-Liver.predictors.txt --ground_truth_file data/predictor_files/CTCF_Fetal-Liver.ground_truth.txt --info_file data/predictor_files/CTCF_Fetal-Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 135 with external jobid 'Submitted batch job 11025122'.
[Sat Dec  2 00:07:34 2023]
Finished job 354.
299 of 1394 steps (21%) done
Select jobs to execute...

[Sat Dec  2 00:07:34 2023]
Job 94: working on tf=CTCF,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Embryo --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Embryo --predictors_file data/predictor_files/CTCF_Embryo.predictors.txt --ground_truth_file data/predictor_files/CTCF_Embryo.ground_truth.txt --info_file data/predictor_files/CTCF_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 94 with external jobid 'Submitted batch job 11025123'.
[Sat Dec  2 00:07:35 2023]
Finished job 376.
300 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:35 2023]
Job 95: working on tf=CTCF,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Cervix --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Cervix --predictors_file data/predictor_files/CTCF_Cervix.predictors.txt --ground_truth_file data/predictor_files/CTCF_Cervix.ground_truth.txt --info_file data/predictor_files/CTCF_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 95 with external jobid 'Submitted batch job 11025124'.
[Sat Dec  2 00:07:36 2023]
Finished job 355.
301 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:36 2023]
Job 193: working on tf=CTCF,tissue=Foreskin
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Foreskin --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Foreskin --predictors_file data/predictor_files/CTCF_Foreskin.predictors.txt --ground_truth_file data/predictor_files/CTCF_Foreskin.ground_truth.txt --info_file data/predictor_files/CTCF_Foreskin.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 193 with external jobid 'Submitted batch job 11025125'.
[Sat Dec  2 00:07:37 2023]
Finished job 356.
302 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:37 2023]
Job 194: working on tf=CTCF,tissue=Pulmonary-Artery
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Pulmonary-Artery --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Pulmonary-Artery --predictors_file data/predictor_files/CTCF_Pulmonary-Artery.predictors.txt --ground_truth_file data/predictor_files/CTCF_Pulmonary-Artery.ground_truth.txt --info_file data/predictor_files/CTCF_Pulmonary-Artery.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 194 with external jobid 'Submitted batch job 11025126'.
[Sat Dec  2 00:07:38 2023]
Finished job 454.
303 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:38 2023]
Job 153: working on tf=CTCF,tissue=Brain
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Brain --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Brain --predictors_file data/predictor_files/CTCF_Brain.predictors.txt --ground_truth_file data/predictor_files/CTCF_Brain.ground_truth.txt --info_file data/predictor_files/CTCF_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 153 with external jobid 'Submitted batch job 11025127'.
[Sat Dec  2 00:07:39 2023]
Finished job 461.
304 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:39 2023]
Job 111: working on tf=CTCF,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Bone-Marrow --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Bone-Marrow --predictors_file data/predictor_files/CTCF_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/CTCF_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/CTCF_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 111 with external jobid 'Submitted batch job 11025128'.
[Sat Dec  2 00:07:40 2023]
Finished job 357.
305 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:40 2023]
Job 98: working on tf=CTCF,tissue=Liver
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Liver --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Liver --predictors_file data/predictor_files/CTCF_Liver.predictors.txt --ground_truth_file data/predictor_files/CTCF_Liver.ground_truth.txt --info_file data/predictor_files/CTCF_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 98 with external jobid 'Submitted batch job 11025129'.
[Sat Dec  2 00:07:42 2023]
Finished job 323.
306 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:42 2023]
Job 112: working on tf=CTCF,tissue=Pancreatic-Islet
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Pancreatic-Islet --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Pancreatic-Islet --predictors_file data/predictor_files/CTCF_Pancreatic-Islet.predictors.txt --ground_truth_file data/predictor_files/CTCF_Pancreatic-Islet.ground_truth.txt --info_file data/predictor_files/CTCF_Pancreatic-Islet.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 112 with external jobid 'Submitted batch job 11025130'.
[Sat Dec  2 00:07:44 2023]
Finished job 346.
307 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:44 2023]
Job 196: working on tf=CTCF,tissue=Connective-Tissue
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Connective-Tissue --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Connective-Tissue --predictors_file data/predictor_files/CTCF_Connective-Tissue.predictors.txt --ground_truth_file data/predictor_files/CTCF_Connective-Tissue.ground_truth.txt --info_file data/predictor_files/CTCF_Connective-Tissue.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 196 with external jobid 'Submitted batch job 11025131'.
[Sat Dec  2 00:07:45 2023]
Finished job 416.
308 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:45 2023]
Job 252: working on tf=CTCF,tissue=gastroesophageal-sphincter
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue gastroesophageal-sphincter --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_gastroesophageal-sphincter --predictors_file data/predictor_files/CTCF_gastroesophageal-sphincter.predictors.txt --ground_truth_file data/predictor_files/CTCF_gastroesophageal-sphincter.ground_truth.txt --info_file data/predictor_files/CTCF_gastroesophageal-sphincter.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 252 with external jobid 'Submitted batch job 11025132'.
[Sat Dec  2 00:07:47 2023]
Finished job 319.
309 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:47 2023]
Job 113: working on tf=CTCF,tissue=Adipose
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Adipose --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Adipose --predictors_file data/predictor_files/CTCF_Adipose.predictors.txt --ground_truth_file data/predictor_files/CTCF_Adipose.ground_truth.txt --info_file data/predictor_files/CTCF_Adipose.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 113 with external jobid 'Submitted batch job 11025133'.
[Sat Dec  2 00:07:47 2023]
Error in rule create_enformer_configuration:
    jobid: 320
    input: data/predictor_files/MAX_Brain.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_MAX_Brain.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Brain.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025075

Error executing rule create_enformer_configuration on cluster (jobid: 320, external: Submitted batch job 11025075, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.320.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 320.
Select jobs to execute...

[Sat Dec  2 00:07:47 2023]
Job 253: working on tf=CTCF,tissue=Stomach
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Stomach --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Stomach --predictors_file data/predictor_files/CTCF_Stomach.predictors.txt --ground_truth_file data/predictor_files/CTCF_Stomach.ground_truth.txt --info_file data/predictor_files/CTCF_Stomach.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 253 with external jobid 'Submitted batch job 11025134'.
[Sat Dec  2 00:07:48 2023]
Finished job 370.
310 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:48 2023]
Job 267: working on tf=CTCF,tissue=Retina
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Retina --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Retina --predictors_file data/predictor_files/CTCF_Retina.predictors.txt --ground_truth_file data/predictor_files/CTCF_Retina.ground_truth.txt --info_file data/predictor_files/CTCF_Retina.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 267 with external jobid 'Submitted batch job 11025135'.
[Sat Dec  2 00:07:49 2023]
Finished job 202.
311 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:49 2023]
Job 141: working on tf=CTCF,tissue=Lung
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Lung --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Lung --predictors_file data/predictor_files/CTCF_Lung.predictors.txt --ground_truth_file data/predictor_files/CTCF_Lung.ground_truth.txt --info_file data/predictor_files/CTCF_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 141 with external jobid 'Submitted batch job 11025136'.
[Sat Dec  2 00:07:50 2023]
Finished job 205.
312 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:50 2023]
Job 100: working on tf=CTCF,tissue=Blood
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Blood --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Blood --predictors_file data/predictor_files/CTCF_Blood.predictors.txt --ground_truth_file data/predictor_files/CTCF_Blood.ground_truth.txt --info_file data/predictor_files/CTCF_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 100 with external jobid 'Submitted batch job 11025137'.
[Sat Dec  2 00:07:51 2023]
Finished job 130.
313 of 1394 steps (22%) done
Select jobs to execute...

[Sat Dec  2 00:07:51 2023]
Job 212: working on tf=CTCF,tissue=Endometrium
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Endometrium --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Endometrium --predictors_file data/predictor_files/CTCF_Endometrium.predictors.txt --ground_truth_file data/predictor_files/CTCF_Endometrium.ground_truth.txt --info_file data/predictor_files/CTCF_Endometrium.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 212 with external jobid 'Submitted batch job 11025138'.
[Sat Dec  2 00:07:55 2023]
Finished job 611.
314 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:07:55 2023]
Job 254: working on tf=CTCF,tissue=Sigmoid-Colon
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Sigmoid-Colon --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Sigmoid-Colon --predictors_file data/predictor_files/CTCF_Sigmoid-Colon.predictors.txt --ground_truth_file data/predictor_files/CTCF_Sigmoid-Colon.ground_truth.txt --info_file data/predictor_files/CTCF_Sigmoid-Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 11025139'.
[Sat Dec  2 00:08:30 2023]
Finished job 270.
315 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:30 2023]
Job 200: working on tf=CTCF,tissue=Kidney
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Kidney --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Kidney --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --ground_truth_file data/predictor_files/CTCF_Kidney.ground_truth.txt --info_file data/predictor_files/CTCF_Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 200 with external jobid 'Submitted batch job 11025153'.
[Sat Dec  2 00:08:40 2023]
Finished job 109.
316 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:40 2023]
Job 145: working on tf=CTCF,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Mammary-Gland --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Mammary-Gland --predictors_file data/predictor_files/CTCF_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/CTCF_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/CTCF_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 145 with external jobid 'Submitted batch job 11025154'.
[Sat Dec  2 00:08:41 2023]
Finished job 263.
317 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:41 2023]
Job 201: working on tf=CTCF,tissue=Pancreas
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Pancreas --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Pancreas --predictors_file data/predictor_files/CTCF_Pancreas.predictors.txt --ground_truth_file data/predictor_files/CTCF_Pancreas.ground_truth.txt --info_file data/predictor_files/CTCF_Pancreas.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 201 with external jobid 'Submitted batch job 11025155'.
[Sat Dec  2 00:08:42 2023]
Finished job 180.
318 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:42 2023]
Job 161: working on tf=CTCF,tissue=Colon
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Colon --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Colon --predictors_file data/predictor_files/CTCF_Colon.predictors.txt --ground_truth_file data/predictor_files/CTCF_Colon.ground_truth.txt --info_file data/predictor_files/CTCF_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 161 with external jobid 'Submitted batch job 11025156'.
[Sat Dec  2 00:08:43 2023]
Finished job 236.
319 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:43 2023]
Job 166: working on tf=CTCF,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Prostate --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Prostate --predictors_file data/predictor_files/CTCF_Prostate.predictors.txt --ground_truth_file data/predictor_files/CTCF_Prostate.ground_truth.txt --info_file data/predictor_files/CTCF_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 166 with external jobid 'Submitted batch job 11025157'.
[Sat Dec  2 00:08:44 2023]
Finished job 294.
320 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:44 2023]
Job 181: working on tf=CTCF,tissue=Bone
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Bone --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Bone --predictors_file data/predictor_files/CTCF_Bone.predictors.txt --ground_truth_file data/predictor_files/CTCF_Bone.ground_truth.txt --info_file data/predictor_files/CTCF_Bone.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 181 with external jobid 'Submitted batch job 11025158'.
[Sat Dec  2 00:08:45 2023]
Finished job 291.
321 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:45 2023]
Job 126: working on tf=CTCF,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Umbilical-Vein --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Umbilical-Vein --predictors_file data/predictor_files/CTCF_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/CTCF_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/CTCF_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 126 with external jobid 'Submitted batch job 11025159'.
[Sat Dec  2 00:08:46 2023]
Finished job 384.
322 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:46 2023]
Job 182: working on tf=CTCF,tissue=Fetal-Lung
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Fetal-Lung --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Fetal-Lung --predictors_file data/predictor_files/CTCF_Fetal-Lung.predictors.txt --ground_truth_file data/predictor_files/CTCF_Fetal-Lung.ground_truth.txt --info_file data/predictor_files/CTCF_Fetal-Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 182 with external jobid 'Submitted batch job 11025160'.
[Sat Dec  2 00:08:47 2023]
Finished job 279.
323 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:47 2023]
Job 127: working on tf=CTCF,tissue=Skin
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Skin --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Skin --predictors_file data/predictor_files/CTCF_Skin.predictors.txt --ground_truth_file data/predictor_files/CTCF_Skin.ground_truth.txt --info_file data/predictor_files/CTCF_Skin.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 127 with external jobid 'Submitted batch job 11025161'.
[Sat Dec  2 00:08:49 2023]
Finished job 377.
324 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:49 2023]
Job 183: working on tf=CTCF,tissue=Gingiva
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Gingiva --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Gingiva --predictors_file data/predictor_files/CTCF_Gingiva.predictors.txt --ground_truth_file data/predictor_files/CTCF_Gingiva.ground_truth.txt --info_file data/predictor_files/CTCF_Gingiva.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 183 with external jobid 'Submitted batch job 11025164'.
[Sat Dec  2 00:08:49 2023]
Finished job 400.
325 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:49 2023]
Job 185: working on tf=CTCF,tissue=Spinal-Cord
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Spinal-Cord --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Spinal-Cord --predictors_file data/predictor_files/CTCF_Spinal-Cord.predictors.txt --ground_truth_file data/predictor_files/CTCF_Spinal-Cord.ground_truth.txt --info_file data/predictor_files/CTCF_Spinal-Cord.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 185 with external jobid 'Submitted batch job 11025166'.
[Sat Dec  2 00:08:50 2023]
Finished job 381.
326 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:50 2023]
Job 186: working on tf=CTCF,tissue=Cerebellum
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Cerebellum --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Cerebellum --predictors_file data/predictor_files/CTCF_Cerebellum.predictors.txt --ground_truth_file data/predictor_files/CTCF_Cerebellum.ground_truth.txt --info_file data/predictor_files/CTCF_Cerebellum.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 186 with external jobid 'Submitted batch job 11025174'.
[Sat Dec  2 00:08:51 2023]
Finished job 147.
327 of 1394 steps (23%) done
Select jobs to execute...

[Sat Dec  2 00:08:51 2023]
Job 187: working on tf=CTCF,tissue=Heart
Reason: Input files updated by another job: data/homer_files/CTCF/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CTCF --tissue Heart --predicted_motif_file data/homer_files/CTCF/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CTCF_Heart --predictors_file data/predictor_files/CTCF_Heart.predictors.txt --ground_truth_file data/predictor_files/CTCF_Heart.ground_truth.txt --info_file data/predictor_files/CTCF_Heart.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 187 with external jobid 'Submitted batch job 11025185'.
[Sat Dec  2 00:08:52 2023]
Finished job 148.
328 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:08:52 2023]
Job 422: working on tf=GATA3,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/GATA3_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA3 --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA3_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA3_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 422 with external jobid 'Submitted batch job 11025186'.
[Sat Dec  2 00:08:53 2023]
Finished job 140.
329 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:08:53 2023]
Job 366: working on tf=GATA3,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/GATA3_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA3 --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA3_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA3_Mammary-Gland.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 366 with external jobid 'Submitted batch job 11025187'.
[Sat Dec  2 00:08:54 2023]
Finished job 154.
330 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:08:54 2023]
Job 295: working on tf=GATA3,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/GATA3_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA3 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA3_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA3_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 295 with external jobid 'Submitted batch job 11025188'.
[Sat Dec  2 00:08:55 2023]
Finished job 192.
331 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:08:55 2023]
Job 456: working on tf=GATA3,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/GATA3_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA3 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA3_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA3_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 456 with external jobid 'Submitted batch job 11025189'.
[Sat Dec  2 00:08:56 2023]
Finished job 248.
332 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:08:56 2023]
Job 388: working on tf=GATA3,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/GATA3_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA3 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA3_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA3_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 388 with external jobid 'Submitted batch job 11025190'.
[Sat Dec  2 00:08:57 2023]
Finished job 139.
333 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:08:57 2023]
Job 149: working on tf=REST,tissue=Blood
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Blood --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Blood --predictors_file data/predictor_files/REST_Blood.predictors.txt --ground_truth_file data/predictor_files/REST_Blood.ground_truth.txt --info_file data/predictor_files/REST_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 149 with external jobid 'Submitted batch job 11025191'.
[Sat Dec  2 00:08:58 2023]
Finished job 116.
334 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:08:58 2023]
Job 209: working on tf=REST,tissue=Lung
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Lung --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Lung --predictors_file data/predictor_files/REST_Lung.predictors.txt --ground_truth_file data/predictor_files/REST_Lung.ground_truth.txt --info_file data/predictor_files/REST_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 209 with external jobid 'Submitted batch job 11025192'.
[Sat Dec  2 00:08:59 2023]
Finished job 146.
335 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:08:59 2023]
Job 143: working on tf=REST,tissue=Adrenal-Gland
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Adrenal-Gland --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Adrenal-Gland --predictors_file data/predictor_files/REST_Adrenal-Gland.predictors.txt --ground_truth_file data/predictor_files/REST_Adrenal-Gland.ground_truth.txt --info_file data/predictor_files/REST_Adrenal-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 143 with external jobid 'Submitted batch job 11025193'.
[Sat Dec  2 00:09:00 2023]
Finished job 188.
336 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:09:00 2023]
Job 215: working on tf=REST,tissue=Endometrium
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Endometrium --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Endometrium --predictors_file data/predictor_files/REST_Endometrium.predictors.txt --ground_truth_file data/predictor_files/REST_Endometrium.ground_truth.txt --info_file data/predictor_files/REST_Endometrium.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 215 with external jobid 'Submitted batch job 11025194'.
[Sat Dec  2 00:09:01 2023]
Finished job 203.
337 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:09:01 2023]
Job 257: working on tf=REST,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Embryonic-Kidney --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Embryonic-Kidney --predictors_file data/predictor_files/REST_Embryonic-Kidney.predictors.txt --ground_truth_file data/predictor_files/REST_Embryonic-Kidney.ground_truth.txt --info_file data/predictor_files/REST_Embryonic-Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 257 with external jobid 'Submitted batch job 11025195'.
[Sat Dec  2 00:09:02 2023]
Finished job 273.
338 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:09:02 2023]
Job 231: working on tf=REST,tissue=Pancreas
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Pancreas --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Pancreas --predictors_file data/predictor_files/REST_Pancreas.predictors.txt --ground_truth_file data/predictor_files/REST_Pancreas.ground_truth.txt --info_file data/predictor_files/REST_Pancreas.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 231 with external jobid 'Submitted batch job 11025196'.
[Sat Dec  2 00:09:03 2023]
Finished job 189.
339 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:09:03 2023]
Job 375: working on tf=CTCF,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/predictor_files/CTCF_Embryonic-Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Embryonic-Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Embryonic-Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Embryonic-Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 375 with external jobid 'Submitted batch job 11025197'.
[Sat Dec  2 00:09:04 2023]
Finished job 106.
340 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:09:04 2023]
Job 292: working on tf=CTCF,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/CTCF_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 292 with external jobid 'Submitted batch job 11025198'.
[Sat Dec  2 00:09:05 2023]
Finished job 204.
341 of 1394 steps (24%) done
Select jobs to execute...

[Sat Dec  2 00:09:05 2023]
Job 232: working on tf=REST,tissue=Brain
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Brain --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Brain --predictors_file data/predictor_files/REST_Brain.predictors.txt --ground_truth_file data/predictor_files/REST_Brain.ground_truth.txt --info_file data/predictor_files/REST_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 232 with external jobid 'Submitted batch job 11025199'.
[Sat Dec  2 00:09:07 2023]
Finished job 135.
342 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:07 2023]
Job 163: working on tf=REST,tissue=Colon
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Colon --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Colon --predictors_file data/predictor_files/REST_Colon.predictors.txt --ground_truth_file data/predictor_files/REST_Colon.ground_truth.txt --info_file data/predictor_files/REST_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 163 with external jobid 'Submitted batch job 11025200'.
[Sat Dec  2 00:09:07 2023]
Finished job 94.
343 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:07 2023]
Job 280: working on tf=CTCF,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/CTCF_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 280 with external jobid 'Submitted batch job 11025201'.
[Sat Dec  2 00:09:09 2023]
Finished job 95.
344 of 1394 steps (25%) done
[Sat Dec  2 00:09:09 2023]
Finished job 193.
345 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:09 2023]
Job 221: working on tf=REST,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Cervix --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Cervix --predictors_file data/predictor_files/REST_Cervix.predictors.txt --ground_truth_file data/predictor_files/REST_Cervix.ground_truth.txt --info_file data/predictor_files/REST_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 221 with external jobid 'Submitted batch job 11025202'.

[Sat Dec  2 00:09:09 2023]
Job 219: working on tf=REST,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Embryo --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Embryo --predictors_file data/predictor_files/REST_Embryo.predictors.txt --ground_truth_file data/predictor_files/REST_Embryo.ground_truth.txt --info_file data/predictor_files/REST_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 219 with external jobid 'Submitted batch job 11025203'.
Select jobs to execute...
[Sat Dec  2 00:09:10 2023]
Finished job 194.
346 of 1394 steps (25%) done

[Sat Dec  2 00:09:10 2023]
Job 225: working on tf=REST,tissue=Liver
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Liver --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Liver --predictors_file data/predictor_files/REST_Liver.predictors.txt --ground_truth_file data/predictor_files/REST_Liver.ground_truth.txt --info_file data/predictor_files/REST_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 225 with external jobid 'Submitted batch job 11025208'.
[Sat Dec  2 00:09:11 2023]
Finished job 153.
347 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:11 2023]
Job 339: working on tf=CTCF,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/CTCF_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 339 with external jobid 'Submitted batch job 11025209'.
[Sat Dec  2 00:09:12 2023]
Finished job 111.
348 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:12 2023]
Job 297: working on tf=CTCF,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/CTCF_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 297 with external jobid 'Submitted batch job 11025210'.
[Sat Dec  2 00:09:13 2023]
Finished job 98.
349 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:13 2023]
Job 284: working on tf=CTCF,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/CTCF_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 284 with external jobid 'Submitted batch job 11025211'.
[Sat Dec  2 00:09:14 2023]
Finished job 112.
350 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:14 2023]
Job 129: working on tf=REST,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Bone-Marrow --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Bone-Marrow --predictors_file data/predictor_files/REST_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/REST_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/REST_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 129 with external jobid 'Submitted batch job 11025212'.
[Sat Dec  2 00:09:15 2023]
Finished job 196.
351 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:15 2023]
Job 228: working on tf=REST,tissue=Breast
Reason: Input files updated by another job: data/homer_files/REST/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor REST --tissue Breast --predicted_motif_file data/homer_files/REST/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/REST_Breast --predictors_file data/predictor_files/REST_Breast.predictors.txt --ground_truth_file data/predictor_files/REST_Breast.ground_truth.txt --info_file data/predictor_files/REST_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 228 with external jobid 'Submitted batch job 11025213'.
[Sat Dec  2 00:09:16 2023]
Finished job 252.
352 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:16 2023]
Job 281: working on tf=CTCF,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/CTCF_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Cervix --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cervix.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 281 with external jobid 'Submitted batch job 11025214'.
[Sat Dec  2 00:09:17 2023]
Finished job 113.
353 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:17 2023]
Job 316: working on tf=GATA3,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/GATA3_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA3 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA3_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA3_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 316 with external jobid 'Submitted batch job 11025215'.
[Sat Dec  2 00:09:18 2023]
Finished job 253.
354 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:18 2023]
Job 320: working on tf=MAX,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/MAX_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 320 with external jobid 'Submitted batch job 11025216'.
[Sat Dec  2 00:09:19 2023]
Finished job 267.
355 of 1394 steps (25%) done
Select jobs to execute...

[Sat Dec  2 00:09:19 2023]
Job 390: working on tf=CTCF,tissue=Eye
Reason: Input files updated by another job: data/predictor_files/CTCF_Eye.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Eye --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Eye.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Eye.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 390 with external jobid 'Submitted batch job 11025217'.
[Sat Dec  2 00:09:20 2023]
Finished job 141.
356 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:09:20 2023]
Job 327: working on tf=CTCF,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/CTCF_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 327 with external jobid 'Submitted batch job 11025218'.
[Sat Dec  2 00:09:22 2023]
Finished job 212.
357 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:09:22 2023]
Job 332: working on tf=CTCF,tissue=Skeletal-Muscle
Reason: Input files updated by another job: data/predictor_files/CTCF_Skeletal-Muscle.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Skeletal-Muscle --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Skeletal-Muscle.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skeletal-Muscle.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 332 with external jobid 'Submitted batch job 11025219'.
[Sat Dec  2 00:09:23 2023]
Finished job 254.
358 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:09:23 2023]
Job 321: working on tf=CTCF,tissue=Fetal-Liver
Reason: Input files updated by another job: data/predictor_files/CTCF_Fetal-Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Fetal-Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Fetal-Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Fetal-Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 321 with external jobid 'Submitted batch job 11025220'.
[Sat Dec  2 00:09:45 2023]
Finished job 632.
359 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:09:45 2023]
Job 380: working on tf=CTCF,tissue=Pulmonary-Artery
Reason: Input files updated by another job: data/predictor_files/CTCF_Pulmonary-Artery.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Pulmonary-Artery --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Pulmonary-Artery.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pulmonary-Artery.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 380 with external jobid 'Submitted batch job 11025225'.
[Sat Dec  2 00:10:19 2023]
Finished job 200.
360 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:19 2023]
Job 386: working on tf=CTCF,tissue=Kidney
Reason: Input files updated by another job: data/predictor_files/CTCF_Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 386 with external jobid 'Submitted batch job 11025239'.
[Sat Dec  2 00:10:29 2023]
Finished job 145.
361 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:29 2023]
Job 331: working on tf=CTCF,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/CTCF_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Mammary-Gland.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 331 with external jobid 'Submitted batch job 11025240'.
[Sat Dec  2 00:10:30 2023]
Finished job 201.
362 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:30 2023]
Job 387: working on tf=CTCF,tissue=Pancreas
Reason: Input files updated by another job: data/predictor_files/CTCF_Pancreas.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Pancreas --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Pancreas.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pancreas.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 387 with external jobid 'Submitted batch job 11025241'.
[Sat Dec  2 00:10:32 2023]
Finished job 161.
363 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:32 2023]
Job 347: working on tf=CTCF,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/CTCF_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 347 with external jobid 'Submitted batch job 11025242'.
[Sat Dec  2 00:10:32 2023]
Finished job 166.
364 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:32 2023]
Job 352: working on tf=CTCF,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/CTCF_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Prostate --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Prostate.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 352 with external jobid 'Submitted batch job 11025243'.
[Sat Dec  2 00:10:34 2023]
Finished job 181.
365 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:34 2023]
Job 367: working on tf=CTCF,tissue=Bone
Reason: Input files updated by another job: data/predictor_files/CTCF_Bone.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Bone --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Bone.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Bone.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 367 with external jobid 'Submitted batch job 11025244'.
[Sat Dec  2 00:10:34 2023]
Finished job 126.
366 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:34 2023]
Job 312: working on tf=CTCF,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/CTCF_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Umbilical-Vein.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 312 with external jobid 'Submitted batch job 11025245'.
[Sat Dec  2 00:10:35 2023]
Finished job 182.
367 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:35 2023]
Job 379: working on tf=CTCF,tissue=Foreskin
Reason: Input files updated by another job: data/predictor_files/CTCF_Foreskin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Foreskin --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Foreskin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Foreskin.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 379 with external jobid 'Submitted batch job 11025246'.
[Sat Dec  2 00:10:36 2023]
Finished job 127.
368 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:36 2023]
Job 313: working on tf=CTCF,tissue=Skin
Reason: Input files updated by another job: data/predictor_files/CTCF_Skin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Skin --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Skin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skin.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 313 with external jobid 'Submitted batch job 11025247'.
[Sat Dec  2 00:10:37 2023]
Finished job 183.
369 of 1394 steps (26%) done
Select jobs to execute...

[Sat Dec  2 00:10:37 2023]
Job 299: working on tf=CTCF,tissue=Adipose
Reason: Input files updated by another job: data/predictor_files/CTCF_Adipose.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Adipose --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Adipose.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Adipose.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 299 with external jobid 'Submitted batch job 11025248'.
[Sat Dec  2 00:10:38 2023]
Finished job 185.
370 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:38 2023]
Job 374: working on tf=CTCF,tissue=Esophagus
Reason: Input files updated by another job: data/predictor_files/CTCF_Esophagus.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Esophagus --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Esophagus.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Esophagus.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 374 with external jobid 'Submitted batch job 11025249'.
[Sat Dec  2 00:10:39 2023]
Finished job 186.
371 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:39 2023]
Job 371: working on tf=CTCF,tissue=Spinal-Cord
Reason: Input files updated by another job: data/predictor_files/CTCF_Spinal-Cord.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Spinal-Cord --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Spinal-Cord.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Spinal-Cord.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 371 with external jobid 'Submitted batch job 11025250'.
[Sat Dec  2 00:10:41 2023]
Finished job 187.
372 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:41 2023]
Job 373: working on tf=CTCF,tissue=Heart
Reason: Input files updated by another job: data/predictor_files/CTCF_Heart.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Heart --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Heart.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Heart.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 373 with external jobid 'Submitted batch job 11025251'.
[Sat Dec  2 00:10:41 2023]
Finished job 422.
373 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:41 2023]
Job 369: working on tf=CTCF,tissue=Gingiva
Reason: Input files updated by another job: data/predictor_files/CTCF_Gingiva.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Gingiva --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Gingiva.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Gingiva.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 369 with external jobid 'Submitted batch job 11025252'.
[Sat Dec  2 00:10:42 2023]
Finished job 366.
374 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:42 2023]
Job 372: working on tf=CTCF,tissue=Cerebellum
Reason: Input files updated by another job: data/predictor_files/CTCF_Cerebellum.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Cerebellum --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Cerebellum.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cerebellum.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 372 with external jobid 'Submitted batch job 11025253'.
[Sat Dec  2 00:10:43 2023]
Finished job 295.
375 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:43 2023]
Job 382: working on tf=CTCF,tissue=Connective-Tissue
Reason: Input files updated by another job: data/predictor_files/CTCF_Connective-Tissue.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Connective-Tissue --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Connective-Tissue.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Connective-Tissue.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 382 with external jobid 'Submitted batch job 11025254'.
[Sat Dec  2 00:10:44 2023]
Finished job 456.
376 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:44 2023]
Job 389: working on tf=CTCF,tissue=Spleen
Reason: Input files updated by another job: data/predictor_files/CTCF_Spleen.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Spleen --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Spleen.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Spleen.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 389 with external jobid 'Submitted batch job 11025255'.
[Sat Dec  2 00:10:45 2023]
Finished job 388.
377 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:45 2023]
Job 368: working on tf=CTCF,tissue=Fetal-Lung
Reason: Input files updated by another job: data/predictor_files/CTCF_Fetal-Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Fetal-Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Fetal-Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Fetal-Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 368 with external jobid 'Submitted batch job 11025256'.
[Sat Dec  2 00:10:46 2023]
Finished job 149.
378 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:46 2023]
Job 453: working on tf=CTCF,tissue=Retina
Reason: Input files updated by another job: data/predictor_files/CTCF_Retina.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Retina --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Retina.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Retina.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 453 with external jobid 'Submitted batch job 11025261'.
[Sat Dec  2 00:10:47 2023]
Finished job 209.
379 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:47 2023]
Job 438: working on tf=CTCF,tissue=gastroesophageal-sphincter
Reason: Input files updated by another job: data/predictor_files/CTCF_gastroesophageal-sphincter.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue gastroesophageal-sphincter --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_gastroesophageal-sphincter.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_gastroesophageal-sphincter.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 438 with external jobid 'Submitted batch job 11025262'.
[Sat Dec  2 00:10:48 2023]
Finished job 143.
380 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:48 2023]
Job 298: working on tf=CTCF,tissue=Pancreatic-Islet
Reason: Input files updated by another job: data/predictor_files/CTCF_Pancreatic-Islet.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Pancreatic-Islet --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Pancreatic-Islet.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pancreatic-Islet.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 298 with external jobid 'Submitted batch job 11025263'.
[Sat Dec  2 00:10:50 2023]
Finished job 215.
381 of 1394 steps (27%) done
[Sat Dec  2 00:10:50 2023]
Finished job 257.
382 of 1394 steps (27%) done
Select jobs to execute...

[Sat Dec  2 00:10:50 2023]
Job 439: working on tf=CTCF,tissue=Stomach
Reason: Input files updated by another job: data/predictor_files/CTCF_Stomach.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Stomach --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Stomach.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Stomach.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 439 with external jobid 'Submitted batch job 11025264'.

[Sat Dec  2 00:10:51 2023]
Job 398: working on tf=CTCF,tissue=Endometrium
Reason: Input files updated by another job: data/predictor_files/CTCF_Endometrium.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Endometrium --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Endometrium.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Endometrium.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 398 with external jobid 'Submitted batch job 11025265'.
Select jobs to execute...
[Sat Dec  2 00:10:52 2023]
Finished job 231.
383 of 1394 steps (27%) done

[Sat Dec  2 00:10:52 2023]
Job 391: working on tf=GATA3,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/GATA3_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA3 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA3_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA3_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 391 with external jobid 'Submitted batch job 11025266'.
[Sat Dec  2 00:10:53 2023]
Finished job 375.
384 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:10:53 2023]
Job 440: working on tf=CTCF,tissue=Sigmoid-Colon
Reason: Input files updated by another job: data/predictor_files/CTCF_Sigmoid-Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Sigmoid-Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Sigmoid-Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Sigmoid-Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 440 with external jobid 'Submitted batch job 11025267'.
[Sat Dec  2 00:10:53 2023]
Finished job 292.
385 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:10:53 2023]
Job 434: working on tf=HSF1,tissue=Bone
Reason: Input files updated by another job: data/predictor_files/HSF1_Bone.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Bone --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Bone.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 434 with external jobid 'Submitted batch job 11025269'.
[Sat Dec  2 00:10:55 2023]
Finished job 232.
386 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:10:55 2023]
Job 338: working on tf=MAX,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/MAX_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MAX --tissue Cervix --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/MAX_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MAX_Cervix.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 338 with external jobid 'Submitted batch job 11025270'.
[Sat Dec  2 00:10:55 2023]
Finished job 163.
387 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:10:55 2023]
Job 459: working on tf=CTCF,tissue=Cord-blood
Reason: Input files updated by another job: data/predictor_files/CTCF_Cord-blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Cord-blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Cord-blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cord-blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 459 with external jobid 'Submitted batch job 11025271'.
[Sat Dec  2 00:10:56 2023]
Finished job 280.
388 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:10:56 2023]
Job 283: working on tf=STAT1,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/STAT1_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT1 --tissue Cervix --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT1_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT1_Cervix.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 283 with external jobid 'Submitted batch job 11025272'.
[Sat Dec  2 00:10:57 2023]
Finished job 221.
389 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:10:57 2023]
Job 449: working on tf=GATA3,tissue=Thymus
Reason: Input files updated by another job: data/predictor_files/GATA3_Thymus.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GATA3 --tissue Thymus --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/GATA3_Thymus.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GATA3_Thymus.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 449 with external jobid 'Submitted batch job 11025273'.
[Sat Dec  2 00:10:58 2023]
Finished job 219.
390 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:10:58 2023]
Job 305: working on tf=STAT1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/STAT1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT1_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 305 with external jobid 'Submitted batch job 11025274'.
[Sat Dec  2 00:10:59 2023]
Finished job 225.
391 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:10:59 2023]
Job 383: working on tf=STAT1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/STAT1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT1_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 383 with external jobid 'Submitted batch job 11025275'.
[Sat Dec  2 00:11:00 2023]
Finished job 339.
392 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:11:00 2023]
Job 405: working on tf=REST,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/REST_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Embryo --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Embryo.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 405 with external jobid 'Submitted batch job 11025276'.
[Sat Dec  2 00:11:01 2023]
Finished job 297.
393 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:11:01 2023]
Job 335: working on tf=REST,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/REST_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 335 with external jobid 'Submitted batch job 11025277'.
[Sat Dec  2 00:11:02 2023]
Finished job 284.
394 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:11:02 2023]
Job 418: working on tf=REST,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/REST_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 418 with external jobid 'Submitted batch job 11025278'.
[Sat Dec  2 00:11:03 2023]
Finished job 129.
395 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:11:03 2023]
Job 401: working on tf=REST,tissue=Endometrium
Reason: Input files updated by another job: data/predictor_files/REST_Endometrium.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Endometrium --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Endometrium.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Endometrium.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 401 with external jobid 'Submitted batch job 11025279'.
[Sat Dec  2 00:11:04 2023]
Finished job 228.
396 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:11:04 2023]
Job 315: working on tf=REST,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/REST_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 315 with external jobid 'Submitted batch job 11025280'.
[Sat Dec  2 00:11:05 2023]
Finished job 281.
397 of 1394 steps (28%) done
Select jobs to execute...

[Sat Dec  2 00:11:05 2023]
Job 414: working on tf=REST,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/REST_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 414 with external jobid 'Submitted batch job 11025281'.
[Sat Dec  2 00:11:06 2023]
Finished job 316.
398 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:11:06 2023]
Job 343: working on tf=YY1,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/YY1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor YY1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/YY1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 343 with external jobid 'Submitted batch job 11025282'.
[Sat Dec  2 00:11:07 2023]
Finished job 320.
399 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:11:07 2023]
Job 407: working on tf=REST,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/REST_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Cervix --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Cervix.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 407 with external jobid 'Submitted batch job 11025283'.
[Sat Dec  2 00:11:08 2023]
Finished job 390.
400 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:11:08 2023]
Job 417: working on tf=REST,tissue=Pancreas
Reason: Input files updated by another job: data/predictor_files/REST_Pancreas.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Pancreas --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Pancreas.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Pancreas.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 417 with external jobid 'Submitted batch job 11025284'.
[Sat Dec  2 00:11:09 2023]
Finished job 327.
401 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:11:09 2023]
Job 334: working on tf=HSF1,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/HSF1_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Mammary-Gland.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 334 with external jobid 'Submitted batch job 11025285'.
[Sat Dec  2 00:11:10 2023]
Finished job 332.
402 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:11:10 2023]
Job 443: working on tf=REST,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/predictor_files/REST_Embryonic-Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Embryonic-Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Embryonic-Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Embryonic-Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 443 with external jobid 'Submitted batch job 11025286'.
[Sat Dec  2 00:11:12 2023]
Finished job 321.
403 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:11:12 2023]
Job 411: working on tf=REST,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/REST_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 411 with external jobid 'Submitted batch job 11025287'.
[Sat Dec  2 00:11:12 2023]
Finished job 380.
404 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:11:12 2023]
Job 395: working on tf=REST,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/REST_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 395 with external jobid 'Submitted batch job 11025288'.
[Sat Dec  2 00:11:14 2023]
Finished job 100.
405 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:11:14 2023]
Job 286: working on tf=CTCF,tissue=Blood
Reason: Missing output files: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Blood.json; Input files updated by another job: data/predictor_files/CTCF_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Blood --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Blood.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 286 with external jobid 'Submitted batch job 11025289'.
[Sat Dec  2 00:12:08 2023]
Error in rule create_enformer_configuration:
    jobid: 386
    input: data/predictor_files/CTCF_Kidney.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025239

Error executing rule create_enformer_configuration on cluster (jobid: 386, external: Submitted batch job 11025239, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.386.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 386.
Select jobs to execute...

[Sat Dec  2 00:12:08 2023]
Job 386: working on tf=CTCF,tissue=Kidney
Reason: Input files updated by another job: data/predictor_files/CTCF_Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 386 with external jobid 'Submitted batch job 11025321'.
[Sat Dec  2 00:12:18 2023]
Finished job 331.
406 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:12:18 2023]
Job 349: working on tf=REST,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/REST_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 349 with external jobid 'Submitted batch job 11025323'.
[Sat Dec  2 00:12:19 2023]
Finished job 387.
407 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:12:19 2023]
Job 326: working on tf=HSF1,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/HSF1_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Breast --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Breast.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 326 with external jobid 'Submitted batch job 11025324'.
[Sat Dec  2 00:12:20 2023]
Finished job 347.
408 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:12:20 2023]
Job 329: working on tf=REST,tissue=Adrenal-Gland
Reason: Input files updated by another job: data/predictor_files/REST_Adrenal-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Adrenal-Gland --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Adrenal-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Adrenal-Gland.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 329 with external jobid 'Submitted batch job 11025325'.
[Sat Dec  2 00:12:21 2023]
Finished job 352.
409 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:12:21 2023]
Job 333: working on tf=HSF1,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/HSF1_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 333 with external jobid 'Submitted batch job 11025326'.
[Sat Dec  2 00:12:22 2023]
Finished job 367.
410 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:12:22 2023]
Job 340: working on tf=HSF1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/HSF1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 340 with external jobid 'Submitted batch job 11025327'.
[Sat Dec  2 00:12:23 2023]
Finished job 312.
411 of 1394 steps (29%) done
Select jobs to execute...

[Sat Dec  2 00:12:23 2023]
Job 378: working on tf=HSF1,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/HSF1_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Liver --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Liver.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 378 with external jobid 'Submitted batch job 11025328'.
[Sat Dec  2 00:12:24 2023]
Finished job 379.
412 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:24 2023]
Job 325: working on tf=HSF1,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/HSF1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 325 with external jobid 'Submitted batch job 11025329'.
[Sat Dec  2 00:12:25 2023]
Error in rule create_enformer_configuration:
    jobid: 313
    input: data/predictor_files/CTCF_Skin.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skin.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Skin --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Skin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skin.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025247

Error executing rule create_enformer_configuration on cluster (jobid: 313, external: Submitted batch job 11025247, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.313.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 313.
Select jobs to execute...

[Sat Dec  2 00:12:25 2023]
Job 313: working on tf=CTCF,tissue=Skin
Reason: Input files updated by another job: data/predictor_files/CTCF_Skin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Skin --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Skin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skin.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 313 with external jobid 'Submitted batch job 11025330'.
[Sat Dec  2 00:12:26 2023]
Finished job 299.
413 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:26 2023]
Job 302: working on tf=HSF1,tissue=Adipose
Reason: Input files updated by another job: data/predictor_files/HSF1_Adipose.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Adipose --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Adipose.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Adipose.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 302 with external jobid 'Submitted batch job 11025331'.
[Sat Dec  2 00:12:27 2023]
Finished job 374.
414 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:27 2023]
Job 542: working on STAT3_Peritoneal-Effusion
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Peritoneal-Effusion.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Peritoneal-Effusion.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Peritoneal-Effusion.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 542 with external jobid 'Submitted batch job 11025332'.
[Sat Dec  2 00:12:28 2023]
Finished job 371.
415 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:28 2023]
Job 566: working on CTCF_Pulmonary-Artery
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Pulmonary-Artery.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pulmonary-Artery.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pulmonary-Artery.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 566 with external jobid 'Submitted batch job 11025333'.
[Sat Dec  2 00:12:29 2023]
Finished job 373.
416 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:29 2023]
Job 561: working on CTCF_Embryonic-Kidney
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Embryonic-Kidney.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Embryonic-Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Embryonic-Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 561 with external jobid 'Submitted batch job 11025334'.
[Sat Dec  2 00:12:30 2023]
Finished job 369.
417 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:30 2023]
Job 640: working on STAT3_Umbilical-Cord
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Umbilical-Cord.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Umbilical-Cord.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Umbilical-Cord.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 640 with external jobid 'Submitted batch job 11025335'.
[Sat Dec  2 00:12:31 2023]
Finished job 372.
418 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:31 2023]
Job 518: working on CTCF_Skeletal-Muscle
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Skeletal-Muscle.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skeletal-Muscle.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skeletal-Muscle.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 518 with external jobid 'Submitted batch job 11025336'.
[Sat Dec  2 00:12:32 2023]
Finished job 382.
419 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:32 2023]
Job 568: working on CTCF_Connective-Tissue
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Connective-Tissue.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Connective-Tissue.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Connective-Tissue.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 568 with external jobid 'Submitted batch job 11025337'.
[Sat Dec  2 00:12:35 2023]
Finished job 389.
420 of 1394 steps (30%) done
[Sat Dec  2 00:12:35 2023]
Finished job 368.
421 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:35 2023]
Job 631: working on YY1_Embryonic-Kidney
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Embryonic-Kidney.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Embryonic-Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Embryonic-Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 631 with external jobid 'Submitted batch job 11025338'.

[Sat Dec  2 00:12:35 2023]
Job 498: working on CTCF_Umbilical-Vein
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Umbilical-Vein.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 498 with external jobid 'Submitted batch job 11025339'.
Select jobs to execute...
[Sat Dec  2 00:12:35 2023]
Finished job 453.
422 of 1394 steps (30%) done

[Sat Dec  2 00:12:35 2023]
Job 552: working on GATA3_Mammary-Gland
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA3_Mammary-Gland.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA3_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA3_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 552 with external jobid 'Submitted batch job 11025340'.
[Sat Dec  2 00:12:37 2023]
Finished job 438.
423 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:37 2023]
Job 624: working on CTCF_gastroesophageal-sphincter
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_gastroesophageal-sphincter.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_gastroesophageal-sphincter.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_gastroesophageal-sphincter.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 624 with external jobid 'Submitted batch job 11025341'.
[Sat Dec  2 00:12:37 2023]
Finished job 298.
424 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:37 2023]
Job 484: working on CTCF_Pancreatic-Islet
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Pancreatic-Islet.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pancreatic-Islet.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pancreatic-Islet.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 484 with external jobid 'Submitted batch job 11025342'.
[Sat Dec  2 00:12:38 2023]
Error in rule create_enformer_configuration:
    jobid: 439
    input: data/predictor_files/CTCF_Stomach.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Stomach.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Stomach --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Stomach.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Stomach.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025264

Error executing rule create_enformer_configuration on cluster (jobid: 439, external: Submitted batch job 11025264, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.439.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 439.
Select jobs to execute...

[Sat Dec  2 00:12:38 2023]
Job 439: working on tf=CTCF,tissue=Stomach
Reason: Input files updated by another job: data/predictor_files/CTCF_Stomach.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Stomach --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Stomach.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Stomach.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 439 with external jobid 'Submitted batch job 11025343'.
[Sat Dec  2 00:12:40 2023]
Finished job 398.
425 of 1394 steps (30%) done
Select jobs to execute...

[Sat Dec  2 00:12:40 2023]
Job 567: working on MAX_Umbilical-Vein
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Umbilical-Vein.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 567 with external jobid 'Submitted batch job 11025344'.
[Sat Dec  2 00:12:40 2023]
Finished job 391.
426 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:40 2023]
Job 517: working on CTCF_Mammary-Gland
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Mammary-Gland.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 517 with external jobid 'Submitted batch job 11025345'.
[Sat Dec  2 00:12:41 2023]
Finished job 440.
427 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:41 2023]
Job 626: working on CTCF_Sigmoid-Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Sigmoid-Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Sigmoid-Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Sigmoid-Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 626 with external jobid 'Submitted batch job 11025346'.
[Sat Dec  2 00:12:42 2023]
Finished job 434.
428 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:42 2023]
Job 540: working on STAT3_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 540 with external jobid 'Submitted batch job 11025347'.
[Sat Dec  2 00:12:43 2023]
Finished job 338.
429 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:43 2023]
Job 574: working on GATA3_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA3_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA3_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA3_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 574 with external jobid 'Submitted batch job 11025348'.
[Sat Dec  2 00:12:45 2023]
Finished job 459.
430 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:45 2023]
Job 483: working on CTCF_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 483 with external jobid 'Submitted batch job 11025349'.
[Sat Dec  2 00:12:46 2023]
Finished job 283.
431 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:46 2023]
Job 507: working on CTCF_Fetal-Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Fetal-Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Fetal-Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Fetal-Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 507 with external jobid 'Submitted batch job 11025350'.
[Sat Dec  2 00:12:46 2023]
Finished job 449.
432 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:46 2023]
Job 584: working on CTCF_Endometrium
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Endometrium.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Endometrium.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Endometrium.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 584 with external jobid 'Submitted batch job 11025351'.
[Sat Dec  2 00:12:48 2023]
Finished job 305.
433 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:48 2023]
Job 543: working on STAT3_Lymph-Node
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Lymph-Node.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Lymph-Node.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 543 with external jobid 'Submitted batch job 11025352'.
[Sat Dec  2 00:12:48 2023]
Finished job 383.
434 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:48 2023]
Job 569: working on STAT1_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 569 with external jobid 'Submitted batch job 11025353'.
[Sat Dec  2 00:12:49 2023]
Finished job 405.
435 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:49 2023]
Job 557: working on CTCF_Spinal-Cord
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Spinal-Cord.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Spinal-Cord.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 557 with external jobid 'Submitted batch job 11025354'.
[Sat Dec  2 00:12:50 2023]
Finished job 335.
436 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:50 2023]
Job 554: working on CTCF_Fetal-Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Fetal-Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Fetal-Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Fetal-Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 554 with external jobid 'Submitted batch job 11025355'.
[Sat Dec  2 00:12:51 2023]
Finished job 418.
437 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:51 2023]
Job 570: working on MAX_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 570 with external jobid 'Submitted batch job 11025356'.
[Sat Dec  2 00:12:52 2023]
Finished job 401.
438 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:52 2023]
Job 587: working on REST_Endometrium
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Endometrium.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Endometrium.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Endometrium.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 587 with external jobid 'Submitted batch job 11025357'.
[Sat Dec  2 00:12:53 2023]
Finished job 315.
439 of 1394 steps (31%) done
Select jobs to execute...

[Sat Dec  2 00:12:53 2023]
Job 501: working on REST_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 501 with external jobid 'Submitted batch job 11025358'.
[Sat Dec  2 00:12:55 2023]
Finished job 414.
440 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:12:55 2023]
Job 586: working on MAX_Endometrium
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Endometrium.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Endometrium.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Endometrium.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 586 with external jobid 'Submitted batch job 11025359'.
[Sat Dec  2 00:12:55 2023]
Finished job 343.
441 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:12:55 2023]
Job 558: working on CTCF_Cerebellum
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Cerebellum.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cerebellum.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cerebellum.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 558 with external jobid 'Submitted batch job 11025360'.
[Sat Dec  2 00:12:57 2023]
Finished job 407.
442 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:12:57 2023]
Job 645: working on CTCF_Cord-blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Cord-blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cord-blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cord-blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 645 with external jobid 'Submitted batch job 11025361'.
[Sat Dec  2 00:12:57 2023]
Finished job 417.
443 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:12:57 2023]
Job 477: working on FOXA1_Prostate
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Prostate.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 477 with external jobid 'Submitted batch job 11025362'.
[Sat Dec  2 00:12:59 2023]
Finished job 334.
444 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:12:59 2023]
Job 520: working on HSF1_Mammary-Gland
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HSF1_Mammary-Gland.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HSF1_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 520 with external jobid 'Submitted batch job 11025363'.
[Sat Dec  2 00:12:59 2023]
Finished job 443.
445 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:12:59 2023]
Job 629: working on REST_Embryonic-Kidney
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Embryonic-Kidney.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Embryonic-Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Embryonic-Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 629 with external jobid 'Submitted batch job 11025364'.
[Sat Dec  2 00:13:00 2023]
Finished job 411.
446 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:13:00 2023]
Job 560: working on CTCF_Esophagus
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Esophagus.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Esophagus.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Esophagus.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 560 with external jobid 'Submitted batch job 11025365'.
[Sat Dec  2 00:13:02 2023]
Error in rule create_enformer_configuration:
    jobid: 395
    input: data/predictor_files/REST_Lung.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025288

Error executing rule create_enformer_configuration on cluster (jobid: 395, external: Submitted batch job 11025288, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.395.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 395.
Select jobs to execute...

[Sat Dec  2 00:13:02 2023]
Job 395: working on tf=REST,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/REST_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 395 with external jobid 'Submitted batch job 11025366'.
[Sat Dec  2 00:13:02 2023]
Finished job 286.
447 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:13:02 2023]
Job 603: working on REST_Pancreas
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Pancreas.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Pancreas.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Pancreas.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 603 with external jobid 'Submitted batch job 11025367'.
[Sat Dec  2 00:13:26 2023]
Finished job 468.
448 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:13:26 2023]
Job 565: working on CTCF_Foreskin
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Foreskin.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Foreskin.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Foreskin.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 565 with external jobid 'Submitted batch job 11025370'.
[Sat Dec  2 00:13:27 2023]
Finished job 622.
449 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:13:27 2023]
Job 538: working on CTCF_Prostate
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Prostate.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 538 with external jobid 'Submitted batch job 11025371'.
[Sat Dec  2 00:13:58 2023]
Error in rule create_enformer_configuration:
    jobid: 386
    input: data/predictor_files/CTCF_Kidney.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025321

Error executing rule create_enformer_configuration on cluster (jobid: 386, external: Submitted batch job 11025321, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.386.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 386.
Select jobs to execute...

[Sat Dec  2 00:13:58 2023]
Job 386: working on tf=CTCF,tissue=Kidney
Reason: Input files updated by another job: data/predictor_files/CTCF_Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 386 with external jobid 'Submitted batch job 11025378'.
[Sat Dec  2 00:14:08 2023]
Finished job 349.
450 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:14:08 2023]
Job 573: working on CTCF_Pancreas
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Pancreas.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pancreas.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Pancreas.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 573 with external jobid 'Submitted batch job 11025382'.
[Sat Dec  2 00:14:09 2023]
Finished job 326.
451 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:14:09 2023]
Job 481: working on GATA3_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA3_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA3_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA3_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 481 with external jobid 'Submitted batch job 11025383'.
[Sat Dec  2 00:14:10 2023]
Finished job 329.
452 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:14:10 2023]
Job 515: working on REST_Adrenal-Gland
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Adrenal-Gland.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Adrenal-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Adrenal-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 515 with external jobid 'Submitted batch job 11025384'.
[Sat Dec  2 00:14:11 2023]
Finished job 333.
453 of 1394 steps (32%) done
Select jobs to execute...

[Sat Dec  2 00:14:11 2023]
Job 485: working on CTCF_Adipose
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Adipose.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Adipose.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Adipose.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 485 with external jobid 'Submitted batch job 11025385'.
[Sat Dec  2 00:14:12 2023]
Error in rule create_enformer_configuration:
    jobid: 340
    input: data/predictor_files/HSF1_Bone-Marrow.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone-Marrow.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone-Marrow.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025327

Error executing rule create_enformer_configuration on cluster (jobid: 340, external: Submitted batch job 11025327, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.340.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 340.
Select jobs to execute...

[Sat Dec  2 00:14:12 2023]
Job 340: working on tf=HSF1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/HSF1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HSF1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/HSF1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone-Marrow.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 340 with external jobid 'Submitted batch job 11025386'.
[Sat Dec  2 00:14:13 2023]
Finished job 378.
454 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:14:13 2023]
Job 616: working on STAT3_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 616 with external jobid 'Submitted batch job 11025387'.
[Sat Dec  2 00:14:14 2023]
Finished job 325.
455 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:14:14 2023]
Job 509: working on STAT3_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 509 with external jobid 'Submitted batch job 11025388'.
[Sat Dec  2 00:14:15 2023]
Finished job 313.
456 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:14:15 2023]
Job 635: working on GATA3_Thymus
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA3_Thymus.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA3_Thymus.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA3_Thymus.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 635 with external jobid 'Submitted batch job 11025389'.
[Sat Dec  2 00:14:16 2023]
Finished job 302.
457 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:14:16 2023]
Job 488: working on HSF1_Adipose
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HSF1_Adipose.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Adipose.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HSF1_Adipose.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 488 with external jobid 'Submitted batch job 11025390'.
[Sat Dec  2 00:14:28 2023]
Finished job 439.
458 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:14:28 2023]
Job 469: working on STAT1_Cervix
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Cervix.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 469 with external jobid 'Submitted batch job 11025391'.
[Sat Dec  2 00:14:51 2023]
Error in rule create_enformer_configuration:
    jobid: 395
    input: data/predictor_files/REST_Lung.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025366

Error executing rule create_enformer_configuration on cluster (jobid: 395, external: Submitted batch job 11025366, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.395.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 395.
Select jobs to execute...

[Sat Dec  2 00:14:51 2023]
Job 395: working on tf=REST,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/REST_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 395 with external jobid 'Submitted batch job 11025481'.
[Sat Dec  2 00:15:17 2023]
Finished job 637.
459 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:15:17 2023]
Job 623: working on RUNX1_Pleura
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Pleura.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Pleura.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Pleura.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 623 with external jobid 'Submitted batch job 11025498'.
[Sat Dec  2 00:15:20 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11024888

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11024888, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.
Select jobs to execute...

[Sat Dec  2 00:15:20 2023]
Job 638: working on RUNX1_Breast
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 638 with external jobid 'Submitted batch job 11025499'.
[Sat Dec  2 00:15:47 2023]
Error in rule create_enformer_configuration:
    jobid: 386
    input: data/predictor_files/CTCF_Kidney.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025378

Error executing rule create_enformer_configuration on cluster (jobid: 386, external: Submitted batch job 11025378, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.386.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 386.
Select jobs to execute...

[Sat Dec  2 00:15:47 2023]
Job 386: working on tf=CTCF,tissue=Kidney
Reason: Input files updated by another job: data/predictor_files/CTCF_Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 386 with external jobid 'Submitted batch job 11025507'.
[Sat Dec  2 00:16:01 2023]
Finished job 340.
460 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:16:01 2023]
Job 526: working on HSF1_Bone-Marrow
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HSF1_Bone-Marrow.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 526 with external jobid 'Submitted batch job 11025511'.
[Sat Dec  2 00:16:07 2023]
Error in rule create_enformer_configuration:
    jobid: 395
    input: data/predictor_files/REST_Lung.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025481

Error executing rule create_enformer_configuration on cluster (jobid: 395, external: Submitted batch job 11025481, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.395.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 395.
Select jobs to execute...

[Sat Dec  2 00:16:07 2023]
Job 395: working on tf=REST,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/REST_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 395 with external jobid 'Submitted batch job 11025512'.
[Sat Dec  2 00:17:05 2023]
Finished job 598.
461 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:17:05 2023]
Job 555: working on CTCF_Gingiva
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Gingiva.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Gingiva.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Gingiva.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 555 with external jobid 'Submitted batch job 11025513'.
[Sat Dec  2 00:17:36 2023]
Error in rule create_enformer_configuration:
    jobid: 386
    input: data/predictor_files/CTCF_Kidney.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025507

Error executing rule create_enformer_configuration on cluster (jobid: 386, external: Submitted batch job 11025507, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.386.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 386.
Select jobs to execute...

[Sat Dec  2 00:17:36 2023]
Job 386: working on tf=CTCF,tissue=Kidney
Reason: Input files updated by another job: data/predictor_files/CTCF_Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 386 with external jobid 'Submitted batch job 11025538'.
[Sat Dec  2 00:17:47 2023]
Error in rule create_enformer_configuration:
    jobid: 395
    input: data/predictor_files/REST_Lung.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025512

Error executing rule create_enformer_configuration on cluster (jobid: 395, external: Submitted batch job 11025512, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.395.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 395.
Select jobs to execute...

[Sat Dec  2 00:17:47 2023]
Job 395: working on tf=REST,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/REST_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor REST --tissue Lung --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/REST_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 395 with external jobid 'Submitted batch job 11025543'.
[Sat Dec  2 00:18:54 2023]
Finished job 496.
462 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:18:54 2023]
Job 625: working on CTCF_Stomach
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Stomach.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Stomach.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Stomach.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 625 with external jobid 'Submitted batch job 11025547'.
[Sat Dec  2 00:18:59 2023]
Finished job 539.
463 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:18:59 2023]
Job 642: working on GATA3_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA3_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA3_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA3_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 642 with external jobid 'Submitted batch job 11025548'.
[Sat Dec  2 00:19:01 2023]
Finished job 530.
464 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:19:01 2023]
Job 548: working on FOXM1_Cervix
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Cervix.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 548 with external jobid 'Submitted batch job 11025549'.
[Sat Dec  2 00:19:25 2023]
Error in rule create_enformer_configuration:
    jobid: 386
    input: data/predictor_files/CTCF_Kidney.predictors.txt
    output: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11025538

Error executing rule create_enformer_configuration on cluster (jobid: 386, external: Submitted batch job 11025538, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.create_enformer_configuration.386.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 386.
Select jobs to execute...

[Sat Dec  2 00:19:25 2023]
Job 386: working on tf=CTCF,tissue=Kidney
Reason: Input files updated by another job: data/predictor_files/CTCF_Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CTCF --tissue Kidney --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/CTCF_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 386 with external jobid 'Submitted batch job 11025556'.
[Sat Dec  2 00:19:35 2023]
Finished job 395.
465 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:19:35 2023]
Job 562: working on STAT3_Cervix
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Cervix.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 562 with external jobid 'Submitted batch job 11025604'.
[Sat Dec  2 00:21:14 2023]
Finished job 386.
466 of 1394 steps (33%) done
Select jobs to execute...

[Sat Dec  2 00:21:14 2023]
Job 549: working on SOX2_Thyroid
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Thyroid.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Thyroid.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Thyroid.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 549 with external jobid 'Submitted batch job 11025679'.
[Sat Dec  2 00:22:42 2023]
Finished job 487.
467 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:22:42 2023]
Job 480: working on FOXA1_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 480 with external jobid 'Submitted batch job 11025695'.
[Sat Dec  2 00:24:27 2023]
Finished job 479.
468 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:24:27 2023]
Job 495: working on PPARG_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_PPARG_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_PPARG_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_PPARG_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 495 with external jobid 'Submitted batch job 11025757'.
[Sat Dec  2 00:24:28 2023]
Finished job 551.
469 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:24:28 2023]
Job 593: working on REST_Cervix
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Cervix.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 593 with external jobid 'Submitted batch job 11025758'.
[Sat Dec  2 00:33:33 2023]
Finished job 523.
470 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:33:33 2023]
Job 607: working on FOXM1_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 607 with external jobid 'Submitted batch job 11025841'.
[Sat Dec  2 00:37:16 2023]
Finished job 630.
471 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:37:16 2023]
Job 497: working on FOXA1_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 497 with external jobid 'Submitted batch job 11025888'.
[Sat Dec  2 00:39:06 2023]
Finished job 590.
472 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:39:06 2023]
Job 608: working on GATA3_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA3_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA3_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA3_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 608 with external jobid 'Submitted batch job 11025904'.
[Sat Dec  2 00:42:47 2023]
Finished job 580.
473 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:42:47 2023]
Job 486: working on FOXA2_Liver
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 486 with external jobid 'Submitted batch job 11025930'.
[Sat Dec  2 00:42:49 2023]
Finished job 628.
474 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:42:49 2023]
Job 500: working on GATA2_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA2_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA2_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA2_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 500 with external jobid 'Submitted batch job 11025931'.
[Sat Dec  2 00:53:41 2023]
Finished job 471.
475 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:53:41 2023]
Job 502: working on GATA3_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA3_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA3_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA3_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 502 with external jobid 'Submitted batch job 11026042'.
[Sat Dec  2 00:53:44 2023]
Finished job 592.
476 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:53:44 2023]
Job 600: working on REST_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 600 with external jobid 'Submitted batch job 11026045'.
[Sat Dec  2 00:53:45 2023]
Finished job 599.
477 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:53:45 2023]
Job 491: working on STAT1_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 491 with external jobid 'Submitted batch job 11026048'.
[Sat Dec  2 00:55:31 2023]
Finished job 473.
478 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:55:31 2023]
Job 464: working on RUNX1_Blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 464 with external jobid 'Submitted batch job 11026067'.
[Sat Dec  2 00:55:35 2023]
Finished job 595.
479 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:55:35 2023]
Job 492: working on SOX2_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 492 with external jobid 'Submitted batch job 11026075'.
[Sat Dec  2 00:55:35 2023]
Finished job 531.
480 of 1394 steps (34%) done
Select jobs to execute...

[Sat Dec  2 00:55:35 2023]
Job 466: working on CTCF_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 466 with external jobid 'Submitted batch job 11026076'.
[Sat Dec  2 00:57:24 2023]
Finished job 617.
481 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 00:57:24 2023]
Job 467: working on CTCF_Cervix
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Cervix.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 467 with external jobid 'Submitted batch job 11026088'.
[Sat Dec  2 00:59:14 2023]
Finished job 494.
482 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 00:59:14 2023]
Job 512: working on HSF1_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HSF1_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HSF1_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 512 with external jobid 'Submitted batch job 11026114'.
[Sat Dec  2 01:08:25 2023]
Finished job 627.
483 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:08:25 2023]
Job 541: working on STAT3_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 541 with external jobid 'Submitted batch job 11026193'.
[Sat Dec  2 01:15:40 2023]
Finished job 649.
484 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:15:40 2023]
Job 639: working on CTCF_Retina
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Retina.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Retina.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Retina.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 639 with external jobid 'Submitted batch job 11026247'.
[Sat Dec  2 01:26:37 2023]
Finished job 601.
485 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:26:37 2023]
Job 528: working on FOXA1_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 528 with external jobid 'Submitted batch job 11026340'.
[Sat Dec  2 01:30:12 2023]
Finished job 474.
486 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:30:12 2023]
Job 544: working on FOXA2_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA2_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 544 with external jobid 'Submitted batch job 11026373'.
[Sat Dec  2 01:39:19 2023]
Finished job 615.
487 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:39:19 2023]
Job 572: working on CTCF_Kidney
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Kidney.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 572 with external jobid 'Submitted batch job 11026453'.
[Sat Dec  2 01:43:02 2023]
Finished job 596.
488 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:43:02 2023]
Job 546: working on RUNX1_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_RUNX1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 546 with external jobid 'Submitted batch job 11026481'.
[Sat Dec  2 01:44:50 2023]
Finished job 606.
489 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:44:50 2023]
Job 589: working on FOXM1_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 589 with external jobid 'Submitted batch job 11026498'.
[Sat Dec  2 01:46:20 2023]
Finished job 636.
490 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:46:20 2023]
Job 478: working on CTCF_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 478 with external jobid 'Submitted batch job 11026514'.
[Sat Dec  2 01:48:31 2023]
Finished job 578.
491 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:48:31 2023]
Job 575: working on CTCF_Spleen
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Spleen.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Spleen.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Spleen.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 575 with external jobid 'Submitted batch job 11026527'.
[Sat Dec  2 01:50:00 2023]
Finished job 618.
492 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:50:00 2023]
Job 591: working on REST_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 591 with external jobid 'Submitted batch job 11026545'.
[Sat Dec  2 01:55:30 2023]
Finished job 634.
493 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:55:30 2023]
Job 648: working on STAT1_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 648 with external jobid 'Submitted batch job 11026587'.
[Sat Dec  2 01:55:47 2023]
Finished job 619.
494 of 1394 steps (35%) done
Select jobs to execute...

[Sat Dec  2 01:55:47 2023]
Job 610: working on PPARG_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_PPARG_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_PPARG_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_PPARG_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 610 with external jobid 'Submitted batch job 11026588'.
[Sat Dec  2 01:57:34 2023]
Finished job 646.
495 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 01:57:34 2023]
Job 597: working on REST_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 597 with external jobid 'Submitted batch job 11026606'.
[Sat Dec  2 01:59:24 2023]
Finished job 609.
496 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 01:59:24 2023]
Job 503: working on YY1_Cervix
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Cervix.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 503 with external jobid 'Submitted batch job 11026625'.
[Sat Dec  2 02:01:02 2023]
Finished job 585.
497 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:01:02 2023]
Job 504: working on FOXM1_Bone
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Bone.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Bone.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Bone.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 504 with external jobid 'Submitted batch job 11026638'.
[Sat Dec  2 02:02:55 2023]
Finished job 643.
498 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:02:55 2023]
Job 602: working on MAX_Breast
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Breast.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 602 with external jobid 'Submitted batch job 11026664'.
[Sat Dec  2 02:04:42 2023]
Finished job 583.
499 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:04:42 2023]
Job 604: working on REST_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 604 with external jobid 'Submitted batch job 11026672'.
[Sat Dec  2 02:06:33 2023]
Finished job 588.
500 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:06:33 2023]
Job 522: working on FOXA2_Lung
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 522 with external jobid 'Submitted batch job 11026692'.
[Sat Dec  2 02:08:23 2023]
Finished job 490.
501 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:08:23 2023]
Job 564: working on HSF1_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HSF1_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HSF1_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 564 with external jobid 'Submitted batch job 11026707'.
[Sat Dec  2 02:08:24 2023]
Finished job 612.
502 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:08:24 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11026708'.
[Sat Dec  2 02:10:20 2023]
Finished job 582.
503 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:10:20 2023]
Job 524: working on MAX_Cervix
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Cervix.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 524 with external jobid 'Submitted batch job 11026735'.
[Sat Dec  2 02:17:31 2023]
Finished job 571.
504 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:17:31 2023]
Job 511: working on HSF1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HSF1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HSF1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 511 with external jobid 'Submitted batch job 11026794'.
[Sat Dec  2 02:21:09 2023]
Finished job 475.
505 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:21:09 2023]
Job 525: working on CTCF_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 525 with external jobid 'Submitted batch job 11026829'.
[Sat Dec  2 02:27:49 2023]
Finished job 542.
506 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:27:49 2023]
Job 470: working on CTCF_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 470 with external jobid 'Submitted batch job 11026866'.
[Sat Dec  2 02:35:47 2023]
Finished job 644.
507 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:35:47 2023]
Job 527: working on SOX2_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 527 with external jobid 'Submitted batch job 11026942'.
[Sat Dec  2 02:46:37 2023]
Finished job 633.
508 of 1394 steps (36%) done
Select jobs to execute...

[Sat Dec  2 02:46:37 2023]
Job 472: working on CTCF_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 472 with external jobid 'Submitted batch job 11027040'.
[Sat Dec  2 02:49:43 2023]
Finished job 640.
509 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 02:49:43 2023]
Job 514: working on FOXA1_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA1_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 514 with external jobid 'Submitted batch job 11027069'.
[Sat Dec  2 02:50:16 2023]
Finished job 482.
510 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 02:50:16 2023]
Job 556: working on MAX_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 556 with external jobid 'Submitted batch job 11027070'.
[Sat Dec  2 02:57:00 2023]
Finished job 566.
511 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 02:57:00 2023]
Job 641: working on FOXA2_Skin
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Skin.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXA2_Skin.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 641 with external jobid 'Submitted batch job 11027116'.
[Sat Dec  2 03:02:31 2023]
Finished job 631.
512 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:02:31 2023]
Job 516: working on YY1_Embryo
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Embryo.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 516 with external jobid 'Submitted batch job 11027173'.
[Sat Dec  2 03:03:01 2023]
Finished job 489.
513 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:03:01 2023]
Job 559: working on CTCF_Heart
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Heart.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Heart.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Heart.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 559 with external jobid 'Submitted batch job 11027174'.
[Sat Dec  2 03:08:32 2023]
Finished job 510.
514 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:08:32 2023]
Job 533: working on CTCF_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 533 with external jobid 'Submitted batch job 11027220'.
[Sat Dec  2 03:11:37 2023]
Finished job 561.
515 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:11:37 2023]
Job 647: working on STAT3_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 647 with external jobid 'Submitted batch job 11027252'.
[Sat Dec  2 03:12:10 2023]
Finished job 614.
516 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:12:10 2023]
Job 577: working on GATA3_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_GATA3_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GATA3_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GATA3_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 577 with external jobid 'Submitted batch job 11027253'.
[Sat Dec  2 03:17:07 2023]
Finished job 568.
517 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:17:07 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:07 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:07 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:07 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:08 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:08 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:08 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:08 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:08 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:08 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 521.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 521: working on REST_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Blood.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:09 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 535.
Select jobs to execute...

[Sat Dec  2 03:17:10 2023]
Job 535: working on REST_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Select jobs to execute...

[Sat Dec  2 03:17:10 2023]
Job 594: working on YY1_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Liver.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 594.
Select jobs to execute...

[Sat Dec  2 03:17:10 2023]
Job 594: working on YY1_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 594 with external jobid 'Submitted batch job 11027293'.
[Sat Dec  2 03:20:45 2023]
Finished job 518.
518 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:20:45 2023]
Job 499: working on CTCF_Skin
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Skin.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skin.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Skin.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 499 with external jobid 'Submitted batch job 11027323'.
[Sat Dec  2 03:23:05 2023]
Finished job 613.
519 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:23:05 2023]
Job 506: working on MAX_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 506 with external jobid 'Submitted batch job 11027340'.
[Sat Dec  2 03:31:46 2023]
Finished job 567.
520 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:31:46 2023]
Job 493: working on YY1_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 493 with external jobid 'Submitted batch job 11027421'.
[Sat Dec  2 03:35:24 2023]
Finished job 484.
521 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:35:24 2023]
Job 465: working on MAX_Blood
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Blood.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 465 with external jobid 'Submitted batch job 11027438'.
[Sat Dec  2 03:37:12 2023]
Finished job 498.
522 of 1394 steps (37%) done
Select jobs to execute...

[Sat Dec  2 03:37:12 2023]
Job 605: working on YY1_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 605 with external jobid 'Submitted batch job 11027453'.
[Sat Dec  2 03:39:05 2023]
Finished job 626.
523 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 03:39:05 2023]
Job 508: working on SOX2_Skin
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Skin.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Skin.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Skin.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 508 with external jobid 'Submitted batch job 11027477'.
[Sat Dec  2 03:39:06 2023]
Finished job 540.
524 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 03:39:06 2023]
Job 550: working on SOX2_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 550 with external jobid 'Submitted batch job 11027478'.
[Sat Dec  2 03:50:05 2023]
Finished job 543.
525 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 03:50:05 2023]
Job 620: working on HSF1_Bone
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HSF1_Bone.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HSF1_Bone.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 620 with external jobid 'Submitted batch job 11027578'.
[Sat Dec  2 03:51:50 2023]
Finished job 624.
526 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 03:51:50 2023]
Job 553: working on CTCF_Bone
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Bone.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Bone.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Bone.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 553 with external jobid 'Submitted batch job 11027599'.
[Sat Dec  2 03:53:40 2023]
Finished job 517.
527 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:40 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 581.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 581: working on REST_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_REST_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_REST_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:41 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 513.
Select jobs to execute...

[Sat Dec  2 03:53:42 2023]
Job 513: working on CTCF_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Lung.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Select jobs to execute...

[Sat Dec  2 03:53:42 2023]
Job 529: working on YY1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 529.
Select jobs to execute...

[Sat Dec  2 03:53:42 2023]
Job 529: working on YY1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 529.
Select jobs to execute...

[Sat Dec  2 03:53:42 2023]
Job 529: working on YY1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 529.
Select jobs to execute...

[Sat Dec  2 03:53:42 2023]
Job 529: working on YY1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 529.
Select jobs to execute...

[Sat Dec  2 03:53:42 2023]
Job 529: working on YY1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 529.
Select jobs to execute...

[Sat Dec  2 03:53:42 2023]
Job 529: working on YY1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json
        
sbatch: error: Verify job submission ...
sbatch: error: Partition: beagle3
sbatch: error: QOS-Flag: beagle3
sbatch: error: Account: pi-haky
sbatch: error: Verification: ***PASSED***
sbatch: error: QOSMaxSubmitJobPerUserLimit
sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)
Error submitting jobscript (exit code 1):

Trying to restart job 529.
Select jobs to execute...

[Sat Dec  2 03:53:42 2023]
Job 529: working on YY1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 529 with external jobid 'Submitted batch job 11027608'.
[Sat Dec  2 03:57:23 2023]
Finished job 569.
528 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 03:57:23 2023]
Job 532: working on MAX_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 532 with external jobid 'Submitted batch job 11027631'.
[Sat Dec  2 04:02:50 2023]
Finished job 584.
529 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 04:02:50 2023]
Job 519: working on HSF1_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HSF1_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HSF1_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HSF1_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 519 with external jobid 'Submitted batch job 11027680'.
[Sat Dec  2 04:06:26 2023]
Finished job 552.
530 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 04:06:26 2023]
Job 563: working on MAX_Liver
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Liver.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 563 with external jobid 'Submitted batch job 11027705'.
[Sat Dec  2 04:08:18 2023]
Finished job 507.
531 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 04:08:18 2023]
Job 505: working on MAX_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_MAX_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MAX_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MAX_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 505 with external jobid 'Submitted batch job 11027729'.
[Sat Dec  2 04:10:12 2023]
Finished job 501.
532 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 04:10:12 2023]
Job 579: working on YY1_Lung
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_YY1_Lung.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_YY1_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_YY1_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 579 with external jobid 'Submitted batch job 11027740'.
[Sat Dec  2 04:11:57 2023]
Finished job 483.
533 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 04:11:57 2023]
Job 576: working on CTCF_Eye
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_CTCF_Eye.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CTCF_Eye.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CTCF_Eye.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 576 with external jobid 'Submitted batch job 11027759'.
[Sat Dec  2 04:12:01 2023]
Finished job 587.
534 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 04:12:01 2023]
Job 822: working on tf=FOXA1,tissue=endometrioid-adenocarcinoma
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_endometrioid-adenocarcinoma.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 822 with external jobid 'Submitted batch job 11027760'.
[Sat Dec  2 04:13:47 2023]
Finished job 574.
535 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 04:13:47 2023]
Job 810: working on tf=CTCF,tissue=gastroesophageal-sphincter
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_gastroesophageal-sphincter.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 810 with external jobid 'Submitted batch job 11027773'.
[Sat Dec  2 04:16:03 2023]
Finished job 822.
536 of 1394 steps (38%) done
Select jobs to execute...

[Sat Dec  2 04:16:03 2023]
Job 1008: preparing tf=FOXA1,tissue=endometrioid-adenocarcinoma training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.csv.gz, data/predictor_files/FOXA1_endometrioid-adenocarcinoma.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.csv.gz --ground_truth_file data/predictor_files/FOXA1_endometrioid-adenocarcinoma.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1008 with external jobid 'Submitted batch job 11027790'.
[Sat Dec  2 04:17:33 2023]
Finished job 520.
537 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:17:33 2023]
Job 728: working on tf=STAT3,tissue=Peritoneal-Effusion
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Peritoneal-Effusion.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Peritoneal-Effusion.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 728 with external jobid 'Submitted batch job 11027798'.
[Sat Dec  2 04:17:50 2023]
Finished job 1008.
538 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:17:50 2023]
Job 1194: training on tf=FOXA1,tissue=endometrioid-adenocarcinoma training data
Reason: Missing output files: output/models/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.linear.rds, output/models/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1194 with external jobid 'Submitted batch job 11027799'.
[Sat Dec  2 04:19:40 2023]
Finished job 1194.
539 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:19:40 2023]
Job 1380: evaluating on tf=FOXA1,tissue=endometrioid-adenocarcinoma training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz, output/models/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.linear.rds --logistic_model output/models/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_endometrioid-adenocarcinoma.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_endometrioid-adenocarcinoma_2023-12-01/aggByCollect_FOXA1_endometrioid-adenocarcinoma
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1380 with external jobid 'Submitted batch job 11027815'.
[Sat Dec  2 04:21:29 2023]
Finished job 1380.
540 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:21:29 2023]
Job 819: working on tf=FOXA1,tissue=Pancreatic-ductal
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Pancreatic-ductal.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Pancreatic-ductal.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 819 with external jobid 'Submitted batch job 11027826'.
[Sat Dec  2 04:21:30 2023]
Finished job 728.
541 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:21:30 2023]
Job 914: preparing tf=STAT3,tissue=Peritoneal-Effusion training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT3_Peritoneal-Effusion.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT3_Peritoneal-Effusion.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Peritoneal-Effusion.csv.gz --ground_truth_file data/predictor_files/STAT3_Peritoneal-Effusion.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 914 with external jobid 'Submitted batch job 11027827'.
[Sat Dec  2 04:21:31 2023]
Finished job 810.
542 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:21:31 2023]
Job 996: preparing tf=CTCF,tissue=gastroesophageal-sphincter training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.csv.gz, data/predictor_files/CTCF_gastroesophageal-sphincter.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.csv.gz --ground_truth_file data/predictor_files/CTCF_gastroesophageal-sphincter.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 996 with external jobid 'Submitted batch job 11027828'.
[Sat Dec  2 04:22:56 2023]
Finished job 554.
543 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:22:56 2023]
Job 804: working on tf=FOXM1,tissue=Embryonic-Kidney
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Embryonic-Kidney.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Embryonic-Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 804 with external jobid 'Submitted batch job 11027846'.
[Sat Dec  2 04:23:02 2023]
Finished job 629.
544 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:23:02 2023]
Job 754: working on tf=CTCF,tissue=Connective-Tissue
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Connective-Tissue.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Connective-Tissue.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 754 with external jobid 'Submitted batch job 11027847'.
[Sat Dec  2 04:23:19 2023]
Finished job 914.
545 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:23:19 2023]
Job 1100: training on tf=STAT3,tissue=Peritoneal-Effusion training data
Reason: Missing output files: output/models/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.logistic.rds, output/models/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1100 with external jobid 'Submitted batch job 11027851'.
[Sat Dec  2 04:25:07 2023]
Finished job 1100.
546 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:25:07 2023]
Job 1286: evaluating on tf=STAT3,tissue=Peritoneal-Effusion training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.logistic.rds, output/models/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.linear.rds --logistic_model output/models/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Peritoneal-Effusion.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Peritoneal-Effusion_2023-12-01/aggByCollect_STAT3_Peritoneal-Effusion
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1286 with external jobid 'Submitted batch job 11027863'.
[Sat Dec  2 04:25:09 2023]
Finished job 996.
547 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:25:09 2023]
Job 1182: training on tf=CTCF,tissue=gastroesophageal-sphincter training data
Reason: Missing output files: output/models/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.logistic.rds, output/models/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz --rds_file output/models/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1182 with external jobid 'Submitted batch job 11027864'.
[Sat Dec  2 04:26:56 2023]
Finished job 1286.
548 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:26:56 2023]
Job 747: working on tf=CTCF,tissue=Embryonic-Kidney
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Embryonic-Kidney.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Embryonic-Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 747 with external jobid 'Submitted batch job 11027878'.
[Sat Dec  2 04:26:59 2023]
Finished job 804.
549 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:26:59 2023]
Job 990: preparing tf=FOXM1,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Embryonic-Kidney.csv.gz, data/predictor_files/FOXM1_Embryonic-Kidney.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Embryonic-Kidney.csv.gz --ground_truth_file data/predictor_files/FOXM1_Embryonic-Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 990 with external jobid 'Submitted batch job 11027881'.
[Sat Dec  2 04:28:31 2023]
Finished job 603.
550 of 1394 steps (39%) done
Select jobs to execute...

[Sat Dec  2 04:28:31 2023]
Job 752: working on tf=CTCF,tissue=Pulmonary-Artery
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Pulmonary-Artery.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Pulmonary-Artery.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 752 with external jobid 'Submitted batch job 11027898'.
[Sat Dec  2 04:28:46 2023]
Finished job 990.
551 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:28:46 2023]
Job 670: working on tf=CTCF,tissue=Pancreatic-Islet
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Pancreatic-Islet.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Pancreatic-Islet.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 670 with external jobid 'Submitted batch job 11027899'.
[Sat Dec  2 04:28:48 2023]
Finished job 1182.
552 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:28:48 2023]
Job 1368: evaluating on tf=CTCF,tissue=gastroesophageal-sphincter training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz, output/models/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.linear.rds, output/models/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.linear.rds --logistic_model output/models/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_gastroesophageal-sphincter.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_gastroesophageal-sphincter_2023-12-01/aggByCollect_CTCF_gastroesophageal-sphincter
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1368 with external jobid 'Submitted batch job 11027900'.
[Sat Dec  2 04:30:16 2023]
Finished job 586.
553 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:30:16 2023]
Job 1176: training on tf=FOXM1,tissue=Embryonic-Kidney training data
Reason: Missing output files: output/models/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.logistic.rds, output/models/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz --rds_file output/models/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1176 with external jobid 'Submitted batch job 11027910'.
[Sat Dec  2 04:32:25 2023]
Finished job 1176.
554 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:32:25 2023]
Job 1362: evaluating on tf=FOXM1,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.logistic.rds, output/models/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.linear.rds --logistic_model output/models/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Embryonic-Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXM1_Embryonic-Kidney_2023-12-01/aggByCollect_FOXM1_Embryonic-Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1362 with external jobid 'Submitted batch job 11027946'.
[Sat Dec  2 04:32:29 2023]
Finished job 754.
555 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:32:29 2023]
Job 940: preparing tf=CTCF,tissue=Connective-Tissue training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Connective-Tissue.csv.gz, data/predictor_files/CTCF_Connective-Tissue.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Connective-Tissue.csv.gz --ground_truth_file data/predictor_files/CTCF_Connective-Tissue.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 940 with external jobid 'Submitted batch job 11027947'.
[Sat Dec  2 04:35:43 2023]
Finished job 557.
556 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:35:43 2023]
Job 815: working on tf=REST,tissue=Embryonic-Kidney
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Embryonic-Kidney.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Embryonic-Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 815 with external jobid 'Submitted batch job 11027971'.
[Sat Dec  2 04:37:35 2023]
Finished job 645.
557 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:37:35 2023]
Job 816: working on tf=SP1,tissue=Embryonic-Kidney
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SP1_Embryonic-Kidney.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SP1_Embryonic-Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 816 with external jobid 'Submitted batch job 11027988'.
[Sat Dec  2 04:37:53 2023]
Finished job 1362.
558 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:37:53 2023]
Job 817: working on tf=YY1,tissue=Embryonic-Kidney
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Embryonic-Kidney.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Embryonic-Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 817 with external jobid 'Submitted batch job 11028000'.
[Sat Dec  2 04:37:56 2023]
Finished job 1368.
559 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:37:56 2023]
Job 657: working on tf=GATA2,tissue=Umbilical-Vein
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA2_Umbilical-Vein.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA2_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 657 with external jobid 'Submitted batch job 11028001'.
[Sat Dec  2 04:37:57 2023]
Finished job 747.
560 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:37:57 2023]
Job 933: preparing tf=CTCF,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Embryonic-Kidney.csv.gz, data/predictor_files/CTCF_Embryonic-Kidney.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Embryonic-Kidney.csv.gz --ground_truth_file data/predictor_files/CTCF_Embryonic-Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 933 with external jobid 'Submitted batch job 11028002'.
[Sat Dec  2 04:37:58 2023]
Finished job 752.
561 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:37:58 2023]
Job 938: preparing tf=CTCF,tissue=Pulmonary-Artery training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Pulmonary-Artery.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Pulmonary-Artery.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Pulmonary-Artery.csv.gz --ground_truth_file data/predictor_files/CTCF_Pulmonary-Artery.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 938 with external jobid 'Submitted batch job 11028003'.
[Sat Dec  2 04:37:59 2023]
Finished job 819.
562 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:37:59 2023]
Job 1005: preparing tf=FOXA1,tissue=Pancreatic-ductal training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Pancreatic-ductal.csv.gz, data/predictor_files/FOXA1_Pancreatic-ductal.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Pancreatic-ductal.csv.gz --ground_truth_file data/predictor_files/FOXA1_Pancreatic-ductal.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1005 with external jobid 'Submitted batch job 11028004'.
[Sat Dec  2 04:39:24 2023]
Finished job 558.
563 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:39:24 2023]
Job 826: working on tf=STAT3,tissue=Umbilical-Cord
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Umbilical-Cord.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Umbilical-Cord.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 826 with external jobid 'Submitted batch job 11028008'.
[Sat Dec  2 04:39:48 2023]
Finished job 940.
564 of 1394 steps (40%) done
Select jobs to execute...

[Sat Dec  2 04:39:48 2023]
Job 1126: training on tf=CTCF,tissue=Connective-Tissue training data
Reason: Missing output files: output/models/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.logistic.rds, output/models/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1126 with external jobid 'Submitted batch job 11028019'.
[Sat Dec  2 04:39:49 2023]
Finished job 670.
565 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:39:49 2023]
Job 856: preparing tf=CTCF,tissue=Pancreatic-Islet training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Pancreatic-Islet.csv.gz, data/predictor_files/CTCF_Pancreatic-Islet.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Pancreatic-Islet.csv.gz --ground_truth_file data/predictor_files/CTCF_Pancreatic-Islet.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 856 with external jobid 'Submitted batch job 11028020'.
[Sat Dec  2 04:41:38 2023]
Finished job 815.
566 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:41:38 2023]
Job 1001: preparing tf=REST,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_REST_Embryonic-Kidney.csv.gz, data/predictor_files/REST_Embryonic-Kidney.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Embryonic-Kidney.csv.gz --ground_truth_file data/predictor_files/REST_Embryonic-Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1001 with external jobid 'Submitted batch job 11028027'.
[Sat Dec  2 04:42:53 2023]
Finished job 515.
567 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:42:53 2023]
Job 704: working on tf=CTCF,tissue=Skeletal-Muscle
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Skeletal-Muscle.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Skeletal-Muscle.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 704 with external jobid 'Submitted batch job 11028034'.
[Sat Dec  2 04:43:22 2023]
Finished job 817.
568 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:43:22 2023]
Job 1003: preparing tf=YY1,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz; Input files updated by another job: data/predictor_files/YY1_Embryonic-Kidney.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_YY1_Embryonic-Kidney.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Embryonic-Kidney.csv.gz --ground_truth_file data/predictor_files/YY1_Embryonic-Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1003 with external jobid 'Submitted batch job 11028040'.
[Sat Dec  2 04:43:24 2023]
Finished job 933.
569 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:43:24 2023]
Job 818: working on tf=E2F1,tissue=Umbilical-Cord
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_E2F1_Umbilical-Cord.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_E2F1_Umbilical-Cord.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 818 with external jobid 'Submitted batch job 11028041'.
[Sat Dec  2 04:43:28 2023]
Finished job 816.
570 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:43:28 2023]
Job 1002: preparing tf=SP1,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_SP1_Embryonic-Kidney.csv.gz, data/predictor_files/SP1_Embryonic-Kidney.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SP1_Embryonic-Kidney.csv.gz --ground_truth_file data/predictor_files/SP1_Embryonic-Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1002 with external jobid 'Submitted batch job 11028045'.
[Sat Dec  2 04:45:12 2023]
Finished job 1126.
571 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:45:12 2023]
Job 1119: training on tf=CTCF,tissue=Embryonic-Kidney training data
Reason: Missing output files: output/models/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.linear.rds, output/models/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1119 with external jobid 'Submitted batch job 11028060'.
[Sat Dec  2 04:45:14 2023]
Finished job 657.
572 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:45:14 2023]
Job 1312: evaluating on tf=CTCF,tissue=Connective-Tissue training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz, output/models/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.logistic.rds, output/models/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.linear.rds --logistic_model output/models/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Connective-Tissue.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Connective-Tissue_2023-12-01/aggByCollect_CTCF_Connective-Tissue
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1312 with external jobid 'Submitted batch job 11028061'.
[Sat Dec  2 04:45:15 2023]
Finished job 938.
573 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:45:15 2023]
Job 843: preparing tf=GATA2,tissue=Umbilical-Vein training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Umbilical-Vein.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Umbilical-Vein.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/GATA2_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 843 with external jobid 'Submitted batch job 11028062'.
[Sat Dec  2 04:45:17 2023]
Finished job 826.
574 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:45:17 2023]
Job 1012: preparing tf=STAT3,tissue=Umbilical-Cord training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT3_Umbilical-Cord.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT3_Umbilical-Cord.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Umbilical-Cord.csv.gz --ground_truth_file data/predictor_files/STAT3_Umbilical-Cord.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1012 with external jobid 'Submitted batch job 11028063'.
[Sat Dec  2 04:47:00 2023]
Finished job 1003.
575 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:47:00 2023]
Job 668: working on tf=FOXA1,tissue=Mammary-Gland
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Mammary-Gland.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 668 with external jobid 'Submitted batch job 11028079'.
[Sat Dec  2 04:47:02 2023]
Finished job 1002.
576 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:47:02 2023]
Job 738: working on tf=GATA3,tissue=Mammary-Gland
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA3_Mammary-Gland.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA3_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 738 with external jobid 'Submitted batch job 11028080'.
[Sat Dec  2 04:47:04 2023]
Finished job 1001.
577 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:47:04 2023]
Job 709: working on tf=ETS1,tissue=Umbilical-Vein
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_ETS1_Umbilical-Vein.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ETS1_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 709 with external jobid 'Submitted batch job 11028081'.
[Sat Dec  2 04:47:05 2023]
Finished job 856.
578 of 1394 steps (41%) done
Select jobs to execute...

[Sat Dec  2 04:47:06 2023]
Job 684: working on tf=CTCF,tissue=Umbilical-Vein
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Umbilical-Vein.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 684 with external jobid 'Submitted batch job 11028082'.
[Sat Dec  2 04:47:07 2023]
Finished job 1005.
579 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:47:07 2023]
Job 808: working on tf=E2F1,tissue=Mammary-Gland
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_E2F1_Mammary-Gland.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_E2F1_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 808 with external jobid 'Submitted batch job 11028083'.
[Sat Dec  2 04:48:52 2023]
Finished job 1312.
580 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:48:52 2023]
Job 753: working on tf=MAX,tissue=Umbilical-Vein
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Umbilical-Vein.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 753 with external jobid 'Submitted batch job 11028105'.
[Sat Dec  2 04:48:53 2023]
Finished job 843.
581 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:48:53 2023]
Job 812: working on tf=CTCF,tissue=Sigmoid-Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Sigmoid-Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Sigmoid-Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 812 with external jobid 'Submitted batch job 11028106'.
[Sat Dec  2 04:48:54 2023]
Finished job 1012.
582 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:48:54 2023]
Job 706: working on tf=HSF1,tissue=Mammary-Gland
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_HSF1_Mammary-Gland.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HSF1_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 706 with external jobid 'Submitted batch job 11028107'.
[Sat Dec  2 04:48:55 2023]
Finished job 818.
583 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:48:55 2023]
Job 1004: preparing tf=E2F1,tissue=Umbilical-Cord training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz; Input files updated by another job: data/predictor_files/E2F1_Umbilical-Cord.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_E2F1_Umbilical-Cord.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_E2F1_Umbilical-Cord.csv.gz --ground_truth_file data/predictor_files/E2F1_Umbilical-Cord.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1004 with external jobid 'Submitted batch job 11028108'.
[Sat Dec  2 04:50:21 2023]
Finished job 560.
584 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:50:21 2023]
Job 701: working on tf=REST,tissue=Adrenal-Gland
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Adrenal-Gland.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Adrenal-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 701 with external jobid 'Submitted batch job 11028120'.
[Sat Dec  2 04:52:34 2023]
Finished job 1119.
585 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:52:34 2023]
Job 1191: training on tf=FOXA1,tissue=Pancreatic-ductal training data
Reason: Missing output files: output/models/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.linear.rds, output/models/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1191 with external jobid 'Submitted batch job 11028135'.
[Sat Dec  2 04:53:51 2023]
Finished job 616.
586 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:53:51 2023]
Job 1305: evaluating on tf=CTCF,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.linear.rds --logistic_model output/models/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Embryonic-Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Embryonic-Kidney_2023-12-01/aggByCollect_CTCF_Embryonic-Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1305 with external jobid 'Submitted batch job 11028149'.
[Sat Dec  2 04:54:25 2023]
Finished job 704.
587 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:54:25 2023]
Job 890: preparing tf=CTCF,tissue=Skeletal-Muscle training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Skeletal-Muscle.csv.gz, data/predictor_files/CTCF_Skeletal-Muscle.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Skeletal-Muscle.csv.gz --ground_truth_file data/predictor_files/CTCF_Skeletal-Muscle.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 890 with external jobid 'Submitted batch job 11028150'.
[Sat Dec  2 04:57:38 2023]
Finished job 565.
588 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:57:38 2023]
Job 703: working on tf=CTCF,tissue=Mammary-Gland
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Mammary-Gland.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 703 with external jobid 'Submitted batch job 11028188'.
[Sat Dec  2 04:58:02 2023]
Finished job 709.
589 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:58:02 2023]
Job 895: preparing tf=ETS1,tissue=Umbilical-Vein training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_ETS1_Umbilical-Vein.csv.gz, data/predictor_files/ETS1_Umbilical-Vein.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ETS1_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/ETS1_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 895 with external jobid 'Submitted batch job 11028189'.
[Sat Dec  2 04:59:26 2023]
Finished job 570.
590 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 04:59:26 2023]
Job 805: working on tf=FOSL2,tissue=Endometrium
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Endometrium.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Endometrium.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 805 with external jobid 'Submitted batch job 11028202'.
[Sat Dec  2 05:01:13 2023]
Finished job 488.
591 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 05:01:13 2023]
Job 820: working on tf=RUNX1,tissue=Fetal-Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Fetal-Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Fetal-Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 820 with external jobid 'Submitted batch job 11028219'.
[Sat Dec  2 05:01:34 2023]
Finished job 1191.
592 of 1394 steps (42%) done
Select jobs to execute...

[Sat Dec  2 05:01:34 2023]
Job 1377: evaluating on tf=FOXA1,tissue=Pancreatic-ductal training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz, output/models/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.linear.rds --logistic_model output/models/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Pancreatic-ductal.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Pancreatic-ductal_2023-12-01/aggByCollect_FOXA1_Pancreatic-ductal
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1377 with external jobid 'Submitted batch job 11028220'.
[Sat Dec  2 05:01:44 2023]
Finished job 808.
593 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:01:44 2023]
Job 1124: training on tf=CTCF,tissue=Pulmonary-Artery training data
Reason: Missing output files: output/models/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.logistic.rds, output/models/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1124 with external jobid 'Submitted batch job 11028221'.
[Sat Dec  2 05:04:56 2023]
Finished job 538.
594 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:04:56 2023]
Job 994: preparing tf=E2F1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/predictor_files/E2F1_Mammary-Gland.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_E2F1_Mammary-Gland.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_E2F1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/E2F1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 994 with external jobid 'Submitted batch job 11028246'.
[Sat Dec  2 05:05:20 2023]
Finished job 1004.
595 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:05:20 2023]
Job 726: working on tf=STAT3,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 726 with external jobid 'Submitted batch job 11028251'.
[Sat Dec  2 05:05:22 2023]
Finished job 668.
596 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:05:22 2023]
Job 854: preparing tf=FOXA1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Mammary-Gland.csv.gz, data/predictor_files/FOXA1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXA1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 854 with external jobid 'Submitted batch job 11028252'.
[Sat Dec  2 05:05:23 2023]
Finished job 738.
597 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:05:23 2023]
Job 924: preparing tf=GATA3,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA3_Mammary-Gland.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA3_Mammary-Gland.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA3_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/GATA3_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 924 with external jobid 'Submitted batch job 11028253'.
[Sat Dec  2 05:05:24 2023]
Finished job 684.
598 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:05:24 2023]
Job 870: preparing tf=CTCF,tissue=Umbilical-Vein training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Umbilical-Vein.csv.gz, data/predictor_files/CTCF_Umbilical-Vein.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/CTCF_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 870 with external jobid 'Submitted batch job 11028254'.
[Sat Dec  2 05:07:03 2023]
Finished job 1124.
599 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:07:03 2023]
Job 1310: evaluating on tf=CTCF,tissue=Pulmonary-Artery training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.logistic.rds, output/models/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.linear.rds --logistic_model output/models/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pulmonary-Artery.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Pulmonary-Artery_2023-12-01/aggByCollect_CTCF_Pulmonary-Artery
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1310 with external jobid 'Submitted batch job 11028267'.
[Sat Dec  2 05:07:09 2023]
Finished job 1305.
600 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:07:09 2023]
Job 1042: training on tf=CTCF,tissue=Pancreatic-Islet training data
Reason: Missing output files: output/models/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.linear.rds, output/models/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1042 with external jobid 'Submitted batch job 11028268'.
[Sat Dec  2 05:07:10 2023]
Finished job 753.
601 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:07:10 2023]
Job 939: preparing tf=MAX,tissue=Umbilical-Vein training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MAX_Umbilical-Vein.csv.gz, data/predictor_files/MAX_Umbilical-Vein.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/MAX_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 939 with external jobid 'Submitted batch job 11028269'.
[Sat Dec  2 05:07:12 2023]
Finished job 706.
602 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:07:12 2023]
Job 892: preparing tf=HSF1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/predictor_files/HSF1_Mammary-Gland.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HSF1_Mammary-Gland.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HSF1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/HSF1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 892 with external jobid 'Submitted batch job 11028270'.
[Sat Dec  2 05:09:00 2023]
Finished job 890.
603 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:09:00 2023]
Job 755: working on tf=STAT1,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT1_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT1_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 755 with external jobid 'Submitted batch job 11028286'.
[Sat Dec  2 05:09:01 2023]
Finished job 812.
604 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:09:01 2023]
Job 998: preparing tf=CTCF,tissue=Sigmoid-Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Sigmoid-Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Sigmoid-Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Sigmoid-Colon.csv.gz --ground_truth_file data/predictor_files/CTCF_Sigmoid-Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 998 with external jobid 'Submitted batch job 11028287'.
[Sat Dec  2 05:09:02 2023]
Finished job 701.
605 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:09:02 2023]
Job 887: preparing tf=REST,tissue=Adrenal-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz; Input files updated by another job: data/predictor_files/REST_Adrenal-Gland.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_REST_Adrenal-Gland.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Adrenal-Gland.csv.gz --ground_truth_file data/predictor_files/REST_Adrenal-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 887 with external jobid 'Submitted batch job 11028288'.
[Sat Dec  2 05:10:19 2023]
Finished job 635.
606 of 1394 steps (43%) done
Select jobs to execute...

[Sat Dec  2 05:10:19 2023]
Job 660: working on tf=GATA2,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA2_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA2_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 660 with external jobid 'Submitted batch job 11028308'.
[Sat Dec  2 05:10:40 2023]
Finished job 1042.
607 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:10:40 2023]
Job 1076: training on tf=CTCF,tissue=Skeletal-Muscle training data
Reason: Missing output files: output/models/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.linear.rds, output/models/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1076 with external jobid 'Submitted batch job 11028309'.
[Sat Dec  2 05:10:48 2023]
Finished job 1377.
608 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:10:48 2023]
Job 1228: evaluating on tf=CTCF,tissue=Pancreatic-Islet training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz, output/models/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.linear.rds --logistic_model output/models/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pancreatic-Islet.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Pancreatic-Islet_2023-12-01/aggByCollect_CTCF_Pancreatic-Islet
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1228 with external jobid 'Submitted batch job 11028310'.
[Sat Dec  2 05:10:50 2023]
Finished job 895.
609 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:10:50 2023]
Job 760: working on tf=GATA3,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA3_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA3_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 760 with external jobid 'Submitted batch job 11028311'.
[Sat Dec  2 05:12:07 2023]
Finished job 485.
610 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:12:07 2023]
Job 769: working on tf=FOXA1,tissue=Endometrium
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Endometrium.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Endometrium.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 769 with external jobid 'Submitted batch job 11028322'.
[Sat Dec  2 05:12:39 2023]
Finished job 994.
611 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:12:39 2023]
Job 771: working on tf=FOXM1,tissue=Endometrium
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Endometrium.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Endometrium.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 771 with external jobid 'Submitted batch job 11028325'.
[Sat Dec  2 05:12:40 2023]
Finished job 820.
612 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:12:40 2023]
Job 1006: preparing tf=RUNX1,tissue=Fetal-Liver training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Fetal-Liver.csv.gz, data/predictor_files/RUNX1_Fetal-Liver.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Fetal-Liver.csv.gz --ground_truth_file data/predictor_files/RUNX1_Fetal-Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1006 with external jobid 'Submitted batch job 11028326'.
[Sat Dec  2 05:14:00 2023]
Finished job 638.
613 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:14:00 2023]
Job 661: working on tf=RUNX1,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 661 with external jobid 'Submitted batch job 11028337'.
[Sat Dec  2 05:15:43 2023]
Finished job 526.
614 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:15:44 2023]
Job 676: working on tf=RUNX1,tissue=Cord-blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Cord-blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Cord-blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 676 with external jobid 'Submitted batch job 11028351'.
[Sat Dec  2 05:15:49 2023]
Finished job 469.
615 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:15:49 2023]
Job 712: working on tf=HSF1,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_HSF1_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HSF1_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 712 with external jobid 'Submitted batch job 11028352'.
[Sat Dec  2 05:15:51 2023]
Finished job 477.
616 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:15:51 2023]
Job 784: working on tf=ETS1,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_ETS1_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ETS1_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 784 with external jobid 'Submitted batch job 11028353'.
[Sat Dec  2 05:16:09 2023]
Finished job 1076.
617 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:16:09 2023]
Job 1262: evaluating on tf=CTCF,tissue=Skeletal-Muscle training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz, output/models/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.logistic.rds, output/models/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.linear.rds --logistic_model output/models/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Skeletal-Muscle.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Skeletal-Muscle_2023-12-01/aggByCollect_CTCF_Skeletal-Muscle
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1262 with external jobid 'Submitted batch job 11028354'.
[Sat Dec  2 05:16:20 2023]
Finished job 726.
618 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:16:20 2023]
Job 1081: training on tf=ETS1,tissue=Umbilical-Vein training data
Reason: Missing output files: output/models/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.linear.rds, output/models/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1081 with external jobid 'Submitted batch job 11028355'.
[Sat Dec  2 05:16:21 2023]
Finished job 854.
619 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:16:21 2023]
Job 912: preparing tf=STAT3,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT3_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT3_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/STAT3_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 912 with external jobid 'Submitted batch job 11028356'.
[Sat Dec  2 05:16:25 2023]
Finished job 703.
620 of 1394 steps (44%) done
Select jobs to execute...

[Sat Dec  2 05:16:25 2023]
Job 889: preparing tf=CTCF,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Mammary-Gland.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Mammary-Gland.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/CTCF_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 889 with external jobid 'Submitted batch job 11028362'.
[Sat Dec  2 05:17:35 2023]
Finished job 548.
621 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:17:35 2023]
Job 770: working on tf=CTCF,tissue=Endometrium
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Endometrium.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Endometrium.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 770 with external jobid 'Submitted batch job 11028372'.
[Sat Dec  2 05:18:10 2023]
Finished job 1310.
622 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:18:10 2023]
Job 693: working on tf=CTCF,tissue=Fetal-Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Fetal-Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Fetal-Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 693 with external jobid 'Submitted batch job 11028374'.
[Sat Dec  2 05:18:11 2023]
Finished job 939.
623 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:18:11 2023]
Job 673: working on tf=GATA2,tissue=Cord-blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA2_Cord-blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA2_Cord-blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 673 with external jobid 'Submitted batch job 11028375'.
[Sat Dec  2 05:18:12 2023]
Finished job 892.
624 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:18:12 2023]
Job 729: working on tf=STAT3,tissue=Lymph-Node
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Lymph-Node.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Lymph-Node.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 729 with external jobid 'Submitted batch job 11028376'.
[Sat Dec  2 05:18:14 2023]
Finished job 870.
625 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:18:14 2023]
Job 743: working on tf=CTCF,tissue=Spinal-Cord
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Spinal-Cord.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Spinal-Cord.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 743 with external jobid 'Submitted batch job 11028377'.
[Sat Dec  2 05:18:15 2023]
Finished job 805.
626 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:18:15 2023]
Job 991: preparing tf=FOSL2,tissue=Endometrium training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOSL2_Endometrium.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOSL2_Endometrium.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOSL2_Endometrium.csv.gz --ground_truth_file data/predictor_files/FOSL2_Endometrium.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 991 with external jobid 'Submitted batch job 11028378'.
[Sat Dec  2 05:19:29 2023]
Finished job 623.
627 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:19:29 2023]
Job 687: working on tf=REST,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 687 with external jobid 'Submitted batch job 11028390'.
[Sat Dec  2 05:20:02 2023]
Finished job 998.
628 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:20:02 2023]
Job 773: working on tf=REST,tissue=Endometrium
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Endometrium.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Endometrium.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 773 with external jobid 'Submitted batch job 11028392'.
[Sat Dec  2 05:20:03 2023]
Finished job 887.
629 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:20:03 2023]
Job 725: working on tf=E2F1,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_E2F1_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_E2F1_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 725 with external jobid 'Submitted batch job 11028393'.
[Sat Dec  2 05:20:05 2023]
Finished job 924.
630 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:20:05 2023]
Job 669: working on tf=CTCF,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 669 with external jobid 'Submitted batch job 11028394'.
[Sat Dec  2 05:21:40 2023]
Finished job 1081.
631 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:21:40 2023]
Job 1040: training on tf=FOXA1,tissue=Mammary-Gland training data
Reason: Missing output files: output/models/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.linear.rds, output/models/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1040 with external jobid 'Submitted batch job 11028412'.
[Sat Dec  2 05:21:50 2023]
Finished job 1228.
632 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:21:50 2023]
Job 1267: evaluating on tf=ETS1,tissue=Umbilical-Vein training and test data
Reason: Missing output files: output/models_eval/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.logistic.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.linear.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.logistic.test_eval.txt.gz, output/models_eval/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz, output/models/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_ETS1_Umbilical-Vein_2023-12-01/aggByCollect_ETS1_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1267 with external jobid 'Submitted batch job 11028413'.
[Sat Dec  2 05:21:53 2023]
Finished job 755.
633 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:21:53 2023]
Job 941: preparing tf=STAT1,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT1_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT1_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT1_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/STAT1_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 941 with external jobid 'Submitted batch job 11028415'.
[Sat Dec  2 05:23:38 2023]
Finished job 771.
634 of 1394 steps (45%) done
Select jobs to execute...

[Sat Dec  2 05:23:38 2023]
Job 957: preparing tf=FOXM1,tissue=Endometrium training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Endometrium.csv.gz, data/predictor_files/FOXM1_Endometrium.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Endometrium.csv.gz --ground_truth_file data/predictor_files/FOXM1_Endometrium.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 957 with external jobid 'Submitted batch job 11028434'.
[Sat Dec  2 05:23:39 2023]
Finished job 1006.
635 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:23:39 2023]
Job 774: working on tf=YY1,tissue=Endometrium
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Endometrium.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Endometrium.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 774 with external jobid 'Submitted batch job 11028435'.
[Sat Dec  2 05:25:31 2023]
Finished job 769.
636 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:25:31 2023]
Job 955: preparing tf=FOXA1,tissue=Endometrium training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Endometrium.csv.gz, data/predictor_files/FOXA1_Endometrium.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Endometrium.csv.gz --ground_truth_file data/predictor_files/FOXA1_Endometrium.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 955 with external jobid 'Submitted batch job 11028450'.
[Sat Dec  2 05:26:43 2023]
Finished job 573.
637 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:26:43 2023]
Job 740: working on tf=CTCF,tissue=Fetal-Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Fetal-Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Fetal-Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 740 with external jobid 'Submitted batch job 11028464'.
[Sat Dec  2 05:26:46 2023]
Finished job 549.
638 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:26:46 2023]
Job 831: working on tf=CTCF,tissue=Cord-blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Cord-blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Cord-blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 831 with external jobid 'Submitted batch job 11028465'.
[Sat Dec  2 05:29:07 2023]
Finished job 676.
639 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:29:07 2023]
Job 862: preparing tf=RUNX1,tissue=Cord-blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Cord-blood.csv.gz, data/predictor_files/RUNX1_Cord-blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Cord-blood.csv.gz --ground_truth_file data/predictor_files/RUNX1_Cord-blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 862 with external jobid 'Submitted batch job 11028483'.
[Sat Dec  2 05:30:42 2023]
Finished job 1040.
640 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:30:42 2023]
Job 1226: evaluating on tf=FOXA1,tissue=Mammary-Gland training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz, output/models/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.linear.rds, output/models/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Mammary-Gland_2023-12-01/aggByCollect_FOXA1_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1226 with external jobid 'Submitted batch job 11028494'.
[Sat Dec  2 05:30:58 2023]
Finished job 712.
641 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:30:58 2023]
Job 1110: training on tf=GATA3,tissue=Mammary-Gland training data
Reason: Missing output files: output/models/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.linear.rds, output/models/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1110 with external jobid 'Submitted batch job 11028512'.
[Sat Dec  2 05:32:09 2023]
Finished job 562.
642 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:32:09 2023]
Job 898: preparing tf=HSF1,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_HSF1_Bone-Marrow.csv.gz, data/predictor_files/HSF1_Bone-Marrow.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HSF1_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/HSF1_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 898 with external jobid 'Submitted batch job 11028518'.
[Sat Dec  2 05:32:50 2023]
Finished job 661.
643 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:32:50 2023]
Job 847: preparing tf=RUNX1,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Bone-Marrow.csv.gz, data/predictor_files/RUNX1_Bone-Marrow.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/RUNX1_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 847 with external jobid 'Submitted batch job 11028527'.
[Sat Dec  2 05:32:51 2023]
Finished job 760.
644 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:32:51 2023]
Job 946: preparing tf=GATA3,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA3_Bone-Marrow.csv.gz, data/predictor_files/GATA3_Bone-Marrow.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA3_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/GATA3_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 946 with external jobid 'Submitted batch job 11028534'.
[Sat Dec  2 05:33:56 2023]
Finished job 495.
645 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:33:56 2023]
Job 756: working on tf=MAX,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 756 with external jobid 'Submitted batch job 11028536'.
[Sat Dec  2 05:34:37 2023]
Finished job 1262.
646 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:34:37 2023]
Job 785: working on tf=SP1,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SP1_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SP1_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 785 with external jobid 'Submitted batch job 11028547'.
[Sat Dec  2 05:34:38 2023]
Finished job 912.
647 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:34:38 2023]
Job 757: working on tf=YY1,tissue=Bone-Marrow
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Bone-Marrow.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 757 with external jobid 'Submitted batch job 11028548'.
[Sat Dec  2 05:34:41 2023]
Finished job 784.
648 of 1394 steps (46%) done
Select jobs to execute...

[Sat Dec  2 05:34:41 2023]
Job 970: preparing tf=ETS1,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/ETS1_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_ETS1_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ETS1_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/ETS1_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 970 with external jobid 'Submitted batch job 11028549'.
[Sat Dec  2 05:34:42 2023]
Finished job 660.
649 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:34:42 2023]
Job 846: preparing tf=GATA2,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA2_Bone-Marrow.csv.gz, data/predictor_files/GATA2_Bone-Marrow.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/GATA2_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 846 with external jobid 'Submitted batch job 11028550'.
[Sat Dec  2 05:35:48 2023]
Finished job 625.
650 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:35:48 2023]
Job 744: working on tf=CTCF,tissue=Cerebellum
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Cerebellum.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Cerebellum.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 744 with external jobid 'Submitted batch job 11028554'.
[Sat Dec  2 05:36:31 2023]
Finished job 889.
651 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:36:31 2023]
Job 772: working on tf=MAX,tissue=Endometrium
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Endometrium.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Endometrium.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 772 with external jobid 'Submitted batch job 11028567'.
[Sat Dec  2 05:37:36 2023]
Finished job 593.
652 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:37:36 2023]
Job 746: working on tf=CTCF,tissue=Esophagus
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Esophagus.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Esophagus.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 746 with external jobid 'Submitted batch job 11028572'.
[Sat Dec  2 05:38:17 2023]
Finished job 673.
653 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:38:17 2023]
Job 859: preparing tf=GATA2,tissue=Cord-blood training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Cord-blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Cord-blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Cord-blood.csv.gz --ground_truth_file data/predictor_files/GATA2_Cord-blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 859 with external jobid 'Submitted batch job 11028588'.
[Sat Dec  2 05:40:07 2023]
Finished job 729.
654 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:40:07 2023]
Job 915: preparing tf=STAT3,tissue=Lymph-Node training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT3_Lymph-Node.csv.gz, data/predictor_files/STAT3_Lymph-Node.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Lymph-Node.csv.gz --ground_truth_file data/predictor_files/STAT3_Lymph-Node.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 915 with external jobid 'Submitted batch job 11028595'.
[Sat Dec  2 05:40:11 2023]
Finished job 770.
655 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:40:11 2023]
Job 956: preparing tf=CTCF,tissue=Endometrium training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Endometrium.csv.gz, data/predictor_files/CTCF_Endometrium.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Endometrium.csv.gz --ground_truth_file data/predictor_files/CTCF_Endometrium.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 956 with external jobid 'Submitted batch job 11028596'.
[Sat Dec  2 05:41:14 2023]
Finished job 607.
656 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:41:14 2023]
Job 803: working on tf=GATA2,tissue=Prostate
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA2_Prostate.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA2_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 803 with external jobid 'Submitted batch job 11028599'.
[Sat Dec  2 05:42:00 2023]
Finished job 991.
657 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:42:00 2023]
Job 663: working on tf=FOXA1,tissue=Prostate
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Prostate.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 663 with external jobid 'Submitted batch job 11028611'.
[Sat Dec  2 05:42:01 2023]
Finished job 687.
658 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:42:01 2023]
Job 873: preparing tf=REST,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/REST_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_REST_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/REST_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 873 with external jobid 'Submitted batch job 11028612'.
[Sat Dec  2 05:43:07 2023]
Finished job 555.
659 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:43:07 2023]
Job 798: working on tf=RUNX1,tissue=Prostate
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Prostate.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 798 with external jobid 'Submitted batch job 11028618'.
[Sat Dec  2 05:43:38 2023]
Finished job 1110.
660 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:43:38 2023]
Job 1296: evaluating on tf=GATA3,tissue=Mammary-Gland training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz, output/models/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.linear.rds, output/models/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA3_Mammary-Gland_2023-12-01/aggByCollect_GATA3_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1296 with external jobid 'Submitted batch job 11028629'.
[Sat Dec  2 05:43:48 2023]
Finished job 773.
661 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:43:48 2023]
Job 1075: training on tf=CTCF,tissue=Mammary-Gland training data
Reason: Missing output files: output/models/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.linear.rds, output/models/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1075 with external jobid 'Submitted batch job 11028630'.
[Sat Dec  2 05:43:51 2023]
Finished job 693.
662 of 1394 steps (47%) done
Select jobs to execute...

[Sat Dec  2 05:43:51 2023]
Job 879: preparing tf=CTCF,tissue=Fetal-Liver training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Fetal-Liver.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Fetal-Liver.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Fetal-Liver.csv.gz --ground_truth_file data/predictor_files/CTCF_Fetal-Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 879 with external jobid 'Submitted batch job 11028631'.
[Sat Dec  2 05:45:32 2023]
Finished job 955.
663 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:45:32 2023]
Job 959: preparing tf=REST,tissue=Endometrium training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz; Input files updated by another job: data/predictor_files/REST_Endometrium.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_REST_Endometrium.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Endometrium.csv.gz --ground_truth_file data/predictor_files/REST_Endometrium.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 959 with external jobid 'Submitted batch job 11028647'.
[Sat Dec  2 05:45:35 2023]
Finished job 957.
664 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:45:35 2023]
Job 829: working on tf=FOXA2,tissue=Endoderm
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA2_Endoderm.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA2_Endoderm.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 829 with external jobid 'Submitted batch job 11028648'.
[Sat Dec  2 05:45:37 2023]
Finished job 1267.
665 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:45:37 2023]
Job 795: working on tf=GATA4,tissue=Stomach
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA4_Stomach.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA4_Stomach.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 795 with external jobid 'Submitted batch job 11028649'.
[Sat Dec  2 05:45:38 2023]
Finished job 941.
666 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:45:38 2023]
Job 789: working on tf=REST,tissue=Pancreas
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Pancreas.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Pancreas.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 789 with external jobid 'Submitted batch job 11028650'.
[Sat Dec  2 05:45:39 2023]
Finished job 725.
667 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:45:39 2023]
Job 911: preparing tf=E2F1,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/E2F1_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_E2F1_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_E2F1_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/E2F1_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 911 with external jobid 'Submitted batch job 11028651'.
[Sat Dec  2 05:45:41 2023]
Finished job 743.
668 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:45:41 2023]
Job 929: preparing tf=CTCF,tissue=Spinal-Cord training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Spinal-Cord.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Spinal-Cord.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Spinal-Cord.csv.gz --ground_truth_file data/predictor_files/CTCF_Spinal-Cord.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 929 with external jobid 'Submitted batch job 11028652'.
[Sat Dec  2 05:47:29 2023]
Finished job 774.
669 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:47:29 2023]
Job 960: preparing tf=YY1,tissue=Endometrium training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz; Input files updated by another job: data/predictor_files/YY1_Endometrium.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_YY1_Endometrium.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Endometrium.csv.gz --ground_truth_file data/predictor_files/YY1_Endometrium.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 960 with external jobid 'Submitted batch job 11028664'.
[Sat Dec  2 05:49:14 2023]
Finished job 1226.
670 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:49:14 2023]
Job 797: working on tf=ETS1,tissue=Pancreas
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_ETS1_Pancreas.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ETS1_Pancreas.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 797 with external jobid 'Submitted batch job 11028677'.
[Sat Dec  2 05:49:16 2023]
Finished job 862.
671 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:49:16 2023]
Job 751: working on tf=CTCF,tissue=Foreskin
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Foreskin.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Foreskin.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 751 with external jobid 'Submitted batch job 11028678'.
[Sat Dec  2 05:50:46 2023]
Finished job 1075.
672 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:50:46 2023]
Job 1261: evaluating on tf=CTCF,tissue=Mammary-Gland training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz, output/models/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz, output/models/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Mammary-Gland_2023-12-01/aggByCollect_CTCF_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1261 with external jobid 'Submitted batch job 11028693'.
[Sat Dec  2 05:51:05 2023]
Finished job 898.
673 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:51:05 2023]
Job 1056: training on tf=CTCF,tissue=Umbilical-Vein training data
Reason: Missing output files: output/models/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.logistic.rds, output/models/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1056 with external jobid 'Submitted batch job 11028694'.
[Sat Dec  2 05:51:07 2023]
Finished job 831.
674 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:51:07 2023]
Job 1017: preparing tf=CTCF,tissue=Cord-blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Cord-blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Cord-blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Cord-blood.csv.gz --ground_truth_file data/predictor_files/CTCF_Cord-blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1017 with external jobid 'Submitted batch job 11028695'.
[Sat Dec  2 05:52:08 2023]
Finished job 500.
675 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:52:08 2023]
Job 737: working on tf=E2F1,tissue=Prostate
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_E2F1_Prostate.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_E2F1_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 737 with external jobid 'Submitted batch job 11028699'.
[Sat Dec  2 05:52:54 2023]
Finished job 847.
676 of 1394 steps (48%) done
Select jobs to execute...

[Sat Dec  2 05:52:54 2023]
Job 675: working on tf=PPARG,tissue=Adipose
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_PPARG_Adipose.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_PPARG_Adipose.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 675 with external jobid 'Submitted batch job 11028724'.
[Sat Dec  2 05:52:55 2023]
Finished job 946.
677 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 05:52:55 2023]
Job 759: working on tf=CTCF,tissue=Pancreas
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Pancreas.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Pancreas.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 759 with external jobid 'Submitted batch job 11028725'.
[Sat Dec  2 05:52:57 2023]
Finished job 740.
678 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 05:52:57 2023]
Job 926: preparing tf=CTCF,tissue=Fetal-Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Fetal-Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Fetal-Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Fetal-Lung.csv.gz --ground_truth_file data/predictor_files/CTCF_Fetal-Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 926 with external jobid 'Submitted batch job 11028726'.
[Sat Dec  2 05:54:43 2023]
Finished job 970.
679 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 05:54:43 2023]
Job 724: working on tf=CTCF,tissue=Prostate
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Prostate.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 724 with external jobid 'Submitted batch job 11028746'.
[Sat Dec  2 05:54:47 2023]
Finished job 669.
680 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 05:54:47 2023]
Job 855: preparing tf=CTCF,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/CTCF_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 855 with external jobid 'Submitted batch job 11028747'.
[Sat Dec  2 05:55:53 2023]
Finished job 509.
681 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 05:55:53 2023]
Job 682: working on tf=ETS1,tissue=Prostate
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_ETS1_Prostate.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ETS1_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 682 with external jobid 'Submitted batch job 11028755'.
[Sat Dec  2 05:56:33 2023]
Finished job 785.
682 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 05:56:33 2023]
Job 971: preparing tf=SP1,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/SP1_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_SP1_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SP1_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/SP1_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 971 with external jobid 'Submitted batch job 11028756'.
[Sat Dec  2 05:56:34 2023]
Finished job 757.
683 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 05:56:34 2023]
Job 943: preparing tf=YY1,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/YY1_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_YY1_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/YY1_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 943 with external jobid 'Submitted batch job 11028757'.
[Sat Dec  2 05:58:02 2023]
Finished job 1056.
684 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 05:58:02 2023]
Job 1242: evaluating on tf=CTCF,tissue=Umbilical-Vein training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz, output/models/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Umbilical-Vein_2023-12-01/aggByCollect_CTCF_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1242 with external jobid 'Submitted batch job 11028772'.
[Sat Dec  2 06:00:14 2023]
Finished job 846.
685 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 06:00:14 2023]
Job 1032: training on tf=GATA2,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.logistic.rds, output/models/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1032 with external jobid 'Submitted batch job 11028791'.
[Sat Dec  2 06:01:13 2023]
Finished job 600.
686 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 06:01:13 2023]
Job 830: working on tf=RUNX1,tissue=Kidney
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Kidney.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 830 with external jobid 'Submitted batch job 11028806'.
[Sat Dec  2 06:02:03 2023]
Finished job 772.
687 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 06:02:03 2023]
Job 958: preparing tf=MAX,tissue=Endometrium training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MAX_Endometrium.csv.gz, data/predictor_files/MAX_Endometrium.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Endometrium.csv.gz --ground_truth_file data/predictor_files/MAX_Endometrium.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 958 with external jobid 'Submitted batch job 11028809'.
[Sat Dec  2 06:02:05 2023]
Finished job 744.
688 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 06:02:05 2023]
Job 930: preparing tf=CTCF,tissue=Cerebellum training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Cerebellum.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Cerebellum.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Cerebellum.csv.gz --ground_truth_file data/predictor_files/CTCF_Cerebellum.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 930 with external jobid 'Submitted batch job 11028810'.
[Sat Dec  2 06:03:50 2023]
Finished job 915.
689 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 06:03:50 2023]
Job 802: working on tf=STAT3,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 802 with external jobid 'Submitted batch job 11028820'.
[Sat Dec  2 06:03:51 2023]
Finished job 956.
690 of 1394 steps (49%) done
Select jobs to execute...

[Sat Dec  2 06:03:51 2023]
Job 824: working on tf=RUNX1,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 824 with external jobid 'Submitted batch job 11028821'.
[Sat Dec  2 06:03:53 2023]
Finished job 859.
691 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:03:53 2023]
Job 809: working on tf=RUNX1,tissue=Pleura
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Pleura.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Pleura.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 809 with external jobid 'Submitted batch job 11028822'.
[Sat Dec  2 06:05:43 2023]
Finished job 746.
692 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:05:43 2023]
Job 932: preparing tf=CTCF,tissue=Esophagus training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Esophagus.csv.gz, data/predictor_files/CTCF_Esophagus.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Esophagus.csv.gz --ground_truth_file data/predictor_files/CTCF_Esophagus.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 932 with external jobid 'Submitted batch job 11028839'.
[Sat Dec  2 06:07:30 2023]
Finished job 873.
693 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:07:30 2023]
Job 671: working on tf=CTCF,tissue=Adipose
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Adipose.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Adipose.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 671 with external jobid 'Submitted batch job 11028852'.
[Sat Dec  2 06:07:33 2023]
Finished job 756.
694 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:07:33 2023]
Job 942: preparing tf=MAX,tissue=Bone-Marrow training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz; Input files updated by another job: data/predictor_files/MAX_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MAX_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/MAX_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 942 with external jobid 'Submitted batch job 11028853'.
[Sat Dec  2 06:09:12 2023]
Finished job 959.
695 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:09:12 2023]
Job 811: working on tf=CTCF,tissue=Stomach
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Stomach.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Stomach.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 811 with external jobid 'Submitted batch job 11028866'.
[Sat Dec  2 06:09:18 2023]
Finished job 1296.
696 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:09:18 2023]
Job 741: working on tf=CTCF,tissue=Gingiva
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Gingiva.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Gingiva.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 741 with external jobid 'Submitted batch job 11028867'.
[Sat Dec  2 06:09:21 2023]
Finished job 798.
697 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:09:21 2023]
Job 984: preparing tf=RUNX1,tissue=Prostate training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Prostate.csv.gz, data/predictor_files/RUNX1_Prostate.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Prostate.csv.gz --ground_truth_file data/predictor_files/RUNX1_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 984 with external jobid 'Submitted batch job 11028868'.
[Sat Dec  2 06:10:47 2023]
Finished job 1032.
698 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:10:47 2023]
Job 1218: evaluating on tf=GATA2,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz, output/models/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz, output/models/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA2_Bone-Marrow_2023-12-01/aggByCollect_GATA2_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1218 with external jobid 'Submitted batch job 11028887'.
[Sat Dec  2 06:11:04 2023]
Finished job 829.
699 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:11:04 2023]
Job 1132: training on tf=GATA3,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.linear.rds, output/models/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1132 with external jobid 'Submitted batch job 11028888'.
[Sat Dec  2 06:11:09 2023]
Finished job 879.
700 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:11:09 2023]
Job 1015: preparing tf=FOXA2,tissue=Endoderm training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA2_Endoderm.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA2_Endoderm.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA2_Endoderm.csv.gz --ground_truth_file data/predictor_files/FOXA2_Endoderm.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1015 with external jobid 'Submitted batch job 11028889'.
[Sat Dec  2 06:12:09 2023]
Finished job 491.
701 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:12:09 2023]
Job 734: working on tf=FOXM1,tissue=Cervix
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Cervix.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 734 with external jobid 'Submitted batch job 11028904'.
[Sat Dec  2 06:12:58 2023]
Finished job 789.
702 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:12:58 2023]
Job 975: preparing tf=REST,tissue=Pancreas training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz; Input files updated by another job: data/predictor_files/REST_Pancreas.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_REST_Pancreas.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Pancreas.csv.gz --ground_truth_file data/predictor_files/REST_Pancreas.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 975 with external jobid 'Submitted batch job 11028906'.
[Sat Dec  2 06:13:55 2023]
Finished job 464.
703 of 1394 steps (50%) done
Select jobs to execute...

[Sat Dec  2 06:13:55 2023]
Job 748: working on tf=STAT3,tissue=Cervix
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Cervix.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 748 with external jobid 'Submitted batch job 11028927'.
[Sat Dec  2 06:14:47 2023]
Finished job 960.
704 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:14:47 2023]
Job 735: working on tf=SOX2,tissue=Thyroid
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SOX2_Thyroid.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SOX2_Thyroid.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 735 with external jobid 'Submitted batch job 11028930'.
[Sat Dec  2 06:14:49 2023]
Finished job 911.
705 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:14:49 2023]
Job 799: working on tf=FOXA1,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 799 with external jobid 'Submitted batch job 11028931'.
[Sat Dec  2 06:14:50 2023]
Finished job 929.
706 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:14:50 2023]
Job 655: working on tf=STAT1,tissue=Cervix
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT1_Cervix.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT1_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 655 with external jobid 'Submitted batch job 11028932'.
[Sat Dec  2 06:14:52 2023]
Finished job 803.
707 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:14:52 2023]
Job 989: preparing tf=GATA2,tissue=Prostate training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Prostate.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Prostate.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Prostate.csv.gz --ground_truth_file data/predictor_files/GATA2_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 989 with external jobid 'Submitted batch job 11028933'.
[Sat Dec  2 06:16:11 2023]
Finished job 1132.
708 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:16:11 2023]
Job 1318: evaluating on tf=GATA3,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz, output/models/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.linear.rds, output/models/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA3_Bone-Marrow_2023-12-01/aggByCollect_GATA3_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1318 with external jobid 'Submitted batch job 11028947'.
[Sat Dec  2 06:16:35 2023]
Finished job 1261.
709 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:16:35 2023]
Job 1065: training on tf=CTCF,tissue=Fetal-Liver training data
Reason: Missing output files: output/models/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.linear.rds, output/models/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1065 with external jobid 'Submitted batch job 11028948'.
[Sat Dec  2 06:16:38 2023]
Finished job 797.
710 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:16:38 2023]
Job 983: preparing tf=ETS1,tissue=Pancreas training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz; Input files updated by another job: data/predictor_files/ETS1_Pancreas.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_ETS1_Pancreas.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ETS1_Pancreas.csv.gz --ground_truth_file data/predictor_files/ETS1_Pancreas.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 983 with external jobid 'Submitted batch job 11028949'.
[Sat Dec  2 06:17:41 2023]
Finished job 642.
711 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:17:41 2023]
Job 674: working on tf=HSF1,tissue=Adipose
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_HSF1_Adipose.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HSF1_Adipose.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 674 with external jobid 'Submitted batch job 11028961'.
[Sat Dec  2 06:18:27 2023]
Finished job 1017.
712 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:18:27 2023]
Job 828: working on tf=GATA3,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA3_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA3_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 828 with external jobid 'Submitted batch job 11028964'.
[Sat Dec  2 06:20:20 2023]
Finished job 663.
713 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:20:20 2023]
Job 849: preparing tf=FOXA1,tissue=Prostate training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA1_Prostate.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA1_Prostate.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Prostate.csv.gz --ground_truth_file data/predictor_files/FOXA1_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 849 with external jobid 'Submitted batch job 11028982'.
[Sat Dec  2 06:21:34 2023]
Finished job 1065.
714 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:21:34 2023]
Job 1251: evaluating on tf=CTCF,tissue=Fetal-Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz, output/models/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.linear.rds --logistic_model output/models/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Fetal-Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Fetal-Liver_2023-12-01/aggByCollect_CTCF_Fetal-Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1251 with external jobid 'Submitted batch job 11028994'.
[Sat Dec  2 06:22:07 2023]
Finished job 737.
715 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:22:07 2023]
Job 1033: training on tf=RUNX1,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.logistic.rds, output/models/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1033 with external jobid 'Submitted batch job 11028995'.
[Sat Dec  2 06:22:08 2023]
Finished job 751.
716 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:22:08 2023]
Job 937: preparing tf=CTCF,tissue=Foreskin training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Foreskin.csv.gz, data/predictor_files/CTCF_Foreskin.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Foreskin.csv.gz --ground_truth_file data/predictor_files/CTCF_Foreskin.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 937 with external jobid 'Submitted batch job 11028997'.
[Sat Dec  2 06:23:57 2023]
Finished job 926.
717 of 1394 steps (51%) done
Select jobs to execute...

[Sat Dec  2 06:23:57 2023]
Job 923: preparing tf=E2F1,tissue=Prostate training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_E2F1_Prostate.csv.gz, data/predictor_files/E2F1_Prostate.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_E2F1_Prostate.csv.gz --ground_truth_file data/predictor_files/E2F1_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 923 with external jobid 'Submitted batch job 11029009'.
[Sat Dec  2 06:24:59 2023]
Finished job 481.
718 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:24:59 2023]
Job 695: working on tf=STAT3,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 695 with external jobid 'Submitted batch job 11029022'.
[Sat Dec  2 06:25:49 2023]
Finished job 795.
719 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:25:49 2023]
Job 981: preparing tf=GATA4,tissue=Stomach training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA4_Stomach.csv.gz, data/predictor_files/GATA4_Stomach.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA4_Stomach.csv.gz --ground_truth_file data/predictor_files/GATA4_Stomach.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 981 with external jobid 'Submitted batch job 11029023'.
[Sat Dec  2 06:26:44 2023]
Finished job 502.
720 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:26:44 2023]
Job 800: working on tf=FOXA2,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA2_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA2_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 800 with external jobid 'Submitted batch job 11029037'.
[Sat Dec  2 06:27:04 2023]
Finished job 1033.
721 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:27:04 2023]
Job 1219: evaluating on tf=RUNX1,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz, output/models/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Bone-Marrow_2023-12-01/aggByCollect_RUNX1_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1219 with external jobid 'Submitted batch job 11029039'.
[Sat Dec  2 06:27:36 2023]
Finished job 855.
722 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:27:36 2023]
Job 1041: training on tf=CTCF,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.logistic.rds, output/models/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1041 with external jobid 'Submitted batch job 11029043'.
[Sat Dec  2 06:28:32 2023]
Finished job 492.
723 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:28:32 2023]
Job 667: working on tf=GATA3,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA3_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA3_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 667 with external jobid 'Submitted batch job 11029055'.
[Sat Dec  2 06:29:29 2023]
Finished job 759.
724 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:29:29 2023]
Job 945: preparing tf=CTCF,tissue=Pancreas training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Pancreas.csv.gz, data/predictor_files/CTCF_Pancreas.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Pancreas.csv.gz --ground_truth_file data/predictor_files/CTCF_Pancreas.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 945 with external jobid 'Submitted batch job 11029058'.
[Sat Dec  2 06:30:26 2023]
Finished job 480.
725 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:30:26 2023]
Job 666: working on tf=FOXA1,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 666 with external jobid 'Submitted batch job 11029067'.
[Sat Dec  2 06:31:14 2023]
Finished job 1242.
726 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:31:14 2023]
Job 821: working on tf=GATA3,tissue=Thymus
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA3_Thymus.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA3_Thymus.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 821 with external jobid 'Submitted batch job 11029074'.
[Sat Dec  2 06:31:15 2023]
Finished job 971.
727 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:31:15 2023]
Job 787: working on tf=FOSL2,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 787 with external jobid 'Submitted batch job 11029075'.
[Sat Dec  2 06:31:16 2023]
Finished job 943.
728 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:31:16 2023]
Job 801: working on tf=GATA4,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA4_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA4_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 801 with external jobid 'Submitted batch job 11029076'.
[Sat Dec  2 06:31:18 2023]
Finished job 682.
729 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:31:18 2023]
Job 868: preparing tf=ETS1,tissue=Prostate training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_ETS1_Prostate.csv.gz, data/predictor_files/ETS1_Prostate.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ETS1_Prostate.csv.gz --ground_truth_file data/predictor_files/ETS1_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 868 with external jobid 'Submitted batch job 11029084'.
[Sat Dec  2 06:32:10 2023]
Finished job 512.
730 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:32:10 2023]
Job 696: working on tf=FOXM1,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 696 with external jobid 'Submitted batch job 11029086'.
[Sat Dec  2 06:33:05 2023]
Finished job 958.
731 of 1394 steps (52%) done
Select jobs to execute...

[Sat Dec  2 06:33:05 2023]
Job 782: working on tf=FOSL2,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 782 with external jobid 'Submitted batch job 11029103'.
[Sat Dec  2 06:33:08 2023]
Finished job 724.
732 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:33:08 2023]
Job 910: preparing tf=CTCF,tissue=Prostate training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Prostate.csv.gz, data/predictor_files/CTCF_Prostate.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Prostate.csv.gz --ground_truth_file data/predictor_files/CTCF_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 910 with external jobid 'Submitted batch job 11029104'.
[Sat Dec  2 06:33:57 2023]
Finished job 528.
733 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:33:57 2023]
Job 698: working on tf=HSF1,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_HSF1_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HSF1_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 698 with external jobid 'Submitted batch job 11029108'.
[Sat Dec  2 06:34:26 2023]
Finished job 1041.
734 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:34:26 2023]
Job 1227: evaluating on tf=CTCF,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz, output/models/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.logistic.rds, output/models/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Bone-Marrow_2023-12-01/aggByCollect_CTCF_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1227 with external jobid 'Submitted batch job 11029109'.
[Sat Dec  2 06:34:54 2023]
Finished job 802.
735 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:34:54 2023]
Job 1177: training on tf=FOSL2,tissue=Endometrium training data
Reason: Missing output files: output/models/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.logistic.rds, output/models/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz --rds_file output/models/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1177 with external jobid 'Submitted batch job 11029125'.
[Sat Dec  2 06:34:57 2023]
Finished job 930.
736 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:34:57 2023]
Job 988: preparing tf=STAT3,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT3_Embryo.csv.gz, data/predictor_files/STAT3_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Embryo.csv.gz --ground_truth_file data/predictor_files/STAT3_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 988 with external jobid 'Submitted batch job 11029126'.
[Sat Dec  2 06:34:59 2023]
Finished job 675.
737 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:34:59 2023]
Job 861: preparing tf=PPARG,tissue=Adipose training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_PPARG_Adipose.csv.gz, data/predictor_files/PPARG_Adipose.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Adipose.csv.gz --ground_truth_file data/predictor_files/PPARG_Adipose.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 861 with external jobid 'Submitted batch job 11029127'.
[Sat Dec  2 06:36:45 2023]
Finished job 932.
738 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:36:45 2023]
Job 677: working on tf=STAT1,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT1_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT1_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 677 with external jobid 'Submitted batch job 11029150'.
[Sat Dec  2 06:36:46 2023]
Finished job 824.
739 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:36:46 2023]
Job 1010: preparing tf=RUNX1,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Breast.csv.gz, data/predictor_files/RUNX1_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Breast.csv.gz --ground_truth_file data/predictor_files/RUNX1_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1010 with external jobid 'Submitted batch job 11029151'.
[Sat Dec  2 06:36:48 2023]
Finished job 830.
740 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:36:48 2023]
Job 1016: preparing tf=RUNX1,tissue=Kidney training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz; Input files updated by another job: data/predictor_files/RUNX1_Kidney.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_RUNX1_Kidney.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Kidney.csv.gz --ground_truth_file data/predictor_files/RUNX1_Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1016 with external jobid 'Submitted batch job 11029152'.
[Sat Dec  2 06:37:37 2023]
Finished job 541.
741 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:37:37 2023]
Job 727: working on tf=STAT3,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 727 with external jobid 'Submitted batch job 11029154'.
[Sat Dec  2 06:37:42 2023]
Finished job 497.
742 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:37:42 2023]
Job 683: working on tf=FOXA1,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 683 with external jobid 'Submitted batch job 11029155'.
[Sat Dec  2 06:38:39 2023]
Finished job 809.
743 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:38:39 2023]
Job 995: preparing tf=RUNX1,tissue=Pleura training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz; Input files updated by another job: data/predictor_files/RUNX1_Pleura.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_RUNX1_Pleura.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Pleura.csv.gz --ground_truth_file data/predictor_files/RUNX1_Pleura.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 995 with external jobid 'Submitted batch job 11029170'.
[Sat Dec  2 06:39:25 2023]
Finished job 546.
744 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:39:25 2023]
Job 732: working on tf=RUNX1,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 732 with external jobid 'Submitted batch job 11029171'.
[Sat Dec  2 06:39:32 2023]
Finished job 608.
745 of 1394 steps (53%) done
Select jobs to execute...

[Sat Dec  2 06:39:32 2023]
Job 650: working on tf=RUNX1,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_RUNX1_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_RUNX1_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 650 with external jobid 'Submitted batch job 11029172'.
[Sat Dec  2 06:39:52 2023]
Finished job 1177.
746 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:39:52 2023]
Job 1363: evaluating on tf=FOSL2,tissue=Endometrium training and test data
Reason: Missing output files: output/models_eval/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.linear.test_eval.txt.gz, output/models_eval/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.linear.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz, output/models/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.linear.rds --logistic_model output/models/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Endometrium.prepared.csv.gz --eval_output output/models_eval/cistrome_FOSL2_Endometrium_2023-12-01/aggByCollect_FOSL2_Endometrium
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1363 with external jobid 'Submitted batch job 11029173'.
[Sat Dec  2 06:40:29 2023]
Finished job 984.
747 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:40:29 2023]
Job 1118: training on tf=CTCF,tissue=Esophagus training data
Reason: Missing output files: output/models/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.linear.rds, output/models/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1118 with external jobid 'Submitted batch job 11029187'.
[Sat Dec  2 06:40:31 2023]
Finished job 942.
748 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:40:31 2023]
Job 678: working on tf=SOX2,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SOX2_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SOX2_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 678 with external jobid 'Submitted batch job 11029188'.
[Sat Dec  2 06:42:13 2023]
Finished job 975.
749 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:42:13 2023]
Job 686: working on tf=GATA2,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA2_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA2_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 686 with external jobid 'Submitted batch job 11029209'.
[Sat Dec  2 06:42:15 2023]
Finished job 1218.
750 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:42:15 2023]
Job 714: working on tf=FOXA1,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 714 with external jobid 'Submitted batch job 11029210'.
[Sat Dec  2 06:42:16 2023]
Finished job 1015.
751 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:42:16 2023]
Job 665: working on tf=E2F1,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_E2F1_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_E2F1_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 665 with external jobid 'Submitted batch job 11029211'.
[Sat Dec  2 06:42:18 2023]
Finished job 811.
752 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:42:18 2023]
Job 997: preparing tf=CTCF,tissue=Stomach training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Stomach.csv.gz, data/predictor_files/CTCF_Stomach.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Stomach.csv.gz --ground_truth_file data/predictor_files/CTCF_Stomach.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 997 with external jobid 'Submitted batch job 11029212'.
[Sat Dec  2 06:44:07 2023]
Finished job 734.
753 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:44:07 2023]
Job 920: preparing tf=FOXM1,tissue=Cervix training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXM1_Cervix.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXM1_Cervix.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Cervix.csv.gz --ground_truth_file data/predictor_files/FOXM1_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 920 with external jobid 'Submitted batch job 11029220'.
[Sat Dec  2 06:44:09 2023]
Finished job 671.
754 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:44:09 2023]
Job 857: preparing tf=CTCF,tissue=Adipose training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Adipose.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Adipose.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Adipose.csv.gz --ground_truth_file data/predictor_files/CTCF_Adipose.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 857 with external jobid 'Submitted batch job 11029221'.
[Sat Dec  2 06:45:17 2023]
Finished job 1118.
755 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:45:17 2023]
Job 1128: training on tf=MAX,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.logistic.rds, output/models/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1128 with external jobid 'Submitted batch job 11029224'.
[Sat Dec  2 06:45:53 2023]
Finished job 735.
756 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:45:53 2023]
Job 1304: evaluating on tf=CTCF,tissue=Esophagus training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz, output/models/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.linear.rds --logistic_model output/models/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Esophagus.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Esophagus_2023-12-01/aggByCollect_CTCF_Esophagus
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1304 with external jobid 'Submitted batch job 11029236'.
[Sat Dec  2 06:45:58 2023]
Finished job 741.
757 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:45:58 2023]
Job 927: preparing tf=CTCF,tissue=Gingiva training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Gingiva.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Gingiva.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Gingiva.csv.gz --ground_truth_file data/predictor_files/CTCF_Gingiva.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 927 with external jobid 'Submitted batch job 11029237'.
[Sat Dec  2 06:47:41 2023]
Finished job 1318.
758 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:47:41 2023]
Job 921: preparing tf=SOX2,tissue=Thyroid training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz; Input files updated by another job: data/predictor_files/SOX2_Thyroid.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_SOX2_Thyroid.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SOX2_Thyroid.csv.gz --ground_truth_file data/predictor_files/SOX2_Thyroid.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 921 with external jobid 'Submitted batch job 11029247'.
[Sat Dec  2 06:47:42 2023]
Finished job 983.
759 of 1394 steps (54%) done
Select jobs to execute...

[Sat Dec  2 06:47:42 2023]
Job 813: working on tf=GATA4,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA4_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA4_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 813 with external jobid 'Submitted batch job 11029248'.
[Sat Dec  2 06:47:47 2023]
Finished job 748.
760 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:47:47 2023]
Job 934: preparing tf=STAT3,tissue=Cervix training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT3_Cervix.csv.gz, data/predictor_files/STAT3_Cervix.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Cervix.csv.gz --ground_truth_file data/predictor_files/STAT3_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 934 with external jobid 'Submitted batch job 11029249'.
[Sat Dec  2 06:49:33 2023]
Finished job 674.
761 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:49:33 2023]
Job 860: preparing tf=HSF1,tissue=Adipose training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz; Input files updated by another job: data/predictor_files/HSF1_Adipose.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HSF1_Adipose.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HSF1_Adipose.csv.gz --ground_truth_file data/predictor_files/HSF1_Adipose.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 860 with external jobid 'Submitted batch job 11029265'.
[Sat Dec  2 06:49:36 2023]
Finished job 989.
762 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:49:36 2023]
Job 792: working on tf=FOSL2,tissue=Brain
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Brain.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 792 with external jobid 'Submitted batch job 11029266'.
[Sat Dec  2 06:50:20 2023]
Finished job 589.
763 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:50:20 2023]
Job 775: working on tf=FOXM1,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 775 with external jobid 'Submitted batch job 11029270'.
[Sat Dec  2 06:51:21 2023]
Finished job 1251.
764 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:51:21 2023]
Job 786: working on tf=REST,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 786 with external jobid 'Submitted batch job 11029283'.
[Sat Dec  2 06:51:26 2023]
Finished job 655.
765 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:51:26 2023]
Job 841: preparing tf=STAT1,tissue=Cervix training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT1_Cervix.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT1_Cervix.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT1_Cervix.csv.gz --ground_truth_file data/predictor_files/STAT1_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 841 with external jobid 'Submitted batch job 11029284'.
[Sat Dec  2 06:53:11 2023]
Finished job 923.
766 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:53:11 2023]
Job 716: working on tf=GATA2,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA2_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 716 with external jobid 'Submitted batch job 11029297'.
[Sat Dec  2 06:53:12 2023]
Finished job 937.
767 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:53:12 2023]
Job 688: working on tf=GATA3,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA3_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA3_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 688 with external jobid 'Submitted batch job 11029298'.
[Sat Dec  2 06:53:14 2023]
Finished job 849.
768 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:53:14 2023]
Job 779: working on tf=REST,tissue=Cervix
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Cervix.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 779 with external jobid 'Submitted batch job 11029299'.
[Sat Dec  2 06:56:16 2023]
Finished job 1128.
769 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:56:16 2023]
Job 1314: evaluating on tf=MAX,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz, output/models/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.logistic.rds, output/models/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Bone-Marrow_2023-12-01/aggByCollect_MAX_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1314 with external jobid 'Submitted batch job 11029327'.
[Sat Dec  2 06:57:40 2023]
Finished job 639.
770 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:57:40 2023]
Job 1035: training on tf=FOXA1,tissue=Prostate training data
Reason: Missing output files: output/models/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.logistic.rds, output/models/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1035 with external jobid 'Submitted batch job 11029339'.
[Sat Dec  2 06:58:40 2023]
Finished job 981.
771 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 06:58:40 2023]
Job 825: working on tf=CTCF,tissue=Retina
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Retina.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Retina.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 825 with external jobid 'Submitted batch job 11029352'.
[Sat Dec  2 07:00:33 2023]
Finished job 799.
772 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 07:00:33 2023]
Job 985: preparing tf=FOXA1,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA1_Embryo.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA1_Embryo.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Embryo.csv.gz --ground_truth_file data/predictor_files/FOXA1_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 985 with external jobid 'Submitted batch job 11029368'.
[Sat Dec  2 07:02:18 2023]
Finished job 1219.
773 of 1394 steps (55%) done
Select jobs to execute...

[Sat Dec  2 07:02:18 2023]
Job 681: working on tf=PPARG,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_PPARG_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_PPARG_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 681 with external jobid 'Submitted batch job 11029386'.
[Sat Dec  2 07:03:04 2023]
Finished job 591.
774 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:03:04 2023]
Job 777: working on tf=REST,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 777 with external jobid 'Submitted batch job 11029393'.
[Sat Dec  2 07:04:12 2023]
Finished job 828.
775 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:04:12 2023]
Job 1014: preparing tf=GATA3,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA3_Embryo.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA3_Embryo.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA3_Embryo.csv.gz --ground_truth_file data/predictor_files/GATA3_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1014 with external jobid 'Submitted batch job 11029408'.
[Sat Dec  2 07:04:52 2023]
Finished job 648.
776 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:04:52 2023]
Job 793: working on tf=FOXM1,tissue=Brain
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Brain.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 793 with external jobid 'Submitted batch job 11029409'.
[Sat Dec  2 07:07:48 2023]
Finished job 945.
777 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:07:48 2023]
Job 717: working on tf=GATA4,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA4_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA4_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 717 with external jobid 'Submitted batch job 11029434'.
[Sat Dec  2 07:08:32 2023]
Finished job 610.
778 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:08:32 2023]
Job 654: working on tf=E2F1,tissue=Cervix
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_E2F1_Cervix.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_E2F1_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 654 with external jobid 'Submitted batch job 11029435'.
[Sat Dec  2 07:09:42 2023]
Finished job 695.
779 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:09:42 2023]
Job 881: preparing tf=STAT3,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT3_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT3_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Breast.csv.gz --ground_truth_file data/predictor_files/STAT3_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 881 with external jobid 'Submitted batch job 11029444'.
[Sat Dec  2 07:10:48 2023]
Finished job 1035.
780 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:10:48 2023]
Job 1221: evaluating on tf=FOXA1,tissue=Prostate training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz, output/models/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.logistic.rds, output/models/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.linear.rds --logistic_model output/models/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Prostate_2023-12-01/aggByCollect_FOXA1_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1221 with external jobid 'Submitted batch job 11029450'.
[Sat Dec  2 07:12:12 2023]
Finished job 572.
781 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:12:12 2023]
Job 1167: training on tf=GATA4,tissue=Stomach training data
Reason: Missing output files: output/models/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.linear.rds, output/models/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz --rds_file output/models/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1167 with external jobid 'Submitted batch job 11029462'.
[Sat Dec  2 07:13:14 2023]
Finished job 821.
782 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:13:14 2023]
Job 1007: preparing tf=GATA3,tissue=Thymus training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA3_Thymus.csv.gz, data/predictor_files/GATA3_Thymus.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA3_Thymus.csv.gz --ground_truth_file data/predictor_files/GATA3_Thymus.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1007 with external jobid 'Submitted batch job 11029468'.
[Sat Dec  2 07:13:21 2023]
Finished job 800.
783 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:13:21 2023]
Job 986: preparing tf=FOXA2,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA2_Embryo.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA2_Embryo.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA2_Embryo.csv.gz --ground_truth_file data/predictor_files/FOXA2_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 986 with external jobid 'Submitted batch job 11029469'.
[Sat Dec  2 07:14:00 2023]
Finished job 597.
784 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:14:00 2023]
Job 758: working on tf=CTCF,tissue=Kidney
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Kidney.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 758 with external jobid 'Submitted batch job 11029482'.
[Sat Dec  2 07:14:02 2023]
Finished job 544.
785 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:14:02 2023]
Job 730: working on tf=FOXA2,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA2_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA2_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 730 with external jobid 'Submitted batch job 11029483'.
[Sat Dec  2 07:15:49 2023]
Finished job 504.
786 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:15:49 2023]
Job 794: working on tf=GATA3,tissue=Brain
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA3_Brain.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA3_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 794 with external jobid 'Submitted batch job 11029503'.
[Sat Dec  2 07:15:50 2023]
Finished job 503.
787 of 1394 steps (56%) done
Select jobs to execute...

[Sat Dec  2 07:15:50 2023]
Job 690: working on tf=FOXM1,tissue=Bone
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Bone.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Bone.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 690 with external jobid 'Submitted batch job 11029504'.
[Sat Dec  2 07:17:43 2023]
Finished job 486.
788 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:17:43 2023]
Job 672: working on tf=FOXA2,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA2_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA2_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 672 with external jobid 'Submitted batch job 11029519'.
[Sat Dec  2 07:18:50 2023]
Finished job 868.
789 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:18:50 2023]
Job 768: working on tf=FOSL2,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOSL2_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 768 with external jobid 'Submitted batch job 11029523'.
[Sat Dec  2 07:18:53 2023]
Finished job 667.
790 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:18:53 2023]
Job 853: preparing tf=GATA3,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA3_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA3_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA3_Breast.csv.gz --ground_truth_file data/predictor_files/GATA3_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 853 with external jobid 'Submitted batch job 11029524'.
[Sat Dec  2 07:19:33 2023]
Finished job 575.
791 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:19:33 2023]
Job 761: working on tf=CTCF,tissue=Spleen
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Spleen.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Spleen.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 761 with external jobid 'Submitted batch job 11029543'.
[Sat Dec  2 07:20:39 2023]
Finished job 787.
792 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:20:39 2023]
Job 973: preparing tf=FOSL2,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Breast.csv.gz, data/predictor_files/FOSL2_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOSL2_Breast.csv.gz --ground_truth_file data/predictor_files/FOSL2_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 973 with external jobid 'Submitted batch job 11029547'.
[Sat Dec  2 07:21:15 2023]
Finished job 564.
793 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:21:15 2023]
Job 796: working on tf=PPARG,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_PPARG_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_PPARG_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 796 with external jobid 'Submitted batch job 11029555'.
[Sat Dec  2 07:21:15 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11026708

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11026708, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.
Select jobs to execute...

[Sat Dec  2 07:21:15 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11029556'.
[Sat Dec  2 07:21:17 2023]
Finished job 604.
794 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:21:17 2023]
Job 783: working on tf=REST,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 783 with external jobid 'Submitted batch job 11029557'.
[Sat Dec  2 07:21:47 2023]
Finished job 1167.
795 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:21:47 2023]
Job 1353: evaluating on tf=GATA4,tissue=Stomach training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz, output/models/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.linear.rds, output/models/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.linear.rds --logistic_model output/models/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Stomach.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA4_Stomach_2023-12-01/aggByCollect_GATA4_Stomach
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1353 with external jobid 'Submitted batch job 11029561'.
[Sat Dec  2 07:22:35 2023]
Finished job 666.
796 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:22:35 2023]
Job 852: preparing tf=FOXA1,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA1_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA1_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Breast.csv.gz --ground_truth_file data/predictor_files/FOXA1_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 852 with external jobid 'Submitted batch job 11029563'.
[Sat Dec  2 07:23:05 2023]
Finished job 511.
797 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:23:05 2023]
Job 1175: training on tf=GATA2,tissue=Prostate training data
Reason: Missing output files: output/models/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.logistic.rds, output/models/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz --rds_file output/models/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1175 with external jobid 'Submitted batch job 11029579'.
[Sat Dec  2 07:23:11 2023]
Finished job 466.
798 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:23:11 2023]
Job 652: working on tf=CTCF,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 652 with external jobid 'Submitted batch job 11029580'.
[Sat Dec  2 07:24:24 2023]
Finished job 801.
799 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:24:24 2023]
Job 987: preparing tf=GATA4,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA4_Embryo.csv.gz, data/predictor_files/GATA4_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA4_Embryo.csv.gz --ground_truth_file data/predictor_files/GATA4_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 987 with external jobid 'Submitted batch job 11029586'.
[Sat Dec  2 07:24:58 2023]
Finished job 478.
800 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:24:58 2023]
Job 664: working on tf=CTCF,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 664 with external jobid 'Submitted batch job 11029608'.
[Sat Dec  2 07:24:59 2023]
Finished job 467.
801 of 1394 steps (57%) done
Select jobs to execute...

[Sat Dec  2 07:24:59 2023]
Job 653: working on tf=CTCF,tissue=Cervix
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Cervix.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 653 with external jobid 'Submitted batch job 11029609'.
[Sat Dec  2 07:26:10 2023]
Finished job 1227.
802 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:26:10 2023]
Job 832: working on tf=GATA4,tissue=Skin
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA4_Skin.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA4_Skin.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 832 with external jobid 'Submitted batch job 11029614'.
[Sat Dec  2 07:26:11 2023]
Finished job 988.
803 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:26:11 2023]
Job 790: working on tf=REST,tissue=Brain
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_REST_Brain.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_REST_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 790 with external jobid 'Submitted batch job 11029615'.
[Sat Dec  2 07:26:14 2023]
Finished job 910.
804 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:26:14 2023]
Job 697: working on tf=HSF1,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_HSF1_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HSF1_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 697 with external jobid 'Submitted batch job 11029616'.
[Sat Dec  2 07:26:16 2023]
Finished job 696.
805 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:26:16 2023]
Job 882: preparing tf=FOXM1,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXM1_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXM1_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Breast.csv.gz --ground_truth_file data/predictor_files/FOXM1_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 882 with external jobid 'Submitted batch job 11029617'.
[Sat Dec  2 07:26:43 2023]
Finished job 527.
806 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:26:43 2023]
Job 713: working on tf=SOX2,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SOX2_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SOX2_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 713 with external jobid 'Submitted batch job 11029620'.
[Sat Dec  2 07:28:00 2023]
Finished job 1010.
807 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:28:00 2023]
Job 823: working on tf=E2F1,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_E2F1_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_E2F1_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 823 with external jobid 'Submitted batch job 11029625'.
[Sat Dec  2 07:28:01 2023]
Finished job 1016.
808 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:28:01 2023]
Job 659: working on tf=ETS1,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_ETS1_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ETS1_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 659 with external jobid 'Submitted batch job 11029626'.
[Sat Dec  2 07:28:05 2023]
Finished job 782.
809 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:28:05 2023]
Job 968: preparing tf=FOSL2,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Liver.csv.gz, data/predictor_files/FOSL2_Liver.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOSL2_Liver.csv.gz --ground_truth_file data/predictor_files/FOSL2_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 968 with external jobid 'Submitted batch job 11029632'.
[Sat Dec  2 07:28:06 2023]
Finished job 698.
810 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:28:06 2023]
Job 884: preparing tf=HSF1,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz; Input files updated by another job: data/predictor_files/HSF1_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HSF1_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HSF1_Breast.csv.gz --ground_truth_file data/predictor_files/HSF1_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 884 with external jobid 'Submitted batch job 11029633'.
[Sat Dec  2 07:29:52 2023]
Finished job 677.
811 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:29:52 2023]
Job 863: preparing tf=STAT1,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT1_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT1_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT1_Blood.csv.gz --ground_truth_file data/predictor_files/STAT1_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 863 with external jobid 'Submitted batch job 11029647'.
[Sat Dec  2 07:29:55 2023]
Finished job 861.
812 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:29:55 2023]
Job 778: working on tf=SP1,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SP1_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SP1_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 778 with external jobid 'Submitted batch job 11029648'.
[Sat Dec  2 07:30:53 2023]
Finished job 1175.
813 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:30:53 2023]
Job 1047: training on tf=PPARG,tissue=Adipose training data
Reason: Missing output files: output/models/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.logistic.rds, output/models/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz --rds_file output/models/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1047 with external jobid 'Submitted batch job 11029654'.
[Sat Dec  2 07:31:38 2023]
Finished job 1363.
814 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:31:38 2023]
Job 1361: evaluating on tf=GATA2,tissue=Prostate training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz, output/models/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.linear.rds, output/models/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.linear.rds --logistic_model output/models/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA2_Prostate_2023-12-01/aggByCollect_GATA2_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1361 with external jobid 'Submitted batch job 11029655'.
[Sat Dec  2 07:31:40 2023]
Finished job 995.
815 of 1394 steps (58%) done
Select jobs to execute...

[Sat Dec  2 07:31:40 2023]
Job 834: working on tf=STAT1,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT1_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT1_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 834 with external jobid 'Submitted batch job 11029656'.
[Sat Dec  2 07:31:41 2023]
Finished job 732.
816 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:31:41 2023]
Job 918: preparing tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/RUNX1_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_RUNX1_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Colon.csv.gz --ground_truth_file data/predictor_files/RUNX1_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 918 with external jobid 'Submitted batch job 11029657'.
[Sat Dec  2 07:31:43 2023]
Finished job 727.
817 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:31:43 2023]
Job 913: preparing tf=STAT3,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT3_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT3_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Blood.csv.gz --ground_truth_file data/predictor_files/STAT3_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 913 with external jobid 'Submitted batch job 11029665'.
[Sat Dec  2 07:35:17 2023]
Finished job 686.
818 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:35:17 2023]
Job 872: preparing tf=GATA2,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA2_Blood.csv.gz, data/predictor_files/GATA2_Blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Blood.csv.gz --ground_truth_file data/predictor_files/GATA2_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 872 with external jobid 'Submitted batch job 11029694'.
[Sat Dec  2 07:35:20 2023]
Finished job 678.
819 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:35:20 2023]
Job 864: preparing tf=SOX2,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz; Input files updated by another job: data/predictor_files/SOX2_Embryo.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_SOX2_Embryo.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SOX2_Embryo.csv.gz --ground_truth_file data/predictor_files/SOX2_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 864 with external jobid 'Submitted batch job 11029695'.
[Sat Dec  2 07:37:08 2023]
Finished job 714.
820 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:37:08 2023]
Job 900: preparing tf=FOXA1,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA1_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA1_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Colon.csv.gz --ground_truth_file data/predictor_files/FOXA1_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 900 with external jobid 'Submitted batch job 11029707'.
[Sat Dec  2 07:37:41 2023]
Finished job 524.
821 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:37:41 2023]
Job 750: working on tf=HSF1,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_HSF1_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HSF1_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 750 with external jobid 'Submitted batch job 11029708'.
[Sat Dec  2 07:37:43 2023]
Finished job 602.
822 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:37:43 2023]
Job 788: working on tf=MAX,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 788 with external jobid 'Submitted batch job 11029709'.
[Sat Dec  2 07:38:58 2023]
Finished job 920.
823 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:38:58 2023]
Job 814: working on tf=SP1,tissue=Breast
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SP1_Breast.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SP1_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 814 with external jobid 'Submitted batch job 11029731'.
[Sat Dec  2 07:39:00 2023]
Finished job 665.
824 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:39:00 2023]
Job 851: preparing tf=E2F1,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz; Input files updated by another job: data/predictor_files/E2F1_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_E2F1_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_E2F1_Breast.csv.gz --ground_truth_file data/predictor_files/E2F1_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 851 with external jobid 'Submitted batch job 11029732'.
[Sat Dec  2 07:39:01 2023]
Finished job 997.
825 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:39:01 2023]
Job 835: working on tf=GATA4,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA4_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA4_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 835 with external jobid 'Submitted batch job 11029733'.
[Sat Dec  2 07:40:45 2023]
Finished job 921.
826 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:40:45 2023]
Job 689: working on tf=YY1,tissue=Cervix
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Cervix.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 689 with external jobid 'Submitted batch job 11029752'.
[Sat Dec  2 07:40:48 2023]
Finished job 1304.
827 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:40:48 2023]
Job 710: working on tf=MAX,tissue=Cervix
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Cervix.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 710 with external jobid 'Submitted batch job 11029753'.
[Sat Dec  2 07:40:50 2023]
Finished job 857.
828 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:40:50 2023]
Job 776: working on tf=SP1,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SP1_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SP1_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 776 with external jobid 'Submitted batch job 11029754'.
[Sat Dec  2 07:42:34 2023]
Finished job 860.
829 of 1394 steps (59%) done
Select jobs to execute...

[Sat Dec  2 07:42:34 2023]
Job 680: working on tf=SP1,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SP1_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SP1_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 680 with external jobid 'Submitted batch job 11029766'.
[Sat Dec  2 07:42:38 2023]
Finished job 934.
830 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:42:38 2023]
Job 781: working on tf=SP1,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SP1_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SP1_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 781 with external jobid 'Submitted batch job 11029767'.
[Sat Dec  2 07:42:39 2023]
Finished job 927.
831 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:42:39 2023]
Job 766: working on tf=ETS1,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_ETS1_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ETS1_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 766 with external jobid 'Submitted batch job 11029768'.
[Sat Dec  2 07:43:35 2023]
Finished job 1047.
832 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:43:35 2023]
Job 1233: evaluating on tf=PPARG,tissue=Adipose training and test data
Reason: Missing output files: output/models_eval/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.logistic.train_eval.txt.gz, output/models_eval/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.linear.train_eval.txt.gz, output/models_eval/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.logistic.test_eval.txt.gz, output/models_eval/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz, output/models/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.logistic.rds, output/models/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.linear.rds --logistic_model output/models/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Adipose.prepared.csv.gz --eval_output output/models_eval/cistrome_PPARG_Adipose_2023-12-01/aggByCollect_PPARG_Adipose
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1233 with external jobid 'Submitted batch job 11029771'.
[Sat Dec  2 07:44:28 2023]
Finished job 813.
833 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:44:28 2023]
Job 1096: training on tf=CTCF,tissue=Prostate training data
Reason: Missing output files: output/models/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.linear.rds, output/models/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1096 with external jobid 'Submitted batch job 11029781'.
[Sat Dec  2 07:44:30 2023]
Finished job 683.
834 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:44:30 2023]
Job 869: preparing tf=FOXA1,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA1_Liver.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA1_Liver.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Liver.csv.gz --ground_truth_file data/predictor_files/FOXA1_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 869 with external jobid 'Submitted batch job 11029782'.
[Sat Dec  2 07:46:15 2023]
Finished job 786.
835 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:46:15 2023]
Job 999: preparing tf=GATA4,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA4_Liver.csv.gz, data/predictor_files/GATA4_Liver.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA4_Liver.csv.gz --ground_truth_file data/predictor_files/GATA4_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 999 with external jobid 'Submitted batch job 11029806'.
[Sat Dec  2 07:46:16 2023]
Finished job 841.
836 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:46:16 2023]
Job 972: preparing tf=REST,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_REST_Breast.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_REST_Breast.prepared.csv.gz; Input files updated by another job: data/predictor_files/REST_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_REST_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Breast.csv.gz --ground_truth_file data/predictor_files/REST_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 972 with external jobid 'Submitted batch job 11029807'.
[Sat Dec  2 07:46:19 2023]
Finished job 650.
837 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:46:19 2023]
Job 836: preparing tf=RUNX1,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/RUNX1_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_RUNX1_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_RUNX1_Blood.csv.gz --ground_truth_file data/predictor_files/RUNX1_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 836 with external jobid 'Submitted batch job 11029808'.
[Sat Dec  2 07:48:04 2023]
Finished job 716.
838 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:48:04 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11029829'.
[Sat Dec  2 07:48:08 2023]
Finished job 775.
839 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:48:08 2023]
Job 961: preparing tf=FOXM1,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXM1_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXM1_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Blood.csv.gz --ground_truth_file data/predictor_files/FOXM1_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 961 with external jobid 'Submitted batch job 11029830'.
[Sat Dec  2 07:49:55 2023]
Finished job 1314.
840 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:49:55 2023]
Job 764: working on tf=SP1,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SP1_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SP1_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 764 with external jobid 'Submitted batch job 11029846'.
[Sat Dec  2 07:49:57 2023]
Finished job 779.
841 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:49:57 2023]
Job 965: preparing tf=REST,tissue=Cervix training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_REST_Cervix.csv.gz, data/predictor_files/REST_Cervix.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Cervix.csv.gz --ground_truth_file data/predictor_files/REST_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 965 with external jobid 'Submitted batch job 11029847'.
[Sat Dec  2 07:50:46 2023]
Finished job 1096.
842 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:50:46 2023]
Job 1282: evaluating on tf=CTCF,tissue=Prostate training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz, output/models/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz, output/models/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.linear.rds --logistic_model output/models/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Prostate_2023-12-01/aggByCollect_CTCF_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1282 with external jobid 'Submitted batch job 11029848'.
[Sat Dec  2 07:52:08 2023]
Finished job 516.
843 of 1394 steps (60%) done
Select jobs to execute...

[Sat Dec  2 07:52:08 2023]
Job 1131: training on tf=CTCF,tissue=Pancreas training data
Reason: Missing output files: output/models/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.logistic.rds, output/models/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1131 with external jobid 'Submitted batch job 11029865'.
[Sat Dec  2 07:53:37 2023]
Finished job 792.
844 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:53:37 2023]
Job 978: preparing tf=FOSL2,tissue=Brain training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Brain.csv.gz, data/predictor_files/FOSL2_Brain.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOSL2_Brain.csv.gz --ground_truth_file data/predictor_files/FOSL2_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 978 with external jobid 'Submitted batch job 11029873'.
[Sat Dec  2 07:55:22 2023]
Finished job 681.
845 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:55:22 2023]
Job 867: preparing tf=PPARG,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_PPARG_Blood.csv.gz, data/predictor_files/PPARG_Blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Blood.csv.gz --ground_truth_file data/predictor_files/PPARG_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 867 with external jobid 'Submitted batch job 11029884'.
[Sat Dec  2 07:55:24 2023]
Finished job 985.
846 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:55:24 2023]
Job 702: working on tf=YY1,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 702 with external jobid 'Submitted batch job 11029885'.
[Sat Dec  2 07:55:25 2023]
Finished job 825.
847 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:55:25 2023]
Job 1011: preparing tf=CTCF,tissue=Retina training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Retina.csv.gz, data/predictor_files/CTCF_Retina.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Retina.csv.gz --ground_truth_file data/predictor_files/CTCF_Retina.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1011 with external jobid 'Submitted batch job 11029886'.
[Sat Dec  2 07:55:26 2023]
Finished job 688.
848 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:55:26 2023]
Job 874: preparing tf=GATA3,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA3_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA3_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA3_Blood.csv.gz --ground_truth_file data/predictor_files/GATA3_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 874 with external jobid 'Submitted batch job 11029887'.
[Sat Dec  2 07:57:11 2023]
Finished job 717.
849 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:57:11 2023]
Job 903: preparing tf=GATA4,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA4_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA4_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA4_Colon.csv.gz --ground_truth_file data/predictor_files/GATA4_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 903 with external jobid 'Submitted batch job 11029899'.
[Sat Dec  2 07:57:15 2023]
Finished job 777.
850 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:57:15 2023]
Job 963: preparing tf=REST,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_REST_Embryo.csv.gz, data/predictor_files/REST_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Embryo.csv.gz --ground_truth_file data/predictor_files/REST_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 963 with external jobid 'Submitted batch job 11029903'.
[Sat Dec  2 07:57:43 2023]
Finished job 522.
851 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:57:43 2023]
Job 708: working on tf=FOXA2,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA2_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA2_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 708 with external jobid 'Submitted batch job 11029904'.
[Sat Dec  2 07:58:03 2023]
Finished job 1131.
852 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:58:03 2023]
Job 1171: training on tf=FOXA1,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.linear.rds, output/models/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1171 with external jobid 'Submitted batch job 11029907'.
[Sat Dec  2 07:59:01 2023]
Finished job 1221.
853 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:59:01 2023]
Job 1317: evaluating on tf=CTCF,tissue=Pancreas training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz, output/models/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.logistic.rds, output/models/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.linear.rds --logistic_model output/models/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Pancreas.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Pancreas_2023-12-01/aggByCollect_CTCF_Pancreas
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1317 with external jobid 'Submitted batch job 11029917'.
[Sat Dec  2 07:59:05 2023]
Finished job 793.
854 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 07:59:05 2023]
Job 979: preparing tf=FOXM1,tissue=Brain training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXM1_Brain.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXM1_Brain.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Brain.csv.gz --ground_truth_file data/predictor_files/FOXM1_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 979 with external jobid 'Submitted batch job 11029918'.
[Sat Dec  2 08:00:48 2023]
Finished job 1007.
855 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 08:00:48 2023]
Job 350: working on tf=STAT3,tissue=Colon
Reason: Missing output files: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Colon.json; Input files updated by another job: data/predictor_files/STAT3_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT3 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT3_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT3_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 350 with external jobid 'Submitted batch job 11029940'.
[Sat Dec  2 08:00:53 2023]
Finished job 654.
856 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 08:00:53 2023]
Job 840: preparing tf=E2F1,tissue=Cervix training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_E2F1_Cervix.csv.gz, data/predictor_files/E2F1_Cervix.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_E2F1_Cervix.csv.gz --ground_truth_file data/predictor_files/E2F1_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 840 with external jobid 'Submitted batch job 11029941'.
[Sat Dec  2 08:00:54 2023]
Finished job 1014.
857 of 1394 steps (61%) done
Select jobs to execute...

[Sat Dec  2 08:00:54 2023]
Job 435: working on tf=FOXM1,tissue=Mammary-Gland
Reason: Missing output files: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Mammary-Gland.json; Input files updated by another job: data/predictor_files/FOXM1_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Mammary-Gland.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 435 with external jobid 'Submitted batch job 11029942'.
[Sat Dec  2 08:01:32 2023]
Finished job 350.
858 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:01:32 2023]
Job 536: working on STAT3_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT3_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT3_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT3_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 536 with external jobid 'Submitted batch job 11029950'.
[Sat Dec  2 08:01:34 2023]
Finished job 435.
859 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:01:34 2023]
Job 621: working on FOXM1_Mammary-Gland
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Mammary-Gland.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 621 with external jobid 'Submitted batch job 11029951'.
[Sat Dec  2 08:02:43 2023]
Finished job 881.
860 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:02:43 2023]
Job 359: working on tf=PPARG,tissue=Colon
Reason: Missing output files: data/prediction_parameters/enformer_parameters_cistrome_PPARG_Colon.json; Input files updated by another job: data/predictor_files/PPARG_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor PPARG --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/PPARG_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_PPARG_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 359 with external jobid 'Submitted batch job 11029967'.
[Sat Dec  2 08:03:07 2023]
Finished job 556.
861 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:03:07 2023]
Job 742: working on tf=MAX,tissue=Embryo
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Embryo.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 742 with external jobid 'Submitted batch job 11029968'.
[Sat Dec  2 08:03:23 2023]
Finished job 359.
862 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:03:23 2023]
Job 545: working on PPARG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_PPARG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_PPARG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_PPARG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 545 with external jobid 'Submitted batch job 11029969'.
[Sat Dec  2 08:04:32 2023]
Finished job 986.
863 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:04:32 2023]
Job 290: working on tf=SOX2,tissue=Brain
Reason: Missing output files: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json; Input files updated by another job: data/predictor_files/SOX2_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SOX2 --tissue Brain --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/SOX2_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 290 with external jobid 'Submitted batch job 11029979'.
[Sat Dec  2 08:05:12 2023]
Finished job 290.
864 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:05:12 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11029984'.
[Sat Dec  2 08:06:21 2023]
Finished job 690.
865 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:06:21 2023]
Job 876: preparing tf=FOXM1,tissue=Bone training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Bone.csv.gz, data/predictor_files/FOXM1_Bone.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Bone.csv.gz --ground_truth_file data/predictor_files/FOXM1_Bone.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 876 with external jobid 'Submitted batch job 11029995'.
[Sat Dec  2 08:06:47 2023]
Finished job 472.
866 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:06:47 2023]
Job 658: working on tf=CTCF,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 658 with external jobid 'Submitted batch job 11029996'.
[Sat Dec  2 08:08:12 2023]
Finished job 758.
867 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:08:12 2023]
Job 944: preparing tf=CTCF,tissue=Kidney training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Kidney.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Kidney.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Kidney.csv.gz --ground_truth_file data/predictor_files/CTCF_Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 944 with external jobid 'Submitted batch job 11030008'.
[Sat Dec  2 08:08:58 2023]
Finished job 1171.
868 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:08:58 2023]
Job 1357: evaluating on tf=FOXA1,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz, output/models/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.linear.rds --logistic_model output/models/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Embryo_2023-12-01/aggByCollect_FOXA1_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1357 with external jobid 'Submitted batch job 11030026'.
[Sat Dec  2 08:11:51 2023]
Finished job 730.
869 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:11:51 2023]
Job 1200: training on tf=GATA3,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.linear.rds, output/models/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz --rds_file output/models/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1200 with external jobid 'Submitted batch job 11030047'.
[Sat Dec  2 08:15:27 2023]
Finished job 853.
870 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:15:27 2023]
Job 916: preparing tf=FOXA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXA2_Colon.csv.gz, data/predictor_files/FOXA2_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA2_Colon.csv.gz --ground_truth_file data/predictor_files/FOXA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 916 with external jobid 'Submitted batch job 11030180'.
[Sat Dec  2 08:17:16 2023]
Finished job 768.
871 of 1394 steps (62%) done
Select jobs to execute...

[Sat Dec  2 08:17:16 2023]
Job 954: preparing tf=FOSL2,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOSL2_Lung.csv.gz, data/predictor_files/FOSL2_Lung.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOSL2_Lung.csv.gz --ground_truth_file data/predictor_files/FOSL2_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 954 with external jobid 'Submitted batch job 11030188'.
[Sat Dec  2 08:17:18 2023]
Finished job 794.
872 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:17:18 2023]
Job 980: preparing tf=GATA3,tissue=Brain training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA3_Brain.csv.gz, data/predictor_files/GATA3_Brain.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA3_Brain.csv.gz --ground_truth_file data/predictor_files/GATA3_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 980 with external jobid 'Submitted batch job 11030189'.
[Sat Dec  2 08:17:36 2023]
Finished job 647.
873 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:17:36 2023]
Job 833: working on tf=STAT3,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 833 with external jobid 'Submitted batch job 11030191'.
[Sat Dec  2 08:19:05 2023]
Finished job 973.
874 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:19:05 2023]
Job 348: working on tf=FOXM1,tissue=Colon
Reason: Missing output files: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json; Input files updated by another job: data/predictor_files/FOXM1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXM1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/FOXM1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 348 with external jobid 'Submitted batch job 11030201'.
[Sat Dec  2 08:19:06 2023]
Finished job 796.
875 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:19:06 2023]
Job 982: preparing tf=PPARG,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_PPARG_Lung.csv.gz, data/predictor_files/PPARG_Lung.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Lung.csv.gz --ground_truth_file data/predictor_files/PPARG_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 982 with external jobid 'Submitted batch job 11030202'.
[Sat Dec  2 08:19:33 2023]
Finished job 525.
876 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:19:33 2023]
Job 711: working on tf=CTCF,tissue=Brain
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Brain.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 711 with external jobid 'Submitted batch job 11030204'.
[Sat Dec  2 08:19:44 2023]
Finished job 348.
877 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:19:44 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11030210'.
[Sat Dec  2 08:20:54 2023]
Finished job 1353.
878 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:20:54 2023]
Job 361: working on tf=STAT1,tissue=Colon
Reason: Missing output files: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json; Input files updated by another job: data/predictor_files/STAT1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory /scratch/midway3/temi --predictors_file data/predictor_files/STAT1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json --date 2023-12-01
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 361 with external jobid 'Submitted batch job 11030211'.
[Sat Dec  2 08:20:59 2023]
Finished job 672.
879 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:20:59 2023]
Job 858: preparing tf=FOXA2,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA2_Liver.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA2_Liver.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA2_Liver.csv.gz --ground_truth_file data/predictor_files/FOXA2_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 858 with external jobid 'Submitted batch job 11030212'.
[Sat Dec  2 08:21:19 2023]
Finished job 559.
880 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:21:19 2023]
Job 745: working on tf=CTCF,tissue=Heart
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Heart.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Heart.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 745 with external jobid 'Submitted batch job 11030218'.
[Sat Dec  2 08:21:34 2023]
Finished job 361.
881 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:21:34 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11030232'.
[Sat Dec  2 08:21:43 2023]
Finished job 1200.
882 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:21:43 2023]
Job 1386: evaluating on tf=GATA3,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz, output/models/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.linear.rds, output/models/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.linear.rds --logistic_model output/models/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA3_Embryo_2023-12-01/aggByCollect_GATA3_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1386 with external jobid 'Submitted batch job 11030233'.
[Sat Dec  2 08:22:47 2023]
Finished job 761.
883 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:22:47 2023]
Job 1039: training on tf=GATA3,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.linear.rds, output/models/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz --rds_file output/models/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1039 with external jobid 'Submitted batch job 11030238'.
[Sat Dec  2 08:22:49 2023]
Finished job 783.
884 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:22:49 2023]
Job 947: preparing tf=CTCF,tissue=Spleen training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Spleen.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Spleen.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Spleen.csv.gz --ground_truth_file data/predictor_files/CTCF_Spleen.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 947 with external jobid 'Submitted batch job 11030239'.
[Sat Dec  2 08:23:06 2023]
Finished job 594.
885 of 1394 steps (63%) done
Select jobs to execute...

[Sat Dec  2 08:23:06 2023]
Job 969: preparing tf=REST,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_REST_Liver.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_REST_Liver.prepared.csv.gz; Input files updated by another job: data/predictor_files/REST_Liver.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_REST_Liver.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Liver.csv.gz --ground_truth_file data/predictor_files/REST_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 969 with external jobid 'Submitted batch job 11030251'.
[Sat Dec  2 08:23:11 2023]
Finished job 470.
886 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:23:11 2023]
Job 656: working on tf=CTCF,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 656 with external jobid 'Submitted batch job 11030252'.
[Sat Dec  2 08:24:36 2023]
Finished job 987.
887 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:24:36 2023]
Job 780: working on tf=YY1,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 780 with external jobid 'Submitted batch job 11030257'.
[Sat Dec  2 08:24:39 2023]
Finished job 852.
888 of 1394 steps (64%) done
Select jobs to execute...
[Sat Dec  2 08:24:57 2023]
Finished job 577.
889 of 1394 steps (64%) done

[Sat Dec  2 08:24:57 2023]
Job 763: working on tf=GATA3,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_GATA3_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GATA3_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 763 with external jobid 'Submitted batch job 11030270'.
[Sat Dec  2 08:30:18 2023]
Finished job 605.
890 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:30:18 2023]
Job 791: working on tf=YY1,tissue=Brain
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Brain.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 791 with external jobid 'Submitted batch job 11030319'.
[Sat Dec  2 08:30:25 2023]
Finished job 652.
891 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:30:25 2023]
Job 838: preparing tf=CTCF,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Embryo.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Embryo.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Embryo.csv.gz --ground_truth_file data/predictor_files/CTCF_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 838 with external jobid 'Submitted batch job 11030320'.
[Sat Dec  2 08:32:29 2023]
Finished job 1039.
892 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:32:29 2023]
Job 1038: training on tf=FOXA1,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.logistic.rds, output/models/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1038 with external jobid 'Submitted batch job 11030327'.

[Sat Dec  2 08:32:29 2023]
Job 1225: evaluating on tf=GATA3,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.logistic.rds, output/models/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.linear.rds --logistic_model output/models/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA3_Breast_2023-12-01/aggByCollect_GATA3_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1225 with external jobid 'Submitted batch job 11030328'.
[Sat Dec  2 08:33:37 2023]
Finished job 790.
893 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:33:37 2023]
Job 976: preparing tf=REST,tissue=Brain training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_REST_Brain.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_REST_Brain.prepared.csv.gz; Input files updated by another job: data/predictor_files/REST_Brain.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_REST_Brain.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_REST_Brain.csv.gz --ground_truth_file data/predictor_files/REST_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 976 with external jobid 'Submitted batch job 11030331'.
[Sat Dec  2 08:33:41 2023]
Finished job 664.
894 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:33:41 2023]
Job 850: preparing tf=CTCF,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Breast.csv.gz, data/predictor_files/CTCF_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Breast.csv.gz --ground_truth_file data/predictor_files/CTCF_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 850 with external jobid 'Submitted batch job 11030332'.
[Sat Dec  2 08:33:42 2023]
Finished job 653.
895 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:33:42 2023]
Job 839: preparing tf=CTCF,tissue=Cervix training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Cervix.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Cervix.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Cervix.csv.gz --ground_truth_file data/predictor_files/CTCF_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 839 with external jobid 'Submitted batch job 11030333'.
[Sat Dec  2 08:35:29 2023]
Finished job 697.
896 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:35:29 2023]
Job 883: preparing tf=HSF1,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_HSF1_Colon.csv.gz, data/predictor_files/HSF1_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HSF1_Colon.csv.gz --ground_truth_file data/predictor_files/HSF1_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 883 with external jobid 'Submitted batch job 11030358'.
[Sat Dec  2 08:35:30 2023]
Finished job 882.
897 of 1394 steps (64%) done
Select jobs to execute...
[Sat Dec  2 08:35:31 2023]
Finished job 713.
898 of 1394 steps (64%) done

[Sat Dec  2 08:35:31 2023]
Job 899: preparing tf=SOX2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_SOX2_Colon.csv.gz, data/predictor_files/SOX2_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SOX2_Colon.csv.gz --ground_truth_file data/predictor_files/SOX2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 899 with external jobid 'Submitted batch job 11030359'.
[Sat Dec  2 08:35:48 2023]
Finished job 533.
899 of 1394 steps (64%) done
Select jobs to execute...

[Sat Dec  2 08:35:48 2023]
Job 719: working on tf=CTCF,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 719 with external jobid 'Submitted batch job 11030366'.
[Sat Dec  2 08:37:16 2023]
Finished job 823.
900 of 1394 steps (65%) done
Select jobs to execute...

[Sat Dec  2 08:37:16 2023]
Job 1009: preparing tf=E2F1,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_E2F1_Blood.csv.gz, data/predictor_files/E2F1_Blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_E2F1_Blood.csv.gz --ground_truth_file data/predictor_files/E2F1_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1009 with external jobid 'Submitted batch job 11030371'.
[Sat Dec  2 08:37:18 2023]
Finished job 968.
901 of 1394 steps (65%) done
Select jobs to execute...
[Sat Dec  2 08:37:19 2023]
Finished job 884.
902 of 1394 steps (65%) done
[Sat Dec  2 08:37:34 2023]
Finished job 493.
903 of 1394 steps (65%) done

[Sat Dec  2 08:37:34 2023]
Job 679: working on tf=YY1,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 679 with external jobid 'Submitted batch job 11030386'.
[Sat Dec  2 08:39:00 2023]
Finished job 1361.
904 of 1394 steps (65%) done
Select jobs to execute...
[Sat Dec  2 08:39:04 2023]
Finished job 863.
905 of 1394 steps (65%) done
[Sat Dec  2 08:39:23 2023]
Finished job 641.
906 of 1394 steps (65%) done

[Sat Dec  2 08:39:23 2023]
Job 827: working on tf=FOXA2,tissue=Skin
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA2_Skin.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA2_Skin.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 827 with external jobid 'Submitted batch job 11030399'.
[Sat Dec  2 08:40:47 2023]
Finished job 834.
907 of 1394 steps (65%) done
Select jobs to execute...

[Sat Dec  2 08:40:47 2023]
Job 1020: preparing tf=STAT1,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT1_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT1_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT1_Lung.csv.gz --ground_truth_file data/predictor_files/STAT1_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1020 with external jobid 'Submitted batch job 11030402'.
[Sat Dec  2 08:40:48 2023]
Finished job 918.
908 of 1394 steps (65%) done
Select jobs to execute...
[Sat Dec  2 08:40:49 2023]
Finished job 913.
909 of 1394 steps (65%) done
[Sat Dec  2 08:40:52 2023]
Finished job 832.
910 of 1394 steps (65%) done

[Sat Dec  2 08:40:52 2023]
Job 1018: preparing tf=GATA4,tissue=Skin training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA4_Skin.csv.gz, data/predictor_files/GATA4_Skin.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA4_Skin.csv.gz --ground_truth_file data/predictor_files/GATA4_Skin.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1018 with external jobid 'Submitted batch job 11030406'.
[Sat Dec  2 08:41:04 2023]
Finished job 550.
911 of 1394 steps (65%) done
Select jobs to execute...

[Sat Dec  2 08:41:04 2023]
Job 736: working on tf=SOX2,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SOX2_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SOX2_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 736 with external jobid 'Submitted batch job 11030407'.
[Sat Dec  2 08:42:29 2023]
Finished job 900.
912 of 1394 steps (65%) done
Select jobs to execute...
[Sat Dec  2 08:42:32 2023]
Finished job 872.
913 of 1394 steps (65%) done
[Sat Dec  2 08:42:33 2023]
Finished job 864.
914 of 1394 steps (66%) done
[Sat Dec  2 08:42:34 2023]
Finished job 778.
915 of 1394 steps (66%) done

[Sat Dec  2 08:42:34 2023]
Job 964: preparing tf=SP1,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_SP1_Embryo.csv.gz, data/predictor_files/SP1_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SP1_Embryo.csv.gz --ground_truth_file data/predictor_files/SP1_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 964 with external jobid 'Submitted batch job 11030411'.
[Sat Dec  2 08:44:09 2023]
Finished job 814.
916 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:44:09 2023]
Job 1000: preparing tf=SP1,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_SP1_Breast.csv.gz, data/predictor_files/SP1_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SP1_Breast.csv.gz --ground_truth_file data/predictor_files/SP1_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1000 with external jobid 'Submitted batch job 11030432'.
[Sat Dec  2 08:44:10 2023]
Finished job 851.
917 of 1394 steps (66%) done
Select jobs to execute...
[Sat Dec  2 08:44:12 2023]
Finished job 750.
918 of 1394 steps (66%) done

[Sat Dec  2 08:44:12 2023]
Job 936: preparing tf=HSF1,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_HSF1_Liver.csv.gz, data/predictor_files/HSF1_Liver.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HSF1_Liver.csv.gz --ground_truth_file data/predictor_files/HSF1_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 936 with external jobid 'Submitted batch job 11030433'.
[Sat Dec  2 08:46:01 2023]
Finished job 529.
919 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:46:01 2023]
Job 715: working on tf=YY1,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 715 with external jobid 'Submitted batch job 11030448'.
[Sat Dec  2 08:46:32 2023]
Finished job 1038.
920 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:46:32 2023]
Job 1172: training on tf=FOXA2,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.linear.rds, output/models/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz --rds_file output/models/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1172 with external jobid 'Submitted batch job 11030459'.

[Sat Dec  2 08:46:32 2023]
Job 1224: evaluating on tf=FOXA1,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.linear.rds, output/models/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.linear.rds --logistic_model output/models/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Breast_2023-12-01/aggByCollect_FOXA1_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1224 with external jobid 'Submitted batch job 11030460'.
[Sat Dec  2 08:47:27 2023]
Finished job 689.
921 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:47:27 2023]
Job 875: preparing tf=YY1,tissue=Cervix training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz; Input files updated by another job: data/predictor_files/YY1_Cervix.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_YY1_Cervix.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Cervix.csv.gz --ground_truth_file data/predictor_files/YY1_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 875 with external jobid 'Submitted batch job 11030465'.
[Sat Dec  2 08:47:32 2023]
Finished job 659.
922 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:47:32 2023]
Job 845: preparing tf=ETS1,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/ETS1_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_ETS1_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ETS1_Blood.csv.gz --ground_truth_file data/predictor_files/ETS1_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 845 with external jobid 'Submitted batch job 11030466'.
[Sat Dec  2 08:49:10 2023]
Finished job 835.
923 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:49:10 2023]
Job 1021: preparing tf=GATA4,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA4_Lung.csv.gz, data/predictor_files/GATA4_Lung.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA4_Lung.csv.gz --ground_truth_file data/predictor_files/GATA4_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1021 with external jobid 'Submitted batch job 11030480'.
[Sat Dec  2 08:49:11 2023]
Finished job 788.
924 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:49:11 2023]
Job 974: preparing tf=MAX,tissue=Breast training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MAX_Breast.csv.gz, data/predictor_files/MAX_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Breast.csv.gz --ground_truth_file data/predictor_files/MAX_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 974 with external jobid 'Submitted batch job 11030481'.
[Sat Dec  2 08:50:49 2023]
Finished job 710.
925 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:50:49 2023]
Job 896: preparing tf=MAX,tissue=Cervix training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz; Input files updated by another job: data/predictor_files/MAX_Cervix.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MAX_Cervix.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Cervix.csv.gz --ground_truth_file data/predictor_files/MAX_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 896 with external jobid 'Submitted batch job 11030497'.
[Sat Dec  2 08:50:50 2023]
Finished job 776.
926 of 1394 steps (66%) done
Select jobs to execute...

[Sat Dec  2 08:50:50 2023]
Job 962: preparing tf=SP1,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/SP1_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_SP1_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SP1_Blood.csv.gz --ground_truth_file data/predictor_files/SP1_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 962 with external jobid 'Submitted batch job 11030498'.
[Sat Dec  2 08:52:25 2023]
Finished job 1233.
927 of 1394 steps (66%) done
Select jobs to execute...
[Sat Dec  2 08:52:28 2023]
Finished job 781.
928 of 1394 steps (67%) done

[Sat Dec  2 08:52:28 2023]
Job 967: preparing tf=SP1,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_SP1_Liver.csv.gz, data/predictor_files/SP1_Liver.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SP1_Liver.csv.gz --ground_truth_file data/predictor_files/SP1_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 967 with external jobid 'Submitted batch job 11030510'.
[Sat Dec  2 08:54:02 2023]
Finished job 999.
929 of 1394 steps (67%) done
Select jobs to execute...
[Sat Dec  2 08:54:03 2023]
Finished job 972.
930 of 1394 steps (67%) done
[Sat Dec  2 08:54:07 2023]
Finished job 766.
931 of 1394 steps (67%) done

[Sat Dec  2 08:54:07 2023]
Job 952: preparing tf=ETS1,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_ETS1_Lung.csv.gz, data/predictor_files/ETS1_Lung.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ETS1_Lung.csv.gz --ground_truth_file data/predictor_files/ETS1_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 952 with external jobid 'Submitted batch job 11030524'.
[Sat Dec  2 08:54:19 2023]
Finished job 506.
932 of 1394 steps (67%) done
Select jobs to execute...

[Sat Dec  2 08:54:19 2023]
Job 692: working on tf=MAX,tissue=Brain
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Brain.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 692 with external jobid 'Submitted batch job 11030527'.
[Sat Dec  2 08:55:40 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11029829

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11029829, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.
Select jobs to execute...

[Sat Dec  2 08:55:40 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11030548'.
[Sat Dec  2 08:55:41 2023]
Finished job 961.
933 of 1394 steps (67%) done
Select jobs to execute...
[Sat Dec  2 08:56:16 2023]
Finished job 1172.
934 of 1394 steps (67%) done

[Sat Dec  2 08:56:16 2023]
Job 1067: training on tf=STAT3,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.logistic.rds, output/models/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1067 with external jobid 'Submitted batch job 11030550'.

[Sat Dec  2 08:56:16 2023]
Job 1358: evaluating on tf=FOXA2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz, output/models/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz, output/models/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.linear.rds --logistic_model output/models/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA2_Embryo_2023-12-01/aggByCollect_FOXA2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1358 with external jobid 'Submitted batch job 11030551'.
[Sat Dec  2 08:57:09 2023]
Finished job 867.
935 of 1394 steps (67%) done
Select jobs to execute...
[Sat Dec  2 08:57:14 2023]
Finished job 1282.
936 of 1394 steps (67%) done
[Sat Dec  2 08:57:16 2023]
Finished job 965.
937 of 1394 steps (67%) done
[Sat Dec  2 08:57:18 2023]
Finished job 869.
938 of 1394 steps (67%) done
[Sat Dec  2 08:57:19 2023]
Finished job 680.
939 of 1394 steps (67%) done

[Sat Dec  2 08:57:19 2023]
Job 866: preparing tf=SP1,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_SP1_Colon.csv.gz, data/predictor_files/SP1_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SP1_Colon.csv.gz --ground_truth_file data/predictor_files/SP1_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 866 with external jobid 'Submitted batch job 11030566'.
[Sat Dec  2 08:58:51 2023]
Finished job 836.
940 of 1394 steps (67%) done
Select jobs to execute...
[Sat Dec  2 08:58:57 2023]
Finished job 519.
941 of 1394 steps (68%) done

[Sat Dec  2 08:58:57 2023]
Job 705: working on tf=HSF1,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_HSF1_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HSF1_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 705 with external jobid 'Submitted batch job 11030575'.
[Sat Dec  2 09:00:17 2023]
Finished job 903.
942 of 1394 steps (68%) done
Select jobs to execute...
[Sat Dec  2 09:00:18 2023]
Finished job 963.
943 of 1394 steps (68%) done
[Sat Dec  2 09:00:21 2023]
Finished job 1011.
944 of 1394 steps (68%) done
[Sat Dec  2 09:00:23 2023]
Finished job 978.
945 of 1394 steps (68%) done
[Sat Dec  2 09:00:24 2023]
Finished job 764.
946 of 1394 steps (68%) done

[Sat Dec  2 09:00:24 2023]
Job 950: preparing tf=SP1,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/SP1_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_SP1_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SP1_Lung.csv.gz --ground_truth_file data/predictor_files/SP1_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 950 with external jobid 'Submitted batch job 11030591'.
[Sat Dec  2 09:01:40 2023]
Finished job 876.
947 of 1394 steps (68%) done
Select jobs to execute...
[Sat Dec  2 09:01:46 2023]
Finished job 840.
948 of 1394 steps (68%) done
[Sat Dec  2 09:01:47 2023]
Finished job 1317.
949 of 1394 steps (68%) done
[Sat Dec  2 09:01:48 2023]
Finished job 979.
950 of 1394 steps (68%) done
[Sat Dec  2 09:01:50 2023]
Finished job 702.
951 of 1394 steps (68%) done

[Sat Dec  2 09:01:50 2023]
Job 888: preparing tf=YY1,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_YY1_Embryo.csv.gz, data/predictor_files/YY1_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Embryo.csv.gz --ground_truth_file data/predictor_files/YY1_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 888 with external jobid 'Submitted batch job 11030597'.
[Sat Dec  2 09:01:51 2023]
Finished job 874.
952 of 1394 steps (68%) done
Select jobs to execute...
[Sat Dec  2 09:03:19 2023]
Finished job 532.
953 of 1394 steps (68%) done

[Sat Dec  2 09:03:19 2023]
Job 718: working on tf=MAX,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 718 with external jobid 'Submitted batch job 11030608'.
[Sat Dec  2 09:03:21 2023]
Finished job 620.
954 of 1394 steps (68%) done
Select jobs to execute...

[Sat Dec  2 09:03:21 2023]
Job 806: working on tf=HSF1,tissue=Bone
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_HSF1_Bone.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HSF1_Bone.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 806 with external jobid 'Submitted batch job 11030609'.
[Sat Dec  2 09:04:30 2023]
Finished job 944.
955 of 1394 steps (69%) done
Select jobs to execute...
[Sat Dec  2 09:05:51 2023]
Finished job 1357.
956 of 1394 steps (69%) done
[Sat Dec  2 09:08:31 2023]
Finished job 916.
957 of 1394 steps (69%) done
[Sat Dec  2 09:09:04 2023]
Finished job 1067.
958 of 1394 steps (69%) done

[Sat Dec  2 09:09:04 2023]
Job 1055: training on tf=FOXA1,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.logistic.rds, output/models/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1055 with external jobid 'Submitted batch job 11030656'.

[Sat Dec  2 09:09:04 2023]
Job 1253: evaluating on tf=STAT3,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz, output/models/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz, output/models/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.linear.rds --logistic_model output/models/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Breast_2023-12-01/aggByCollect_STAT3_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1253 with external jobid 'Submitted batch job 11030657'.
[Sat Dec  2 09:09:57 2023]
Finished job 708.
959 of 1394 steps (69%) done
Select jobs to execute...

[Sat Dec  2 09:09:57 2023]
Job 894: preparing tf=FOXA2,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXA2_Lung.csv.gz, data/predictor_files/FOXA2_Lung.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA2_Lung.csv.gz --ground_truth_file data/predictor_files/FOXA2_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 894 with external jobid 'Submitted batch job 11030669'.
[Sat Dec  2 09:11:07 2023]
Finished job 982.
960 of 1394 steps (69%) done
Select jobs to execute...
[Sat Dec  2 09:11:09 2023]
Finished job 954.
961 of 1394 steps (69%) done
[Sat Dec  2 09:11:17 2023]
Finished job 742.
962 of 1394 steps (69%) done

[Sat Dec  2 09:11:17 2023]
Job 928: preparing tf=MAX,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MAX_Embryo.csv.gz, data/predictor_files/MAX_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Embryo.csv.gz --ground_truth_file data/predictor_files/MAX_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 928 with external jobid 'Submitted batch job 11030683'.
[Sat Dec  2 09:11:23 2023]
Finished job 553.
963 of 1394 steps (69%) done
Select jobs to execute...

[Sat Dec  2 09:11:23 2023]
Job 739: working on tf=CTCF,tissue=Bone
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Bone.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Bone.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 739 with external jobid 'Submitted batch job 11030684'.
[Sat Dec  2 09:11:25 2023]
Finished job 465.
964 of 1394 steps (69%) done
Select jobs to execute...

[Sat Dec  2 09:11:25 2023]
Job 651: working on tf=MAX,tissue=Blood
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Blood.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 651 with external jobid 'Submitted batch job 11030686'.
[Sat Dec  2 09:12:34 2023]
Finished job 658.
965 of 1394 steps (69%) done
Select jobs to execute...

[Sat Dec  2 09:12:34 2023]
Job 844: preparing tf=CTCF,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Blood.csv.gz, data/predictor_files/CTCF_Blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Blood.csv.gz --ground_truth_file data/predictor_files/CTCF_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 844 with external jobid 'Submitted batch job 11030692'.
[Sat Dec  2 09:12:38 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11029556

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11029556, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.
Select jobs to execute...

[Sat Dec  2 09:12:38 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11030693'.
[Sat Dec  2 09:12:40 2023]
Finished job 579.
966 of 1394 steps (69%) done
Select jobs to execute...

[Sat Dec  2 09:12:40 2023]
Job 765: working on tf=YY1,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_YY1_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_YY1_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 765 with external jobid 'Submitted batch job 11030694'.
[Sat Dec  2 09:14:01 2023]
Finished job 508.
967 of 1394 steps (69%) done
Select jobs to execute...

[Sat Dec  2 09:14:01 2023]
Job 694: working on tf=SOX2,tissue=Skin
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_SOX2_Skin.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SOX2_Skin.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 694 with external jobid 'Submitted batch job 11030711'.
[Sat Dec  2 09:14:04 2023]
Finished job 514.
968 of 1394 steps (69%) done
Select jobs to execute...

[Sat Dec  2 09:14:04 2023]
Job 700: working on tf=FOXA1,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXA1_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXA1_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 700 with external jobid 'Submitted batch job 11030712'.
[Sat Dec  2 09:15:13 2023]
Finished job 980.
969 of 1394 steps (70%) done
Select jobs to execute...
[Sat Dec  2 09:15:14 2023]
Finished job 833.
970 of 1394 steps (70%) done

[Sat Dec  2 09:15:14 2023]
Job 1019: preparing tf=STAT3,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/STAT3_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT3_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Lung.csv.gz --ground_truth_file data/predictor_files/STAT3_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1019 with external jobid 'Submitted batch job 11030720'.
[Sat Dec  2 09:15:17 2023]
Finished job 536.
971 of 1394 steps (70%) done
Select jobs to execute...

[Sat Dec  2 09:15:17 2023]
Job 722: working on tf=STAT3,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_STAT3_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT3_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 722 with external jobid 'Submitted batch job 11030721'.
[Sat Dec  2 09:15:18 2023]
Finished job 621.
972 of 1394 steps (70%) done
Select jobs to execute...

[Sat Dec  2 09:15:18 2023]
Job 807: working on tf=FOXM1,tissue=Mammary-Gland
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 807 with external jobid 'Submitted batch job 11030722'.
[Sat Dec  2 09:16:25 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030232

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11030232, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.
Select jobs to execute...

[Sat Dec  2 09:16:25 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11030740'.
[Sat Dec  2 09:16:26 2023]
Finished job 1386.
973 of 1394 steps (70%) done
Select jobs to execute...
[Sat Dec  2 09:16:28 2023]
Finished job 969.
974 of 1394 steps (70%) done
[Sat Dec  2 09:16:30 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030210

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11030210, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.

[Sat Dec  2 09:16:30 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11030741'.
[Sat Dec  2 09:16:31 2023]
Finished job 858.
975 of 1394 steps (70%) done
Select jobs to execute...
[Sat Dec  2 09:16:34 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11029984

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11029984, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.

[Sat Dec  2 09:16:34 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11030742'.
[Sat Dec  2 09:16:35 2023]
Finished job 545.
976 of 1394 steps (70%) done
Select jobs to execute...

[Sat Dec  2 09:16:35 2023]
Job 731: working on tf=PPARG,tissue=Colon
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_PPARG_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 731 with external jobid 'Submitted batch job 11030743'.
[Sat Dec  2 09:16:39 2023]
Finished job 499.
977 of 1394 steps (70%) done
Select jobs to execute...

[Sat Dec  2 09:16:39 2023]
Job 685: working on tf=CTCF,tissue=Skin
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Skin.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Skin.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 685 with external jobid 'Submitted batch job 11030746'.
[Sat Dec  2 09:17:06 2023]
Finished job 1055.
978 of 1394 steps (70%) done
Select jobs to execute...

[Sat Dec  2 09:17:06 2023]
Job 1241: evaluating on tf=FOXA1,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz, output/models/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.linear.rds --logistic_model output/models/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Liver_2023-12-01/aggByCollect_FOXA1_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1241 with external jobid 'Submitted batch job 11030750'.

[Sat Dec  2 09:17:06 2023]
Job 1022: training on tf=RUNX1,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.logistic.rds, output/models/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1022 with external jobid 'Submitted batch job 11030751'.
[Sat Dec  2 09:17:40 2023]
Finished job 1225.
979 of 1394 steps (70%) done
Select jobs to execute...
[Sat Dec  2 09:17:41 2023]
Finished job 976.
980 of 1394 steps (70%) done
[Sat Dec  2 09:17:47 2023]
Finished job 947.
981 of 1394 steps (70%) done
[Sat Dec  2 09:18:52 2023]
Finished job 883.
982 of 1394 steps (70%) done
[Sat Dec  2 09:18:53 2023]
Finished job 899.
983 of 1394 steps (71%) done
[Sat Dec  2 09:18:57 2023]
Finished job 791.
984 of 1394 steps (71%) done

[Sat Dec  2 09:18:57 2023]
Job 977: preparing tf=YY1,tissue=Brain training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_YY1_Brain.csv.gz, data/predictor_files/YY1_Brain.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Brain.csv.gz --ground_truth_file data/predictor_files/YY1_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 977 with external jobid 'Submitted batch job 11030767'.
[Sat Dec  2 09:18:58 2023]
Finished job 780.
985 of 1394 steps (71%) done
Select jobs to execute...

[Sat Dec  2 09:18:58 2023]
Job 966: preparing tf=YY1,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_YY1_Liver.csv.gz, data/predictor_files/YY1_Liver.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Liver.csv.gz --ground_truth_file data/predictor_files/YY1_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 966 with external jobid 'Submitted batch job 11030768'.
[Sat Dec  2 09:19:06 2023]
Finished job 838.
986 of 1394 steps (71%) done
Select jobs to execute...
[Sat Dec  2 09:20:04 2023]
Finished job 1009.
987 of 1394 steps (71%) done
[Sat Dec  2 09:20:07 2023]
Finished job 850.
988 of 1394 steps (71%) done
[Sat Dec  2 09:20:08 2023]
Finished job 839.
989 of 1394 steps (71%) done
[Sat Dec  2 09:20:12 2023]
Finished job 711.
990 of 1394 steps (71%) done

[Sat Dec  2 09:20:12 2023]
Job 897: preparing tf=CTCF,tissue=Brain training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Brain.csv.gz, data/predictor_files/CTCF_Brain.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Brain.csv.gz --ground_truth_file data/predictor_files/CTCF_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 897 with external jobid 'Submitted batch job 11030787'.
[Sat Dec  2 09:21:10 2023]
Finished job 1020.
991 of 1394 steps (71%) done
Select jobs to execute...
[Sat Dec  2 09:21:16 2023]
Finished job 763.
992 of 1394 steps (71%) done

[Sat Dec  2 09:21:16 2023]
Job 949: preparing tf=GATA3,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GATA3_Lung.csv.gz, data/predictor_files/GATA3_Lung.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA3_Lung.csv.gz --ground_truth_file data/predictor_files/GATA3_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 949 with external jobid 'Submitted batch job 11030792'.
[Sat Dec  2 09:22:11 2023]
Finished job 875.
993 of 1394 steps (71%) done
Select jobs to execute...
[Sat Dec  2 09:22:14 2023]
Finished job 1000.
994 of 1394 steps (71%) done
[Sat Dec  2 09:22:15 2023]
Finished job 936.
995 of 1394 steps (71%) done
[Sat Dec  2 09:22:16 2023]
Finished job 964.
996 of 1394 steps (71%) done
[Sat Dec  2 09:22:18 2023]
Finished job 736.
997 of 1394 steps (72%) done

[Sat Dec  2 09:22:18 2023]
Job 922: preparing tf=SOX2,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/SOX2_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_SOX2_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SOX2_Lung.csv.gz --ground_truth_file data/predictor_files/SOX2_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 922 with external jobid 'Submitted batch job 11030801'.
[Sat Dec  2 09:22:20 2023]
Finished job 679.
998 of 1394 steps (72%) done
Select jobs to execute...

[Sat Dec  2 09:22:20 2023]
Job 865: preparing tf=YY1,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz; Input files updated by another job: data/predictor_files/YY1_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_YY1_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Blood.csv.gz --ground_truth_file data/predictor_files/YY1_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 865 with external jobid 'Submitted batch job 11030802'.
[Sat Dec  2 09:22:23 2023]
Finished job 745.
999 of 1394 steps (72%) done
Select jobs to execute...

[Sat Dec  2 09:22:23 2023]
Job 931: preparing tf=CTCF,tissue=Heart training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Heart.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Heart.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Heart.csv.gz --ground_truth_file data/predictor_files/CTCF_Heart.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 931 with external jobid 'Submitted batch job 11030803'.
[Sat Dec  2 09:23:16 2023]
Finished job 1021.
1000 of 1394 steps (72%) done
Select jobs to execute...
[Sat Dec  2 09:23:18 2023]
Finished job 1224.
1001 of 1394 steps (72%) done
[Sat Dec  2 09:24:15 2023]
Finished job 896.
1002 of 1394 steps (72%) done
[Sat Dec  2 09:24:16 2023]
Finished job 962.
1003 of 1394 steps (72%) done
[Sat Dec  2 09:24:17 2023]
Finished job 974.
1004 of 1394 steps (72%) done
[Sat Dec  2 09:24:19 2023]
Finished job 715.
1005 of 1394 steps (72%) done

[Sat Dec  2 09:24:19 2023]
Job 901: preparing tf=YY1,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/YY1_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_YY1_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Colon.csv.gz --ground_truth_file data/predictor_files/YY1_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 901 with external jobid 'Submitted batch job 11030818'.
[Sat Dec  2 09:24:20 2023]
Finished job 1018.
1006 of 1394 steps (72%) done
Select jobs to execute...
[Sat Dec  2 09:24:26 2023]
Finished job 563.
1007 of 1394 steps (72%) done

[Sat Dec  2 09:24:26 2023]
Job 749: working on tf=MAX,tissue=Liver
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Liver.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 749 with external jobid 'Submitted batch job 11030819'.
[Sat Dec  2 09:25:11 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030548

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11030548, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.
Select jobs to execute...

[Sat Dec  2 09:25:11 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11030820'.
[Sat Dec  2 09:25:12 2023]
Finished job 952.
1008 of 1394 steps (72%) done
Select jobs to execute...
[Sat Dec  2 09:25:14 2023]
Finished job 967.
1009 of 1394 steps (72%) done
[Sat Dec  2 09:25:15 2023]
Finished job 845.
1010 of 1394 steps (72%) done
[Sat Dec  2 09:26:02 2023]
Finished job 888.
1011 of 1394 steps (73%) done
[Sat Dec  2 09:26:03 2023]
Finished job 950.
1012 of 1394 steps (73%) done
[Sat Dec  2 09:26:05 2023]
Finished job 1358.
1013 of 1394 steps (73%) done
[Sat Dec  2 09:26:10 2023]
Finished job 656.
1014 of 1394 steps (73%) done

[Sat Dec  2 09:26:10 2023]
Job 842: preparing tf=CTCF,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CTCF_Liver.csv.gz, data/predictor_files/CTCF_Liver.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Liver.csv.gz --ground_truth_file data/predictor_files/CTCF_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 842 with external jobid 'Submitted batch job 11030821'.
[Sat Dec  2 09:26:52 2023]
Finished job 1253.
1015 of 1394 steps (73%) done
Select jobs to execute...
[Sat Dec  2 09:26:55 2023]
Finished job 705.
1016 of 1394 steps (73%) done

[Sat Dec  2 09:26:55 2023]
Job 891: preparing tf=HSF1,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/HSF1_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HSF1_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HSF1_Lung.csv.gz --ground_truth_file data/predictor_files/HSF1_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 891 with external jobid 'Submitted batch job 11030822'.
[Sat Dec  2 09:26:56 2023]
Finished job 866.
1017 of 1394 steps (73%) done
Select jobs to execute...
[Sat Dec  2 09:27:25 2023]
Finished job 1022.
1018 of 1394 steps (73%) done

[Sat Dec  2 09:27:25 2023]
Job 1166: training on tf=GATA3,tissue=Brain training data
Reason: Missing output files: output/models/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.logistic.rds, output/models/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz --rds_file output/models/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1166 with external jobid 'Submitted batch job 11030824'.

[Sat Dec  2 09:27:25 2023]
Job 1208: evaluating on tf=RUNX1,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz, output/models/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.linear.rds, output/models/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.linear.rds --logistic_model output/models/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Blood_2023-12-01/aggByCollect_RUNX1_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1208 with external jobid 'Submitted batch job 11030825'.
[Sat Dec  2 09:27:47 2023]
Finished job 719.
1019 of 1394 steps (73%) done
Select jobs to execute...

[Sat Dec  2 09:27:47 2023]
Job 905: preparing tf=CTCF,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Colon.csv.gz --ground_truth_file data/predictor_files/CTCF_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 905 with external jobid 'Submitted batch job 11030827'.
[Sat Dec  2 09:28:28 2023]
Finished job 928.
1020 of 1394 steps (73%) done
Select jobs to execute...
[Sat Dec  2 09:28:31 2023]
Finished job 894.
1021 of 1394 steps (73%) done
[Sat Dec  2 09:29:13 2023]
Finished job 844.
1022 of 1394 steps (73%) done
[Sat Dec  2 09:29:59 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030693

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11030693, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.

[Sat Dec  2 09:29:59 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11030835'.
[Sat Dec  2 09:30:40 2023]
Finished job 1019.
1023 of 1394 steps (73%) done
Select jobs to execute...
[Sat Dec  2 09:30:45 2023]
Finished job 765.
1024 of 1394 steps (73%) done

[Sat Dec  2 09:30:45 2023]
Job 951: preparing tf=YY1,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/YY1_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_YY1_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_YY1_Lung.csv.gz --ground_truth_file data/predictor_files/YY1_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 951 with external jobid 'Submitted batch job 11030836'.
[Sat Dec  2 09:30:48 2023]
Finished job 718.
1025 of 1394 steps (74%) done
Select jobs to execute...

[Sat Dec  2 09:30:48 2023]
Job 904: preparing tf=MAX,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MAX_Colon.csv.gz, data/predictor_files/MAX_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Colon.csv.gz --ground_truth_file data/predictor_files/MAX_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 904 with external jobid 'Submitted batch job 11030837'.
[Sat Dec  2 09:30:49 2023]
Finished job 806.
1026 of 1394 steps (74%) done
Select jobs to execute...

[Sat Dec  2 09:30:49 2023]
Job 992: preparing tf=HSF1,tissue=Bone training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_HSF1_Bone.csv.gz, data/predictor_files/HSF1_Bone.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HSF1_Bone.csv.gz --ground_truth_file data/predictor_files/HSF1_Bone.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 992 with external jobid 'Submitted batch job 11030838'.
[Sat Dec  2 09:32:12 2023]
Finished job 722.
1027 of 1394 steps (74%) done
Select jobs to execute...

[Sat Dec  2 09:32:12 2023]
Job 908: preparing tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT3_Colon.csv.gz, data/predictor_files/STAT3_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT3_Colon.csv.gz --ground_truth_file data/predictor_files/STAT3_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 908 with external jobid 'Submitted batch job 11030940'.
[Sat Dec  2 09:32:13 2023]
Finished job 807.
1028 of 1394 steps (74%) done
Select jobs to execute...

[Sat Dec  2 09:32:13 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11030941'.
[Sat Dec  2 09:32:18 2023]
Finished job 692.
1029 of 1394 steps (74%) done
Select jobs to execute...

[Sat Dec  2 09:32:18 2023]
Job 878: preparing tf=MAX,tissue=Brain training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz; Input files updated by another job: data/predictor_files/MAX_Brain.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MAX_Brain.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Brain.csv.gz --ground_truth_file data/predictor_files/MAX_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 878 with external jobid 'Submitted batch job 11030942'.
[Sat Dec  2 09:32:54 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030740

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11030740, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.
Select jobs to execute...

[Sat Dec  2 09:32:54 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11030943'.
[Sat Dec  2 09:32:55 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030741

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11030741, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:32:55 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11030944'.
[Sat Dec  2 09:33:37 2023]
Finished job 977.
1030 of 1394 steps (74%) done
Select jobs to execute...
[Sat Dec  2 09:33:38 2023]
Finished job 966.
1031 of 1394 steps (74%) done
[Sat Dec  2 09:33:39 2023]
Finished job 1241.
1032 of 1394 steps (74%) done
[Sat Dec  2 09:34:16 2023]
Finished job 922.
1033 of 1394 steps (74%) done
[Sat Dec  2 09:34:21 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030742

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11030742, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.

[Sat Dec  2 09:34:21 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11030946'.
[Sat Dec  2 09:34:22 2023]
Finished job 731.
1034 of 1394 steps (74%) done
Select jobs to execute...

[Sat Dec  2 09:34:22 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11030947'.
[Sat Dec  2 09:34:26 2023]
Finished job 739.
1035 of 1394 steps (74%) done
Select jobs to execute...

[Sat Dec  2 09:34:26 2023]
Job 925: preparing tf=CTCF,tissue=Bone training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Bone.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Bone.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Bone.csv.gz --ground_truth_file data/predictor_files/CTCF_Bone.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 925 with external jobid 'Submitted batch job 11030948'.
[Sat Dec  2 09:34:53 2023]
Finished job 1166.
1036 of 1394 steps (74%) done
Select jobs to execute...

[Sat Dec  2 09:34:53 2023]
Job 1352: evaluating on tf=GATA3,tissue=Brain training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz, output/models/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.linear.rds --logistic_model output/models/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA3_Brain_2023-12-01/aggByCollect_GATA3_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1352 with external jobid 'Submitted batch job 11030949'.

[Sat Dec  2 09:34:53 2023]
Job 1204: training on tf=GATA4,tissue=Skin training data
Reason: Missing output files: output/models/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.linear.rds, output/models/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz --rds_file output/models/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1204 with external jobid 'Submitted batch job 11030950'.
[Sat Dec  2 09:34:59 2023]
Finished job 901.
1037 of 1394 steps (74%) done
Select jobs to execute...
[Sat Dec  2 09:35:00 2023]
Finished job 865.
1038 of 1394 steps (74%) done
[Sat Dec  2 09:35:02 2023]
Finished job 949.
1039 of 1394 steps (75%) done
[Sat Dec  2 09:35:37 2023]
Finished job 891.
1040 of 1394 steps (75%) done
[Sat Dec  2 09:35:46 2023]
Finished job 827.
1041 of 1394 steps (75%) done

[Sat Dec  2 09:35:46 2023]
Job 1013: preparing tf=FOXA2,tissue=Skin training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA2_Skin.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA2_Skin.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA2_Skin.csv.gz --ground_truth_file data/predictor_files/FOXA2_Skin.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1013 with external jobid 'Submitted batch job 11030954'.
[Sat Dec  2 09:36:17 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030820

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11030820, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.
Select jobs to execute...

[Sat Dec  2 09:36:17 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11030955'.
[Sat Dec  2 09:36:18 2023]
Finished job 931.
1042 of 1394 steps (75%) done
Select jobs to execute...
[Sat Dec  2 09:36:19 2023]
Finished job 897.
1043 of 1394 steps (75%) done
[Sat Dec  2 09:36:48 2023]
Finished job 951.
1044 of 1394 steps (75%) done
[Sat Dec  2 09:37:26 2023]
Finished job 1208.
1045 of 1394 steps (75%) done
[Sat Dec  2 09:37:28 2023]
Finished job 842.
1046 of 1394 steps (75%) done
[Sat Dec  2 09:37:54 2023]
Finished job 908.
1047 of 1394 steps (75%) done
[Sat Dec  2 09:37:57 2023]
Finished job 904.
1048 of 1394 steps (75%) done
[Sat Dec  2 09:37:59 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030835

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11030835, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.

[Sat Dec  2 09:37:59 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11030957'.
[Sat Dec  2 09:38:29 2023]
Finished job 992.
1049 of 1394 steps (75%) done
Select jobs to execute...
[Sat Dec  2 09:38:30 2023]
Finished job 905.
1050 of 1394 steps (75%) done
[Sat Dec  2 09:38:34 2023]
Finished job 651.
1051 of 1394 steps (75%) done

[Sat Dec  2 09:38:34 2023]
Job 837: preparing tf=MAX,tissue=Blood training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MAX_Blood.csv.gz, data/predictor_files/MAX_Blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Blood.csv.gz --ground_truth_file data/predictor_files/MAX_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 837 with external jobid 'Submitted batch job 11030958'.
[Sat Dec  2 09:38:58 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030941

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11030941, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:38:58 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11030959'.
[Sat Dec  2 09:39:51 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030947

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11030947, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.
Select jobs to execute...

[Sat Dec  2 09:39:51 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11030960'.
[Sat Dec  2 09:39:53 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030943

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11030943, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.
Select jobs to execute...

[Sat Dec  2 09:39:53 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11030961'.
[Sat Dec  2 09:39:55 2023]
Finished job 878.
1052 of 1394 steps (75%) done
Select jobs to execute...
[Sat Dec  2 09:39:57 2023]
Finished job 694.
1053 of 1394 steps (76%) done

[Sat Dec  2 09:39:57 2023]
Job 880: preparing tf=SOX2,tissue=Skin training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz; Input files updated by another job: data/predictor_files/SOX2_Skin.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_SOX2_Skin.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SOX2_Skin.csv.gz --ground_truth_file data/predictor_files/SOX2_Skin.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 880 with external jobid 'Submitted batch job 11030963'.
[Sat Dec  2 09:40:21 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030946

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11030946, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.
Select jobs to execute...

[Sat Dec  2 09:40:21 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11030964'.
[Sat Dec  2 09:40:23 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030944

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11030944, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:40:23 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11030965'.
[Sat Dec  2 09:40:48 2023]
Finished job 1352.
1054 of 1394 steps (76%) done
Select jobs to execute...
[Sat Dec  2 09:41:13 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030955

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11030955, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.

[Sat Dec  2 09:41:13 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11030966'.
[Sat Dec  2 09:41:17 2023]
Finished job 925.
1055 of 1394 steps (76%) done
Select jobs to execute...
[Sat Dec  2 09:41:17 2023]
Finished job 685.
1056 of 1394 steps (76%) done

[Sat Dec  2 09:41:18 2023]
Job 871: preparing tf=CTCF,tissue=Skin training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Skin.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Skin.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Skin.csv.gz --ground_truth_file data/predictor_files/CTCF_Skin.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 871 with external jobid 'Submitted batch job 11030967'.
[Sat Dec  2 09:41:22 2023]
Finished job 749.
1057 of 1394 steps (76%) done
Select jobs to execute...

[Sat Dec  2 09:41:22 2023]
Job 935: preparing tf=MAX,tissue=Liver training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz; Input files updated by another job: data/predictor_files/MAX_Liver.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MAX_Liver.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Liver.csv.gz --ground_truth_file data/predictor_files/MAX_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 935 with external jobid 'Submitted batch job 11030968'.
[Sat Dec  2 09:41:39 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030959

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11030959, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:41:39 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031063'.
[Sat Dec  2 09:41:41 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030957

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11030957, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.
Select jobs to execute...

[Sat Dec  2 09:41:41 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11031068'.
[Sat Dec  2 09:42:03 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030960

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11030960, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.
Select jobs to execute...

[Sat Dec  2 09:42:03 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031071'.
[Sat Dec  2 09:42:50 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030966

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11030966, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.
Select jobs to execute...

[Sat Dec  2 09:42:50 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11031273'.
[Sat Dec  2 09:42:54 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030961

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11030961, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.
Select jobs to execute...

[Sat Dec  2 09:42:54 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11031414'.
[Sat Dec  2 09:43:00 2023]
Finished job 576.
1058 of 1394 steps (76%) done
Select jobs to execute...

[Sat Dec  2 09:43:00 2023]
Job 762: working on tf=CTCF,tissue=Eye
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_CTCF_Eye.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CTCF_Eye.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 762 with external jobid 'Submitted batch job 11031415'.
[Sat Dec  2 09:43:19 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030964

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11030964, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.
Select jobs to execute...

[Sat Dec  2 09:43:19 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11031416'.
[Sat Dec  2 09:43:20 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11030965

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11030965, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:43:20 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11031417'.
[Sat Dec  2 09:43:22 2023]
Finished job 837.
1059 of 1394 steps (76%) done
Select jobs to execute...
[Sat Dec  2 09:43:27 2023]
Finished job 935.
1060 of 1394 steps (76%) done
[Sat Dec  2 09:43:43 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031063

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031063, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.

[Sat Dec  2 09:43:43 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031419'.
[Sat Dec  2 09:43:46 2023]
Finished job 880.
1061 of 1394 steps (76%) done
Select jobs to execute...
[Sat Dec  2 09:43:47 2023]
Finished job 1013.
1062 of 1394 steps (76%) done
[Sat Dec  2 09:44:06 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031071

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031071, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.

[Sat Dec  2 09:44:06 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031420'.
[Sat Dec  2 09:44:08 2023]
Finished job 871.
1063 of 1394 steps (76%) done
Select jobs to execute...
[Sat Dec  2 09:44:25 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031273

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11031273, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.

[Sat Dec  2 09:44:25 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11031421'.
[Sat Dec  2 09:44:28 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031068

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11031068, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.
Select jobs to execute...

[Sat Dec  2 09:44:28 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11031422'.
[Sat Dec  2 09:44:47 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031414

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11031414, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.
Select jobs to execute...

[Sat Dec  2 09:44:47 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11031423'.
[Sat Dec  2 09:44:50 2023]
Finished job 700.
1064 of 1394 steps (76%) done
Select jobs to execute...

[Sat Dec  2 09:44:50 2023]
Job 886: preparing tf=FOXA1,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/FOXA1_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXA1_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXA1_Lung.csv.gz --ground_truth_file data/predictor_files/FOXA1_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 886 with external jobid 'Submitted batch job 11031424'.
[Sat Dec  2 09:45:06 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031419

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031419, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:45:06 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031425'.
[Sat Dec  2 09:45:26 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031420

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031420, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.
Select jobs to execute...

[Sat Dec  2 09:45:26 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031427'.
[Sat Dec  2 09:45:27 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031416

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11031416, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.
Select jobs to execute...

[Sat Dec  2 09:45:27 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11031428'.
[Sat Dec  2 09:45:28 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031417

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11031417, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:45:28 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11031429'.
[Sat Dec  2 09:45:47 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031421

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11031421, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.
Select jobs to execute...

[Sat Dec  2 09:45:47 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11031430'.
[Sat Dec  2 09:46:25 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031425

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031425, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:46:25 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031432'.
[Sat Dec  2 09:46:28 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031422

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11031422, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.
Select jobs to execute...

[Sat Dec  2 09:46:28 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11031433'.
[Sat Dec  2 09:46:44 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031427

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031427, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.
Select jobs to execute...

[Sat Dec  2 09:46:44 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031434'.
[Sat Dec  2 09:46:47 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031423

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11031423, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.
Select jobs to execute...

[Sat Dec  2 09:46:47 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11031435'.
[Sat Dec  2 09:47:05 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031430

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11031430, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.
Select jobs to execute...

[Sat Dec  2 09:47:05 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11031436'.
[Sat Dec  2 09:47:26 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031428

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11031428, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.
Select jobs to execute...

[Sat Dec  2 09:47:26 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11031437'.
[Sat Dec  2 09:47:27 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031429

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11031429, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:47:27 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11031438'.
[Sat Dec  2 09:47:46 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031432

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031432, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:47:46 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031439'.
[Sat Dec  2 09:48:05 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031434

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031434, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.
Select jobs to execute...

[Sat Dec  2 09:48:05 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031440'.
[Sat Dec  2 09:48:25 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031436

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11031436, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.
Select jobs to execute...

[Sat Dec  2 09:48:25 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11031441'.
[Sat Dec  2 09:48:27 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031433

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11031433, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.
Select jobs to execute...

[Sat Dec  2 09:48:27 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11031442'.
[Sat Dec  2 09:48:47 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031435

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11031435, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.
Select jobs to execute...

[Sat Dec  2 09:48:47 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11031443'.
[Sat Dec  2 09:49:05 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031439

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031439, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:49:05 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031445'.
[Sat Dec  2 09:49:08 2023]
Finished job 886.
1065 of 1394 steps (76%) done
Select jobs to execute...
[Sat Dec  2 09:49:25 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031440

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031440, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.

[Sat Dec  2 09:49:25 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031446'.
[Sat Dec  2 09:49:26 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031437

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11031437, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.
Select jobs to execute...

[Sat Dec  2 09:49:26 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11031447'.
[Sat Dec  2 09:49:27 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031438

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11031438, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:49:27 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11031448'.
[Sat Dec  2 09:49:45 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031441

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11031441, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 902.
Select jobs to execute...

[Sat Dec  2 09:49:45 2023]
Job 902: preparing tf=GATA2,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/GATA2_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 902 with external jobid 'Submitted batch job 11031449'.
[Sat Dec  2 09:49:48 2023]
Finished job 1204.
1066 of 1394 steps (76%) done
Select jobs to execute...

[Sat Dec  2 09:49:48 2023]
Job 1072: training on tf=FOXA1,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.logistic.rds, output/models/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1072 with external jobid 'Submitted batch job 11031450'.

[Sat Dec  2 09:49:48 2023]
Job 1390: evaluating on tf=GATA4,tissue=Skin training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz, output/models/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.linear.rds --logistic_model output/models/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Skin.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA4_Skin_2023-12-01/aggByCollect_GATA4_Skin
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1390 with external jobid 'Submitted batch job 11031451'.
[Sat Dec  2 09:50:25 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031445

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031445, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:50:25 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031452'.
[Sat Dec  2 09:50:27 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031442

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11031442, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 537.
Select jobs to execute...

[Sat Dec  2 09:50:27 2023]
Job 537: working on E2F1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 11031453'.
[Sat Dec  2 09:50:44 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031446

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031446, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.
Select jobs to execute...

[Sat Dec  2 09:50:44 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031455'.
[Sat Dec  2 09:50:47 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031443

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11031443, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.
Select jobs to execute...

[Sat Dec  2 09:50:47 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11031456'.
[Sat Dec  2 09:50:49 2023]
Finished job 505.
1067 of 1394 steps (77%) done
Select jobs to execute...

[Sat Dec  2 09:50:49 2023]
Job 691: working on tf=MAX,tissue=Lung
Reason: Missing output files: data/aggregation_folder/cistrome_aggByCollect_MAX_Lung.csv.gz; Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MAX_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 691 with external jobid 'Submitted batch job 11031457'.
[Sat Dec  2 09:51:03 2023]
Error in rule prepare_training_data:
    jobid: 902
    input: data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz, data/predictor_files/GATA2_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GATA2_Colon.csv.gz --ground_truth_file data/predictor_files/GATA2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031449

Error executing rule prepare_training_data on cluster (jobid: 902, external: Submitted batch job 11031449, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.902.sh). For error details see the cluster log and the log files of the involved rule(s).
Select jobs to execute...
[Sat Dec  2 09:51:05 2023]
Finished job 1390.
1068 of 1394 steps (77%) done
[Sat Dec  2 09:51:08 2023]
Finished job 762.
1069 of 1394 steps (77%) done

[Sat Dec  2 09:51:08 2023]
Job 948: preparing tf=CTCF,tissue=Eye training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz; Input files updated by another job: data/predictor_files/CTCF_Eye.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CTCF_Eye.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CTCF_Eye.csv.gz --ground_truth_file data/predictor_files/CTCF_Eye.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 948 with external jobid 'Submitted batch job 11031458'.
[Sat Dec  2 09:51:25 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031447

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11031447, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.
Select jobs to execute...

[Sat Dec  2 09:51:25 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11031459'.
[Sat Dec  2 09:51:26 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031448

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11031448, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:51:26 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11031460'.
[Sat Dec  2 09:51:42 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031452

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031452, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:51:42 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031462'.
[Sat Dec  2 09:51:59 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031455

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031455, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.
Select jobs to execute...

[Sat Dec  2 09:51:59 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031463'.
[Sat Dec  2 09:52:19 2023]
Error in rule predict_with_enformer:
    jobid: 537
    input: data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_E2F1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_E2F1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031453

Error executing rule predict_with_enformer on cluster (jobid: 537, external: Submitted batch job 11031453, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.537.sh). For error details see the cluster log and the log files of the involved rule(s).
Select jobs to execute...
[Sat Dec  2 09:52:36 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031456

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11031456, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.

[Sat Dec  2 09:52:36 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11031465'.
[Sat Dec  2 09:53:07 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031462

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031462, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 993.
Select jobs to execute...

[Sat Dec  2 09:53:07 2023]
Job 993: preparing tf=FOXM1,tissue=Mammary-Gland training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 993 with external jobid 'Submitted batch job 11031743'.
[Sat Dec  2 09:53:10 2023]
Finished job 948.
1070 of 1394 steps (77%) done
Select jobs to execute...
[Sat Dec  2 09:53:24 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031463

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031463, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 917.

[Sat Dec  2 09:53:24 2023]
Job 917: preparing tf=PPARG,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz; Input files updated by another job: data/predictor_files/PPARG_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 917 with external jobid 'Submitted batch job 11031968'.
[Sat Dec  2 09:53:25 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031459

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11031459, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.
Select jobs to execute...

[Sat Dec  2 09:53:25 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11031981'.
[Sat Dec  2 09:53:26 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031460

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11031460, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:53:26 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11031995'.
[Sat Dec  2 09:54:29 2023]
Error in rule prepare_training_data:
    jobid: 993
    input: data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz, data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXM1_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/FOXM1_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Mammary-Gland.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031743

Error executing rule prepare_training_data on cluster (jobid: 993, external: Submitted batch job 11031743, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.993.sh). For error details see the cluster log and the log files of the involved rule(s).
Select jobs to execute...
[Sat Dec  2 09:54:30 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031465

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11031465, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 547.

[Sat Dec  2 09:54:30 2023]
Job 547: working on STAT1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 11032507'.
[Sat Dec  2 09:54:42 2023]
Error in rule prepare_training_data:
    jobid: 917
    input: data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz, data/predictor_files/PPARG_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PPARG_Colon.csv.gz --ground_truth_file data/predictor_files/PPARG_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031968

Error executing rule prepare_training_data on cluster (jobid: 917, external: Submitted batch job 11031968, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.prepare_training_data.917.sh). For error details see the cluster log and the log files of the involved rule(s).
Select jobs to execute...
[Sat Dec  2 09:55:11 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031981

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11031981, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 476.

[Sat Dec  2 09:55:11 2023]
Job 476: working on SOX2_Brain
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
[Sat Dec  2 09:55:12 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11031995

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11031995, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 11032517'.
Trying to restart job 534.
Select jobs to execute...

[Sat Dec  2 09:55:13 2023]
Job 534: working on FOXM1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 11032519'.
[Sat Dec  2 09:56:25 2023]
Error in rule predict_with_enformer:
    jobid: 547
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11032507

Error executing rule predict_with_enformer on cluster (jobid: 547, external: Submitted batch job 11032507, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.547.sh). For error details see the cluster log and the log files of the involved rule(s).
Select jobs to execute...
[Sat Dec  2 09:56:50 2023]
Finished job 1072.
1071 of 1394 steps (77%) done

[Sat Dec  2 09:56:50 2023]
Job 1199: training on tf=FOXA2,tissue=Skin training data
Reason: Missing output files: output/models/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.logistic.rds, output/models/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz --rds_file output/models/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1199 with external jobid 'Submitted batch job 11032521'.

[Sat Dec  2 09:56:52 2023]
Job 1258: evaluating on tf=FOXA1,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz, output/models/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.logistic.rds, output/models/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.linear.rds --logistic_model output/models/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Lung_2023-12-01/aggByCollect_FOXA1_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1258 with external jobid 'Submitted batch job 11032522'.
[Sat Dec  2 09:57:16 2023]
Error in rule predict_with_enformer:
    jobid: 476
    input: data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
    output: data/prediction_parameters/aggregation_config_cistrome_SOX2_Brain.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SOX2_Brain.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11032517

Error executing rule predict_with_enformer on cluster (jobid: 476, external: Submitted batch job 11032517, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.476.sh). For error details see the cluster log and the log files of the involved rule(s).
Select jobs to execute...
[Sat Dec  2 09:57:18 2023]
Error in rule predict_with_enformer:
    jobid: 534
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXM1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXM1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11032519

Error executing rule predict_with_enformer on cluster (jobid: 534, external: Submitted batch job 11032519, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.predict_with_enformer.534.sh). For error details see the cluster log and the log files of the involved rule(s).
[Sat Dec  2 09:58:08 2023]
Finished job 1258.
1072 of 1394 steps (77%) done
[Sat Dec  2 10:02:20 2023]
Finished job 691.
1073 of 1394 steps (77%) done

[Sat Dec  2 10:02:20 2023]
Job 877: preparing tf=MAX,tissue=Lung training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz; Input files updated by another job: data/predictor_files/MAX_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MAX_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MAX_Lung.csv.gz --ground_truth_file data/predictor_files/MAX_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 877 with external jobid 'Submitted batch job 11032573'.
[Sat Dec  2 10:08:02 2023]
Finished job 877.
1074 of 1394 steps (77%) done
Select jobs to execute...
[Sat Dec  2 10:08:12 2023]
Finished job 1199.
1075 of 1394 steps (77%) done

[Sat Dec  2 10:08:12 2023]
Job 1044: training on tf=FOXA2,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.linear.rds, output/models/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz --rds_file output/models/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1044 with external jobid 'Submitted batch job 11032970'.

[Sat Dec  2 10:08:15 2023]
Job 1385: evaluating on tf=FOXA2,tissue=Skin training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz, output/models/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.logistic.rds, output/models/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.linear.rds --logistic_model output/models/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Skin.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA2_Skin_2023-12-01/aggByCollect_FOXA2_Skin
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1385 with external jobid 'Submitted batch job 11032971'.
[Sat Dec  2 10:09:40 2023]
Finished job 1385.
1076 of 1394 steps (77%) done
Select jobs to execute...
[Sat Dec  2 10:14:41 2023]
Finished job 1044.
1077 of 1394 steps (77%) done

[Sat Dec  2 10:14:41 2023]
Job 1031: training on tf=ETS1,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.logistic.rds, output/models/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz --rds_file output/models/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1031 with external jobid 'Submitted batch job 11033017'.

[Sat Dec  2 10:14:43 2023]
Job 1230: evaluating on tf=FOXA2,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz, output/models/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.linear.rds --logistic_model output/models/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA2_Liver_2023-12-01/aggByCollect_FOXA2_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1230 with external jobid 'Submitted batch job 11033018'.
[Sat Dec  2 10:16:09 2023]
Finished job 1230.
1078 of 1394 steps (77%) done
Select jobs to execute...
[Sat Dec  2 10:22:09 2023]
Finished job 1031.
1079 of 1394 steps (77%) done

[Sat Dec  2 10:22:09 2023]
Job 1217: evaluating on tf=ETS1,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz, output/models/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.linear.rds --logistic_model output/models/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_ETS1_Blood_2023-12-01/aggByCollect_ETS1_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1217 with external jobid 'Submitted batch job 11033076'.

[Sat Dec  2 10:22:10 2023]
Job 1023: training on tf=MAX,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.linear.rds, output/models/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz --rds_file output/models/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1023 with external jobid 'Submitted batch job 11033077'.
[Sat Dec  2 10:23:25 2023]
Finished job 1217.
1080 of 1394 steps (77%) done
Select jobs to execute...
[Sat Dec  2 10:32:17 2023]
Finished job 1023.
1081 of 1394 steps (78%) done

[Sat Dec  2 10:32:17 2023]
Job 1209: evaluating on tf=MAX,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz, output/models/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.linear.rds --logistic_model output/models/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Blood_2023-12-01/aggByCollect_MAX_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1209 with external jobid 'Submitted batch job 11033373'.

[Sat Dec  2 10:32:18 2023]
Job 1063: training on tf=MAX,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.logistic.rds, output/models/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz --rds_file output/models/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1063 with external jobid 'Submitted batch job 11033375'.
[Sat Dec  2 10:33:22 2023]
Finished job 1209.
1082 of 1394 steps (78%) done
Select jobs to execute...
[Sat Dec  2 10:39:53 2023]
Finished job 1063.
1083 of 1394 steps (78%) done

[Sat Dec  2 10:39:53 2023]
Job 1249: evaluating on tf=MAX,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz, output/models/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.logistic.rds, output/models/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.linear.rds --logistic_model output/models/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Lung_2023-12-01/aggByCollect_MAX_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1249 with external jobid 'Submitted batch job 11033482'.

[Sat Dec  2 10:39:56 2023]
Job 1036: training on tf=CTCF,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.logistic.rds, output/models/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1036 with external jobid 'Submitted batch job 11033485'.
[Sat Dec  2 10:41:20 2023]
Finished job 1249.
1084 of 1394 steps (78%) done
Select jobs to execute...
[Sat Dec  2 10:49:41 2023]
Finished job 1036.
1085 of 1394 steps (78%) done

[Sat Dec  2 10:49:41 2023]
Job 1173: training on tf=GATA4,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.linear.rds, output/models/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz --rds_file output/models/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1173 with external jobid 'Submitted batch job 11033684'.

[Sat Dec  2 10:49:42 2023]
Job 1222: evaluating on tf=CTCF,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz, output/models/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.linear.rds, output/models/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.linear.rds --logistic_model output/models/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Breast_2023-12-01/aggByCollect_CTCF_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1222 with external jobid 'Submitted batch job 11033686'.
[Sat Dec  2 10:53:11 2023]
Finished job 1222.
1086 of 1394 steps (78%) done
Select jobs to execute...
[Sat Dec  2 10:58:41 2023]
Finished job 1173.
1087 of 1394 steps (78%) done

[Sat Dec  2 10:58:41 2023]
Job 1164: training on tf=FOSL2,tissue=Brain training data
Reason: Missing output files: output/models/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.logistic.rds, output/models/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz --rds_file output/models/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1164 with external jobid 'Submitted batch job 11034047'.

[Sat Dec  2 10:58:44 2023]
Job 1359: evaluating on tf=GATA4,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz, output/models/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz, output/models/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.linear.rds --logistic_model output/models/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA4_Embryo_2023-12-01/aggByCollect_GATA4_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1359 with external jobid 'Submitted batch job 11034051'.
[Sat Dec  2 11:00:31 2023]
Finished job 1359.
1088 of 1394 steps (78%) done
Select jobs to execute...
[Sat Dec  2 11:05:41 2023]
Finished job 1164.
1089 of 1394 steps (78%) done

[Sat Dec  2 11:05:41 2023]
Job 1066: training on tf=SOX2,tissue=Skin training data
Reason: Missing output files: output/models/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.linear.rds, output/models/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz --rds_file output/models/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1066 with external jobid 'Submitted batch job 11034232'.

[Sat Dec  2 11:05:42 2023]
Job 1350: evaluating on tf=FOSL2,tissue=Brain training and test data
Reason: Missing output files: output/models_eval/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.linear.test_eval.txt.gz, output/models_eval/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.linear.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz, output/models/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.linear.rds --logistic_model output/models/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_FOSL2_Brain_2023-12-01/aggByCollect_FOSL2_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1350 with external jobid 'Submitted batch job 11034235'.
[Sat Dec  2 11:07:09 2023]
Finished job 1350.
1090 of 1394 steps (78%) done
Select jobs to execute...
[Sat Dec  2 11:15:00 2023]
Finished job 1066.
1091 of 1394 steps (78%) done

[Sat Dec  2 11:15:00 2023]
Job 1030: training on tf=CTCF,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.logistic.rds, output/models/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1030 with external jobid 'Submitted batch job 11034485'.

[Sat Dec  2 11:15:01 2023]
Job 1252: evaluating on tf=SOX2,tissue=Skin training and test data
Reason: Missing output files: output/models_eval/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.logistic.test_eval.txt.gz, output/models_eval/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.linear.test_eval.txt.gz, output/models_eval/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.linear.train_eval.txt.gz, output/models_eval/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz, output/models/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.linear.rds --logistic_model output/models/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Skin.prepared.csv.gz --eval_output output/models_eval/cistrome_SOX2_Skin_2023-12-01/aggByCollect_SOX2_Skin
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1252 with external jobid 'Submitted batch job 11034487'.
[Sat Dec  2 11:19:02 2023]
Finished job 1252.
1092 of 1394 steps (78%) done
Select jobs to execute...
[Sat Dec  2 11:25:52 2023]
Finished job 1030.
1093 of 1394 steps (78%) done

[Sat Dec  2 11:25:52 2023]
Job 1080: training on tf=FOXA2,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.linear.rds, output/models/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz --rds_file output/models/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1080 with external jobid 'Submitted batch job 11034972'.

[Sat Dec  2 11:25:53 2023]
Job 1216: evaluating on tf=CTCF,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz, output/models/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz, output/models/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.linear.rds --logistic_model output/models/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Blood_2023-12-01/aggByCollect_CTCF_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1216 with external jobid 'Submitted batch job 11034975'.
[Sat Dec  2 11:27:20 2023]
Finished job 1216.
1094 of 1394 steps (78%) done
Select jobs to execute...
[Sat Dec  2 11:31:01 2023]
Finished job 1080.
1095 of 1394 steps (79%) done

[Sat Dec  2 11:31:01 2023]
Job 1024: training on tf=CTCF,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.logistic.rds, output/models/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1024 with external jobid 'Submitted batch job 11035210'.

[Sat Dec  2 11:31:02 2023]
Job 1266: evaluating on tf=FOXA2,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.logistic.rds, output/models/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.linear.rds --logistic_model output/models/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA2_Lung_2023-12-01/aggByCollect_FOXA2_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1266 with external jobid 'Submitted batch job 11035213'.
[Sat Dec  2 11:32:18 2023]
Finished job 1266.
1096 of 1394 steps (79%) done
Select jobs to execute...
[Sat Dec  2 11:39:18 2023]
Finished job 1024.
1097 of 1394 steps (79%) done

[Sat Dec  2 11:39:18 2023]
Job 1102: training on tf=FOXA2,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.linear.rds, output/models/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz --rds_file output/models/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1102 with external jobid 'Submitted batch job 11035631'.

[Sat Dec  2 11:39:22 2023]
Job 1210: evaluating on tf=CTCF,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz, output/models/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.linear.rds --logistic_model output/models/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Embryo_2023-12-01/aggByCollect_CTCF_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1210 with external jobid 'Submitted batch job 11035639'.
[Sat Dec  2 11:40:24 2023]
Finished job 1210.
1098 of 1394 steps (79%) done
Select jobs to execute...
[Sat Dec  2 11:44:34 2023]
Finished job 1102.
1099 of 1394 steps (79%) done

[Sat Dec  2 11:44:34 2023]
Job 1028: training on tf=CTCF,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.logistic.rds, output/models/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1028 with external jobid 'Submitted batch job 11035933'.

[Sat Dec  2 11:44:37 2023]
Job 1288: evaluating on tf=FOXA2,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz, output/models/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz, output/models/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.linear.rds --logistic_model output/models/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA2_Colon_2023-12-01/aggByCollect_FOXA2_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1288 with external jobid 'Submitted batch job 11035936'.
[Sat Dec  2 11:45:40 2023]
Finished job 1288.
1100 of 1394 steps (79%) done
Select jobs to execute...
[Sat Dec  2 11:51:41 2023]
Finished job 1028.
1101 of 1394 steps (79%) done

[Sat Dec  2 11:51:41 2023]
Job 1214: evaluating on tf=CTCF,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz, output/models/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.linear.rds, output/models/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.linear.rds --logistic_model output/models/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Liver_2023-12-01/aggByCollect_CTCF_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1214 with external jobid 'Submitted batch job 11036159'.

[Sat Dec  2 11:51:41 2023]
Job 1091: training on tf=CTCF,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.logistic.rds, output/models/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1091 with external jobid 'Submitted batch job 11036161'.
[Sat Dec  2 11:52:57 2023]
Finished job 1214.
1102 of 1394 steps (79%) done
Select jobs to execute...
[Sat Dec  2 11:58:48 2023]
Finished job 1091.
1103 of 1394 steps (79%) done

[Sat Dec  2 11:58:48 2023]
Job 1277: evaluating on tf=CTCF,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz, output/models/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.linear.rds --logistic_model output/models/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Colon_2023-12-01/aggByCollect_CTCF_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1277 with external jobid 'Submitted batch job 11036342'.

[Sat Dec  2 11:58:51 2023]
Job 1083: training on tf=CTCF,tissue=Brain training data
Reason: Missing output files: output/models/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.logistic.rds, output/models/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1083 with external jobid 'Submitted batch job 11036346'.
[Sat Dec  2 11:59:53 2023]
Finished job 1277.
1104 of 1394 steps (79%) done
Select jobs to execute...
[Sat Dec  2 12:04:54 2023]
Finished job 1083.
1105 of 1394 steps (79%) done

[Sat Dec  2 12:04:54 2023]
Job 1269: evaluating on tf=CTCF,tissue=Brain training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz, output/models/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.linear.rds --logistic_model output/models/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Brain_2023-12-01/aggByCollect_CTCF_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1269 with external jobid 'Submitted batch job 11036615'.

[Sat Dec  2 12:04:55 2023]
Job 1057: training on tf=CTCF,tissue=Skin training data
Reason: Missing output files: output/models/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.linear.rds, output/models/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1057 with external jobid 'Submitted batch job 11036619'.
[Sat Dec  2 12:06:10 2023]
Finished job 1269.
1106 of 1394 steps (79%) done
Select jobs to execute...
[Sat Dec  2 12:11:22 2023]
Finished job 1057.
1107 of 1394 steps (79%) done

[Sat Dec  2 12:11:22 2023]
Job 1243: evaluating on tf=CTCF,tissue=Skin training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.linear.rds, output/models/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.linear.rds --logistic_model output/models/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Skin.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Skin_2023-12-01/aggByCollect_CTCF_Skin
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1243 with external jobid 'Submitted batch job 11036845'.

[Sat Dec  2 12:11:25 2023]
Job 1140: training on tf=FOSL2,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.linear.rds, output/models/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz --rds_file output/models/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1140 with external jobid 'Submitted batch job 11036847'.
[Sat Dec  2 12:13:11 2023]
Finished job 1243.
1108 of 1394 steps (79%) done
Select jobs to execute...
[Sat Dec  2 12:17:12 2023]
Finished job 1140.
1109 of 1394 steps (80%) done

[Sat Dec  2 12:17:12 2023]
Job 1326: evaluating on tf=FOSL2,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz, output/models/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.linear.rds, output/models/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.linear.rds --logistic_model output/models/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_FOSL2_Lung_2023-12-01/aggByCollect_FOSL2_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1326 with external jobid 'Submitted batch job 11037059'.

[Sat Dec  2 12:17:13 2023]
Job 1130: training on tf=CTCF,tissue=Kidney training data
Reason: Missing output files: output/models/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.linear.rds, output/models/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1130 with external jobid 'Submitted batch job 11037060'.
[Sat Dec  2 12:18:28 2023]
Finished job 1326.
1110 of 1394 steps (80%) done
Select jobs to execute...
[Sat Dec  2 12:23:59 2023]
Finished job 1130.
1111 of 1394 steps (80%) done

[Sat Dec  2 12:23:59 2023]
Job 1114: training on tf=MAX,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.linear.rds, output/models/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz --rds_file output/models/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1114 with external jobid 'Submitted batch job 11037269'.

[Sat Dec  2 12:24:01 2023]
Job 1316: evaluating on tf=CTCF,tissue=Kidney training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.linear.rds, output/models/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.linear.rds --logistic_model output/models/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Kidney_2023-12-01/aggByCollect_CTCF_Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1316 with external jobid 'Submitted batch job 11037272'.
[Sat Dec  2 12:26:22 2023]
Finished job 1316.
1112 of 1394 steps (80%) done
Select jobs to execute...
[Sat Dec  2 12:30:33 2023]
Finished job 1114.
1113 of 1394 steps (80%) done

[Sat Dec  2 12:30:33 2023]
Job 1060: training on tf=GATA3,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.linear.rds, output/models/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz --rds_file output/models/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1060 with external jobid 'Submitted batch job 11037536'.

[Sat Dec  2 12:30:36 2023]
Job 1300: evaluating on tf=MAX,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz, output/models/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.linear.rds --logistic_model output/models/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Embryo_2023-12-01/aggByCollect_MAX_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1300 with external jobid 'Submitted batch job 11037540'.
[Sat Dec  2 12:31:50 2023]
Finished job 1300.
1114 of 1394 steps (80%) done
Select jobs to execute...
[Sat Dec  2 12:36:40 2023]
Finished job 1060.
1115 of 1394 steps (80%) done

[Sat Dec  2 12:36:40 2023]
Job 1025: training on tf=CTCF,tissue=Cervix training data
Reason: Missing output files: output/models/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.linear.rds, output/models/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1025 with external jobid 'Submitted batch job 11037775'.

[Sat Dec  2 12:36:41 2023]
Job 1246: evaluating on tf=GATA3,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz, output/models/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.linear.rds, output/models/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.linear.rds --logistic_model output/models/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA3_Blood_2023-12-01/aggByCollect_GATA3_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1246 with external jobid 'Submitted batch job 11037783'.
[Sat Dec  2 12:38:08 2023]
Finished job 1246.
1116 of 1394 steps (80%) done
Select jobs to execute...
[Sat Dec  2 12:42:18 2023]
Finished job 1025.
1117 of 1394 steps (80%) done

[Sat Dec  2 12:42:18 2023]
Job 1052: training on tf=SP1,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.logistic.rds, output/models/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz --rds_file output/models/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1052 with external jobid 'Submitted batch job 11037960'.

[Sat Dec  2 12:42:21 2023]
Job 1211: evaluating on tf=CTCF,tissue=Cervix training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz, output/models/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.linear.rds --logistic_model output/models/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Cervix_2023-12-01/aggByCollect_CTCF_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1211 with external jobid 'Submitted batch job 11037961'.
[Sat Dec  2 12:43:13 2023]
Finished job 1211.
1118 of 1394 steps (80%) done
Select jobs to execute...
[Sat Dec  2 12:52:04 2023]
Finished job 1052.
1119 of 1394 steps (80%) done

[Sat Dec  2 12:52:04 2023]
Job 1064: training on tf=MAX,tissue=Brain training data
Reason: Missing output files: output/models/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.linear.rds, output/models/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz --rds_file output/models/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1064 with external jobid 'Submitted batch job 11038308'.

[Sat Dec  2 12:52:06 2023]
Job 1238: evaluating on tf=SP1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz, output/models/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz, output/models/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.linear.rds --logistic_model output/models/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_SP1_Colon_2023-12-01/aggByCollect_SP1_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1238 with external jobid 'Submitted batch job 11038312'.
[Sat Dec  2 12:53:43 2023]
Finished job 1238.
1120 of 1394 steps (80%) done
Select jobs to execute...
[Sat Dec  2 12:57:33 2023]
Finished job 1064.
1121 of 1394 steps (80%) done

[Sat Dec  2 12:57:33 2023]
Job 1250: evaluating on tf=MAX,tissue=Brain training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.logistic.train_eval.txt.gz, output/models_eval/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz, output/models/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.logistic.rds, output/models/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.linear.rds --logistic_model output/models/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Brain_2023-12-01/aggByCollect_MAX_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1250 with external jobid 'Submitted batch job 11038552'.

[Sat Dec  2 12:57:34 2023]
Job 1068: training on tf=FOXM1,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.linear.rds, output/models/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz --rds_file output/models/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1068 with external jobid 'Submitted batch job 11038558'.
[Sat Dec  2 12:58:49 2023]
Finished job 1250.
1122 of 1394 steps (80%) done
Select jobs to execute...
[Sat Dec  2 13:02:00 2023]
Finished job 1068.
1123 of 1394 steps (81%) done

[Sat Dec  2 13:02:00 2023]
Job 1254: evaluating on tf=FOXM1,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz, output/models/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.linear.rds, output/models/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.linear.rds --logistic_model output/models/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXM1_Breast_2023-12-01/aggByCollect_FOXM1_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1254 with external jobid 'Submitted batch job 11038719'.

[Sat Dec  2 13:02:01 2023]
Job 1134: training on tf=CTCF,tissue=Eye training data
Reason: Missing output files: output/models/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.linear.rds, output/models/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1134 with external jobid 'Submitted batch job 11038723'.
[Sat Dec  2 13:03:27 2023]
Finished job 1254.
1124 of 1394 steps (81%) done
Select jobs to execute...
[Sat Dec  2 13:07:39 2023]
Finished job 1134.
1125 of 1394 steps (81%) done

[Sat Dec  2 13:07:39 2023]
Job 1320: evaluating on tf=CTCF,tissue=Eye training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz, output/models/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.linear.rds --logistic_model output/models/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Eye.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Eye_2023-12-01/aggByCollect_CTCF_Eye
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1320 with external jobid 'Submitted batch job 11038910'.

[Sat Dec  2 13:07:40 2023]
Job 1111: training on tf=CTCF,tissue=Bone training data
Reason: Missing output files: output/models/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.linear.rds, output/models/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1111 with external jobid 'Submitted batch job 11038914'.
[Sat Dec  2 13:08:44 2023]
Finished job 1320.
1126 of 1394 steps (81%) done
Select jobs to execute...
[Sat Dec  2 13:12:55 2023]
Finished job 1111.
1127 of 1394 steps (81%) done

[Sat Dec  2 13:12:55 2023]
Job 1297: evaluating on tf=CTCF,tissue=Bone training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz, output/models/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.linear.rds --logistic_model output/models/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Bone.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Bone_2023-12-01/aggByCollect_CTCF_Bone
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1297 with external jobid 'Submitted batch job 11039146'.

[Sat Dec  2 13:12:55 2023]
Job 1117: training on tf=CTCF,tissue=Heart training data
Reason: Missing output files: output/models/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.logistic.rds, output/models/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1117 with external jobid 'Submitted batch job 11039149'.
[Sat Dec  2 13:13:49 2023]
Finished job 1297.
1128 of 1394 steps (81%) done
Select jobs to execute...
[Sat Dec  2 13:17:10 2023]
Finished job 1117.
1129 of 1394 steps (81%) done

[Sat Dec  2 13:17:10 2023]
Job 1123: training on tf=CTCF,tissue=Foreskin training data
Reason: Missing output files: output/models/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.logistic.rds, output/models/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1123 with external jobid 'Submitted batch job 11039303'.

[Sat Dec  2 13:17:12 2023]
Job 1303: evaluating on tf=CTCF,tissue=Heart training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz, output/models/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.linear.rds --logistic_model output/models/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Heart.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Heart_2023-12-01/aggByCollect_CTCF_Heart
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1303 with external jobid 'Submitted batch job 11039305'.
[Sat Dec  2 13:18:27 2023]
Finished job 1303.
1130 of 1394 steps (81%) done
Select jobs to execute...
[Sat Dec  2 13:21:07 2023]
Finished job 1123.
1131 of 1394 steps (81%) done

[Sat Dec  2 13:21:07 2023]
Job 1309: evaluating on tf=CTCF,tissue=Foreskin training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz, output/models/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.linear.rds, output/models/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.linear.rds --logistic_model output/models/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Foreskin.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Foreskin_2023-12-01/aggByCollect_CTCF_Foreskin
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1309 with external jobid 'Submitted batch job 11039459'.

[Sat Dec  2 13:21:11 2023]
Job 1043: training on tf=CTCF,tissue=Adipose training data
Reason: Missing output files: output/models/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.logistic.rds, output/models/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1043 with external jobid 'Submitted batch job 11039464'.
[Sat Dec  2 13:22:23 2023]
Finished job 1309.
1132 of 1394 steps (81%) done
Select jobs to execute...
[Sat Dec  2 13:25:14 2023]
Finished job 1043.
1133 of 1394 steps (81%) done

[Sat Dec  2 13:25:14 2023]
Job 1159: training on tf=FOSL2,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.linear.rds, output/models/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz --rds_file output/models/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1159 with external jobid 'Submitted batch job 11039620'.

[Sat Dec  2 13:25:16 2023]
Job 1229: evaluating on tf=CTCF,tissue=Adipose training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz, output/models/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz, output/models/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.linear.rds --logistic_model output/models/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Adipose.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Adipose_2023-12-01/aggByCollect_CTCF_Adipose
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1229 with external jobid 'Submitted batch job 11039625'.
[Sat Dec  2 13:26:54 2023]
Finished job 1229.
1134 of 1394 steps (81%) done
Select jobs to execute...
[Sat Dec  2 13:30:14 2023]
Finished job 1159.
1135 of 1394 steps (81%) done

[Sat Dec  2 13:30:14 2023]
Job 1115: training on tf=CTCF,tissue=Spinal-Cord training data
Reason: Missing output files: output/models/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.logistic.rds, output/models/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1115 with external jobid 'Submitted batch job 11039785'.

[Sat Dec  2 13:30:14 2023]
Job 1345: evaluating on tf=FOSL2,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz, output/models/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz, output/models/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.linear.rds --logistic_model output/models/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_FOSL2_Breast_2023-12-01/aggByCollect_FOSL2_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1345 with external jobid 'Submitted batch job 11039786'.
[Sat Dec  2 13:31:31 2023]
Finished job 1345.
1136 of 1394 steps (81%) done
Select jobs to execute...
[Sat Dec  2 13:34:31 2023]
Finished job 1115.
1137 of 1394 steps (82%) done

[Sat Dec  2 13:34:31 2023]
Job 1301: evaluating on tf=CTCF,tissue=Spinal-Cord training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz, output/models/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz, output/models/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.linear.rds --logistic_model output/models/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Spinal-Cord.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Spinal-Cord_2023-12-01/aggByCollect_CTCF_Spinal-Cord
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1301 with external jobid 'Submitted batch job 11039982'.

[Sat Dec  2 13:34:32 2023]
Job 1113: training on tf=CTCF,tissue=Gingiva training data
Reason: Missing output files: output/models/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.linear.rds, output/models/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1113 with external jobid 'Submitted batch job 11039987'.
[Sat Dec  2 13:35:25 2023]
Finished job 1301.
1138 of 1394 steps (82%) done
Select jobs to execute...
[Sat Dec  2 13:38:26 2023]
Finished job 1113.
1139 of 1394 steps (82%) done

[Sat Dec  2 13:38:26 2023]
Job 1116: training on tf=CTCF,tissue=Cerebellum training data
Reason: Missing output files: output/models/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.linear.rds, output/models/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1116 with external jobid 'Submitted batch job 11040146'.

[Sat Dec  2 13:38:28 2023]
Job 1299: evaluating on tf=CTCF,tissue=Gingiva training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz, output/models/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz, output/models/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.linear.rds --logistic_model output/models/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Gingiva.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Gingiva_2023-12-01/aggByCollect_CTCF_Gingiva
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1299 with external jobid 'Submitted batch job 11040150'.
[Sat Dec  2 13:39:43 2023]
Finished job 1299.
1140 of 1394 steps (82%) done
Select jobs to execute...
[Sat Dec  2 13:42:43 2023]
Finished job 1116.
1141 of 1394 steps (82%) done

[Sat Dec  2 13:42:43 2023]
Job 1302: evaluating on tf=CTCF,tissue=Cerebellum training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz, output/models/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.linear.rds --logistic_model output/models/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cerebellum.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Cerebellum_2023-12-01/aggByCollect_CTCF_Cerebellum
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1302 with external jobid 'Submitted batch job 11040337'.

[Sat Dec  2 13:42:46 2023]
Job 1154: training on tf=FOSL2,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.linear.rds, output/models/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz --rds_file output/models/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1154 with external jobid 'Submitted batch job 11040342'.
[Sat Dec  2 13:45:05 2023]
Finished job 1302.
1142 of 1394 steps (82%) done
Select jobs to execute...
[Sat Dec  2 13:49:57 2023]
Finished job 1154.
1143 of 1394 steps (82%) done

[Sat Dec  2 13:49:57 2023]
Job 1340: evaluating on tf=FOSL2,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz, output/models/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz, output/models/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.linear.rds --logistic_model output/models/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOSL2_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_FOSL2_Liver_2023-12-01/aggByCollect_FOSL2_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1340 with external jobid 'Submitted batch job 11040613'.

[Sat Dec  2 13:49:59 2023]
Job 1133: training on tf=CTCF,tissue=Spleen training data
Reason: Missing output files: output/models/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.linear.rds, output/models/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1133 with external jobid 'Submitted batch job 11040614'.
[Sat Dec  2 13:51:24 2023]
Finished job 1340.
1144 of 1394 steps (82%) done
Select jobs to execute...
[Sat Dec  2 13:54:45 2023]
Finished job 1133.
1145 of 1394 steps (82%) done

[Sat Dec  2 13:54:45 2023]
Job 1319: evaluating on tf=CTCF,tissue=Spleen training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz, output/models/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.linear.rds, output/models/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.linear.rds --logistic_model output/models/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Spleen.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Spleen_2023-12-01/aggByCollect_CTCF_Spleen
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1319 with external jobid 'Submitted batch job 11040805'.

[Sat Dec  2 13:54:48 2023]
Job 1112: training on tf=CTCF,tissue=Fetal-Lung training data
Reason: Missing output files: output/models/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.linear.rds, output/models/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1112 with external jobid 'Submitted batch job 11040807'.
[Sat Dec  2 13:56:12 2023]
Finished job 1319.
1146 of 1394 steps (82%) done
Select jobs to execute...
[Sat Dec  2 13:59:13 2023]
Finished job 1112.
1147 of 1394 steps (82%) done

[Sat Dec  2 13:59:13 2023]
Job 1298: evaluating on tf=CTCF,tissue=Fetal-Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz, output/models/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.logistic.rds, output/models/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.linear.rds --logistic_model output/models/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Fetal-Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Fetal-Lung_2023-12-01/aggByCollect_CTCF_Fetal-Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1298 with external jobid 'Submitted batch job 11040986'.

[Sat Dec  2 13:59:15 2023]
Job 1121: training on tf=MAX,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.linear.rds, output/models/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz --rds_file output/models/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1121 with external jobid 'Submitted batch job 11040989'.
[Sat Dec  2 14:02:08 2023]
Finished job 1298.
1148 of 1394 steps (82%) done
Select jobs to execute...
[Sat Dec  2 14:04:40 2023]
Finished job 1121.
1149 of 1394 steps (82%) done

[Sat Dec  2 14:04:40 2023]
Job 1307: evaluating on tf=MAX,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.linear.test_eval.txt.gz, output/models_eval/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz, output/models/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.linear.rds --logistic_model output/models/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Liver_2023-12-01/aggByCollect_MAX_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1307 with external jobid 'Submitted batch job 11041194'.

[Sat Dec  2 14:04:40 2023]
Job 1197: training on tf=CTCF,tissue=Retina training data
Reason: Missing output files: output/models/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.logistic.rds, output/models/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1197 with external jobid 'Submitted batch job 11041198'.
[Sat Dec  2 14:07:13 2023]
Finished job 1307.
1150 of 1394 steps (82%) done
Select jobs to execute...
[Sat Dec  2 14:10:04 2023]
Finished job 1197.
1151 of 1394 steps (83%) done

[Sat Dec  2 14:10:04 2023]
Job 1383: evaluating on tf=CTCF,tissue=Retina training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz, output/models/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.linear.rds --logistic_model output/models/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Retina.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Retina_2023-12-01/aggByCollect_CTCF_Retina
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1383 with external jobid 'Submitted batch job 11041417'.

[Sat Dec  2 14:10:08 2023]
Job 1160: training on tf=MAX,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.linear.rds, output/models/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz --rds_file output/models/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1160 with external jobid 'Submitted batch job 11041423'.
[Sat Dec  2 14:10:58 2023]
Finished job 1383.
1152 of 1394 steps (83%) done
Select jobs to execute...
[Sat Dec  2 14:13:39 2023]
Finished job 1160.
1153 of 1394 steps (83%) done

[Sat Dec  2 14:13:39 2023]
Job 1142: training on tf=CTCF,tissue=Endometrium training data
Reason: Missing output files: output/models/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.linear.rds, output/models/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1142 with external jobid 'Submitted batch job 11041540'.

[Sat Dec  2 14:13:41 2023]
Job 1346: evaluating on tf=MAX,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz, output/models/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.linear.rds, output/models/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.linear.rds --logistic_model output/models/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Breast_2023-12-01/aggByCollect_MAX_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1346 with external jobid 'Submitted batch job 11041542'.
[Sat Dec  2 14:14:56 2023]
Finished job 1346.
1154 of 1394 steps (83%) done
Select jobs to execute...
[Sat Dec  2 14:16:56 2023]
Finished job 1142.
1155 of 1394 steps (83%) done

[Sat Dec  2 14:16:56 2023]
Job 1328: evaluating on tf=CTCF,tissue=Endometrium training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.linear.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz, output/models/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.linear.rds, output/models/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.linear.rds --logistic_model output/models/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Endometrium.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Endometrium_2023-12-01/aggByCollect_CTCF_Endometrium
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1328 with external jobid 'Submitted batch job 11041692'.

[Sat Dec  2 14:17:00 2023]
Job 1183: training on tf=CTCF,tissue=Stomach training data
Reason: Missing output files: output/models/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.logistic.rds, output/models/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1183 with external jobid 'Submitted batch job 11041694'.
[Sat Dec  2 14:18:01 2023]
Finished job 1328.
1156 of 1394 steps (83%) done
Select jobs to execute...
[Sat Dec  2 14:20:02 2023]
Finished job 1183.
1157 of 1394 steps (83%) done

[Sat Dec  2 14:20:02 2023]
Job 1144: training on tf=MAX,tissue=Endometrium training data
Reason: Missing output files: output/models/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.logistic.rds, output/models/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz --rds_file output/models/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1144 with external jobid 'Submitted batch job 11041812'.

[Sat Dec  2 14:20:03 2023]
Job 1369: evaluating on tf=CTCF,tissue=Stomach training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz, output/models/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz, output/models/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.linear.rds --logistic_model output/models/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Stomach.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Stomach_2023-12-01/aggByCollect_CTCF_Stomach
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1369 with external jobid 'Submitted batch job 11041814'.
[Sat Dec  2 14:20:47 2023]
Finished job 1369.
1158 of 1394 steps (83%) done
Select jobs to execute...
[Sat Dec  2 14:23:07 2023]
Finished job 1144.
1159 of 1394 steps (83%) done

[Sat Dec  2 14:23:07 2023]
Job 1330: evaluating on tf=MAX,tissue=Endometrium training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.logistic.train_eval.txt.gz, output/models_eval/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz, output/models/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz, output/models/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.linear.rds --logistic_model output/models/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Endometrium.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Endometrium_2023-12-01/aggByCollect_MAX_Endometrium
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1330 with external jobid 'Submitted batch job 11041977'.

[Sat Dec  2 14:23:10 2023]
Job 1029: training on tf=GATA2,tissue=Umbilical-Vein training data
Reason: Missing output files: output/models/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.logistic.rds, output/models/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1029 with external jobid 'Submitted batch job 11041978'.
[Sat Dec  2 14:24:01 2023]
Finished job 1330.
1160 of 1394 steps (83%) done
Select jobs to execute...
[Sat Dec  2 14:27:42 2023]
Finished job 1029.
1161 of 1394 steps (83%) done

[Sat Dec  2 14:27:42 2023]
Job 1215: evaluating on tf=GATA2,tissue=Umbilical-Vein training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz, output/models/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.linear.rds, output/models/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA2_Umbilical-Vein_2023-12-01/aggByCollect_GATA2_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1215 with external jobid 'Submitted batch job 11042163'.

[Sat Dec  2 14:27:45 2023]
Job 1125: training on tf=MAX,tissue=Umbilical-Vein training data
Reason: Missing output files: output/models/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.linear.rds, output/models/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1125 with external jobid 'Submitted batch job 11042166'.
[Sat Dec  2 14:30:37 2023]
Finished job 1215.
1162 of 1394 steps (83%) done
Select jobs to execute...
[Sat Dec  2 14:33:08 2023]
Finished job 1125.
1163 of 1394 steps (83%) done

[Sat Dec  2 14:33:08 2023]
Job 1311: evaluating on tf=MAX,tissue=Umbilical-Vein training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.linear.test_eval.txt.gz, output/models_eval/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz, output/models/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.logistic.rds, output/models/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Umbilical-Vein_2023-12-01/aggByCollect_MAX_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1311 with external jobid 'Submitted batch job 11042389'.

[Sat Dec  2 14:33:09 2023]
Job 1135: training on tf=GATA3,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.linear.rds, output/models/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz --rds_file output/models/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1135 with external jobid 'Submitted batch job 11042392'.
[Sat Dec  2 14:33:51 2023]
Finished job 1311.
1164 of 1394 steps (84%) done
Select jobs to execute...
[Sat Dec  2 14:35:53 2023]
Finished job 1135.
1165 of 1394 steps (84%) done

[Sat Dec  2 14:35:53 2023]
Job 1207: training on tf=GATA4,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.logistic.rds, output/models/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz --rds_file output/models/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1207 with external jobid 'Submitted batch job 11042514'.

[Sat Dec  2 14:35:55 2023]
Job 1321: evaluating on tf=GATA3,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz, output/models/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.linear.rds, output/models/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.linear.rds --logistic_model output/models/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA3_Lung_2023-12-01/aggByCollect_GATA3_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1321 with external jobid 'Submitted batch job 11042517'.
[Sat Dec  2 14:36:59 2023]
Finished job 1321.
1166 of 1394 steps (84%) done
Select jobs to execute...
[Sat Dec  2 14:39:29 2023]
Finished job 1207.
1167 of 1394 steps (84%) done

[Sat Dec  2 14:39:29 2023]
Job 1184: training on tf=CTCF,tissue=Sigmoid-Colon training data
Reason: Missing output files: output/models/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.linear.rds, output/models/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1184 with external jobid 'Submitted batch job 11042658'.

[Sat Dec  2 14:39:31 2023]
Job 1393: evaluating on tf=GATA4,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz, output/models/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.linear.rds --logistic_model output/models/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA4_Lung_2023-12-01/aggByCollect_GATA4_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1393 with external jobid 'Submitted batch job 11042661'.
[Sat Dec  2 14:40:46 2023]
Finished job 1393.
1168 of 1394 steps (84%) done
Select jobs to execute...
[Sat Dec  2 14:42:16 2023]
Finished job 1184.
1169 of 1394 steps (84%) done

[Sat Dec  2 14:42:16 2023]
Job 1370: evaluating on tf=CTCF,tissue=Sigmoid-Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz, output/models/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.linear.rds, output/models/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.linear.rds --logistic_model output/models/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Sigmoid-Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Sigmoid-Colon_2023-12-01/aggByCollect_CTCF_Sigmoid-Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1370 with external jobid 'Submitted batch job 11042754'.

[Sat Dec  2 14:42:17 2023]
Job 1090: training on tf=MAX,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.linear.rds, output/models/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz --rds_file output/models/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1090 with external jobid 'Submitted batch job 11042756'.
[Sat Dec  2 14:43:21 2023]
Finished job 1370.
1170 of 1394 steps (84%) done
Select jobs to execute...
[Sat Dec  2 14:45:02 2023]
Finished job 1090.
1171 of 1394 steps (84%) done

[Sat Dec  2 14:45:02 2023]
Job 1276: evaluating on tf=MAX,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.linear.rds, output/models/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.linear.rds --logistic_model output/models/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Colon_2023-12-01/aggByCollect_MAX_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1276 with external jobid 'Submitted batch job 11042873'.

[Sat Dec  2 14:45:03 2023]
Job 1178: training on tf=HSF1,tissue=Bone training data
Reason: Missing output files: output/models/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.logistic.rds, output/models/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz --rds_file output/models/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1178 with external jobid 'Submitted batch job 11042876'.
[Sat Dec  2 14:47:13 2023]
Finished job 1276.
1172 of 1394 steps (84%) done
Select jobs to execute...
[Sat Dec  2 14:53:35 2023]
Finished job 1178.
1173 of 1394 steps (84%) done

[Sat Dec  2 14:53:35 2023]
Job 1082: training on tf=MAX,tissue=Cervix training data
Reason: Missing output files: output/models/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.linear.rds, output/models/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz --rds_file output/models/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1082 with external jobid 'Submitted batch job 11043231'.

[Sat Dec  2 14:53:37 2023]
Job 1364: evaluating on tf=HSF1,tissue=Bone training and test data
Reason: Missing output files: output/models_eval/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.linear.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.linear.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.logistic.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz, output/models/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.linear.rds --logistic_model output/models/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Bone.prepared.csv.gz --eval_output output/models_eval/cistrome_HSF1_Bone_2023-12-01/aggByCollect_HSF1_Bone
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1364 with external jobid 'Submitted batch job 11043233'.
[Sat Dec  2 14:54:30 2023]
Finished job 1364.
1174 of 1394 steps (84%) done
Select jobs to execute...
[Sat Dec  2 14:56:00 2023]
Finished job 1082.
1175 of 1394 steps (84%) done

[Sat Dec  2 14:56:00 2023]
Job 1268: evaluating on tf=MAX,tissue=Cervix training and test data
Reason: Missing output files: output/models_eval/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.logistic.train_eval.txt.gz, output/models_eval/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.linear.train_eval.txt.gz, output/models_eval/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.logistic.test_eval.txt.gz, output/models_eval/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz, output/models/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz, output/models/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.linear.rds --logistic_model output/models/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MAX_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_MAX_Cervix_2023-12-01/aggByCollect_MAX_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1268 with external jobid 'Submitted batch job 11043317'.

[Sat Dec  2 14:56:01 2023]
Job 1202: training on tf=RUNX1,tissue=Kidney training data
Reason: Missing output files: output/models/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.logistic.rds, output/models/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1202 with external jobid 'Submitted batch job 11043322'.
[Sat Dec  2 14:57:49 2023]
Finished job 1268.
1176 of 1394 steps (84%) done
Select jobs to execute...
[Sat Dec  2 14:58:50 2023]
Finished job 1202.
1177 of 1394 steps (84%) done

[Sat Dec  2 14:58:50 2023]
Job 1150: training on tf=SP1,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.logistic.rds, output/models/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz --rds_file output/models/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1150 with external jobid 'Submitted batch job 11043417'.

[Sat Dec  2 14:58:54 2023]
Job 1388: evaluating on tf=RUNX1,tissue=Kidney training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.logistic.rds, output/models/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.linear.rds --logistic_model output/models/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Kidney_2023-12-01/aggByCollect_RUNX1_Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1388 with external jobid 'Submitted batch job 11043420'.
[Sat Dec  2 15:00:18 2023]
Finished job 1388.
1178 of 1394 steps (85%) done
Select jobs to execute...
[Sat Dec  2 15:03:18 2023]
Finished job 1150.
1179 of 1394 steps (85%) done

[Sat Dec  2 15:03:18 2023]
Job 1136: training on tf=SP1,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.logistic.rds, output/models/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz --rds_file output/models/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1136 with external jobid 'Submitted batch job 11043588'.

[Sat Dec  2 15:03:20 2023]
Job 1336: evaluating on tf=SP1,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz, output/models/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.logistic.rds, output/models/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.linear.rds --logistic_model output/models/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SP1_Embryo_2023-12-01/aggByCollect_SP1_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1336 with external jobid 'Submitted batch job 11043590'.
[Sat Dec  2 15:04:24 2023]
Finished job 1336.
1180 of 1394 steps (85%) done
Select jobs to execute...
[Sat Dec  2 15:06:44 2023]
Finished job 1136.
1181 of 1394 steps (85%) done

[Sat Dec  2 15:06:44 2023]
Job 1203: training on tf=CTCF,tissue=Cord-blood training data
Reason: Missing output files: output/models/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.linear.rds, output/models/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz --rds_file output/models/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1203 with external jobid 'Submitted batch job 11043710'.

[Sat Dec  2 15:06:45 2023]
Job 1322: evaluating on tf=SP1,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.logistic.rds, output/models/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.linear.rds --logistic_model output/models/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_SP1_Lung_2023-12-01/aggByCollect_SP1_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1322 with external jobid 'Submitted batch job 11043711'.
[Sat Dec  2 15:07:28 2023]
Finished job 1322.
1182 of 1394 steps (85%) done
Select jobs to execute...
[Sat Dec  2 15:08:48 2023]
Finished job 1203.
1183 of 1394 steps (85%) done

[Sat Dec  2 15:08:48 2023]
Job 1389: evaluating on tf=CTCF,tissue=Cord-blood training and test data
Reason: Missing output files: output/models_eval/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.linear.test_eval.txt.gz, output/models_eval/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz, output/models/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.logistic.rds, output/models/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.linear.rds --logistic_model output/models/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CTCF_Cord-blood.prepared.csv.gz --eval_output output/models_eval/cistrome_CTCF_Cord-blood_2023-12-01/aggByCollect_CTCF_Cord-blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1389 with external jobid 'Submitted batch job 11043784'.

[Sat Dec  2 15:08:51 2023]
Job 1027: training on tf=STAT1,tissue=Cervix training data
Reason: Missing output files: output/models/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.logistic.rds, output/models/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz --rds_file output/models/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1027 with external jobid 'Submitted batch job 11043788'.
[Sat Dec  2 15:10:04 2023]
Finished job 1389.
1184 of 1394 steps (85%) done
Select jobs to execute...
[Sat Dec  2 15:11:25 2023]
Finished job 1027.
1185 of 1394 steps (85%) done

[Sat Dec  2 15:11:25 2023]
Job 1213: evaluating on tf=STAT1,tissue=Cervix training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz, output/models/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.linear.rds --logistic_model output/models/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT1_Cervix_2023-12-01/aggByCollect_STAT1_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1213 with external jobid 'Submitted batch job 11043912'.

[Sat Dec  2 15:11:26 2023]
Job 1188: training on tf=SP1,tissue=Embryonic-Kidney training data
Reason: Missing output files: output/models/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.linear.rds, output/models/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz --rds_file output/models/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1188 with external jobid 'Submitted batch job 11043923'.
[Sat Dec  2 15:13:15 2023]
Finished job 1213.
1186 of 1394 steps (85%) done
Select jobs to execute...
[Sat Dec  2 15:18:06 2023]
Finished job 1188.
1187 of 1394 steps (85%) done

[Sat Dec  2 15:18:06 2023]
Job 1374: evaluating on tf=SP1,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: output/models_eval/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.linear.train_eval.txt.gz, output/models_eval/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.linear.test_eval.txt.gz, output/models_eval/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.logistic.test_eval.txt.gz, output/models_eval/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.logistic.rds, output/models/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.linear.rds --logistic_model output/models/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Embryonic-Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_SP1_Embryonic-Kidney_2023-12-01/aggByCollect_SP1_Embryonic-Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1374 with external jobid 'Submitted batch job 11044372'.

[Sat Dec  2 15:18:08 2023]
Job 1148: training on tf=SP1,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.linear.rds, output/models/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz --rds_file output/models/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1148 with external jobid 'Submitted batch job 11044378'.
[Sat Dec  2 15:19:22 2023]
Finished job 1374.
1188 of 1394 steps (85%) done
Select jobs to execute...
[Sat Dec  2 15:28:23 2023]
Finished job 1148.
1189 of 1394 steps (85%) done

[Sat Dec  2 15:28:23 2023]
Job 1074: training on tf=YY1,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.logistic.rds, output/models/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz --rds_file output/models/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1074 with external jobid 'Submitted batch job 11044917'.

[Sat Dec  2 15:28:24 2023]
Job 1334: evaluating on tf=SP1,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz, output/models/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.linear.rds --logistic_model output/models/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_SP1_Blood_2023-12-01/aggByCollect_SP1_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1334 with external jobid 'Submitted batch job 11044919'.
[Sat Dec  2 15:29:51 2023]
Finished job 1334.
1190 of 1394 steps (85%) done
Select jobs to execute...
[Sat Dec  2 15:38:32 2023]
Finished job 1074.
1191 of 1394 steps (85%) done

[Sat Dec  2 15:38:32 2023]
Job 1181: training on tf=RUNX1,tissue=Pleura training data
Reason: Missing output files: output/models/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.linear.rds, output/models/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1181 with external jobid 'Submitted batch job 11045457'.

[Sat Dec  2 15:38:33 2023]
Job 1260: evaluating on tf=YY1,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz, output/models/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.linear.rds --logistic_model output/models/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Embryo_2023-12-01/aggByCollect_YY1_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1260 with external jobid 'Submitted batch job 11045463'.
[Sat Dec  2 15:39:38 2023]
Finished job 1260.
1192 of 1394 steps (86%) done
Select jobs to execute...
[Sat Dec  2 15:51:58 2023]
Finished job 1181.
1193 of 1394 steps (86%) done

[Sat Dec  2 15:51:58 2023]
Job 1367: evaluating on tf=RUNX1,tissue=Pleura training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz, output/models/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.linear.rds --logistic_model output/models/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Pleura.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Pleura_2023-12-01/aggByCollect_RUNX1_Pleura
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1367 with external jobid 'Submitted batch job 11046069'.

[Sat Dec  2 15:51:59 2023]
Job 1205: training on tf=STAT3,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.logistic.rds, output/models/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1205 with external jobid 'Submitted batch job 11046071'.
[Sat Dec  2 15:54:32 2023]
Finished job 1367.
1194 of 1394 steps (86%) done
Select jobs to execute...
[Sat Dec  2 15:56:53 2023]
Finished job 1205.
1195 of 1394 steps (86%) done

[Sat Dec  2 15:56:53 2023]
Job 1391: evaluating on tf=STAT3,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz, output/models/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.logistic.rds, output/models/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.linear.rds --logistic_model output/models/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Lung_2023-12-01/aggByCollect_STAT3_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1391 with external jobid 'Submitted batch job 11046263'.

[Sat Dec  2 15:56:56 2023]
Job 1120: training on tf=STAT3,tissue=Cervix training data
Reason: Missing output files: output/models/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.linear.rds, output/models/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1120 with external jobid 'Submitted batch job 11046265'.
[Sat Dec  2 15:57:36 2023]
Finished job 1391.
1196 of 1394 steps (86%) done
Select jobs to execute...
[Sat Dec  2 15:58:47 2023]
Finished job 1120.
1197 of 1394 steps (86%) done

[Sat Dec  2 15:58:47 2023]
Job 1306: evaluating on tf=STAT3,tissue=Cervix training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz, output/models/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.linear.rds, output/models/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.linear.rds --logistic_model output/models/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Cervix_2023-12-01/aggByCollect_STAT3_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1306 with external jobid 'Submitted batch job 11046327'.

[Sat Dec  2 15:58:50 2023]
Job 1050: training on tf=SOX2,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.logistic.rds, output/models/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz --rds_file output/models/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1050 with external jobid 'Submitted batch job 11046331'.
[Sat Dec  2 15:59:52 2023]
Finished job 1306.
1198 of 1394 steps (86%) done
Select jobs to execute...
[Sat Dec  2 16:00:43 2023]
Finished job 1050.
1199 of 1394 steps (86%) done

[Sat Dec  2 16:00:43 2023]
Job 1236: evaluating on tf=SOX2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz, output/models/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz, output/models/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.linear.rds --logistic_model output/models/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SOX2_Embryo_2023-12-01/aggByCollect_SOX2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1236 with external jobid 'Submitted batch job 11046438'.

[Sat Dec  2 16:00:45 2023]
Job 1037: training on tf=E2F1,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.linear.rds, output/models/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz --rds_file output/models/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1037 with external jobid 'Submitted batch job 11046444'.
[Sat Dec  2 16:03:05 2023]
Finished job 1236.
1200 of 1394 steps (86%) done
Select jobs to execute...
[Sat Dec  2 16:18:57 2023]
Finished job 1037.
1201 of 1394 steps (86%) done

[Sat Dec  2 16:18:57 2023]
Job 1153: training on tf=SP1,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.linear.rds, output/models/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz --rds_file output/models/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1153 with external jobid 'Submitted batch job 11047163'.

[Sat Dec  2 16:18:58 2023]
Job 1223: evaluating on tf=E2F1,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz, output/models/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.linear.rds, output/models/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.linear.rds --logistic_model output/models/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_E2F1_Breast_2023-12-01/aggByCollect_E2F1_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1223 with external jobid 'Submitted batch job 11047166'.
[Sat Dec  2 16:19:30 2023]
Finished job 1223.
1202 of 1394 steps (86%) done
Select jobs to execute...
[Sat Dec  2 16:20:00 2023]
Finished job 1153.
1203 of 1394 steps (86%) done

[Sat Dec  2 16:20:00 2023]
Job 1339: evaluating on tf=SP1,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.linear.test_eval.txt.gz, output/models_eval/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.logistic.test_eval.txt.gz, output/models_eval/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz, output/models/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.logistic.rds, output/models/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.linear.rds --logistic_model output/models/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_SP1_Liver_2023-12-01/aggByCollect_SP1_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1339 with external jobid 'Submitted batch job 11047189'.

[Sat Dec  2 16:20:03 2023]
Job 1193: training on tf=GATA3,tissue=Thymus training data
Reason: Missing output files: output/models/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.linear.rds, output/models/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz --rds_file output/models/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1193 with external jobid 'Submitted batch job 11047191'.
[Sat Dec  2 16:21:16 2023]
Finished job 1339.
1204 of 1394 steps (86%) done
Select jobs to execute...
[Sat Dec  2 16:21:27 2023]
Finished job 1193.
1205 of 1394 steps (86%) done

[Sat Dec  2 16:21:27 2023]
Job 1109: training on tf=E2F1,tissue=Prostate training data
Reason: Missing output files: output/models/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.linear.rds, output/models/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz --rds_file output/models/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1109 with external jobid 'Submitted batch job 11047214'.

[Sat Dec  2 16:21:28 2023]
Job 1379: evaluating on tf=GATA3,tissue=Thymus training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.linear.rds, output/models/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.linear.rds --logistic_model output/models/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA3_Thymus.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA3_Thymus_2023-12-01/aggByCollect_GATA3_Thymus
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1379 with external jobid 'Submitted batch job 11047215'.
[Sat Dec  2 16:22:11 2023]
Finished job 1379.
1206 of 1394 steps (87%) done
Select jobs to execute...
[Sat Dec  2 16:22:31 2023]
Finished job 1109.
1207 of 1394 steps (87%) done

[Sat Dec  2 16:22:31 2023]
Job 1098: training on tf=STAT3,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.logistic.rds, output/models/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1098 with external jobid 'Submitted batch job 11047236'.

[Sat Dec  2 16:22:34 2023]
Job 1295: evaluating on tf=E2F1,tissue=Prostate training and test data
Reason: Missing output files: output/models_eval/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.linear.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.logistic.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.linear.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz, output/models/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.linear.rds --logistic_model output/models/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_E2F1_Prostate_2023-12-01/aggByCollect_E2F1_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1295 with external jobid 'Submitted batch job 11047238'.
[Sat Dec  2 16:27:39 2023]
Finished job 1295.
1208 of 1394 steps (87%) done
Select jobs to execute...
[Sat Dec  2 16:27:59 2023]
Finished job 1098.
1209 of 1394 steps (87%) done

[Sat Dec  2 16:27:59 2023]
Job 1284: evaluating on tf=STAT3,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz, output/models/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.logistic.rds, output/models/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Bone-Marrow_2023-12-01/aggByCollect_STAT3_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1284 with external jobid 'Submitted batch job 11047459'.

[Sat Dec  2 16:28:00 2023]
Job 1048: training on tf=RUNX1,tissue=Cord-blood training data
Reason: Missing output files: output/models/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.linear.rds, output/models/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1048 with external jobid 'Submitted batch job 11047461'.
[Sat Dec  2 16:30:21 2023]
Finished job 1284.
1210 of 1394 steps (87%) done
Select jobs to execute...
[Sat Dec  2 16:30:32 2023]
Finished job 1048.
1211 of 1394 steps (87%) done

[Sat Dec  2 16:30:32 2023]
Job 1234: evaluating on tf=RUNX1,tissue=Cord-blood training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz, output/models/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.linear.rds, output/models/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.linear.rds --logistic_model output/models/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Cord-blood.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Cord-blood_2023-12-01/aggByCollect_RUNX1_Cord-blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1234 with external jobid 'Submitted batch job 11047544'.

[Sat Dec  2 16:30:33 2023]
Job 1147: training on tf=FOXM1,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.linear.rds, output/models/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz --rds_file output/models/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1147 with external jobid 'Submitted batch job 11047547'.
[Sat Dec  2 16:32:00 2023]
Finished job 1234.
1212 of 1394 steps (87%) done
Select jobs to execute...
[Sat Dec  2 16:32:11 2023]
Finished job 1147.
1213 of 1394 steps (87%) done

[Sat Dec  2 16:32:11 2023]
Job 1156: training on tf=ETS1,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.linear.rds, output/models/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1156 with external jobid 'Submitted batch job 11047595'.

[Sat Dec  2 16:32:14 2023]
Job 1333: evaluating on tf=FOXM1,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz, output/models/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz, output/models/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.linear.rds --logistic_model output/models/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXM1_Blood_2023-12-01/aggByCollect_FOXM1_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1333 with external jobid 'Submitted batch job 11047596'.
[Sat Dec  2 16:32:55 2023]
Finished job 1333.
1214 of 1394 steps (87%) done
Select jobs to execute...
[Sat Dec  2 16:33:15 2023]
Finished job 1156.
1215 of 1394 steps (87%) done

[Sat Dec  2 16:33:15 2023]
Job 1129: training on tf=YY1,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.linear.rds, output/models/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1129 with external jobid 'Submitted batch job 11047626'.

[Sat Dec  2 16:33:18 2023]
Job 1342: evaluating on tf=ETS1,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.logistic.test_eval.txt.gz, output/models_eval/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz, output/models/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.linear.rds, output/models/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_ETS1_Bone-Marrow_2023-12-01/aggByCollect_ETS1_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1342 with external jobid 'Submitted batch job 11047630'.
[Sat Dec  2 16:33:59 2023]
Finished job 1342.
1216 of 1394 steps (87%) done
Select jobs to execute...
[Sat Dec  2 16:34:19 2023]
Finished job 1129.
1217 of 1394 steps (87%) done

[Sat Dec  2 16:34:19 2023]
Job 1315: evaluating on tf=YY1,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz, output/models/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Bone-Marrow_2023-12-01/aggByCollect_YY1_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1315 with external jobid 'Submitted batch job 11047658'.

[Sat Dec  2 16:34:21 2023]
Job 1049: training on tf=STAT1,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.linear.rds, output/models/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz --rds_file output/models/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1049 with external jobid 'Submitted batch job 11047659'.
[Sat Dec  2 16:35:02 2023]
Finished job 1315.
1218 of 1394 steps (87%) done
Select jobs to execute...
[Sat Dec  2 16:35:13 2023]
Finished job 1049.
1219 of 1394 steps (87%) done

[Sat Dec  2 16:35:13 2023]
Job 1101: training on tf=STAT3,tissue=Lymph-Node training data
Reason: Missing output files: output/models/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.linear.rds, output/models/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1101 with external jobid 'Submitted batch job 11047691'.

[Sat Dec  2 16:35:13 2023]
Job 1235: evaluating on tf=STAT1,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz, output/models/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz, output/models/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.linear.rds --logistic_model output/models/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT1_Blood_2023-12-01/aggByCollect_STAT1_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1235 with external jobid 'Submitted batch job 11047692'.
[Sat Dec  2 16:36:08 2023]
Finished job 1235.
1220 of 1394 steps (88%) done
Select jobs to execute...
[Sat Dec  2 16:36:28 2023]
Finished job 1101.
1221 of 1394 steps (88%) done

[Sat Dec  2 16:36:28 2023]
Job 1157: training on tf=SP1,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.linear.rds, output/models/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1157 with external jobid 'Submitted batch job 11047716'.

[Sat Dec  2 16:36:31 2023]
Job 1287: evaluating on tf=STAT3,tissue=Lymph-Node training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz, output/models/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz, output/models/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.linear.rds --logistic_model output/models/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Lymph-Node.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Lymph-Node_2023-12-01/aggByCollect_STAT3_Lymph-Node
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1287 with external jobid 'Submitted batch job 11047718'.
[Sat Dec  2 16:40:30 2023]
Finished job 1287.
1222 of 1394 steps (88%) done
Select jobs to execute...
[Sat Dec  2 16:40:50 2023]
Finished job 1157.
1223 of 1394 steps (88%) done

[Sat Dec  2 16:40:50 2023]
Job 1343: evaluating on tf=SP1,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.logistic.test_eval.txt.gz, output/models_eval/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz, output/models/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_SP1_Bone-Marrow_2023-12-01/aggByCollect_SP1_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1343 with external jobid 'Submitted batch job 11047940'.

[Sat Dec  2 16:40:51 2023]
Job 1141: training on tf=FOXA1,tissue=Endometrium training data
Reason: Missing output files: output/models/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.logistic.rds, output/models/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1141 with external jobid 'Submitted batch job 11047944'.
[Sat Dec  2 16:41:44 2023]
Finished job 1343.
1224 of 1394 steps (88%) done
Select jobs to execute...
[Sat Dec  2 16:41:55 2023]
Finished job 1141.
1225 of 1394 steps (88%) done

[Sat Dec  2 16:41:55 2023]
Job 1058: training on tf=GATA2,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.logistic.rds, output/models/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz --rds_file output/models/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1058 with external jobid 'Submitted batch job 11047968'.

[Sat Dec  2 16:41:57 2023]
Job 1327: evaluating on tf=FOXA1,tissue=Endometrium training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz, output/models/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.linear.rds --logistic_model output/models/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Endometrium.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Endometrium_2023-12-01/aggByCollect_FOXA1_Endometrium
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1327 with external jobid 'Submitted batch job 11047969'.
[Sat Dec  2 16:43:12 2023]
Finished job 1327.
1226 of 1394 steps (88%) done
Select jobs to execute...
[Sat Dec  2 16:43:32 2023]
Finished job 1058.
1227 of 1394 steps (88%) done

[Sat Dec  2 16:43:32 2023]
Job 1244: evaluating on tf=GATA2,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.logistic.rds, output/models/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.linear.rds --logistic_model output/models/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA2_Blood_2023-12-01/aggByCollect_GATA2_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1244 with external jobid 'Submitted batch job 11048007'.

[Sat Dec  2 16:43:35 2023]
Job 1099: training on tf=STAT3,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.logistic.rds, output/models/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1099 with external jobid 'Submitted batch job 11048008'.
[Sat Dec  2 16:44:04 2023]
Finished job 1244.
1228 of 1394 steps (88%) done
Select jobs to execute...
[Sat Dec  2 16:44:25 2023]
Finished job 1099.
1229 of 1394 steps (88%) done

[Sat Dec  2 16:44:25 2023]
Job 1285: evaluating on tf=STAT3,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.logistic.rds, output/models/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.linear.rds --logistic_model output/models/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Blood_2023-12-01/aggByCollect_STAT3_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1285 with external jobid 'Submitted batch job 11048015'.

[Sat Dec  2 16:44:26 2023]
Job 1138: training on tf=ETS1,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.linear.rds, output/models/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz --rds_file output/models/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1138 with external jobid 'Submitted batch job 11048016'.
[Sat Dec  2 16:45:08 2023]
Finished job 1285.
1230 of 1394 steps (88%) done
Select jobs to execute...
[Sat Dec  2 16:45:19 2023]
Finished job 1138.
1231 of 1394 steps (88%) done

[Sat Dec  2 16:45:19 2023]
Job 1324: evaluating on tf=ETS1,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz, output/models/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.linear.rds --logistic_model output/models/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_ETS1_Lung_2023-12-01/aggByCollect_ETS1_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1324 with external jobid 'Submitted batch job 11048032'.

[Sat Dec  2 16:45:22 2023]
Job 1051: training on tf=YY1,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.logistic.rds, output/models/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz --rds_file output/models/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1051 with external jobid 'Submitted batch job 11048034'.
[Sat Dec  2 16:46:13 2023]
Finished job 1324.
1232 of 1394 steps (88%) done
Select jobs to execute...
[Sat Dec  2 16:46:34 2023]
Finished job 1051.
1233 of 1394 steps (88%) done

[Sat Dec  2 16:46:34 2023]
Job 1054: training on tf=ETS1,tissue=Prostate training data
Reason: Missing output files: output/models/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.linear.rds, output/models/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz --rds_file output/models/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1054 with external jobid 'Submitted batch job 11048050'.

[Sat Dec  2 16:46:36 2023]
Job 1237: evaluating on tf=YY1,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz, output/models/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.logistic.rds, output/models/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.linear.rds --logistic_model output/models/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Blood_2023-12-01/aggByCollect_YY1_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1237 with external jobid 'Submitted batch job 11048055'.
[Sat Dec  2 16:53:44 2023]
Finished job 1237.
1234 of 1394 steps (89%) done
Select jobs to execute...
[Sat Dec  2 17:00:04 2023]
Finished job 1054.
1235 of 1394 steps (89%) done

[Sat Dec  2 17:00:04 2023]
Job 1240: evaluating on tf=ETS1,tissue=Prostate training and test data
Reason: Missing output files: output/models_eval/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.linear.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.logistic.test_eval.txt.gz, output/models_eval/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.logistic.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz, output/models/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.linear.rds --logistic_model output/models/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_ETS1_Prostate_2023-12-01/aggByCollect_ETS1_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1240 with external jobid 'Submitted batch job 11048642'.

[Sat Dec  2 17:00:06 2023]
Job 1026: training on tf=E2F1,tissue=Cervix training data
Reason: Missing output files: output/models/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.linear.rds, output/models/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz --rds_file output/models/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1026 with external jobid 'Submitted batch job 11048648'.
[Sat Dec  2 17:01:42 2023]
Finished job 1240.
1236 of 1394 steps (89%) done
Select jobs to execute...
[Sat Dec  2 17:02:03 2023]
Finished job 1026.
1237 of 1394 steps (89%) done

[Sat Dec  2 17:02:03 2023]
Job 1212: evaluating on tf=E2F1,tissue=Cervix training and test data
Reason: Missing output files: output/models_eval/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.logistic.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.logistic.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.linear.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz, output/models/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.linear.rds --logistic_model output/models/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_E2F1_Cervix_2023-12-01/aggByCollect_E2F1_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1212 with external jobid 'Submitted batch job 11048772'.

[Sat Dec  2 17:02:05 2023]
Job 1185: training on tf=GATA4,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.logistic.rds, output/models/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz --rds_file output/models/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1185 with external jobid 'Submitted batch job 11048774'.
[Sat Dec  2 17:03:30 2023]
Finished job 1212.
1238 of 1394 steps (89%) done
Select jobs to execute...
[Sat Dec  2 17:03:51 2023]
Finished job 1185.
1239 of 1394 steps (89%) done

[Sat Dec  2 17:03:51 2023]
Job 1180: training on tf=E2F1,tissue=Mammary-Gland training data
Reason: Missing output files: output/models/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.linear.rds, output/models/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1180 with external jobid 'Submitted batch job 11048822'.

[Sat Dec  2 17:03:55 2023]
Job 1371: evaluating on tf=GATA4,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz, output/models/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.linear.rds --logistic_model output/models/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA4_Liver_2023-12-01/aggByCollect_GATA4_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1371 with external jobid 'Submitted batch job 11048825'.
[Sat Dec  2 17:05:19 2023]
Finished job 1371.
1240 of 1394 steps (89%) done
Select jobs to execute...
[Sat Dec  2 17:05:39 2023]
Finished job 1180.
1241 of 1394 steps (89%) done

[Sat Dec  2 17:05:39 2023]
Job 1366: evaluating on tf=E2F1,tissue=Mammary-Gland training and test data
Reason: Missing output files: output/models_eval/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.linear.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.logistic.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.linear.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz, output/models/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz, output/models/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_E2F1_Mammary-Gland_2023-12-01/aggByCollect_E2F1_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1366 with external jobid 'Submitted batch job 11048870'.

[Sat Dec  2 17:05:42 2023]
Job 1127: training on tf=STAT1,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.linear.rds, output/models/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1127 with external jobid 'Submitted batch job 11048871'.
[Sat Dec  2 17:06:11 2023]
Finished job 1366.
1242 of 1394 steps (89%) done
Select jobs to execute...
[Sat Dec  2 17:06:32 2023]
Finished job 1127.
1243 of 1394 steps (89%) done

[Sat Dec  2 17:06:32 2023]
Job 1313: evaluating on tf=STAT1,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz, output/models/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.logistic.rds, output/models/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT1_Bone-Marrow_2023-12-01/aggByCollect_STAT1_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1313 with external jobid 'Submitted batch job 11048892'.

[Sat Dec  2 17:06:35 2023]
Job 1163: training on tf=YY1,tissue=Brain training data
Reason: Missing output files: output/models/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.logistic.rds, output/models/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz --rds_file output/models/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1163 with external jobid 'Submitted batch job 11048894'.
[Sat Dec  2 17:07:05 2023]
Finished job 1313.
1244 of 1394 steps (89%) done
Select jobs to execute...
[Sat Dec  2 17:08:16 2023]
Finished job 1163.
1245 of 1394 steps (89%) done

[Sat Dec  2 17:08:16 2023]
Job 1349: evaluating on tf=YY1,tissue=Brain training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.logistic.test_eval.txt.gz, output/models_eval/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz, output/models/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.linear.rds --logistic_model output/models/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Brain_2023-12-01/aggByCollect_YY1_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1349 with external jobid 'Submitted batch job 11048917'.

[Sat Dec  2 17:08:16 2023]
Job 1195: training on tf=E2F1,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.logistic.rds, output/models/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz --rds_file output/models/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1195 with external jobid 'Submitted batch job 11048920'.
[Sat Dec  2 17:08:59 2023]
Finished job 1349.
1246 of 1394 steps (89%) done
Select jobs to execute...
[Sat Dec  2 17:09:20 2023]
Finished job 1195.
1247 of 1394 steps (89%) done

[Sat Dec  2 17:09:20 2023]
Job 1381: evaluating on tf=E2F1,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.linear.rds, output/models/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.linear.rds --logistic_model output/models/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_E2F1_Blood_2023-12-01/aggByCollect_E2F1_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1381 with external jobid 'Submitted batch job 11048940'.

[Sat Dec  2 17:09:20 2023]
Job 1146: training on tf=YY1,tissue=Endometrium training data
Reason: Missing output files: output/models/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.logistic.rds, output/models/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz --rds_file output/models/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1146 with external jobid 'Submitted batch job 11048941'.
[Sat Dec  2 17:10:03 2023]
Finished job 1381.
1248 of 1394 steps (90%) done
Select jobs to execute...
[Sat Dec  2 17:10:14 2023]
Finished job 1146.
1249 of 1394 steps (90%) done

[Sat Dec  2 17:10:14 2023]
Job 1332: evaluating on tf=YY1,tissue=Endometrium training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.logistic.test_eval.txt.gz, output/models_eval/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.logistic.train_eval.txt.gz, output/models_eval/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz, output/models/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.linear.rds --logistic_model output/models/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Endometrium.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Endometrium_2023-12-01/aggByCollect_YY1_Endometrium
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1332 with external jobid 'Submitted batch job 11048951'.

[Sat Dec  2 17:10:16 2023]
Job 1189: training on tf=YY1,tissue=Embryonic-Kidney training data
Reason: Missing output files: output/models/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.linear.rds, output/models/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz --rds_file output/models/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1189 with external jobid 'Submitted batch job 11048952'.
[Sat Dec  2 17:10:46 2023]
Finished job 1332.
1250 of 1394 steps (90%) done
Select jobs to execute...
[Sat Dec  2 17:11:07 2023]
Finished job 1189.
1251 of 1394 steps (90%) done

[Sat Dec  2 17:11:07 2023]
Job 1375: evaluating on tf=YY1,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.logistic.test_eval.txt.gz, output/models_eval/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.logistic.rds, output/models/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.linear.rds --logistic_model output/models/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Embryonic-Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Embryonic-Kidney_2023-12-01/aggByCollect_YY1_Embryonic-Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1375 with external jobid 'Submitted batch job 11048964'.

[Sat Dec  2 17:11:08 2023]
Job 1107: training on tf=SOX2,tissue=Thyroid training data
Reason: Missing output files: output/models/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.logistic.rds, output/models/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz --rds_file output/models/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1107 with external jobid 'Submitted batch job 11048966'.
[Sat Dec  2 17:11:39 2023]
Finished job 1375.
1252 of 1394 steps (90%) done
Select jobs to execute...
[Sat Dec  2 17:12:20 2023]
Finished job 1107.
1253 of 1394 steps (90%) done

[Sat Dec  2 17:12:20 2023]
Job 1152: training on tf=YY1,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.linear.rds, output/models/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz --rds_file output/models/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1152 with external jobid 'Submitted batch job 11048988'.

[Sat Dec  2 17:12:24 2023]
Job 1293: evaluating on tf=SOX2,tissue=Thyroid training and test data
Reason: Missing output files: output/models_eval/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.logistic.train_eval.txt.gz, output/models_eval/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.linear.test_eval.txt.gz, output/models_eval/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.linear.train_eval.txt.gz, output/models_eval/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz, output/models/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.linear.rds --logistic_model output/models/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Thyroid.prepared.csv.gz --eval_output output/models_eval/cistrome_SOX2_Thyroid_2023-12-01/aggByCollect_SOX2_Thyroid
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1293 with external jobid 'Submitted batch job 11048993'.
[Sat Dec  2 17:12:53 2023]
Finished job 1293.
1254 of 1394 steps (90%) done
Select jobs to execute...
[Sat Dec  2 17:13:13 2023]
Finished job 1152.
1255 of 1394 steps (90%) done

[Sat Dec  2 17:13:13 2023]
Job 1338: evaluating on tf=YY1,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz, output/models/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.logistic.rds, output/models/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.linear.rds --logistic_model output/models/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Liver_2023-12-01/aggByCollect_YY1_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1338 with external jobid 'Submitted batch job 11049024'.

[Sat Dec  2 17:13:17 2023]
Job 1137: training on tf=YY1,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.linear.rds, output/models/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz --rds_file output/models/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1137 with external jobid 'Submitted batch job 11049028'.
[Sat Dec  2 17:14:18 2023]
Finished job 1338.
1256 of 1394 steps (90%) done
Select jobs to execute...
[Sat Dec  2 17:14:39 2023]
Finished job 1137.
1257 of 1394 steps (90%) done

[Sat Dec  2 17:14:39 2023]
Job 1190: training on tf=E2F1,tissue=Umbilical-Cord training data
Reason: Missing output files: output/models/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.logistic.rds, output/models/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz --rds_file output/models/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1190 with external jobid 'Submitted batch job 11049086'.

[Sat Dec  2 17:14:45 2023]
Job 1323: evaluating on tf=YY1,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz, output/models/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.linear.rds --logistic_model output/models/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Lung_2023-12-01/aggByCollect_YY1_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1323 with external jobid 'Submitted batch job 11049096'.
[Sat Dec  2 17:18:08 2023]
Finished job 1323.
1258 of 1394 steps (90%) done
Select jobs to execute...
[Sat Dec  2 17:24:18 2023]
Finished job 1190.
1259 of 1394 steps (90%) done

[Sat Dec  2 17:24:18 2023]
Job 1376: evaluating on tf=E2F1,tissue=Umbilical-Cord training and test data
Reason: Missing output files: output/models_eval/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.linear.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.logistic.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.linear.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.logistic.rds, output/models/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.linear.rds --logistic_model output/models/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Umbilical-Cord.prepared.csv.gz --eval_output output/models_eval/cistrome_E2F1_Umbilical-Cord_2023-12-01/aggByCollect_E2F1_Umbilical-Cord
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1376 with external jobid 'Submitted batch job 11049671'.

[Sat Dec  2 17:24:20 2023]
Job 1149: training on tf=REST,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.linear.rds, output/models/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz --rds_file output/models/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1149 with external jobid 'Submitted batch job 11049674'.
[Sat Dec  2 17:25:57 2023]
Finished job 1376.
1260 of 1394 steps (90%) done
Select jobs to execute...
[Sat Dec  2 17:34:08 2023]
Finished job 1149.
1261 of 1394 steps (90%) done

[Sat Dec  2 17:34:08 2023]
Job 1192: training on tf=RUNX1,tissue=Fetal-Liver training data
Reason: Missing output files: output/models/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.logistic.rds, output/models/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1192 with external jobid 'Submitted batch job 11050009'.

[Sat Dec  2 17:34:11 2023]
Job 1335: evaluating on tf=REST,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz, output/models/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.linear.rds, output/models/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.linear.rds --logistic_model output/models/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Embryo_2023-12-01/aggByCollect_REST_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1335 with external jobid 'Submitted batch job 11050011'.
[Sat Dec  2 17:35:03 2023]
Finished job 1335.
1262 of 1394 steps (91%) done
Select jobs to execute...
[Sat Dec  2 17:35:23 2023]
Finished job 1192.
1263 of 1394 steps (91%) done

[Sat Dec  2 17:35:23 2023]
Job 1097: training on tf=E2F1,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.linear.rds, output/models/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1097 with external jobid 'Submitted batch job 11050049'.

[Sat Dec  2 17:35:26 2023]
Job 1378: evaluating on tf=RUNX1,tissue=Fetal-Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz, output/models/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz, output/models/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.linear.rds --logistic_model output/models/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Fetal-Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Fetal-Liver_2023-12-01/aggByCollect_RUNX1_Fetal-Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1378 with external jobid 'Submitted batch job 11050052'.
[Sat Dec  2 17:36:07 2023]
Finished job 1378.
1264 of 1394 steps (91%) done
Select jobs to execute...
[Sat Dec  2 17:36:27 2023]
Finished job 1097.
1265 of 1394 steps (91%) done

[Sat Dec  2 17:36:27 2023]
Job 1143: training on tf=FOXM1,tissue=Endometrium training data
Reason: Missing output files: output/models/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.logistic.rds, output/models/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz --rds_file output/models/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1143 with external jobid 'Submitted batch job 11050094'.

[Sat Dec  2 17:36:29 2023]
Job 1283: evaluating on tf=E2F1,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz, output/models/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_E2F1_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_E2F1_Bone-Marrow_2023-12-01/aggByCollect_E2F1_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1283 with external jobid 'Submitted batch job 11050101'.
[Sat Dec  2 17:37:11 2023]
Finished job 1283.
1266 of 1394 steps (91%) done
Select jobs to execute...
[Sat Dec  2 17:53:52 2023]
Finished job 1143.
1267 of 1394 steps (91%) done

[Sat Dec  2 17:53:52 2023]
Job 1329: evaluating on tf=FOXM1,tissue=Endometrium training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz, output/models/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.linear.rds --logistic_model output/models/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Endometrium.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXM1_Endometrium_2023-12-01/aggByCollect_FOXM1_Endometrium
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1329 with external jobid 'Submitted batch job 11050846'.

[Sat Dec  2 17:53:53 2023]
Job 1162: training on tf=REST,tissue=Brain training data
Reason: Missing output files: output/models/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.linear.rds, output/models/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Brain.prepared.csv.gz --rds_file output/models/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1162 with external jobid 'Submitted batch job 11050851'.
[Sat Dec  2 17:54:35 2023]
Finished job 1329.
1268 of 1394 steps (91%) done
Select jobs to execute...
[Sat Dec  2 18:42:18 2023]
Finished job 1162.
1269 of 1394 steps (91%) done

[Sat Dec  2 18:42:18 2023]
Job 1165: training on tf=FOXM1,tissue=Brain training data
Reason: Missing output files: output/models/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.logistic.rds, output/models/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz --rds_file output/models/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1165 with external jobid 'Submitted batch job 11052671'.

[Sat Dec  2 18:42:23 2023]
Job 1348: evaluating on tf=REST,tissue=Brain training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.linear.test_eval.txt.gz, output/models_eval/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Brain.prepared.csv.gz, output/models/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_REST_Brain.prepared.csv.gz, output/models/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.linear.rds --logistic_model output/models/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Brain_2023-12-01/aggByCollect_REST_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1348 with external jobid 'Submitted batch job 11052675'.
[Sat Dec  2 18:43:12 2023]
Finished job 1348.
1270 of 1394 steps (91%) done
Select jobs to execute...
[Sat Dec  2 18:43:32 2023]
Finished job 1165.
1271 of 1394 steps (91%) done

[Sat Dec  2 18:43:32 2023]
Job 1145: training on tf=REST,tissue=Endometrium training data
Reason: Missing output files: output/models/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.linear.rds, output/models/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz --rds_file output/models/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1145 with external jobid 'Submitted batch job 11052713'.

[Sat Dec  2 18:43:35 2023]
Job 1351: evaluating on tf=FOXM1,tissue=Brain training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz, output/models/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.linear.rds --logistic_model output/models/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXM1_Brain_2023-12-01/aggByCollect_FOXM1_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1351 with external jobid 'Submitted batch job 11052714'.
[Sat Dec  2 18:44:06 2023]
Finished job 1351.
1272 of 1394 steps (91%) done
Select jobs to execute...
[Sat Dec  2 18:44:16 2023]
Finished job 1145.
1273 of 1394 steps (91%) done

[Sat Dec  2 18:44:16 2023]
Job 1059: training on tf=REST,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.logistic.rds, output/models/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1059 with external jobid 'Submitted batch job 11052731'.

[Sat Dec  2 18:44:17 2023]
Job 1331: evaluating on tf=REST,tissue=Endometrium training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.logistic.test_eval.txt.gz, output/models_eval/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz, output/models/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.linear.rds, output/models/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.linear.rds --logistic_model output/models/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Endometrium.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Endometrium_2023-12-01/aggByCollect_REST_Endometrium
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1331 with external jobid 'Submitted batch job 11052735'.
[Sat Dec  2 18:45:11 2023]
Finished job 1331.
1274 of 1394 steps (91%) done
Select jobs to execute...
[Sat Dec  2 18:45:31 2023]
Finished job 1059.
1275 of 1394 steps (91%) done

[Sat Dec  2 18:45:31 2023]
Job 1158: training on tf=REST,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.linear.rds, output/models/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Breast.prepared.csv.gz --rds_file output/models/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1158 with external jobid 'Submitted batch job 11052781'.

[Sat Dec  2 18:45:33 2023]
Job 1245: evaluating on tf=REST,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.linear.test_eval.txt.gz, output/models_eval/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz, output/models/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.logistic.rds, output/models/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Bone-Marrow_2023-12-01/aggByCollect_REST_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1245 with external jobid 'Submitted batch job 11052784'.
[Sat Dec  2 18:46:04 2023]
Finished job 1245.
1276 of 1394 steps (92%) done
Select jobs to execute...
[Sat Dec  2 18:46:24 2023]
Finished job 1158.
1277 of 1394 steps (92%) done

[Sat Dec  2 18:46:24 2023]
Job 1087: training on tf=YY1,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.logistic.rds, output/models/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz --rds_file output/models/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1087 with external jobid 'Submitted batch job 11052811'.

[Sat Dec  2 18:46:25 2023]
Job 1344: evaluating on tf=REST,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Breast.prepared.csv.gz, output/models/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_REST_Breast.prepared.csv.gz, output/models/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.linear.rds --logistic_model output/models/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Breast_2023-12-01/aggByCollect_REST_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1344 with external jobid 'Submitted batch job 11052814'.
[Sat Dec  2 18:48:14 2023]
Finished job 1344.
1278 of 1394 steps (92%) done
Select jobs to execute...
[Sat Dec  2 18:48:34 2023]
Finished job 1087.
1279 of 1394 steps (92%) done

[Sat Dec  2 18:48:34 2023]
Job 1151: training on tf=REST,tissue=Cervix training data
Reason: Missing output files: output/models/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.logistic.rds, output/models/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz --rds_file output/models/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1151 with external jobid 'Submitted batch job 11052896'.

[Sat Dec  2 18:48:36 2023]
Job 1273: evaluating on tf=YY1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz, output/models/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz, output/models/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.linear.rds --logistic_model output/models/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Colon_2023-12-01/aggByCollect_YY1_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1273 with external jobid 'Submitted batch job 11052900'.
[Sat Dec  2 18:49:18 2023]
Finished job 1273.
1280 of 1394 steps (92%) done
Select jobs to execute...
[Sat Dec  2 18:49:38 2023]
Finished job 1151.
1281 of 1394 steps (92%) done

[Sat Dec  2 18:49:38 2023]
Job 1161: training on tf=REST,tissue=Pancreas training data
Reason: Missing output files: output/models/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.logistic.rds, output/models/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz --rds_file output/models/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1161 with external jobid 'Submitted batch job 11052941'.

[Sat Dec  2 18:49:40 2023]
Job 1337: evaluating on tf=REST,tissue=Cervix training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.linear.test_eval.txt.gz, output/models_eval/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.logistic.test_eval.txt.gz, output/models_eval/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz, output/models/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.logistic.rds, output/models/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.linear.rds --logistic_model output/models/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Cervix_2023-12-01/aggByCollect_REST_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1337 with external jobid 'Submitted batch job 11052943'.
[Sat Dec  2 18:50:44 2023]
Finished job 1337.
1282 of 1394 steps (92%) done
Select jobs to execute...
[Sat Dec  2 18:50:54 2023]
Finished job 1161.
1283 of 1394 steps (92%) done

[Sat Dec  2 18:50:54 2023]
Job 1347: evaluating on tf=REST,tissue=Pancreas training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.logistic.test_eval.txt.gz, output/models_eval/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz, output/models/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.linear.rds, output/models/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.linear.rds --logistic_model output/models/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Pancreas.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Pancreas_2023-12-01/aggByCollect_REST_Pancreas
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1347 with external jobid 'Submitted batch job 11052995'.

[Sat Dec  2 18:50:56 2023]
Job 1078: training on tf=HSF1,tissue=Mammary-Gland training data
Reason: Missing output files: output/models/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.linear.rds, output/models/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1078 with external jobid 'Submitted batch job 11052997'.
[Sat Dec  2 18:51:26 2023]
Finished job 1347.
1284 of 1394 steps (92%) done
Select jobs to execute...
[Sat Dec  2 18:51:47 2023]
Finished job 1078.
1285 of 1394 steps (92%) done

[Sat Dec  2 18:51:47 2023]
Job 1187: training on tf=REST,tissue=Embryonic-Kidney training data
Reason: Missing output files: output/models/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.logistic.rds, output/models/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz --rds_file output/models/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1187 with external jobid 'Submitted batch job 11053029'.

[Sat Dec  2 18:51:49 2023]
Job 1264: evaluating on tf=HSF1,tissue=Mammary-Gland training and test data
Reason: Missing output files: output/models_eval/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.logistic.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.linear.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.linear.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz, output/models/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_HSF1_Mammary-Gland_2023-12-01/aggByCollect_HSF1_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1264 with external jobid 'Submitted batch job 11053033'.
[Sat Dec  2 18:52:31 2023]
Finished job 1264.
1286 of 1394 steps (92%) done
Select jobs to execute...
[Sat Dec  2 18:52:41 2023]
Finished job 1187.
1287 of 1394 steps (92%) done

[Sat Dec  2 18:52:41 2023]
Job 1373: evaluating on tf=REST,tissue=Embryonic-Kidney training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.linear.test_eval.txt.gz, output/models_eval/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.linear.rds --logistic_model output/models/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Embryonic-Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Embryonic-Kidney_2023-12-01/aggByCollect_REST_Embryonic-Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1373 with external jobid 'Submitted batch job 11053066'.

[Sat Dec  2 18:52:44 2023]
Job 1155: training on tf=REST,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.linear.rds, output/models/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Liver.prepared.csv.gz --rds_file output/models/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1155 with external jobid 'Submitted batch job 11053070'.
[Sat Dec  2 18:54:19 2023]
Finished job 1373.
1288 of 1394 steps (92%) done
Select jobs to execute...
[Sat Dec  2 18:54:40 2023]
Finished job 1155.
1289 of 1394 steps (92%) done

[Sat Dec  2 18:54:40 2023]
Job 1053: training on tf=PPARG,tissue=Blood training data
Reason: Missing output files: output/models/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.linear.rds, output/models/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz --rds_file output/models/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1053 with external jobid 'Submitted batch job 11053142'.

[Sat Dec  2 18:54:42 2023]
Job 1341: evaluating on tf=REST,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.logistic.test_eval.txt.gz, output/models_eval/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Liver.prepared.csv.gz, output/models/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.linear.rds, output/models/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_REST_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.linear.rds --logistic_model output/models/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Liver_2023-12-01/aggByCollect_REST_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1341 with external jobid 'Submitted batch job 11053147'.
[Sat Dec  2 18:55:24 2023]
Finished job 1341.
1290 of 1394 steps (93%) done
Select jobs to execute...
[Sat Dec  2 18:55:34 2023]
Finished job 1053.
1291 of 1394 steps (93%) done

[Sat Dec  2 18:55:34 2023]
Job 1108: training on tf=SOX2,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.linear.rds, output/models/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz --rds_file output/models/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1108 with external jobid 'Submitted batch job 11053179'.

[Sat Dec  2 18:55:35 2023]
Job 1239: evaluating on tf=PPARG,tissue=Blood training and test data
Reason: Missing output files: output/models_eval/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.linear.test_eval.txt.gz, output/models_eval/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.linear.train_eval.txt.gz, output/models_eval/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz, output/models/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.logistic.rds, output/models/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.linear.rds --logistic_model output/models/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_PPARG_Blood_2023-12-01/aggByCollect_PPARG_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1239 with external jobid 'Submitted batch job 11053184'.
[Sat Dec  2 18:56:51 2023]
Finished job 1239.
1292 of 1394 steps (93%) done
Select jobs to execute...
[Sat Dec  2 18:57:11 2023]
Finished job 1108.
1293 of 1394 steps (93%) done

[Sat Dec  2 18:57:11 2023]
Job 1070: training on tf=HSF1,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.linear.rds, output/models/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz --rds_file output/models/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1070 with external jobid 'Submitted batch job 11053223'.

[Sat Dec  2 18:57:12 2023]
Job 1294: evaluating on tf=SOX2,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz, output/models/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.linear.rds, output/models/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.linear.rds --logistic_model output/models/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_SOX2_Lung_2023-12-01/aggByCollect_SOX2_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1294 with external jobid 'Submitted batch job 11053229'.
[Sat Dec  2 18:59:23 2023]
Finished job 1294.
1294 of 1394 steps (93%) done
Select jobs to execute...
[Sat Dec  2 18:59:43 2023]
Finished job 1070.
1295 of 1394 steps (93%) done

[Sat Dec  2 18:59:43 2023]
Job 1073: training on tf=REST,tissue=Adrenal-Gland training data
Reason: Missing output files: output/models/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.logistic.rds, output/models/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz --rds_file output/models/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1073 with external jobid 'Submitted batch job 11053309'.

[Sat Dec  2 18:59:46 2023]
Job 1256: evaluating on tf=HSF1,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.logistic.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz, output/models/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.linear.rds, output/models/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.linear.rds --logistic_model output/models/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_HSF1_Breast_2023-12-01/aggByCollect_HSF1_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1256 with external jobid 'Submitted batch job 11053312'.
[Sat Dec  2 19:00:50 2023]
Finished job 1256.
1296 of 1394 steps (93%) done
Select jobs to execute...
[Sat Dec  2 19:01:10 2023]
Finished job 1073.
1297 of 1394 steps (93%) done

[Sat Dec  2 19:01:10 2023]
Job 1259: evaluating on tf=REST,tissue=Adrenal-Gland training and test data
Reason: Missing output files: output/models_eval/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.logistic.test_eval.txt.gz, output/models_eval/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.logistic.train_eval.txt.gz, output/models_eval/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.linear.train_eval.txt.gz, output/models_eval/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz, output/models/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.logistic.rds, output/models/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.linear.rds --logistic_model output/models/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_REST_Adrenal-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_REST_Adrenal-Gland_2023-12-01/aggByCollect_REST_Adrenal-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1259 with external jobid 'Submitted batch job 11053362'.

[Sat Dec  2 19:01:10 2023]
Job 1085: training on tf=SOX2,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.linear.rds, output/models/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz --rds_file output/models/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1085 with external jobid 'Submitted batch job 11053366'.
[Sat Dec  2 19:02:04 2023]
Finished job 1259.
1298 of 1394 steps (93%) done
Select jobs to execute...
[Sat Dec  2 19:02:25 2023]
Finished job 1085.
1299 of 1394 steps (93%) done

[Sat Dec  2 19:02:25 2023]
Job 1170: training on tf=RUNX1,tissue=Prostate training data
Reason: Missing output files: output/models/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.logistic.rds, output/models/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1170 with external jobid 'Submitted batch job 11053409'.

[Sat Dec  2 19:02:28 2023]
Job 1271: evaluating on tf=SOX2,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz, output/models/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.linear.rds --logistic_model output/models/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SOX2_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_SOX2_Colon_2023-12-01/aggByCollect_SOX2_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1271 with external jobid 'Submitted batch job 11053410'.
[Sat Dec  2 19:03:20 2023]
Finished job 1271.
1300 of 1394 steps (93%) done
Select jobs to execute...
[Sat Dec  2 19:03:30 2023]
Finished job 1170.
1301 of 1394 steps (93%) done

[Sat Dec  2 19:03:30 2023]
Job 1356: evaluating on tf=RUNX1,tissue=Prostate training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.logistic.rds, output/models/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.linear.rds --logistic_model output/models/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Prostate_2023-12-01/aggByCollect_RUNX1_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1356 with external jobid 'Submitted batch job 11053440'.

[Sat Dec  2 19:03:34 2023]
Job 1077: training on tf=HSF1,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.logistic.rds, output/models/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz --rds_file output/models/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1077 with external jobid 'Submitted batch job 11053443'.
[Sat Dec  2 19:05:19 2023]
Finished job 1356.
1302 of 1394 steps (93%) done
Select jobs to execute...
[Sat Dec  2 19:05:30 2023]
Finished job 1077.
1303 of 1394 steps (93%) done

[Sat Dec  2 19:05:30 2023]
Job 1263: evaluating on tf=HSF1,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz, output/models/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.linear.rds --logistic_model output/models/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_HSF1_Lung_2023-12-01/aggByCollect_HSF1_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1263 with external jobid 'Submitted batch job 11053507'.

[Sat Dec  2 19:05:30 2023]
Job 1061: training on tf=YY1,tissue=Cervix training data
Reason: Missing output files: output/models/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.logistic.rds, output/models/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz --rds_file output/models/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1061 with external jobid 'Submitted batch job 11053510'.
[Sat Dec  2 19:08:47 2023]
Finished job 1263.
1304 of 1394 steps (94%) done
Select jobs to execute...
[Sat Dec  2 19:09:08 2023]
Finished job 1061.
1305 of 1394 steps (94%) done

[Sat Dec  2 19:09:08 2023]
Job 1196: training on tf=RUNX1,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.logistic.rds, output/models/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1196 with external jobid 'Submitted batch job 11053633'.

[Sat Dec  2 19:09:10 2023]
Job 1247: evaluating on tf=YY1,tissue=Cervix training and test data
Reason: Missing output files: output/models_eval/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.linear.train_eval.txt.gz, output/models_eval/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.linear.test_eval.txt.gz, output/models_eval/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.logistic.test_eval.txt.gz, output/models_eval/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz, output/models/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.logistic.rds, output/models/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.linear.rds --logistic_model output/models/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_YY1_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_YY1_Cervix_2023-12-01/aggByCollect_YY1_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1247 with external jobid 'Submitted batch job 11053638'.
[Sat Dec  2 19:09:41 2023]
Finished job 1247.
1306 of 1394 steps (94%) done
Select jobs to execute...
[Sat Dec  2 19:10:01 2023]
Finished job 1196.
1307 of 1394 steps (94%) done

[Sat Dec  2 19:10:01 2023]
Job 1382: evaluating on tf=RUNX1,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz, output/models/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.logistic.rds, output/models/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.linear.rds --logistic_model output/models/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Breast_2023-12-01/aggByCollect_RUNX1_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1382 with external jobid 'Submitted batch job 11053667'.

[Sat Dec  2 19:10:02 2023]
Job 1169: training on tf=ETS1,tissue=Pancreas training data
Reason: Missing output files: output/models/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.logistic.rds, output/models/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz --rds_file output/models/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1169 with external jobid 'Submitted batch job 11053670'.
[Sat Dec  2 19:10:33 2023]
Finished job 1382.
1308 of 1394 steps (94%) done
Select jobs to execute...
[Sat Dec  2 19:10:54 2023]
Finished job 1169.
1309 of 1394 steps (94%) done

[Sat Dec  2 19:10:54 2023]
Job 1198: training on tf=STAT3,tissue=Umbilical-Cord training data
Reason: Missing output files: output/models/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.logistic.rds, output/models/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1198 with external jobid 'Submitted batch job 11053698'.

[Sat Dec  2 19:10:58 2023]
Job 1355: evaluating on tf=ETS1,tissue=Pancreas training and test data
Reason: Missing output files: output/models_eval/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.linear.test_eval.txt.gz, output/models_eval/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.logistic.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.linear.train_eval.txt.gz, output/models_eval/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz, output/models/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz, output/models/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.linear.rds --logistic_model output/models/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ETS1_Pancreas.prepared.csv.gz --eval_output output/models_eval/cistrome_ETS1_Pancreas_2023-12-01/aggByCollect_ETS1_Pancreas
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1355 with external jobid 'Submitted batch job 11053707'.
[Sat Dec  2 19:12:11 2023]
Finished job 1355.
1310 of 1394 steps (94%) done
Select jobs to execute...
[Sat Dec  2 19:12:31 2023]
Finished job 1198.
1311 of 1394 steps (94%) done

[Sat Dec  2 19:12:31 2023]
Job 1186: training on tf=SP1,tissue=Breast training data
Reason: Missing output files: output/models/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.logistic.rds, output/models/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz --rds_file output/models/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1186 with external jobid 'Submitted batch job 11053801'.

[Sat Dec  2 19:12:32 2023]
Job 1384: evaluating on tf=STAT3,tissue=Umbilical-Cord training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz, output/models/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz, output/models/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.linear.rds --logistic_model output/models/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Umbilical-Cord.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Umbilical-Cord_2023-12-01/aggByCollect_STAT3_Umbilical-Cord
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1384 with external jobid 'Submitted batch job 11053803'.
[Sat Dec  2 19:13:26 2023]
Finished job 1384.
1312 of 1394 steps (94%) done
Select jobs to execute...
[Sat Dec  2 19:13:46 2023]
Finished job 1186.
1313 of 1394 steps (94%) done

[Sat Dec  2 19:13:46 2023]
Job 1372: evaluating on tf=SP1,tissue=Breast training and test data
Reason: Missing output files: output/models_eval/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.linear.test_eval.txt.gz, output/models_eval/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.linear.train_eval.txt.gz, output/models_eval/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.logistic.test_eval.txt.gz, output/models_eval/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.logistic.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz, output/models/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.linear.rds --logistic_model output/models/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SP1_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_SP1_Breast_2023-12-01/aggByCollect_SP1_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1372 with external jobid 'Submitted batch job 11053904'.

[Sat Dec  2 19:13:49 2023]
Job 1084: training on tf=HSF1,tissue=Bone-Marrow training data
Reason: Missing output files: output/models/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.logistic.rds, output/models/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1084 with external jobid 'Submitted batch job 11053909'.
[Sat Dec  2 19:16:09 2023]
Finished job 1372.
1314 of 1394 steps (94%) done
Select jobs to execute...
[Sat Dec  2 19:16:30 2023]
Finished job 1084.
1315 of 1394 steps (94%) done

[Sat Dec  2 19:16:30 2023]
Job 1122: training on tf=HSF1,tissue=Liver training data
Reason: Missing output files: output/models/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.linear.rds, output/models/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz --rds_file output/models/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1122 with external jobid 'Submitted batch job 11054049'.

[Sat Dec  2 19:16:33 2023]
Job 1270: evaluating on tf=HSF1,tissue=Bone-Marrow training and test data
Reason: Missing output files: output/models_eval/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.linear.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.logistic.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.logistic.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz, output/models/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.linear.rds, output/models/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_HSF1_Bone-Marrow_2023-12-01/aggByCollect_HSF1_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1270 with external jobid 'Submitted batch job 11054054'.
[Sat Dec  2 19:17:47 2023]
Finished job 1270.
1316 of 1394 steps (94%) done
Select jobs to execute...
[Sat Dec  2 19:18:07 2023]
Finished job 1122.
1317 of 1394 steps (94%) done

[Sat Dec  2 19:18:07 2023]
Job 1069: training on tf=HSF1,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.logistic.rds, output/models/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz --rds_file output/models/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1069 with external jobid 'Submitted batch job 11054120'.

[Sat Dec  2 19:18:10 2023]
Job 1308: evaluating on tf=HSF1,tissue=Liver training and test data
Reason: Missing output files: output/models_eval/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.linear.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.logistic.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.logistic.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz, output/models/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz, output/models/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.linear.rds --logistic_model output/models/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_HSF1_Liver_2023-12-01/aggByCollect_HSF1_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1308 with external jobid 'Submitted batch job 11054123'.
[Sat Dec  2 19:19:13 2023]
Finished job 1308.
1318 of 1394 steps (95%) done
Select jobs to execute...
[Sat Dec  2 19:19:23 2023]
Finished job 1069.
1319 of 1394 steps (95%) done

[Sat Dec  2 19:19:23 2023]
Job 1255: evaluating on tf=HSF1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz, output/models/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.linear.rds --logistic_model output/models/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_HSF1_Colon_2023-12-01/aggByCollect_HSF1_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1255 with external jobid 'Submitted batch job 11054176'.

[Sat Dec  2 19:19:23 2023]
Job 1089: training on tf=GATA4,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.logistic.rds, output/models/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz --rds_file output/models/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1089 with external jobid 'Submitted batch job 11054177'.
[Sat Dec  2 19:19:55 2023]
Finished job 1255.
1320 of 1394 steps (95%) done
Select jobs to execute...
[Sat Dec  2 19:20:16 2023]
Finished job 1089.
1321 of 1394 steps (95%) done

[Sat Dec  2 19:20:16 2023]
Job 1045: training on tf=GATA2,tissue=Cord-blood training data
Reason: Missing output files: output/models/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.logistic.rds, output/models/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz --rds_file output/models/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1045 with external jobid 'Submitted batch job 11054204'.

[Sat Dec  2 19:20:19 2023]
Job 1275: evaluating on tf=GATA4,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz, output/models/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.logistic.rds, output/models/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.linear.rds --logistic_model output/models/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA4_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA4_Colon_2023-12-01/aggByCollect_GATA4_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1275 with external jobid 'Submitted batch job 11054209'.
[Sat Dec  2 19:21:33 2023]
Finished job 1275.
1322 of 1394 steps (95%) done
Select jobs to execute...
[Sat Dec  2 19:21:53 2023]
Finished job 1045.
1323 of 1394 steps (95%) done

[Sat Dec  2 19:21:53 2023]
Job 1231: evaluating on tf=GATA2,tissue=Cord-blood training and test data
Reason: Missing output files: output/models_eval/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.logistic.train_eval.txt.gz, output/models_eval/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.logistic.test_eval.txt.gz, output/models_eval/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.linear.train_eval.txt.gz, output/models_eval/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz, output/models/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.linear.rds, output/models/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.linear.rds --logistic_model output/models/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GATA2_Cord-blood.prepared.csv.gz --eval_output output/models_eval/cistrome_GATA2_Cord-blood_2023-12-01/aggByCollect_GATA2_Cord-blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1231 with external jobid 'Submitted batch job 11054287'.

[Sat Dec  2 19:21:56 2023]
Job 1106: training on tf=FOXM1,tissue=Cervix training data
Reason: Missing output files: output/models/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.logistic.rds, output/models/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz --rds_file output/models/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1106 with external jobid 'Submitted batch job 11054290'.
[Sat Dec  2 19:23:09 2023]
Finished job 1231.
1324 of 1394 steps (95%) done
Select jobs to execute...
[Sat Dec  2 19:23:30 2023]
Finished job 1106.
1325 of 1394 steps (95%) done

[Sat Dec  2 19:23:30 2023]
Job 1086: training on tf=FOXA1,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.logistic.rds, output/models/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz --rds_file output/models/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1086 with external jobid 'Submitted batch job 11054359'.

[Sat Dec  2 19:23:31 2023]
Job 1292: evaluating on tf=FOXM1,tissue=Cervix training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.linear.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.logistic.rds, output/models/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.linear.rds --logistic_model output/models/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXM1_Cervix_2023-12-01/aggByCollect_FOXM1_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1292 with external jobid 'Submitted batch job 11054362'.
[Sat Dec  2 19:25:53 2023]
Finished job 1292.
1326 of 1394 steps (95%) done
Select jobs to execute...
[Sat Dec  2 19:26:03 2023]
Finished job 1086.
1327 of 1394 steps (95%) done

[Sat Dec  2 19:26:03 2023]
Job 1272: evaluating on tf=FOXA1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz, output/models/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.linear.rds --logistic_model output/models/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA1_Colon_2023-12-01/aggByCollect_FOXA1_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1272 with external jobid 'Submitted batch job 11054480'.

[Sat Dec  2 19:26:06 2023]
Job 1168: training on tf=PPARG,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.logistic.rds, output/models/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz --rds_file output/models/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1168 with external jobid 'Submitted batch job 11054482'.
[Sat Dec  2 19:27:08 2023]
Finished job 1272.
1328 of 1394 steps (95%) done
Select jobs to execute...
[Sat Dec  2 19:35:20 2023]
Finished job 1168.
1329 of 1394 steps (95%) done

[Sat Dec  2 19:35:20 2023]
Job 1206: training on tf=STAT1,tissue=Lung training data
Reason: Missing output files: output/models/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.linear.rds, output/models/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz --rds_file output/models/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1206 with external jobid 'Submitted batch job 11054840'.

[Sat Dec  2 19:35:20 2023]
Job 1354: evaluating on tf=PPARG,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.linear.train_eval.txt.gz, output/models_eval/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz, output/models/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.linear.rds --logistic_model output/models/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_PPARG_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_PPARG_Lung_2023-12-01/aggByCollect_PPARG_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1354 with external jobid 'Submitted batch job 11054843'.
[Sat Dec  2 19:36:26 2023]
Finished job 1354.
1330 of 1394 steps (95%) done
Select jobs to execute...
[Sat Dec  2 19:36:46 2023]
Finished job 1206.
1331 of 1394 steps (95%) done

[Sat Dec  2 19:36:46 2023]
Job 1062: training on tf=FOXM1,tissue=Bone training data
Reason: Missing output files: output/models/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.logistic.rds, output/models/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz --rds_file output/models/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1062 with external jobid 'Submitted batch job 11054897'.

[Sat Dec  2 19:36:46 2023]
Job 1392: evaluating on tf=STAT1,tissue=Lung training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.linear.train_eval.txt.gz; Input files updated by another job: output/models/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.linear.rds, output/models/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.linear.rds --logistic_model output/models/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT1_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT1_Lung_2023-12-01/aggByCollect_STAT1_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1392 with external jobid 'Submitted batch job 11054901'.
[Sat Dec  2 19:37:52 2023]
Finished job 1392.
1332 of 1394 steps (96%) done
Select jobs to execute...
[Sat Dec  2 19:38:12 2023]
Finished job 1062.
1333 of 1394 steps (96%) done

[Sat Dec  2 19:38:12 2023]
Job 1248: evaluating on tf=FOXM1,tissue=Bone training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.linear.train_eval.txt.gz, output/models_eval/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.logistic.rds, output/models/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.linear.rds --logistic_model output/models/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXM1_Bone.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXM1_Bone_2023-12-01/aggByCollect_FOXM1_Bone
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1248 with external jobid 'Submitted batch job 11054957'.

[Sat Dec  2 19:38:15 2023]
Job 1174: training on tf=STAT3,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.linear.rds, output/models/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1174 with external jobid 'Submitted batch job 11054961'.
[Sat Dec  2 19:39:28 2023]
Finished job 1248.
1334 of 1394 steps (96%) done
Select jobs to execute...
[Sat Dec  2 19:39:39 2023]
Finished job 1174.
1335 of 1394 steps (96%) done

[Sat Dec  2 19:39:39 2023]
Job 1360: evaluating on tf=STAT3,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.logistic.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz, output/models/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.logistic.rds, output/models/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.linear.rds --logistic_model output/models/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Embryo_2023-12-01/aggByCollect_STAT3_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1360 with external jobid 'Submitted batch job 11055027'.

[Sat Dec  2 19:39:40 2023]
Job 1046: training on tf=HSF1,tissue=Adipose training data
Reason: Missing output files: output/models/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.logistic.rds, output/models/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz --rds_file output/models/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1046 with external jobid 'Submitted batch job 11055032'.
[Sat Dec  2 19:41:50 2023]
Finished job 1360.
1336 of 1394 steps (96%) done
Select jobs to execute...
[Sat Dec  2 19:42:11 2023]
Finished job 1046.
1337 of 1394 steps (96%) done

[Sat Dec  2 19:42:11 2023]
Job 1201: training on tf=FOXA2,tissue=Endoderm training data
Reason: Missing output files: output/models/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.linear.rds, output/models/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz --rds_file output/models/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1201 with external jobid 'Submitted batch job 11055149'.

[Sat Dec  2 19:42:14 2023]
Job 1232: evaluating on tf=HSF1,tissue=Adipose training and test data
Reason: Missing output files: output/models_eval/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.logistic.train_eval.txt.gz, output/models_eval/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.logistic.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.linear.test_eval.txt.gz, output/models_eval/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz, output/models/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.logistic.rds, output/models/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.linear.rds --logistic_model output/models/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HSF1_Adipose.prepared.csv.gz --eval_output output/models_eval/cistrome_HSF1_Adipose_2023-12-01/aggByCollect_HSF1_Adipose
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1232 with external jobid 'Submitted batch job 11055153'.
[Sat Dec  2 19:44:45 2023]
Finished job 1232.
1338 of 1394 steps (96%) done
Select jobs to execute...
[Sat Dec  2 19:44:55 2023]
Finished job 1201.
1339 of 1394 steps (96%) done

[Sat Dec  2 19:44:55 2023]
Job 1094: training on tf=STAT3,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --rds_file output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1094 with external jobid 'Submitted batch job 11055287'.

[Sat Dec  2 19:44:56 2023]
Job 1387: evaluating on tf=FOXA2,tissue=Endoderm training and test data
Reason: Missing output files: output/models_eval/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.logistic.train_eval.txt.gz, output/models_eval/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.linear.test_eval.txt.gz, output/models_eval/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.logistic.test_eval.txt.gz, output/models_eval/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.linear.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz, output/models/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.logistic.rds, output/models/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.linear.rds --logistic_model output/models/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXA2_Endoderm.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXA2_Endoderm_2023-12-01/aggByCollect_FOXA2_Endoderm
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1387 with external jobid 'Submitted batch job 11055292'.
[Sat Dec  2 19:47:51 2023]
Finished job 1387.
1340 of 1394 steps (96%) done
Select jobs to execute...
[Sat Dec  2 19:48:11 2023]
Finished job 1094.
1341 of 1394 steps (96%) done

[Sat Dec  2 19:48:11 2023]
Job 1104: training on tf=RUNX1,tissue=Colon training data
Reason: Missing output files: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --rds_file output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1104 with external jobid 'Submitted batch job 11055445'.

[Sat Dec  2 19:48:12 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11055448'.
[Sat Dec  2 19:50:23 2023]
Finished job 1104.
1342 of 1394 steps (96%) done
Select jobs to execute...

[Sat Dec  2 19:50:23 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11055508'.
[Sat Dec  2 19:51:08 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055448

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11055448, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 19:51:08 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11055527'.
[Sat Dec  2 19:53:08 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055508

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11055508, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 19:53:08 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11055589'.
[Sat Dec  2 19:53:09 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055527

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11055527, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 19:53:09 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11055590'.
[Sat Dec  2 19:54:58 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055589

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11055589, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 19:54:58 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
[Sat Dec  2 19:54:59 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055590

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11055590, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11055648'.
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 19:55:00 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11055653'.
[Sat Dec  2 20:01:02 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055653

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11055653, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 20:01:02 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11055933'.
[Sat Dec  2 20:01:12 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055648

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11055648, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 20:01:12 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11055939'.
[Sat Dec  2 20:05:03 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055939

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11055939, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 20:05:03 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11056055'.
[Sat Dec  2 20:05:04 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11055933

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11055933, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 20:05:04 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11056056'.
[Sat Dec  2 20:07:04 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056055

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11056055, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 20:07:04 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
[Sat Dec  2 20:07:05 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056056

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11056056, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11056107'.
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 20:07:06 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11056108'.
[Sat Dec  2 20:08:43 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056107

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11056107, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 20:08:44 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
[Sat Dec  2 20:08:44 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056108

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11056108, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11056194'.
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 20:08:45 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11056197'.
[Sat Dec  2 20:10:45 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056194

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11056194, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 20:10:45 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
[Sat Dec  2 20:10:46 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056197

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11056197, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11056293'.
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 20:10:47 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11056295'.
[Sat Dec  2 20:12:35 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056293

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11056293, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 20:12:35 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
[Sat Dec  2 20:12:36 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056295

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11056295, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11056359'.
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 20:12:38 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11056363'.
[Sat Dec  2 20:14:03 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056359

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11056359, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 20:14:03 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
[Sat Dec  2 20:14:04 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056363

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11056363, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11056417'.
Trying to restart job 1280.
Select jobs to execute...

[Sat Dec  2 20:14:06 2023]
Job 1280: evaluating on tf=STAT3,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz; Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1280 with external jobid 'Submitted batch job 11056421'.
[Sat Dec  2 20:16:37 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056417

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11056417, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 1290.
Select jobs to execute...

[Sat Dec  2 20:16:37 2023]
Job 1290: evaluating on tf=RUNX1,tissue=Colon training and test data
Reason: Missing output files: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz; Input files updated by another job: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
[Sat Dec  2 20:16:38 2023]
Error in rule evaluate_TFPred:
    jobid: 1280
    input: output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds, output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.linear.rds --logistic_model output/models/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT3_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT3_Colon_2023-12-01/aggByCollect_STAT3_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056421

Error executing rule evaluate_TFPred on cluster (jobid: 1280, external: Submitted batch job 11056421, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1280.sh). For error details see the cluster log and the log files of the involved rule(s).
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1290 with external jobid 'Submitted batch job 11056457'.
[Sat Dec  2 20:18:08 2023]
Error in rule evaluate_TFPred:
    jobid: 1290
    input: output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds, output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz
    output: output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.test_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.train_eval.txt.gz, output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.linear.rds --logistic_model output/models/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_RUNX1_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_RUNX1_Colon_2023-12-01/aggByCollect_RUNX1_Colon
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 11056457

Error executing rule evaluate_TFPred on cluster (jobid: 1290, external: Submitted batch job 11056457, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.pf7xmyjo/snakejob.evaluate_TFPred.1290.sh). For error details see the cluster log and the log files of the involved rule(s).
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2023-12-01T234726.288971.snakemake.log
186 valid TF-tissue pairs were found.
