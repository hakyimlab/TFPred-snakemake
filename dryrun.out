INFO - Verified 1 assays
INFO - Running ENFORMER is set to True. Running the pipeline with ENFORMER...
Building DAG of jobs...
Job stats:
job                              count    min threads    max threads
-----------------------------  -------  -------------  -------------
aggregate_predictions                1              1              1
all                                  1              1              1
create_enformer_configuration        1              1              1
predict_with_enformer                1              1              1
total                                4              1              1


[Wed Jul 24 13:19:54 2024]
Job 7: working on tf=AR,tissue=Prostate
Reason: Missing output files: data/NKI_13_2024-07-23/prediction_parameters/enformer_config_NKI_13_2024-07-23.AR_Prostate.json; Code has changed since last execution; Params have changed since last execution
DAG of jobs will be updated after completion.


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset NKI_13 --transcription_factor AR --tissue Prostate --base_directives experiments/bpnet/enformer.base.yaml --project_directory /scratch/midway3/temi --predictors_file data/NKI_13_2024-07-23/predictor_files/AR_Prostate.predictors.txt --model /project/haky/data/enformer/raw --fasta_file /project/haky/users/temi/projects/bpnet-AR/data/NKI_13.fa --parameters_file data/NKI_13_2024-07-23/prediction_parameters/enformer_config_NKI_13_2024-07-23.AR_Prostate.json --date 2024-07-23 --personalized_directives /beagle3/haky/users/temi/projects/TFPred-snakemake/config/personalized_base.yaml; sleep 5
        

[Wed Jul 24 13:19:54 2024]
Job 6: working on AR_Prostate
Reason: Missing output files: data/NKI_13_2024-07-23/prediction_parameters/aggregation_config_NKI_13_AR_Prostate.json; Input files updated by another job: data/NKI_13_2024-07-23/prediction_parameters/enformer_config_NKI_13_2024-07-23.AR_Prostate.json
DAG of jobs will be updated after completion.


            sbatch workflow/src/run_enformer.sbatch /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py data/NKI_13_2024-07-23/prediction_parameters/enformer_config_NKI_13_2024-07-23.AR_Prostate.json
        

[Wed Jul 24 13:19:54 2024]
Job 5: working on tf=AR,tissue=Prostate
Reason: Missing output files: data/NKI_13_2024-07-23/aggregation_folder/NKI_13_aggByCollect_AR_Prostate.csv.gz; Input files updated by another job: data/NKI_13_2024-07-23/prediction_parameters/aggregation_config_NKI_13_AR_Prostate.json

[Wed Jul 24 13:19:54 2024]
localrule all:
    input: data/homer_instances/scannedMotifs/scanMotifsGenomeWide.are.motif.txt, data/homer_instances/scannedMotifs/scanMotifsGenomeWide.ar-half.motif.txt, data/homer_instances/AR/merged_motif_file.txt, data/NKI_13_2024-07-23/predictor_files/AR_Prostate.predictors.txt, data/NKI_13_2024-07-23/predictor_files/AR_Prostate.ground_truth.txt, data/NKI_13_2024-07-23/aggregation_folder/NKI_13_aggByCollect_AR_Prostate.csv.gz
    jobid: 0
    reason: Input files updated by another job: data/NKI_13_2024-07-23/aggregation_folder/NKI_13_aggByCollect_AR_Prostate.csv.gz
    resources: mem_mb=<TBD>, disk_mb=<TBD>, tmpdir=/scratch/midway3/temi, partition=caslake, time=02:00:00, account=pi-haky, nodes=1, gpu=0, mem_cpu=4, cpu_task=8

Job stats:
job                              count    min threads    max threads
-----------------------------  -------  -------------  -------------
aggregate_predictions                1              1              1
all                                  1              1              1
create_enformer_configuration        1              1              1
predict_with_enformer                1              1              1
total                                4              1              1

Reasons:
    (check individual jobs above for details)
    code has changed since last execution:
        create_enformer_configuration
    input files updated by another job:
        aggregate_predictions, all, predict_with_enformer
    missing output files:
        aggregate_predictions, create_enformer_configuration, predict_with_enformer
    params have changed since last execution:
        create_enformer_configuration
Some jobs were triggered by provenance information, see 'reason' section in the rule displays above.
If you prefer that only modification time is used to determine whether a job shall be executed, use the command line option '--rerun-triggers mtime' (also see --help).
If you are sure that a change for a certain output file (say, <outfile>) won't change the result (e.g. because you just changed the formatting of a script or environment definition), you can also wipe its metadata to skip such a trigger via 'snakemake --cleanup-metadata <outfile>'. 
Rules with provenance triggered jobs: create_enformer_configuration


This was a dry-run (flag -n). The order of jobs does not reflect the order of execution.
The run involves checkpoint jobs, which will result in alteration of the DAG of jobs (e.g. adding more jobs) after their completion.
