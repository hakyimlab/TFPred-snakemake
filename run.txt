Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 100
Provided resources: load=50
Job stats:
job                              count    min threads    max threads
-----------------------------  -------  -------------  -------------
aggregate_predictions               84              1              1
all                                  1              1              1
create_enformer_configuration       84              1              1
create_training_set                 84              8              8
evaluate_TFPred                     84              1              1
find_homer_motifs                   23              1              1
merge_homer_motifs                  20              1              1
predict_with_enformer               84              1              1
prepare_training_data               84              1              1
train_TFPred_weights                84              1              1
total                              632              1              8

Select jobs to execute...

[Tue Nov 28 12:56:52 2023]
Job 14: working on motif_file=stat6.2,tf=STAT6
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT6/stat6.2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT6/scanMotifsGenomeWide_stat6.2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 14 with external jobid 'Submitted batch job 10862527'.

[Tue Nov 28 12:56:52 2023]
Job 3: working on motif_file=hif1a,tf=HIF1A
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/HIF1A/hif1a.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/HIF1A/scanMotifsGenomeWide_hif1a.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 3 with external jobid 'Submitted batch job 10862528'.

[Tue Nov 28 12:56:52 2023]
Job 22: working on motif_file=jun-ap1,tf=JUN
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/JUN/jun-ap1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/JUN/scanMotifsGenomeWide_jun-ap1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 22 with external jobid 'Submitted batch job 10862530'.

[Tue Nov 28 12:56:52 2023]
Job 8: working on motif_file=foxo1,tf=FOXO1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FOXO1/foxo1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FOXO1/scanMotifsGenomeWide_foxo1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 8 with external jobid 'Submitted batch job 10862531'.

[Tue Nov 28 12:56:52 2023]
Job 15: working on motif_file=otx2,tf=OTX2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/OTX2/otx2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/OTX2/scanMotifsGenomeWide_otx2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 15 with external jobid 'Submitted batch job 10862532'.

[Tue Nov 28 12:56:52 2023]
Job 1: working on motif_file=erg,tf=ERG
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ERG/erg.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ERG/scanMotifsGenomeWide_erg.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 1 with external jobid 'Submitted batch job 10862533'.

[Tue Nov 28 12:56:52 2023]
Job 9: working on motif_file=neurog2,tf=NEUROG2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/NEUROG2/neurog2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/NEUROG2/scanMotifsGenomeWide_neurog2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 9 with external jobid 'Submitted batch job 10862534'.

[Tue Nov 28 12:56:52 2023]
Job 23: working on motif_file=vdr,tf=VDR
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/VDR/vdr.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/VDR/scanMotifsGenomeWide_vdr.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 23 with external jobid 'Submitted batch job 10862535'.

[Tue Nov 28 12:56:53 2023]
Job 2: working on motif_file=ews-erg,tf=ERG
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ERG/ews-erg.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ERG/scanMotifsGenomeWide_ews-erg.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 2 with external jobid 'Submitted batch job 10862536'.

[Tue Nov 28 12:56:53 2023]
Job 16: working on motif_file=p53-myc,tf=MYC
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/MYC/p53-myc.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/MYC/scanMotifsGenomeWide_p53-myc.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 16 with external jobid 'Submitted batch job 10862537'.

[Tue Nov 28 12:56:53 2023]
Job 10: working on motif_file=stat4,tf=STAT4
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT4/stat4.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT4/scanMotifsGenomeWide_stat4.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 10 with external jobid 'Submitted batch job 10862538'.

[Tue Nov 28 12:56:53 2023]
Job 17: working on motif_file=hoxb13,tf=HOXB13
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/HOXB13/hoxb13.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/HOXB13/scanMotifsGenomeWide_hoxb13.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 17 with external jobid 'Submitted batch job 10862539'.

[Tue Nov 28 12:56:53 2023]
Job 21: working on motif_file=jun-cre,tf=JUN
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/JUN/jun-cre.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/JUN/scanMotifsGenomeWide_jun-cre.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 21 with external jobid 'Submitted batch job 10862540'.

[Tue Nov 28 12:56:53 2023]
Job 11: working on motif_file=tcf4,tf=TCF4
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/TCF4/tcf4.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/TCF4/scanMotifsGenomeWide_tcf4.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 11 with external jobid 'Submitted batch job 10862542'.

[Tue Nov 28 12:56:53 2023]
Job 18: working on motif_file=ascl1,tf=ASCL1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ASCL1/ascl1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ASCL1/scanMotifsGenomeWide_ascl1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 18 with external jobid 'Submitted batch job 10862543'.

[Tue Nov 28 12:56:53 2023]
Job 12: working on motif_file=grhl2,tf=GRHL2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/GRHL2/grhl2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/GRHL2/scanMotifsGenomeWide_grhl2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 12 with external jobid 'Submitted batch job 10862544'.

[Tue Nov 28 12:56:53 2023]
Job 5: working on motif_file=ews-fli1,tf=FLI1
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/FLI1/ews-fli1.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/FLI1/scanMotifsGenomeWide_ews-fli1.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 5 with external jobid 'Submitted batch job 10862545'.

[Tue Nov 28 12:56:53 2023]
Job 19: working on motif_file=pr,tf=PR
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/PR/pr.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/PR/scanMotifsGenomeWide_pr.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 19 with external jobid 'Submitted batch job 10862546'.

[Tue Nov 28 12:56:53 2023]
Job 4: working on motif_file=snai2,tf=SNAI2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/SNAI2/snai2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/SNAI2/scanMotifsGenomeWide_snai2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 4 with external jobid 'Submitted batch job 10862547'.

[Tue Nov 28 12:56:54 2023]
Job 13: working on motif_file=stat6,tf=STAT6
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/STAT6/stat6.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/STAT6/scanMotifsGenomeWide_stat6.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 13 with external jobid 'Submitted batch job 10862548'.

[Tue Nov 28 12:56:54 2023]
Job 20: working on motif_file=cdx2,tf=CDX2
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/CDX2/cdx2.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/CDX2/scanMotifsGenomeWide_cdx2.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 20 with external jobid 'Submitted batch job 10862549'.

[Tue Nov 28 12:56:54 2023]
Job 6: working on motif_file=ar-half,tf=AR
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/AR/ar-half.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/AR/scanMotifsGenomeWide_ar-half.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 6 with external jobid 'Submitted batch job 10862550'.

[Tue Nov 28 12:56:54 2023]
Job 7: working on motif_file=znf382,tf=ZNF382
Reason: Forced execution


        perl /project2/haky/temi/software/homer/bin/scanMotifGenomeWide.pl data/homer_files/ZNF382/znf382.motif /project2/haky/temi/software/homer/data/genomes/hg38 > data/homer_files/ZNF382/scanMotifsGenomeWide_znf382.txt
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 7 with external jobid 'Submitted batch job 10862551'.
[Tue Nov 28 13:08:15 2023]
Finished job 3.
1 of 632 steps (0.2%) done
Select jobs to execute...

[Tue Nov 28 13:08:15 2023]
Job 36: working on tf=HIF1A data/homer_files/HIF1A/scanMotifsGenomeWide_hif1a.txt
Reason: Missing output files: data/homer_files/HIF1A/merged_motif_file.txt; Input files updated by another job: data/homer_files/HIF1A/scanMotifsGenomeWide_hif1a.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 36 with external jobid 'Submitted batch job 10863726'.
[Tue Nov 28 13:08:46 2023]
Finished job 36.
2 of 632 steps (0.3%) done
Select jobs to execute...

[Tue Nov 28 13:08:46 2023]
Job 98: working on tf=HIF1A,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/HIF1A/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HIF1A --tissue Mammary-Gland --predicted_motif_file data/homer_files/HIF1A/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HIF1A_Mammary-Gland --predictors_file data/predictor_files/HIF1A_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/HIF1A_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/HIF1A_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 98 with external jobid 'Submitted batch job 10863795'.

[Tue Nov 28 13:08:47 2023]
Job 62: working on tf=HIF1A,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/HIF1A/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HIF1A --tissue Umbilical-Vein --predicted_motif_file data/homer_files/HIF1A/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HIF1A_Umbilical-Vein --predictors_file data/predictor_files/HIF1A_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/HIF1A_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/HIF1A_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 62 with external jobid 'Submitted batch job 10863796'.

[Tue Nov 28 13:08:47 2023]
Job 90: working on tf=HIF1A,tissue=Kidney
Reason: Input files updated by another job: data/homer_files/HIF1A/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HIF1A --tissue Kidney --predicted_motif_file data/homer_files/HIF1A/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HIF1A_Kidney --predictors_file data/predictor_files/HIF1A_Kidney.predictors.txt --ground_truth_file data/predictor_files/HIF1A_Kidney.ground_truth.txt --info_file data/predictor_files/HIF1A_Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 90 with external jobid 'Submitted batch job 10863799'.

[Tue Nov 28 13:08:47 2023]
Job 124: working on tf=HIF1A,tissue=Bone
Reason: Input files updated by another job: data/homer_files/HIF1A/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HIF1A --tissue Bone --predicted_motif_file data/homer_files/HIF1A/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HIF1A_Bone --predictors_file data/predictor_files/HIF1A_Bone.predictors.txt --ground_truth_file data/predictor_files/HIF1A_Bone.ground_truth.txt --info_file data/predictor_files/HIF1A_Bone.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 124 with external jobid 'Submitted batch job 10863801'.

[Tue Nov 28 13:08:47 2023]
Job 113: working on tf=HIF1A,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/HIF1A/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HIF1A --tissue Cervix --predicted_motif_file data/homer_files/HIF1A/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HIF1A_Cervix --predictors_file data/predictor_files/HIF1A_Cervix.predictors.txt --ground_truth_file data/predictor_files/HIF1A_Cervix.ground_truth.txt --info_file data/predictor_files/HIF1A_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 113 with external jobid 'Submitted batch job 10863804'.

[Tue Nov 28 13:08:47 2023]
Job 117: working on tf=HIF1A,tissue=Lung
Reason: Input files updated by another job: data/homer_files/HIF1A/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HIF1A --tissue Lung --predicted_motif_file data/homer_files/HIF1A/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HIF1A_Lung --predictors_file data/predictor_files/HIF1A_Lung.predictors.txt --ground_truth_file data/predictor_files/HIF1A_Lung.ground_truth.txt --info_file data/predictor_files/HIF1A_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 117 with external jobid 'Submitted batch job 10863807'.

[Tue Nov 28 13:08:48 2023]
Job 81: working on tf=HIF1A,tissue=Colon
Reason: Input files updated by another job: data/homer_files/HIF1A/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HIF1A --tissue Colon --predicted_motif_file data/homer_files/HIF1A/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HIF1A_Colon --predictors_file data/predictor_files/HIF1A_Colon.predictors.txt --ground_truth_file data/predictor_files/HIF1A_Colon.ground_truth.txt --info_file data/predictor_files/HIF1A_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 81 with external jobid 'Submitted batch job 10863808'.
[Tue Nov 28 13:09:24 2023]
Finished job 81.
3 of 632 steps (0.5%) done
Select jobs to execute...

[Tue Nov 28 13:09:24 2023]
Job 165: working on tf=HIF1A,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/HIF1A_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HIF1A --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HIF1A_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 165 with external jobid 'Submitted batch job 10863870'.
[Tue Nov 28 13:09:25 2023]
Finished job 14.
4 of 632 steps (1%) done
[Tue Nov 28 13:09:27 2023]
Finished job 8.
5 of 632 steps (1%) done
Select jobs to execute...

[Tue Nov 28 13:09:27 2023]
Job 40: working on tf=FOXO1 data/homer_files/FOXO1/scanMotifsGenomeWide_foxo1.txt
Reason: Missing output files: data/homer_files/FOXO1/merged_motif_file.txt; Input files updated by another job: data/homer_files/FOXO1/scanMotifsGenomeWide_foxo1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 40 with external jobid 'Submitted batch job 10863872'.
[Tue Nov 28 13:09:28 2023]
Finished job 15.
6 of 632 steps (1%) done
Select jobs to execute...

[Tue Nov 28 13:09:28 2023]
Job 38: working on tf=OTX2 data/homer_files/OTX2/scanMotifsGenomeWide_otx2.txt
Reason: Missing output files: data/homer_files/OTX2/merged_motif_file.txt; Input files updated by another job: data/homer_files/OTX2/scanMotifsGenomeWide_otx2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 38 with external jobid 'Submitted batch job 10863873'.
[Tue Nov 28 13:09:29 2023]
Finished job 1.
7 of 632 steps (1%) done
[Tue Nov 28 13:09:30 2023]
Finished job 9.
8 of 632 steps (1%) done
Select jobs to execute...

[Tue Nov 28 13:09:30 2023]
Job 25: working on tf=NEUROG2 data/homer_files/NEUROG2/scanMotifsGenomeWide_neurog2.txt
Reason: Missing output files: data/homer_files/NEUROG2/merged_motif_file.txt; Input files updated by another job: data/homer_files/NEUROG2/scanMotifsGenomeWide_neurog2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 25 with external jobid 'Submitted batch job 10863874'.
[Tue Nov 28 13:09:32 2023]
Finished job 2.
9 of 632 steps (1%) done
Select jobs to execute...

[Tue Nov 28 13:09:32 2023]
Job 31: working on tf=ERG data/homer_files/ERG/scanMotifsGenomeWide_erg.txt data/homer_files/ERG/scanMotifsGenomeWide_ews-erg.txt
Reason: Missing output files: data/homer_files/ERG/merged_motif_file.txt; Input files updated by another job: data/homer_files/ERG/scanMotifsGenomeWide_ews-erg.txt, data/homer_files/ERG/scanMotifsGenomeWide_erg.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 31 with external jobid 'Submitted batch job 10863877'.
[Tue Nov 28 13:09:40 2023]
Finished job 5.
10 of 632 steps (2%) done
Select jobs to execute...

[Tue Nov 28 13:09:40 2023]
Job 29: working on tf=FLI1 data/homer_files/FLI1/scanMotifsGenomeWide_ews-fli1.txt
Reason: Missing output files: data/homer_files/FLI1/merged_motif_file.txt; Input files updated by another job: data/homer_files/FLI1/scanMotifsGenomeWide_ews-fli1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 29 with external jobid 'Submitted batch job 10863883'.
[Tue Nov 28 13:09:56 2023]
Finished job 165.
11 of 632 steps (2%) done
Select jobs to execute...

[Tue Nov 28 13:09:56 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10863918'.
[Tue Nov 28 13:09:57 2023]
Finished job 40.
12 of 632 steps (2%) done
Select jobs to execute...

[Tue Nov 28 13:09:57 2023]
Job 110: working on tf=FOXO1,tissue=Endometrium
Reason: Input files updated by another job: data/homer_files/FOXO1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXO1 --tissue Endometrium --predicted_motif_file data/homer_files/FOXO1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXO1_Endometrium --predictors_file data/predictor_files/FOXO1_Endometrium.predictors.txt --ground_truth_file data/predictor_files/FOXO1_Endometrium.ground_truth.txt --info_file data/predictor_files/FOXO1_Endometrium.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 110 with external jobid 'Submitted batch job 10863932'.

[Tue Nov 28 13:09:58 2023]
Job 114: working on tf=FOXO1,tissue=Tonsil
Reason: Input files updated by another job: data/homer_files/FOXO1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXO1 --tissue Tonsil --predicted_motif_file data/homer_files/FOXO1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXO1_Tonsil --predictors_file data/predictor_files/FOXO1_Tonsil.predictors.txt --ground_truth_file data/predictor_files/FOXO1_Tonsil.ground_truth.txt --info_file data/predictor_files/FOXO1_Tonsil.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 114 with external jobid 'Submitted batch job 10863935'.

[Tue Nov 28 13:09:58 2023]
Job 126: working on tf=FOXO1,tissue=Cord-blood
Reason: Input files updated by another job: data/homer_files/FOXO1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXO1 --tissue Cord-blood --predicted_motif_file data/homer_files/FOXO1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXO1_Cord-blood --predictors_file data/predictor_files/FOXO1_Cord-blood.predictors.txt --ground_truth_file data/predictor_files/FOXO1_Cord-blood.ground_truth.txt --info_file data/predictor_files/FOXO1_Cord-blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 126 with external jobid 'Submitted batch job 10863938'.

[Tue Nov 28 13:09:58 2023]
Job 86: working on tf=FOXO1,tissue=Colon
Reason: Input files updated by another job: data/homer_files/FOXO1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FOXO1 --tissue Colon --predicted_motif_file data/homer_files/FOXO1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FOXO1_Colon --predictors_file data/predictor_files/FOXO1_Colon.predictors.txt --ground_truth_file data/predictor_files/FOXO1_Colon.ground_truth.txt --info_file data/predictor_files/FOXO1_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 86 with external jobid 'Submitted batch job 10863940'.
[Tue Nov 28 13:09:58 2023]
Finished job 38.
13 of 632 steps (2%) done
Select jobs to execute...

[Tue Nov 28 13:09:58 2023]
Job 104: working on tf=OTX2,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/OTX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor OTX2 --tissue Embryo --predicted_motif_file data/homer_files/OTX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/OTX2_Embryo --predictors_file data/predictor_files/OTX2_Embryo.predictors.txt --ground_truth_file data/predictor_files/OTX2_Embryo.ground_truth.txt --info_file data/predictor_files/OTX2_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 104 with external jobid 'Submitted batch job 10863945'.
[Tue Nov 28 13:09:59 2023]
Finished job 25.
14 of 632 steps (2%) done
Select jobs to execute...

[Tue Nov 28 13:09:59 2023]
Job 123: working on tf=NEUROG2,tissue=Fetal-Lung
Reason: Input files updated by another job: data/homer_files/NEUROG2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor NEUROG2 --tissue Fetal-Lung --predicted_motif_file data/homer_files/NEUROG2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/NEUROG2_Fetal-Lung --predictors_file data/predictor_files/NEUROG2_Fetal-Lung.predictors.txt --ground_truth_file data/predictor_files/NEUROG2_Fetal-Lung.ground_truth.txt --info_file data/predictor_files/NEUROG2_Fetal-Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 123 with external jobid 'Submitted batch job 10863958'.
[Tue Nov 28 13:10:00 2023]
Finished job 31.
15 of 632 steps (2%) done
Select jobs to execute...

[Tue Nov 28 13:10:00 2023]
Job 76: working on tf=ERG,tissue=Breast
Reason: Input files updated by another job: data/homer_files/ERG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ERG --tissue Breast --predicted_motif_file data/homer_files/ERG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ERG_Breast --predictors_file data/predictor_files/ERG_Breast.predictors.txt --ground_truth_file data/predictor_files/ERG_Breast.ground_truth.txt --info_file data/predictor_files/ERG_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 76 with external jobid 'Submitted batch job 10863971'.

[Tue Nov 28 13:10:01 2023]
Job 78: working on tf=ERG,tissue=Colon
Reason: Input files updated by another job: data/homer_files/ERG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ERG --tissue Colon --predicted_motif_file data/homer_files/ERG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ERG_Colon --predictors_file data/predictor_files/ERG_Colon.predictors.txt --ground_truth_file data/predictor_files/ERG_Colon.ground_truth.txt --info_file data/predictor_files/ERG_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 78 with external jobid 'Submitted batch job 10863973'.

[Tue Nov 28 13:10:01 2023]
Job 50: working on tf=ERG,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/ERG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ERG --tissue Prostate --predicted_motif_file data/homer_files/ERG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ERG_Prostate --predictors_file data/predictor_files/ERG_Prostate.predictors.txt --ground_truth_file data/predictor_files/ERG_Prostate.ground_truth.txt --info_file data/predictor_files/ERG_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 50 with external jobid 'Submitted batch job 10863975'.

[Tue Nov 28 13:10:01 2023]
Job 71: working on tf=ERG,tissue=Blood
Reason: Input files updated by another job: data/homer_files/ERG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ERG --tissue Blood --predicted_motif_file data/homer_files/ERG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ERG_Blood --predictors_file data/predictor_files/ERG_Blood.predictors.txt --ground_truth_file data/predictor_files/ERG_Blood.ground_truth.txt --info_file data/predictor_files/ERG_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 71 with external jobid 'Submitted batch job 10863977'.

[Tue Nov 28 13:10:01 2023]
Job 67: working on tf=ERG,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/ERG/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ERG --tissue Bone-Marrow --predicted_motif_file data/homer_files/ERG/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ERG_Bone-Marrow --predictors_file data/predictor_files/ERG_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/ERG_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/ERG_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 67 with external jobid 'Submitted batch job 10863979'.
[Tue Nov 28 13:10:01 2023]
Finished job 29.
16 of 632 steps (3%) done
Select jobs to execute...

[Tue Nov 28 13:10:01 2023]
Job 56: working on tf=FLI1,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/FLI1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FLI1 --tissue Umbilical-Vein --predicted_motif_file data/homer_files/FLI1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FLI1_Umbilical-Vein --predictors_file data/predictor_files/FLI1_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/FLI1_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/FLI1_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 56 with external jobid 'Submitted batch job 10863983'.

[Tue Nov 28 13:10:01 2023]
Job 70: working on tf=FLI1,tissue=Blood
Reason: Input files updated by another job: data/homer_files/FLI1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FLI1 --tissue Blood --predicted_motif_file data/homer_files/FLI1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FLI1_Blood --predictors_file data/predictor_files/FLI1_Blood.predictors.txt --ground_truth_file data/predictor_files/FLI1_Blood.ground_truth.txt --info_file data/predictor_files/FLI1_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 70 with external jobid 'Submitted batch job 10863985'.

[Tue Nov 28 13:10:02 2023]
Job 100: working on tf=FLI1,tissue=Brain
Reason: Input files updated by another job: data/homer_files/FLI1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FLI1 --tissue Brain --predicted_motif_file data/homer_files/FLI1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FLI1_Brain --predictors_file data/predictor_files/FLI1_Brain.predictors.txt --ground_truth_file data/predictor_files/FLI1_Brain.ground_truth.txt --info_file data/predictor_files/FLI1_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 100 with external jobid 'Submitted batch job 10863987'.

[Tue Nov 28 13:10:02 2023]
Job 74: working on tf=FLI1,tissue=Pleura
Reason: Input files updated by another job: data/homer_files/FLI1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FLI1 --tissue Pleura --predicted_motif_file data/homer_files/FLI1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FLI1_Pleura --predictors_file data/predictor_files/FLI1_Pleura.predictors.txt --ground_truth_file data/predictor_files/FLI1_Pleura.ground_truth.txt --info_file data/predictor_files/FLI1_Pleura.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 74 with external jobid 'Submitted batch job 10863989'.

[Tue Nov 28 13:10:02 2023]
Job 52: working on tf=FLI1,tissue=Cord-blood
Reason: Input files updated by another job: data/homer_files/FLI1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FLI1 --tissue Cord-blood --predicted_motif_file data/homer_files/FLI1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FLI1_Cord-blood --predictors_file data/predictor_files/FLI1_Cord-blood.predictors.txt --ground_truth_file data/predictor_files/FLI1_Cord-blood.ground_truth.txt --info_file data/predictor_files/FLI1_Cord-blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 52 with external jobid 'Submitted batch job 10863993'.

[Tue Nov 28 13:10:02 2023]
Job 68: working on tf=FLI1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/FLI1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FLI1 --tissue Bone-Marrow --predicted_motif_file data/homer_files/FLI1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FLI1_Bone-Marrow --predictors_file data/predictor_files/FLI1_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/FLI1_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/FLI1_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 68 with external jobid 'Submitted batch job 10863996'.

[Tue Nov 28 13:10:02 2023]
Job 101: working on tf=FLI1,tissue=Muscle
Reason: Input files updated by another job: data/homer_files/FLI1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor FLI1 --tissue Muscle --predicted_motif_file data/homer_files/FLI1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/FLI1_Muscle --predictors_file data/predictor_files/FLI1_Muscle.predictors.txt --ground_truth_file data/predictor_files/FLI1_Muscle.ground_truth.txt --info_file data/predictor_files/FLI1_Muscle.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 101 with external jobid 'Submitted batch job 10863998'.
[Tue Nov 28 13:10:03 2023]
Finished job 98.
17 of 632 steps (3%) done
Select jobs to execute...

[Tue Nov 28 13:10:03 2023]
Job 182: working on tf=HIF1A,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/HIF1A_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HIF1A --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HIF1A_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Mammary-Gland.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 182 with external jobid 'Submitted batch job 10864001'.
[Tue Nov 28 13:10:03 2023]
Finished job 62.
18 of 632 steps (3%) done
Select jobs to execute...

[Tue Nov 28 13:10:03 2023]
Job 146: working on tf=HIF1A,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/HIF1A_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HIF1A --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HIF1A_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Umbilical-Vein.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 146 with external jobid 'Submitted batch job 10864009'.
[Tue Nov 28 13:10:04 2023]
Finished job 90.
19 of 632 steps (3%) done
Select jobs to execute...

[Tue Nov 28 13:10:04 2023]
Job 174: working on tf=HIF1A,tissue=Kidney
Reason: Input files updated by another job: data/predictor_files/HIF1A_Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HIF1A --tissue Kidney --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HIF1A_Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Kidney.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 174 with external jobid 'Submitted batch job 10864016'.
[Tue Nov 28 13:10:05 2023]
Finished job 124.
20 of 632 steps (3%) done
Select jobs to execute...

[Tue Nov 28 13:10:05 2023]
Job 208: working on tf=HIF1A,tissue=Bone
Reason: Input files updated by another job: data/predictor_files/HIF1A_Bone.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HIF1A --tissue Bone --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HIF1A_Bone.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Bone.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 208 with external jobid 'Submitted batch job 10864024'.
[Tue Nov 28 13:10:06 2023]
Finished job 113.
21 of 632 steps (3%) done
Select jobs to execute...

[Tue Nov 28 13:10:06 2023]
Job 197: working on tf=HIF1A,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/HIF1A_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HIF1A --tissue Cervix --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HIF1A_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Cervix.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 197 with external jobid 'Submitted batch job 10864025'.
[Tue Nov 28 13:10:07 2023]
Finished job 117.
22 of 632 steps (3%) done
Select jobs to execute...

[Tue Nov 28 13:10:07 2023]
Job 201: working on tf=HIF1A,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/HIF1A_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HIF1A --tissue Lung --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HIF1A_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Lung.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 201 with external jobid 'Submitted batch job 10864027'.
[Tue Nov 28 13:10:08 2023]
Finished job 22.
23 of 632 steps (4%) done
[Tue Nov 28 13:10:12 2023]
Finished job 17.
24 of 632 steps (4%) done
Select jobs to execute...

[Tue Nov 28 13:10:12 2023]
Job 43: working on tf=HOXB13 data/homer_files/HOXB13/scanMotifsGenomeWide_hoxb13.txt
Reason: Missing output files: data/homer_files/HOXB13/merged_motif_file.txt; Input files updated by another job: data/homer_files/HOXB13/scanMotifsGenomeWide_hoxb13.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 43 with external jobid 'Submitted batch job 10864030'.
[Tue Nov 28 13:10:13 2023]
Finished job 21.
25 of 632 steps (4%) done
Select jobs to execute...

[Tue Nov 28 13:10:13 2023]
Job 32: working on tf=JUN data/homer_files/JUN/scanMotifsGenomeWide_jun-cre.txt data/homer_files/JUN/scanMotifsGenomeWide_jun-ap1.txt
Reason: Missing output files: data/homer_files/JUN/merged_motif_file.txt; Input files updated by another job: data/homer_files/JUN/scanMotifsGenomeWide_jun-ap1.txt, data/homer_files/JUN/scanMotifsGenomeWide_jun-cre.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 32 with external jobid 'Submitted batch job 10864032'.
[Tue Nov 28 13:10:14 2023]
Finished job 11.
26 of 632 steps (4%) done
Select jobs to execute...

[Tue Nov 28 13:10:14 2023]
Job 28: working on tf=TCF4 data/homer_files/TCF4/scanMotifsGenomeWide_tcf4.txt
Reason: Missing output files: data/homer_files/TCF4/merged_motif_file.txt; Input files updated by another job: data/homer_files/TCF4/scanMotifsGenomeWide_tcf4.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 28 with external jobid 'Submitted batch job 10864033'.
[Tue Nov 28 13:10:20 2023]
Finished job 20.
27 of 632 steps (4%) done
Select jobs to execute...

[Tue Nov 28 13:10:20 2023]
Job 35: working on tf=CDX2 data/homer_files/CDX2/scanMotifsGenomeWide_cdx2.txt
Reason: Input files updated by another job: data/homer_files/CDX2/scanMotifsGenomeWide_cdx2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 35 with external jobid 'Submitted batch job 10864036'.
[Tue Nov 28 13:10:39 2023]
Finished job 76.
28 of 632 steps (4%) done
Select jobs to execute...

[Tue Nov 28 13:10:39 2023]
Job 160: working on tf=ERG,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/ERG_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ERG --tissue Breast --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/ERG_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ERG_Breast.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 160 with external jobid 'Submitted batch job 10864050'.
[Tue Nov 28 13:10:40 2023]
Finished job 78.
29 of 632 steps (5%) done
Select jobs to execute...

[Tue Nov 28 13:10:40 2023]
Job 162: working on tf=ERG,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/ERG_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ERG --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/ERG_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 162 with external jobid 'Submitted batch job 10864051'.
[Tue Nov 28 13:10:42 2023]
Finished job 71.
30 of 632 steps (5%) done
Select jobs to execute...

[Tue Nov 28 13:10:43 2023]
Job 155: working on tf=ERG,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/ERG_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ERG --tissue Blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/ERG_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ERG_Blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 155 with external jobid 'Submitted batch job 10864053'.
[Tue Nov 28 13:10:43 2023]
Finished job 67.
31 of 632 steps (5%) done
Select jobs to execute...

[Tue Nov 28 13:10:44 2023]
Job 151: working on tf=ERG,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/ERG_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ERG --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/ERG_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ERG_Bone-Marrow.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 151 with external jobid 'Submitted batch job 10864055'.
[Tue Nov 28 13:10:44 2023]
Finished job 56.
32 of 632 steps (5%) done
Select jobs to execute...

[Tue Nov 28 13:10:44 2023]
Job 140: working on tf=FLI1,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/FLI1_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FLI1 --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FLI1_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FLI1_Umbilical-Vein.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 140 with external jobid 'Submitted batch job 10864057'.
[Tue Nov 28 13:10:45 2023]
Finished job 70.
33 of 632 steps (5%) done
Select jobs to execute...

[Tue Nov 28 13:10:45 2023]
Job 154: working on tf=FLI1,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/FLI1_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FLI1 --tissue Blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FLI1_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FLI1_Blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 154 with external jobid 'Submitted batch job 10864058'.
[Tue Nov 28 13:10:46 2023]
Finished job 100.
34 of 632 steps (5%) done
Select jobs to execute...

[Tue Nov 28 13:10:46 2023]
Job 184: working on tf=FLI1,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/FLI1_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FLI1 --tissue Brain --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FLI1_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FLI1_Brain.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 184 with external jobid 'Submitted batch job 10864059'.
[Tue Nov 28 13:10:47 2023]
Finished job 74.
35 of 632 steps (6%) done
Select jobs to execute...

[Tue Nov 28 13:10:47 2023]
Job 158: working on tf=FLI1,tissue=Pleura
Reason: Input files updated by another job: data/predictor_files/FLI1_Pleura.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FLI1 --tissue Pleura --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FLI1_Pleura.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FLI1_Pleura.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 158 with external jobid 'Submitted batch job 10864062'.
[Tue Nov 28 13:10:48 2023]
Finished job 52.
36 of 632 steps (6%) done
Select jobs to execute...

[Tue Nov 28 13:10:48 2023]
Job 136: working on tf=FLI1,tissue=Cord-blood
Reason: Input files updated by another job: data/predictor_files/FLI1_Cord-blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FLI1 --tissue Cord-blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FLI1_Cord-blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FLI1_Cord-blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 136 with external jobid 'Submitted batch job 10864064'.
[Tue Nov 28 13:10:49 2023]
Finished job 68.
37 of 632 steps (6%) done
Select jobs to execute...

[Tue Nov 28 13:10:49 2023]
Job 152: working on tf=FLI1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/FLI1_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FLI1 --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FLI1_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FLI1_Bone-Marrow.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 152 with external jobid 'Submitted batch job 10864066'.
[Tue Nov 28 13:10:50 2023]
Finished job 101.
38 of 632 steps (6%) done
Select jobs to execute...

[Tue Nov 28 13:10:50 2023]
Job 185: working on tf=FLI1,tissue=Muscle
Reason: Input files updated by another job: data/predictor_files/FLI1_Muscle.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FLI1 --tissue Muscle --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FLI1_Muscle.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FLI1_Muscle.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 185 with external jobid 'Submitted batch job 10864067'.
[Tue Nov 28 13:10:51 2023]
Finished job 182.
39 of 632 steps (6%) done
Select jobs to execute...

[Tue Nov 28 13:10:52 2023]
Job 266: working on HIF1A_Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 266 with external jobid 'Submitted batch job 10864068'.
[Tue Nov 28 13:10:52 2023]
Finished job 146.
40 of 632 steps (6%) done
Select jobs to execute...

[Tue Nov 28 13:10:52 2023]
Job 230: working on HIF1A_Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 230 with external jobid 'Submitted batch job 10864071'.
[Tue Nov 28 13:10:53 2023]
Finished job 174.
41 of 632 steps (6%) done
Select jobs to execute...

[Tue Nov 28 13:10:53 2023]
Job 258: working on HIF1A_Kidney
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 258 with external jobid 'Submitted batch job 10864073'.
[Tue Nov 28 13:10:54 2023]
Finished job 208.
42 of 632 steps (7%) done
Select jobs to execute...

[Tue Nov 28 13:10:54 2023]
Job 292: working on HIF1A_Bone
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Bone.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Bone.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 292 with external jobid 'Submitted batch job 10864074'.
[Tue Nov 28 13:10:55 2023]
Finished job 197.
43 of 632 steps (7%) done
Select jobs to execute...

[Tue Nov 28 13:10:55 2023]
Job 281: working on HIF1A_Cervix
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 281 with external jobid 'Submitted batch job 10864076'.
[Tue Nov 28 13:10:56 2023]
Finished job 201.
44 of 632 steps (7%) done
Select jobs to execute...

[Tue Nov 28 13:10:56 2023]
Job 285: working on HIF1A_Lung
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 285 with external jobid 'Submitted batch job 10864077'.
[Tue Nov 28 13:10:57 2023]
Finished job 43.
45 of 632 steps (7%) done
Select jobs to execute...

[Tue Nov 28 13:10:57 2023]
Job 112: working on tf=HOXB13,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/HOXB13/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HOXB13 --tissue Prostate --predicted_motif_file data/homer_files/HOXB13/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HOXB13_Prostate --predictors_file data/predictor_files/HOXB13_Prostate.predictors.txt --ground_truth_file data/predictor_files/HOXB13_Prostate.ground_truth.txt --info_file data/predictor_files/HOXB13_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 112 with external jobid 'Submitted batch job 10864079'.

[Tue Nov 28 13:10:57 2023]
Job 80: working on tf=HOXB13,tissue=Colon
Reason: Input files updated by another job: data/homer_files/HOXB13/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor HOXB13 --tissue Colon --predicted_motif_file data/homer_files/HOXB13/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/HOXB13_Colon --predictors_file data/predictor_files/HOXB13_Colon.predictors.txt --ground_truth_file data/predictor_files/HOXB13_Colon.ground_truth.txt --info_file data/predictor_files/HOXB13_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 80 with external jobid 'Submitted batch job 10864080'.
[Tue Nov 28 13:10:58 2023]
Finished job 32.
46 of 632 steps (7%) done
Select jobs to execute...

[Tue Nov 28 13:10:59 2023]
Job 93: working on tf=JUN,tissue=Liver
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Liver --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Liver --predictors_file data/predictor_files/JUN_Liver.predictors.txt --ground_truth_file data/predictor_files/JUN_Liver.ground_truth.txt --info_file data/predictor_files/JUN_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 93 with external jobid 'Submitted batch job 10864088'.

[Tue Nov 28 13:10:59 2023]
Job 48: working on tf=JUN,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Bone-Marrow --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Bone-Marrow --predictors_file data/predictor_files/JUN_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/JUN_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/JUN_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 48 with external jobid 'Submitted batch job 10864089'.

[Tue Nov 28 13:10:59 2023]
Job 92: working on tf=JUN,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Cervix --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Cervix --predictors_file data/predictor_files/JUN_Cervix.predictors.txt --ground_truth_file data/predictor_files/JUN_Cervix.ground_truth.txt --info_file data/predictor_files/JUN_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 92 with external jobid 'Submitted batch job 10864090'.

[Tue Nov 28 13:10:59 2023]
Job 108: working on tf=JUN,tissue=Coronary-artery-smooth-muscle
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Coronary-artery-smooth-muscle --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Coronary-artery-smooth-muscle --predictors_file data/predictor_files/JUN_Coronary-artery-smooth-muscle.predictors.txt --ground_truth_file data/predictor_files/JUN_Coronary-artery-smooth-muscle.ground_truth.txt --info_file data/predictor_files/JUN_Coronary-artery-smooth-muscle.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 108 with external jobid 'Submitted batch job 10864091'.

[Tue Nov 28 13:11:00 2023]
Job 94: working on tf=JUN,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Umbilical-Vein --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Umbilical-Vein --predictors_file data/predictor_files/JUN_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/JUN_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/JUN_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 94 with external jobid 'Submitted batch job 10864092'.

[Tue Nov 28 13:11:00 2023]
Job 82: working on tf=JUN,tissue=Colon
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Colon --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Colon --predictors_file data/predictor_files/JUN_Colon.predictors.txt --ground_truth_file data/predictor_files/JUN_Colon.ground_truth.txt --info_file data/predictor_files/JUN_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 82 with external jobid 'Submitted batch job 10864093'.

[Tue Nov 28 13:11:00 2023]
Job 75: working on tf=JUN,tissue=Lung
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Lung --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Lung --predictors_file data/predictor_files/JUN_Lung.predictors.txt --ground_truth_file data/predictor_files/JUN_Lung.ground_truth.txt --info_file data/predictor_files/JUN_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 75 with external jobid 'Submitted batch job 10864094'.

[Tue Nov 28 13:11:00 2023]
Job 91: working on tf=JUN,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Embryo --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Embryo --predictors_file data/predictor_files/JUN_Embryo.predictors.txt --ground_truth_file data/predictor_files/JUN_Embryo.ground_truth.txt --info_file data/predictor_files/JUN_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 91 with external jobid 'Submitted batch job 10864095'.

[Tue Nov 28 13:11:00 2023]
Job 51: working on tf=JUN,tissue=Breast
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Breast --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Breast --predictors_file data/predictor_files/JUN_Breast.predictors.txt --ground_truth_file data/predictor_files/JUN_Breast.ground_truth.txt --info_file data/predictor_files/JUN_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 51 with external jobid 'Submitted batch job 10864096'.

[Tue Nov 28 13:11:00 2023]
Job 95: working on tf=JUN,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/JUN/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor JUN --tissue Mammary-Gland --predicted_motif_file data/homer_files/JUN/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/JUN_Mammary-Gland --predictors_file data/predictor_files/JUN_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/JUN_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/JUN_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 95 with external jobid 'Submitted batch job 10864097'.
[Tue Nov 28 13:11:00 2023]
Finished job 28.
47 of 632 steps (7%) done
Select jobs to execute...

[Tue Nov 28 13:11:00 2023]
Job 106: working on tf=TCF4,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/TCF4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor TCF4 --tissue Embryo --predicted_motif_file data/homer_files/TCF4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/TCF4_Embryo --predictors_file data/predictor_files/TCF4_Embryo.predictors.txt --ground_truth_file data/predictor_files/TCF4_Embryo.ground_truth.txt --info_file data/predictor_files/TCF4_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 106 with external jobid 'Submitted batch job 10864098'.

[Tue Nov 28 13:11:00 2023]
Job 44: working on tf=TCF4,tissue=Colon
Reason: Input files updated by another job: data/homer_files/TCF4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor TCF4 --tissue Colon --predicted_motif_file data/homer_files/TCF4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/TCF4_Colon --predictors_file data/predictor_files/TCF4_Colon.predictors.txt --ground_truth_file data/predictor_files/TCF4_Colon.ground_truth.txt --info_file data/predictor_files/TCF4_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 44 with external jobid 'Submitted batch job 10864100'.
[Tue Nov 28 13:11:01 2023]
Finished job 35.
48 of 632 steps (8%) done
Select jobs to execute...

[Tue Nov 28 13:11:01 2023]
Job 103: working on tf=CDX2,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/CDX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CDX2 --tissue Embryo --predicted_motif_file data/homer_files/CDX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CDX2_Embryo --predictors_file data/predictor_files/CDX2_Embryo.predictors.txt --ground_truth_file data/predictor_files/CDX2_Embryo.ground_truth.txt --info_file data/predictor_files/CDX2_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 103 with external jobid 'Submitted batch job 10864101'.

[Tue Nov 28 13:11:01 2023]
Job 45: working on tf=CDX2,tissue=Colon
Reason: Input files updated by another job: data/homer_files/CDX2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor CDX2 --tissue Colon --predicted_motif_file data/homer_files/CDX2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/CDX2_Colon --predictors_file data/predictor_files/CDX2_Colon.predictors.txt --ground_truth_file data/predictor_files/CDX2_Colon.ground_truth.txt --info_file data/predictor_files/CDX2_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 45 with external jobid 'Submitted batch job 10864102'.
[Tue Nov 28 13:11:02 2023]
Finished job 16.
49 of 632 steps (8%) done
Select jobs to execute...

[Tue Nov 28 13:11:02 2023]
Job 33: working on tf=MYC data/homer_files/MYC/scanMotifsGenomeWide_p53-myc.txt
Reason: Missing output files: data/homer_files/MYC/merged_motif_file.txt; Input files updated by another job: data/homer_files/MYC/scanMotifsGenomeWide_p53-myc.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 33 with external jobid 'Submitted batch job 10864104'.
[Tue Nov 28 13:11:03 2023]
Finished job 10.
50 of 632 steps (8%) done
Select jobs to execute...

[Tue Nov 28 13:11:03 2023]
Job 30: working on tf=STAT4 data/homer_files/STAT4/scanMotifsGenomeWide_stat4.txt
Reason: Missing output files: data/homer_files/STAT4/merged_motif_file.txt; Input files updated by another job: data/homer_files/STAT4/scanMotifsGenomeWide_stat4.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 30 with external jobid 'Submitted batch job 10864106'.
[Tue Nov 28 13:11:04 2023]
Finished job 18.
51 of 632 steps (8%) done
Select jobs to execute...

[Tue Nov 28 13:11:04 2023]
Job 42: working on tf=ASCL1 data/homer_files/ASCL1/scanMotifsGenomeWide_ascl1.txt
Reason: Missing output files: data/homer_files/ASCL1/merged_motif_file.txt; Input files updated by another job: data/homer_files/ASCL1/scanMotifsGenomeWide_ascl1.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 42 with external jobid 'Submitted batch job 10864108'.
[Tue Nov 28 13:11:07 2023]
Finished job 4.
52 of 632 steps (8%) done
Select jobs to execute...

[Tue Nov 28 13:11:07 2023]
Job 34: working on tf=SNAI2 data/homer_files/SNAI2/scanMotifsGenomeWide_snai2.txt
Reason: Missing output files: data/homer_files/SNAI2/merged_motif_file.txt; Input files updated by another job: data/homer_files/SNAI2/scanMotifsGenomeWide_snai2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 34 with external jobid 'Submitted batch job 10864109'.
[Tue Nov 28 13:11:08 2023]
Finished job 13.
53 of 632 steps (8%) done
Select jobs to execute...

[Tue Nov 28 13:11:08 2023]
Job 39: working on tf=STAT6 data/homer_files/STAT6/scanMotifsGenomeWide_stat6.txt data/homer_files/STAT6/scanMotifsGenomeWide_stat6.2.txt
Reason: Missing output files: data/homer_files/STAT6/merged_motif_file.txt; Input files updated by another job: data/homer_files/STAT6/scanMotifsGenomeWide_stat6.2.txt, data/homer_files/STAT6/scanMotifsGenomeWide_stat6.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 39 with external jobid 'Submitted batch job 10864110'.
[Tue Nov 28 13:11:20 2023]
Finished job 160.
54 of 632 steps (9%) done
Select jobs to execute...

[Tue Nov 28 13:11:20 2023]
Job 244: working on ERG_Breast
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 244 with external jobid 'Submitted batch job 10864117'.
[Tue Nov 28 13:11:21 2023]
Finished job 162.
55 of 632 steps (9%) done
Select jobs to execute...

[Tue Nov 28 13:11:21 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10864118'.
[Tue Nov 28 13:11:22 2023]
Finished job 155.
56 of 632 steps (9%) done
Select jobs to execute...

[Tue Nov 28 13:11:23 2023]
Job 239: working on ERG_Blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 239 with external jobid 'Submitted batch job 10864121'.
[Tue Nov 28 13:11:23 2023]
Finished job 151.
57 of 632 steps (9%) done
Select jobs to execute...

[Tue Nov 28 13:11:24 2023]
Job 235: working on ERG_Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 235 with external jobid 'Submitted batch job 10864123'.
[Tue Nov 28 13:11:24 2023]
Finished job 140.
58 of 632 steps (9%) done
Select jobs to execute...

[Tue Nov 28 13:11:24 2023]
Job 224: working on FLI1_Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FLI1_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FLI1_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 224 with external jobid 'Submitted batch job 10864124'.
[Tue Nov 28 13:11:25 2023]
Finished job 154.
59 of 632 steps (9%) done
Select jobs to execute...

[Tue Nov 28 13:11:26 2023]
Job 238: working on FLI1_Blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FLI1_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FLI1_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 238 with external jobid 'Submitted batch job 10864125'.
[Tue Nov 28 13:11:26 2023]
Finished job 184.
60 of 632 steps (9%) done
Select jobs to execute...

[Tue Nov 28 13:11:26 2023]
Job 268: working on FLI1_Brain
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FLI1_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FLI1_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 268 with external jobid 'Submitted batch job 10864126'.
[Tue Nov 28 13:11:27 2023]
Finished job 158.
61 of 632 steps (10%) done
Select jobs to execute...

[Tue Nov 28 13:11:28 2023]
Job 242: working on FLI1_Pleura
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FLI1_Pleura.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FLI1_Pleura.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 242 with external jobid 'Submitted batch job 10864134'.
[Tue Nov 28 13:11:28 2023]
Finished job 136.
62 of 632 steps (10%) done
Select jobs to execute...

[Tue Nov 28 13:11:29 2023]
Job 220: working on FLI1_Cord-blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FLI1_Cord-blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FLI1_Cord-blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 220 with external jobid 'Submitted batch job 10864136'.
[Tue Nov 28 13:11:29 2023]
Finished job 152.
63 of 632 steps (10%) done
Select jobs to execute...

[Tue Nov 28 13:11:30 2023]
Job 236: working on FLI1_Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FLI1_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FLI1_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 236 with external jobid 'Submitted batch job 10864138'.
[Tue Nov 28 13:11:30 2023]
Finished job 185.
64 of 632 steps (10%) done
Select jobs to execute...

[Tue Nov 28 13:11:30 2023]
Job 269: working on FLI1_Muscle
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FLI1_Muscle.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FLI1_Muscle.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 269 with external jobid 'Submitted batch job 10864140'.
[Tue Nov 28 13:11:38 2023]
Finished job 80.
65 of 632 steps (10%) done
Select jobs to execute...

[Tue Nov 28 13:11:39 2023]
Job 164: working on tf=HOXB13,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/HOXB13_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HOXB13 --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HOXB13_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HOXB13_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 164 with external jobid 'Submitted batch job 10864145'.
[Tue Nov 28 13:11:39 2023]
Finished job 93.
66 of 632 steps (10%) done
Select jobs to execute...

[Tue Nov 28 13:11:39 2023]
Job 177: working on tf=JUN,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/JUN_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Liver --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Liver.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 177 with external jobid 'Submitted batch job 10864146'.
[Tue Nov 28 13:11:40 2023]
Finished job 48.
67 of 632 steps (11%) done
Select jobs to execute...

[Tue Nov 28 13:11:41 2023]
Job 132: working on tf=JUN,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/JUN_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Bone-Marrow.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 132 with external jobid 'Submitted batch job 10864147'.
[Tue Nov 28 13:11:41 2023]
Finished job 92.
68 of 632 steps (11%) done
Select jobs to execute...

[Tue Nov 28 13:11:41 2023]
Job 176: working on tf=JUN,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/JUN_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Cervix --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Cervix.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 176 with external jobid 'Submitted batch job 10864148'.
[Tue Nov 28 13:11:42 2023]
Finished job 108.
69 of 632 steps (11%) done
Select jobs to execute...

[Tue Nov 28 13:11:42 2023]
Job 192: working on tf=JUN,tissue=Coronary-artery-smooth-muscle
Reason: Input files updated by another job: data/predictor_files/JUN_Coronary-artery-smooth-muscle.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Coronary-artery-smooth-muscle --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Coronary-artery-smooth-muscle.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Coronary-artery-smooth-muscle.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 192 with external jobid 'Submitted batch job 10864155'.
[Tue Nov 28 13:11:43 2023]
Finished job 94.
70 of 632 steps (11%) done
Select jobs to execute...

[Tue Nov 28 13:11:44 2023]
Job 178: working on tf=JUN,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/JUN_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Umbilical-Vein.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 178 with external jobid 'Submitted batch job 10864157'.
[Tue Nov 28 13:11:44 2023]
Finished job 82.
71 of 632 steps (11%) done
Select jobs to execute...

[Tue Nov 28 13:11:44 2023]
Job 166: working on tf=JUN,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/JUN_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 166 with external jobid 'Submitted batch job 10864159'.
[Tue Nov 28 13:11:46 2023]
Finished job 75.
72 of 632 steps (11%) done
Select jobs to execute...

[Tue Nov 28 13:11:46 2023]
Job 159: working on tf=JUN,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/JUN_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Lung --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Lung.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 159 with external jobid 'Submitted batch job 10864161'.
[Tue Nov 28 13:11:46 2023]
Finished job 91.
73 of 632 steps (12%) done
Select jobs to execute...

[Tue Nov 28 13:11:47 2023]
Job 175: working on tf=JUN,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/JUN_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Embryo --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Embryo.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 175 with external jobid 'Submitted batch job 10864162'.
[Tue Nov 28 13:11:47 2023]
Finished job 51.
74 of 632 steps (12%) done
Select jobs to execute...

[Tue Nov 28 13:11:48 2023]
Job 135: working on tf=JUN,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/JUN_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Breast --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Breast.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 135 with external jobid 'Submitted batch job 10864163'.
[Tue Nov 28 13:11:48 2023]
Finished job 95.
75 of 632 steps (12%) done
Select jobs to execute...

[Tue Nov 28 13:11:48 2023]
Job 179: working on tf=JUN,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/JUN_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor JUN --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/JUN_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_JUN_Mammary-Gland.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 179 with external jobid 'Submitted batch job 10864164'.
[Tue Nov 28 13:11:49 2023]
Finished job 106.
76 of 632 steps (12%) done
Select jobs to execute...

[Tue Nov 28 13:11:50 2023]
Job 190: working on tf=TCF4,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/TCF4_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor TCF4 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/TCF4_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_TCF4_Embryo.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 190 with external jobid 'Submitted batch job 10864165'.
[Tue Nov 28 13:11:51 2023]
Finished job 103.
77 of 632 steps (12%) done
Select jobs to execute...

[Tue Nov 28 13:11:52 2023]
Job 187: working on tf=CDX2,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/CDX2_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CDX2 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/CDX2_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CDX2_Embryo.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 187 with external jobid 'Submitted batch job 10864167'.
[Tue Nov 28 13:11:53 2023]
Finished job 33.
78 of 632 steps (12%) done
Select jobs to execute...

[Tue Nov 28 13:11:54 2023]
Job 55: working on tf=MYC,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Embryo --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Embryo --predictors_file data/predictor_files/MYC_Embryo.predictors.txt --ground_truth_file data/predictor_files/MYC_Embryo.ground_truth.txt --info_file data/predictor_files/MYC_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 55 with external jobid 'Submitted batch job 10864171'.

[Tue Nov 28 13:11:54 2023]
Job 77: working on tf=MYC,tissue=Breast
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Breast --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Breast --predictors_file data/predictor_files/MYC_Breast.predictors.txt --ground_truth_file data/predictor_files/MYC_Breast.ground_truth.txt --info_file data/predictor_files/MYC_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 77 with external jobid 'Submitted batch job 10864172'.

[Tue Nov 28 13:11:54 2023]
Job 58: working on tf=MYC,tissue=Cervix
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Cervix --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Cervix --predictors_file data/predictor_files/MYC_Cervix.predictors.txt --ground_truth_file data/predictor_files/MYC_Cervix.ground_truth.txt --info_file data/predictor_files/MYC_Cervix.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 58 with external jobid 'Submitted batch job 10864173'.

[Tue Nov 28 13:11:54 2023]
Job 72: working on tf=MYC,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Mammary-Gland --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Mammary-Gland --predictors_file data/predictor_files/MYC_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/MYC_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/MYC_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 72 with external jobid 'Submitted batch job 10864175'.

[Tue Nov 28 13:11:54 2023]
Job 60: working on tf=MYC,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Umbilical-Vein --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Umbilical-Vein --predictors_file data/predictor_files/MYC_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/MYC_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/MYC_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 60 with external jobid 'Submitted batch job 10864176'.

[Tue Nov 28 13:11:54 2023]
Job 116: working on tf=MYC,tissue=Foreskin
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Foreskin --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Foreskin --predictors_file data/predictor_files/MYC_Foreskin.predictors.txt --ground_truth_file data/predictor_files/MYC_Foreskin.ground_truth.txt --info_file data/predictor_files/MYC_Foreskin.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 116 with external jobid 'Submitted batch job 10864177'.

[Tue Nov 28 13:11:55 2023]
Job 64: working on tf=MYC,tissue=Lung
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Lung --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Lung --predictors_file data/predictor_files/MYC_Lung.predictors.txt --ground_truth_file data/predictor_files/MYC_Lung.ground_truth.txt --info_file data/predictor_files/MYC_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 64 with external jobid 'Submitted batch job 10864178'.

[Tue Nov 28 13:11:55 2023]
Job 66: working on tf=MYC,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Embryonic-Kidney --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Embryonic-Kidney --predictors_file data/predictor_files/MYC_Embryonic-Kidney.predictors.txt --ground_truth_file data/predictor_files/MYC_Embryonic-Kidney.ground_truth.txt --info_file data/predictor_files/MYC_Embryonic-Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 66 with external jobid 'Submitted batch job 10864179'.

[Tue Nov 28 13:11:55 2023]
Job 122: working on tf=MYC,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Prostate --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Prostate --predictors_file data/predictor_files/MYC_Prostate.predictors.txt --ground_truth_file data/predictor_files/MYC_Prostate.ground_truth.txt --info_file data/predictor_files/MYC_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 122 with external jobid 'Submitted batch job 10864180'.

[Tue Nov 28 13:11:55 2023]
Job 96: working on tf=MYC,tissue=Bone
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Bone --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Bone --predictors_file data/predictor_files/MYC_Bone.predictors.txt --ground_truth_file data/predictor_files/MYC_Bone.ground_truth.txt --info_file data/predictor_files/MYC_Bone.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 96 with external jobid 'Submitted batch job 10864181'.

[Tue Nov 28 13:11:55 2023]
Job 61: working on tf=MYC,tissue=Skin
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Skin --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Skin --predictors_file data/predictor_files/MYC_Skin.predictors.txt --ground_truth_file data/predictor_files/MYC_Skin.ground_truth.txt --info_file data/predictor_files/MYC_Skin.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 61 with external jobid 'Submitted batch job 10864182'.

[Tue Nov 28 13:11:55 2023]
Job 119: working on tf=MYC,tissue=LNCaP-cells
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue LNCaP-cells --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_LNCaP-cells --predictors_file data/predictor_files/MYC_LNCaP-cells.predictors.txt --ground_truth_file data/predictor_files/MYC_LNCaP-cells.ground_truth.txt --info_file data/predictor_files/MYC_LNCaP-cells.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 119 with external jobid 'Submitted batch job 10864183'.

[Tue Nov 28 13:11:55 2023]
Job 59: working on tf=MYC,tissue=Liver
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Liver --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Liver --predictors_file data/predictor_files/MYC_Liver.predictors.txt --ground_truth_file data/predictor_files/MYC_Liver.ground_truth.txt --info_file data/predictor_files/MYC_Liver.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 59 with external jobid 'Submitted batch job 10864184'.

[Tue Nov 28 13:11:55 2023]
Job 47: working on tf=MYC,tissue=Blood
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Blood --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Blood --predictors_file data/predictor_files/MYC_Blood.predictors.txt --ground_truth_file data/predictor_files/MYC_Blood.ground_truth.txt --info_file data/predictor_files/MYC_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 47 with external jobid 'Submitted batch job 10864185'.

[Tue Nov 28 13:11:56 2023]
Job 49: working on tf=MYC,tissue=Bone-Marrow
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Bone-Marrow --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Bone-Marrow --predictors_file data/predictor_files/MYC_Bone-Marrow.predictors.txt --ground_truth_file data/predictor_files/MYC_Bone-Marrow.ground_truth.txt --info_file data/predictor_files/MYC_Bone-Marrow.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 49 with external jobid 'Submitted batch job 10864186'.

[Tue Nov 28 13:11:57 2023]
Job 79: working on tf=MYC,tissue=Colon
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Colon --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Colon --predictors_file data/predictor_files/MYC_Colon.predictors.txt --ground_truth_file data/predictor_files/MYC_Colon.ground_truth.txt --info_file data/predictor_files/MYC_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 79 with external jobid 'Submitted batch job 10864187'.

[Tue Nov 28 13:11:57 2023]
Job 63: working on tf=MYC,tissue=Brain
Reason: Input files updated by another job: data/homer_files/MYC/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor MYC --tissue Brain --predicted_motif_file data/homer_files/MYC/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/MYC_Brain --predictors_file data/predictor_files/MYC_Brain.predictors.txt --ground_truth_file data/predictor_files/MYC_Brain.ground_truth.txt --info_file data/predictor_files/MYC_Brain.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 63 with external jobid 'Submitted batch job 10864188'.
[Tue Nov 28 13:11:57 2023]
Finished job 30.
79 of 632 steps (12%) done
[Tue Nov 28 13:11:57 2023]
Finished job 42.
80 of 632 steps (13%) done
[Tue Nov 28 13:11:57 2023]
Finished job 34.
81 of 632 steps (13%) done
Select jobs to execute...

[Tue Nov 28 13:11:57 2023]
Job 99: working on tf=ASCL1,tissue=Lung
Reason: Input files updated by another job: data/homer_files/ASCL1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ASCL1 --tissue Lung --predicted_motif_file data/homer_files/ASCL1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ASCL1_Lung --predictors_file data/predictor_files/ASCL1_Lung.predictors.txt --ground_truth_file data/predictor_files/ASCL1_Lung.ground_truth.txt --info_file data/predictor_files/ASCL1_Lung.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 99 with external jobid 'Submitted batch job 10864190'.

[Tue Nov 28 13:11:58 2023]
Job 85: working on tf=ASCL1,tissue=Skin
Reason: Input files updated by another job: data/homer_files/ASCL1/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ASCL1 --tissue Skin --predicted_motif_file data/homer_files/ASCL1/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ASCL1_Skin --predictors_file data/predictor_files/ASCL1_Skin.predictors.txt --ground_truth_file data/predictor_files/ASCL1_Skin.ground_truth.txt --info_file data/predictor_files/ASCL1_Skin.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 85 with external jobid 'Submitted batch job 10864191'.

[Tue Nov 28 13:11:58 2023]
Job 87: working on tf=STAT4,tissue=Colon
Reason: Input files updated by another job: data/homer_files/STAT4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT4 --tissue Colon --predicted_motif_file data/homer_files/STAT4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT4_Colon --predictors_file data/predictor_files/STAT4_Colon.predictors.txt --ground_truth_file data/predictor_files/STAT4_Colon.ground_truth.txt --info_file data/predictor_files/STAT4_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 87 with external jobid 'Submitted batch job 10864192'.

[Tue Nov 28 13:11:58 2023]
Job 105: working on tf=SNAI2,tissue=Embryo
Reason: Input files updated by another job: data/homer_files/SNAI2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor SNAI2 --tissue Embryo --predicted_motif_file data/homer_files/SNAI2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/SNAI2_Embryo --predictors_file data/predictor_files/SNAI2_Embryo.predictors.txt --ground_truth_file data/predictor_files/SNAI2_Embryo.ground_truth.txt --info_file data/predictor_files/SNAI2_Embryo.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 105 with external jobid 'Submitted batch job 10864193'.

[Tue Nov 28 13:11:58 2023]
Job 53: working on tf=STAT4,tissue=Blood
Reason: Input files updated by another job: data/homer_files/STAT4/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT4 --tissue Blood --predicted_motif_file data/homer_files/STAT4/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT4_Blood --predictors_file data/predictor_files/STAT4_Blood.predictors.txt --ground_truth_file data/predictor_files/STAT4_Blood.ground_truth.txt --info_file data/predictor_files/STAT4_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 53 with external jobid 'Submitted batch job 10864194'.
[Tue Nov 28 13:11:58 2023]
Finished job 39.
82 of 632 steps (13%) done
Select jobs to execute...

[Tue Nov 28 13:11:58 2023]
Job 88: working on tf=STAT6,tissue=Colon
Reason: Input files updated by another job: data/homer_files/STAT6/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT6 --tissue Colon --predicted_motif_file data/homer_files/STAT6/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT6_Colon --predictors_file data/predictor_files/STAT6_Colon.predictors.txt --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --info_file data/predictor_files/STAT6_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 88 with external jobid 'Submitted batch job 10864195'.

[Tue Nov 28 13:11:58 2023]
Job 125: working on tf=STAT6,tissue=Blood
Reason: Input files updated by another job: data/homer_files/STAT6/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT6 --tissue Blood --predicted_motif_file data/homer_files/STAT6/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT6_Blood --predictors_file data/predictor_files/STAT6_Blood.predictors.txt --ground_truth_file data/predictor_files/STAT6_Blood.ground_truth.txt --info_file data/predictor_files/STAT6_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 125 with external jobid 'Submitted batch job 10864197'.

[Tue Nov 28 13:11:59 2023]
Job 54: working on tf=STAT6,tissue=Cord-blood
Reason: Input files updated by another job: data/homer_files/STAT6/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor STAT6 --tissue Cord-blood --predicted_motif_file data/homer_files/STAT6/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/STAT6_Cord-blood --predictors_file data/predictor_files/STAT6_Cord-blood.predictors.txt --ground_truth_file data/predictor_files/STAT6_Cord-blood.ground_truth.txt --info_file data/predictor_files/STAT6_Cord-blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 54 with external jobid 'Submitted batch job 10864198'.
[Tue Nov 28 13:11:59 2023]
Finished job 110.
83 of 632 steps (13%) done
Select jobs to execute...

[Tue Nov 28 13:11:59 2023]
Job 194: working on tf=FOXO1,tissue=Endometrium
Reason: Input files updated by another job: data/predictor_files/FOXO1_Endometrium.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXO1 --tissue Endometrium --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FOXO1_Endometrium.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Endometrium.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 194 with external jobid 'Submitted batch job 10864199'.
[Tue Nov 28 13:12:00 2023]
Finished job 114.
84 of 632 steps (13%) done
Select jobs to execute...

[Tue Nov 28 13:12:00 2023]
Job 198: working on tf=FOXO1,tissue=Tonsil
Reason: Input files updated by another job: data/predictor_files/FOXO1_Tonsil.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXO1 --tissue Tonsil --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FOXO1_Tonsil.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Tonsil.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 198 with external jobid 'Submitted batch job 10864201'.
[Tue Nov 28 13:12:01 2023]
Finished job 126.
85 of 632 steps (13%) done
Select jobs to execute...

[Tue Nov 28 13:12:01 2023]
Job 210: working on tf=FOXO1,tissue=Cord-blood
Reason: Input files updated by another job: data/predictor_files/FOXO1_Cord-blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXO1 --tissue Cord-blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FOXO1_Cord-blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Cord-blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 210 with external jobid 'Submitted batch job 10864203'.
[Tue Nov 28 13:12:03 2023]
Finished job 86.
86 of 632 steps (14%) done
Select jobs to execute...

[Tue Nov 28 13:12:03 2023]
Job 170: working on tf=FOXO1,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/FOXO1_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor FOXO1 --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/FOXO1_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 170 with external jobid 'Submitted batch job 10864204'.
[Tue Nov 28 13:12:04 2023]
Finished job 104.
87 of 632 steps (14%) done
Select jobs to execute...

[Tue Nov 28 13:12:04 2023]
Job 188: working on tf=OTX2,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/OTX2_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor OTX2 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/OTX2_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_OTX2_Embryo.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 188 with external jobid 'Submitted batch job 10864205'.
[Tue Nov 28 13:12:05 2023]
Finished job 123.
88 of 632 steps (14%) done
Select jobs to execute...

[Tue Nov 28 13:12:05 2023]
Job 207: working on tf=NEUROG2,tissue=Fetal-Lung
Reason: Input files updated by another job: data/predictor_files/NEUROG2_Fetal-Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor NEUROG2 --tissue Fetal-Lung --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/NEUROG2_Fetal-Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_NEUROG2_Fetal-Lung.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 207 with external jobid 'Submitted batch job 10864206'.
[Tue Nov 28 13:12:05 2023]
Finished job 50.
89 of 632 steps (14%) done
Select jobs to execute...

[Tue Nov 28 13:12:06 2023]
Job 134: working on tf=ERG,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/ERG_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ERG --tissue Prostate --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/ERG_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ERG_Prostate.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 134 with external jobid 'Submitted batch job 10864207'.
[Tue Nov 28 13:12:10 2023]
Finished job 6.
90 of 632 steps (14%) done
Select jobs to execute...

[Tue Nov 28 13:12:10 2023]
Job 27: working on tf=AR data/homer_files/AR/scanMotifsGenomeWide_ar-half.txt
Reason: Missing output files: data/homer_files/AR/merged_motif_file.txt; Input files updated by another job: data/homer_files/AR/scanMotifsGenomeWide_ar-half.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 27 with external jobid 'Submitted batch job 10864211'.
[Tue Nov 28 13:12:32 2023]
Finished job 164.
91 of 632 steps (14%) done
Select jobs to execute...

[Tue Nov 28 13:12:32 2023]
Job 248: working on HOXB13_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HOXB13_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HOXB13_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 248 with external jobid 'Submitted batch job 10864221'.
[Tue Nov 28 13:12:32 2023]
Finished job 177.
92 of 632 steps (15%) done
Select jobs to execute...

[Tue Nov 28 13:12:33 2023]
Job 261: working on JUN_Liver
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 261 with external jobid 'Submitted batch job 10864223'.
[Tue Nov 28 13:12:34 2023]
Finished job 132.
93 of 632 steps (15%) done
Select jobs to execute...

[Tue Nov 28 13:12:34 2023]
Job 216: working on JUN_Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 216 with external jobid 'Submitted batch job 10864224'.
[Tue Nov 28 13:12:35 2023]
Finished job 176.
94 of 632 steps (15%) done
Select jobs to execute...

[Tue Nov 28 13:12:35 2023]
Job 260: working on JUN_Cervix
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 260 with external jobid 'Submitted batch job 10864226'.
[Tue Nov 28 13:12:36 2023]
Finished job 192.
95 of 632 steps (15%) done
Select jobs to execute...

[Tue Nov 28 13:12:36 2023]
Job 276: working on JUN_Coronary-artery-smooth-muscle
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Coronary-artery-smooth-muscle.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Coronary-artery-smooth-muscle.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 276 with external jobid 'Submitted batch job 10864227'.
[Tue Nov 28 13:12:37 2023]
Finished job 178.
96 of 632 steps (15%) done
Select jobs to execute...

[Tue Nov 28 13:12:37 2023]
Job 262: working on JUN_Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 262 with external jobid 'Submitted batch job 10864228'.
[Tue Nov 28 13:12:37 2023]
Finished job 166.
97 of 632 steps (15%) done
Select jobs to execute...

[Tue Nov 28 13:12:37 2023]
Job 250: working on JUN_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 250 with external jobid 'Submitted batch job 10864229'.
[Tue Nov 28 13:12:39 2023]
Finished job 159.
98 of 632 steps (16%) done
Select jobs to execute...

[Tue Nov 28 13:12:39 2023]
Job 243: working on JUN_Lung
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 243 with external jobid 'Submitted batch job 10864231'.
[Tue Nov 28 13:12:39 2023]
Finished job 175.
99 of 632 steps (16%) done
Select jobs to execute...

[Tue Nov 28 13:12:40 2023]
Job 259: working on JUN_Embryo
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 259 with external jobid 'Submitted batch job 10864233'.
[Tue Nov 28 13:12:41 2023]
Finished job 135.
100 of 632 steps (16%) done
Select jobs to execute...

[Tue Nov 28 13:12:41 2023]
Job 219: working on JUN_Breast
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 219 with external jobid 'Submitted batch job 10864235'.
[Tue Nov 28 13:12:42 2023]
Finished job 179.
101 of 632 steps (16%) done
Select jobs to execute...

[Tue Nov 28 13:12:42 2023]
Job 263: working on JUN_Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_JUN_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_JUN_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 263 with external jobid 'Submitted batch job 10864236'.
[Tue Nov 28 13:12:43 2023]
Finished job 190.
102 of 632 steps (16%) done
Select jobs to execute...

[Tue Nov 28 13:12:43 2023]
Job 274: working on TCF4_Embryo
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_TCF4_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_TCF4_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 274 with external jobid 'Submitted batch job 10864238'.
[Tue Nov 28 13:12:44 2023]
Finished job 187.
103 of 632 steps (16%) done
Select jobs to execute...

[Tue Nov 28 13:12:44 2023]
Job 271: working on CDX2_Embryo
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CDX2_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CDX2_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 271 with external jobid 'Submitted batch job 10864239'.
[Tue Nov 28 13:12:45 2023]
Finished job 55.
104 of 632 steps (16%) done
Select jobs to execute...

[Tue Nov 28 13:12:45 2023]
Job 139: working on tf=MYC,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/MYC_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Embryo --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Embryo.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 139 with external jobid 'Submitted batch job 10864240'.
[Tue Nov 28 13:12:46 2023]
Finished job 77.
105 of 632 steps (17%) done
Select jobs to execute...

[Tue Nov 28 13:12:46 2023]
Job 161: working on tf=MYC,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/MYC_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Breast --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Breast.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 161 with external jobid 'Submitted batch job 10864242'.
[Tue Nov 28 13:12:47 2023]
Finished job 58.
106 of 632 steps (17%) done
Select jobs to execute...

[Tue Nov 28 13:12:47 2023]
Job 142: working on tf=MYC,tissue=Cervix
Reason: Input files updated by another job: data/predictor_files/MYC_Cervix.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Cervix --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Cervix.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Cervix.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 142 with external jobid 'Submitted batch job 10864244'.
[Tue Nov 28 13:12:48 2023]
Finished job 72.
107 of 632 steps (17%) done
Select jobs to execute...

[Tue Nov 28 13:12:48 2023]
Job 156: working on tf=MYC,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/MYC_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Mammary-Gland.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 156 with external jobid 'Submitted batch job 10864245'.
[Tue Nov 28 13:12:49 2023]
Finished job 60.
108 of 632 steps (17%) done
Select jobs to execute...

[Tue Nov 28 13:12:49 2023]
Job 144: working on tf=MYC,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/MYC_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Umbilical-Vein.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 144 with external jobid 'Submitted batch job 10864247'.
[Tue Nov 28 13:12:50 2023]
Finished job 116.
109 of 632 steps (17%) done
Select jobs to execute...

[Tue Nov 28 13:12:50 2023]
Job 200: working on tf=MYC,tissue=Foreskin
Reason: Input files updated by another job: data/predictor_files/MYC_Foreskin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Foreskin --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Foreskin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Foreskin.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 200 with external jobid 'Submitted batch job 10864249'.
[Tue Nov 28 13:12:51 2023]
Finished job 64.
110 of 632 steps (17%) done
Select jobs to execute...

[Tue Nov 28 13:12:51 2023]
Job 148: working on tf=MYC,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/MYC_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Lung --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Lung.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 148 with external jobid 'Submitted batch job 10864250'.
[Tue Nov 28 13:12:52 2023]
Finished job 66.
111 of 632 steps (18%) done
Select jobs to execute...

[Tue Nov 28 13:12:52 2023]
Job 150: working on tf=MYC,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/predictor_files/MYC_Embryonic-Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Embryonic-Kidney --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Embryonic-Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Embryonic-Kidney.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 150 with external jobid 'Submitted batch job 10864251'.
[Tue Nov 28 13:12:53 2023]
Finished job 122.
112 of 632 steps (18%) done
Select jobs to execute...

[Tue Nov 28 13:12:53 2023]
Job 206: working on tf=MYC,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/MYC_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Prostate --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Prostate.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 206 with external jobid 'Submitted batch job 10864253'.
[Tue Nov 28 13:12:54 2023]
Finished job 96.
113 of 632 steps (18%) done
Select jobs to execute...

[Tue Nov 28 13:12:54 2023]
Job 180: working on tf=MYC,tissue=Bone
Reason: Input files updated by another job: data/predictor_files/MYC_Bone.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Bone --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Bone.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Bone.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 180 with external jobid 'Submitted batch job 10864254'.
[Tue Nov 28 13:12:55 2023]
Finished job 61.
114 of 632 steps (18%) done
Select jobs to execute...

[Tue Nov 28 13:12:55 2023]
Job 145: working on tf=MYC,tissue=Skin
Reason: Input files updated by another job: data/predictor_files/MYC_Skin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Skin --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Skin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Skin.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 145 with external jobid 'Submitted batch job 10864256'.
[Tue Nov 28 13:12:56 2023]
Finished job 119.
115 of 632 steps (18%) done
Select jobs to execute...

[Tue Nov 28 13:12:56 2023]
Job 203: working on tf=MYC,tissue=LNCaP-cells
Reason: Input files updated by another job: data/predictor_files/MYC_LNCaP-cells.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue LNCaP-cells --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_LNCaP-cells.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_LNCaP-cells.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 203 with external jobid 'Submitted batch job 10864257'.
[Tue Nov 28 13:12:57 2023]
Finished job 59.
116 of 632 steps (18%) done
Select jobs to execute...

[Tue Nov 28 13:12:57 2023]
Job 143: working on tf=MYC,tissue=Liver
Reason: Input files updated by another job: data/predictor_files/MYC_Liver.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Liver --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Liver.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Liver.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 143 with external jobid 'Submitted batch job 10864258'.
[Tue Nov 28 13:12:58 2023]
Finished job 47.
117 of 632 steps (19%) done
Select jobs to execute...

[Tue Nov 28 13:12:58 2023]
Job 131: working on tf=MYC,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/MYC_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 131 with external jobid 'Submitted batch job 10864261'.
[Tue Nov 28 13:12:59 2023]
Finished job 49.
118 of 632 steps (19%) done
Select jobs to execute...

[Tue Nov 28 13:12:59 2023]
Job 133: working on tf=MYC,tissue=Bone-Marrow
Reason: Input files updated by another job: data/predictor_files/MYC_Bone-Marrow.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Bone-Marrow --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Bone-Marrow.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Bone-Marrow.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 133 with external jobid 'Submitted batch job 10864262'.
[Tue Nov 28 13:13:00 2023]
Finished job 79.
119 of 632 steps (19%) done
Select jobs to execute...

[Tue Nov 28 13:13:00 2023]
Job 163: working on tf=MYC,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/MYC_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 163 with external jobid 'Submitted batch job 10864263'.
[Tue Nov 28 13:13:01 2023]
Finished job 63.
120 of 632 steps (19%) done
Select jobs to execute...

[Tue Nov 28 13:13:01 2023]
Job 147: working on tf=MYC,tissue=Brain
Reason: Input files updated by another job: data/predictor_files/MYC_Brain.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor MYC --tissue Brain --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/MYC_Brain.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_MYC_Brain.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 147 with external jobid 'Submitted batch job 10864264'.
[Tue Nov 28 13:13:02 2023]
Finished job 99.
121 of 632 steps (19%) done
Select jobs to execute...

[Tue Nov 28 13:13:02 2023]
Job 183: working on tf=ASCL1,tissue=Lung
Reason: Input files updated by another job: data/predictor_files/ASCL1_Lung.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ASCL1 --tissue Lung --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/ASCL1_Lung.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ASCL1_Lung.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 183 with external jobid 'Submitted batch job 10864266'.
[Tue Nov 28 13:13:03 2023]
Finished job 85.
122 of 632 steps (19%) done
Select jobs to execute...

[Tue Nov 28 13:13:03 2023]
Job 169: working on tf=ASCL1,tissue=Skin
Reason: Input files updated by another job: data/predictor_files/ASCL1_Skin.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ASCL1 --tissue Skin --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/ASCL1_Skin.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ASCL1_Skin.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 169 with external jobid 'Submitted batch job 10864268'.
[Tue Nov 28 13:13:04 2023]
Finished job 87.
123 of 632 steps (19%) done
Select jobs to execute...

[Tue Nov 28 13:13:04 2023]
Job 171: working on tf=STAT4,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/STAT4_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT4 --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/STAT4_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 171 with external jobid 'Submitted batch job 10864269'.
[Tue Nov 28 13:13:05 2023]
Finished job 105.
124 of 632 steps (20%) done
Select jobs to execute...

[Tue Nov 28 13:13:05 2023]
Job 189: working on tf=SNAI2,tissue=Embryo
Reason: Input files updated by another job: data/predictor_files/SNAI2_Embryo.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor SNAI2 --tissue Embryo --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/SNAI2_Embryo.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_SNAI2_Embryo.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 189 with external jobid 'Submitted batch job 10864270'.
[Tue Nov 28 13:13:06 2023]
Finished job 53.
125 of 632 steps (20%) done
Select jobs to execute...

[Tue Nov 28 13:13:06 2023]
Job 137: working on tf=STAT4,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/STAT4_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT4 --tissue Blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/STAT4_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT4_Blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 137 with external jobid 'Submitted batch job 10864273'.
[Tue Nov 28 13:13:07 2023]
Finished job 88.
126 of 632 steps (20%) done
Select jobs to execute...

[Tue Nov 28 13:13:07 2023]
Job 172: working on tf=STAT6,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/STAT6_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT6 --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/STAT6_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT6_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 172 with external jobid 'Submitted batch job 10864274'.
[Tue Nov 28 13:13:08 2023]
Finished job 125.
127 of 632 steps (20%) done
Select jobs to execute...

[Tue Nov 28 13:13:08 2023]
Job 209: working on tf=STAT6,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/STAT6_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT6 --tissue Blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/STAT6_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT6_Blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 209 with external jobid 'Submitted batch job 10864275'.
[Tue Nov 28 13:13:09 2023]
Finished job 54.
128 of 632 steps (20%) done
Select jobs to execute...

[Tue Nov 28 13:13:09 2023]
Job 138: working on tf=STAT6,tissue=Cord-blood
Reason: Input files updated by another job: data/predictor_files/STAT6_Cord-blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor STAT6 --tissue Cord-blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/STAT6_Cord-blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_STAT6_Cord-blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 138 with external jobid 'Submitted batch job 10864276'.
[Tue Nov 28 13:13:10 2023]
Finished job 194.
129 of 632 steps (20%) done
Select jobs to execute...

[Tue Nov 28 13:13:10 2023]
Job 278: working on FOXO1_Endometrium
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Endometrium.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Endometrium.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 278 with external jobid 'Submitted batch job 10864278'.
[Tue Nov 28 13:13:11 2023]
Finished job 198.
130 of 632 steps (21%) done
Select jobs to execute...

[Tue Nov 28 13:13:11 2023]
Job 282: working on FOXO1_Tonsil
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Tonsil.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Tonsil.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 282 with external jobid 'Submitted batch job 10864280'.
[Tue Nov 28 13:13:12 2023]
Finished job 210.
131 of 632 steps (21%) done
Select jobs to execute...

[Tue Nov 28 13:13:12 2023]
Job 294: working on FOXO1_Cord-blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Cord-blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Cord-blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 294 with external jobid 'Submitted batch job 10864281'.
[Tue Nov 28 13:13:13 2023]
Finished job 170.
132 of 632 steps (21%) done
Select jobs to execute...

[Tue Nov 28 13:13:13 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10864282'.
[Tue Nov 28 13:13:14 2023]
Finished job 188.
133 of 632 steps (21%) done
Select jobs to execute...

[Tue Nov 28 13:13:14 2023]
Job 272: working on OTX2_Embryo
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_OTX2_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_OTX2_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 272 with external jobid 'Submitted batch job 10864285'.
[Tue Nov 28 13:13:15 2023]
Finished job 207.
134 of 632 steps (21%) done
Select jobs to execute...

[Tue Nov 28 13:13:15 2023]
Job 291: working on NEUROG2_Fetal-Lung
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_NEUROG2_Fetal-Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_NEUROG2_Fetal-Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 291 with external jobid 'Submitted batch job 10864286'.
[Tue Nov 28 13:13:16 2023]
Finished job 134.
135 of 632 steps (21%) done
Select jobs to execute...

[Tue Nov 28 13:13:16 2023]
Job 218: working on ERG_Prostate
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 218 with external jobid 'Submitted batch job 10864287'.
[Tue Nov 28 13:13:17 2023]
Finished job 27.
136 of 632 steps (22%) done
Select jobs to execute...

[Tue Nov 28 13:13:17 2023]
Job 83: working on tf=AR,tissue=Colon
Reason: Input files updated by another job: data/homer_files/AR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor AR --tissue Colon --predicted_motif_file data/homer_files/AR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/AR_Colon --predictors_file data/predictor_files/AR_Colon.predictors.txt --ground_truth_file data/predictor_files/AR_Colon.ground_truth.txt --info_file data/predictor_files/AR_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 83 with external jobid 'Submitted batch job 10864288'.

[Tue Nov 28 13:13:17 2023]
Job 97: working on tf=AR,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/homer_files/AR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor AR --tissue Embryonic-Kidney --predicted_motif_file data/homer_files/AR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/AR_Embryonic-Kidney --predictors_file data/predictor_files/AR_Embryonic-Kidney.predictors.txt --ground_truth_file data/predictor_files/AR_Embryonic-Kidney.ground_truth.txt --info_file data/predictor_files/AR_Embryonic-Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 97 with external jobid 'Submitted batch job 10864290'.

[Tue Nov 28 13:13:17 2023]
Job 118: working on tf=AR,tissue=Breast
Reason: Input files updated by another job: data/homer_files/AR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor AR --tissue Breast --predicted_motif_file data/homer_files/AR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/AR_Breast --predictors_file data/predictor_files/AR_Breast.predictors.txt --ground_truth_file data/predictor_files/AR_Breast.ground_truth.txt --info_file data/predictor_files/AR_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 118 with external jobid 'Submitted batch job 10864291'.

[Tue Nov 28 13:13:17 2023]
Job 127: working on tf=AR,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/AR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor AR --tissue Prostate --predicted_motif_file data/homer_files/AR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/AR_Prostate --predictors_file data/predictor_files/AR_Prostate.predictors.txt --ground_truth_file data/predictor_files/AR_Prostate.ground_truth.txt --info_file data/predictor_files/AR_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 127 with external jobid 'Submitted batch job 10864292'.

[Tue Nov 28 13:13:17 2023]
Job 73: working on tf=AR,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/AR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor AR --tissue Mammary-Gland --predicted_motif_file data/homer_files/AR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/AR_Mammary-Gland --predictors_file data/predictor_files/AR_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/AR_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/AR_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 73 with external jobid 'Submitted batch job 10864293'.

[Tue Nov 28 13:13:17 2023]
Job 107: working on tf=AR,tissue=Ovary
Reason: Input files updated by another job: data/homer_files/AR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor AR --tissue Ovary --predicted_motif_file data/homer_files/AR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/AR_Ovary --predictors_file data/predictor_files/AR_Ovary.predictors.txt --ground_truth_file data/predictor_files/AR_Ovary.ground_truth.txt --info_file data/predictor_files/AR_Ovary.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 107 with external jobid 'Submitted batch job 10864294'.
[Tue Nov 28 13:13:24 2023]
Finished job 112.
137 of 632 steps (22%) done
Select jobs to execute...

[Tue Nov 28 13:13:24 2023]
Job 196: working on tf=HOXB13,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/HOXB13_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor HOXB13 --tissue Prostate --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/HOXB13_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_HOXB13_Prostate.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 196 with external jobid 'Submitted batch job 10864298'.
[Tue Nov 28 13:13:26 2023]
Finished job 45.
138 of 632 steps (22%) done
Select jobs to execute...

[Tue Nov 28 13:13:26 2023]
Job 129: working on tf=CDX2,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/CDX2_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor CDX2 --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/CDX2_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_CDX2_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 129 with external jobid 'Submitted batch job 10864299'.
[Tue Nov 28 13:13:28 2023]
Finished job 23.
139 of 632 steps (22%) done
Select jobs to execute...

[Tue Nov 28 13:13:28 2023]
Job 41: working on tf=VDR data/homer_files/VDR/scanMotifsGenomeWide_vdr.txt
Reason: Input files updated by another job: data/homer_files/VDR/scanMotifsGenomeWide_vdr.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 41 with external jobid 'Submitted batch job 10864302'.
[Tue Nov 28 13:13:29 2023]
Finished job 12.
140 of 632 steps (22%) done
Select jobs to execute...

[Tue Nov 28 13:13:29 2023]
Job 24: working on tf=GRHL2 data/homer_files/GRHL2/scanMotifsGenomeWide_grhl2.txt
Reason: Missing output files: data/homer_files/GRHL2/merged_motif_file.txt; Input files updated by another job: data/homer_files/GRHL2/scanMotifsGenomeWide_grhl2.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 24 with external jobid 'Submitted batch job 10864303'.
[Tue Nov 28 13:13:30 2023]
Finished job 19.
141 of 632 steps (22%) done
Select jobs to execute...

[Tue Nov 28 13:13:30 2023]
Job 37: working on tf=PR data/homer_files/PR/scanMotifsGenomeWide_pr.txt
Reason: Missing output files: data/homer_files/PR/merged_motif_file.txt; Input files updated by another job: data/homer_files/PR/scanMotifsGenomeWide_pr.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 37 with external jobid 'Submitted batch job 10864305'.
[Tue Nov 28 13:13:31 2023]
Finished job 7.
142 of 632 steps (22%) done
Select jobs to execute...

[Tue Nov 28 13:13:31 2023]
Job 26: working on tf=ZNF382 data/homer_files/ZNF382/scanMotifsGenomeWide_znf382.txt
Reason: Missing output files: data/homer_files/ZNF382/merged_motif_file.txt; Input files updated by another job: data/homer_files/ZNF382/scanMotifsGenomeWide_znf382.txt

sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 26 with external jobid 'Submitted batch job 10864307'.
[Tue Nov 28 13:13:54 2023]
Finished job 139.
143 of 632 steps (23%) done
Select jobs to execute...

[Tue Nov 28 13:13:54 2023]
Job 223: working on MYC_Embryo
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 223 with external jobid 'Submitted batch job 10864395'.
[Tue Nov 28 13:13:55 2023]
Finished job 161.
144 of 632 steps (23%) done
Select jobs to execute...

[Tue Nov 28 13:13:55 2023]
Job 245: working on MYC_Breast
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 245 with external jobid 'Submitted batch job 10864406'.
[Tue Nov 28 13:13:56 2023]
Finished job 142.
145 of 632 steps (23%) done
Select jobs to execute...

[Tue Nov 28 13:13:56 2023]
Job 226: working on MYC_Cervix
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Cervix.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Cervix.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 226 with external jobid 'Submitted batch job 10864420'.
[Tue Nov 28 13:13:57 2023]
Finished job 156.
146 of 632 steps (23%) done
Select jobs to execute...

[Tue Nov 28 13:13:57 2023]
Job 240: working on MYC_Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 240 with external jobid 'Submitted batch job 10864421'.
[Tue Nov 28 13:13:58 2023]
Finished job 144.
147 of 632 steps (23%) done
Select jobs to execute...

[Tue Nov 28 13:13:58 2023]
Job 228: working on MYC_Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 228 with external jobid 'Submitted batch job 10864422'.
[Tue Nov 28 13:13:59 2023]
Finished job 200.
148 of 632 steps (23%) done
Select jobs to execute...

[Tue Nov 28 13:13:59 2023]
Job 284: working on MYC_Foreskin
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Foreskin.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Foreskin.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 284 with external jobid 'Submitted batch job 10864423'.
[Tue Nov 28 13:14:00 2023]
Finished job 148.
149 of 632 steps (24%) done
Select jobs to execute...

[Tue Nov 28 13:14:00 2023]
Job 232: working on MYC_Lung
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 232 with external jobid 'Submitted batch job 10864424'.
[Tue Nov 28 13:14:01 2023]
Finished job 150.
150 of 632 steps (24%) done
Select jobs to execute...

[Tue Nov 28 13:14:01 2023]
Job 234: working on MYC_Embryonic-Kidney
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Embryonic-Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Embryonic-Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 234 with external jobid 'Submitted batch job 10864426'.
[Tue Nov 28 13:14:02 2023]
Finished job 206.
151 of 632 steps (24%) done
Select jobs to execute...

[Tue Nov 28 13:14:02 2023]
Job 290: working on MYC_Prostate
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 290 with external jobid 'Submitted batch job 10864428'.
[Tue Nov 28 13:14:03 2023]
Finished job 180.
152 of 632 steps (24%) done
Select jobs to execute...

[Tue Nov 28 13:14:03 2023]
Job 264: working on MYC_Bone
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Bone.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Bone.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 264 with external jobid 'Submitted batch job 10864429'.
[Tue Nov 28 13:14:04 2023]
Finished job 145.
153 of 632 steps (24%) done
Select jobs to execute...

[Tue Nov 28 13:14:04 2023]
Job 229: working on MYC_Skin
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Skin.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Skin.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 229 with external jobid 'Submitted batch job 10864431'.
[Tue Nov 28 13:14:05 2023]
Finished job 203.
154 of 632 steps (24%) done
Select jobs to execute...

[Tue Nov 28 13:14:05 2023]
Job 287: working on MYC_LNCaP-cells
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_LNCaP-cells.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_LNCaP-cells.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 287 with external jobid 'Submitted batch job 10864432'.
[Tue Nov 28 13:14:06 2023]
Finished job 143.
155 of 632 steps (25%) done
Select jobs to execute...

[Tue Nov 28 13:14:06 2023]
Job 227: working on MYC_Liver
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Liver.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Liver.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 227 with external jobid 'Submitted batch job 10864434'.
[Tue Nov 28 13:14:07 2023]
Finished job 131.
156 of 632 steps (25%) done
Select jobs to execute...

[Tue Nov 28 13:14:07 2023]
Job 215: working on MYC_Blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 215 with external jobid 'Submitted batch job 10864436'.
[Tue Nov 28 13:14:08 2023]
Finished job 133.
157 of 632 steps (25%) done
Select jobs to execute...

[Tue Nov 28 13:14:08 2023]
Job 217: working on MYC_Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Bone-Marrow.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Bone-Marrow.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 217 with external jobid 'Submitted batch job 10864437'.
[Tue Nov 28 13:14:09 2023]
Finished job 163.
158 of 632 steps (25%) done
Select jobs to execute...

[Tue Nov 28 13:14:09 2023]
Job 247: working on MYC_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 247 with external jobid 'Submitted batch job 10864438'.
[Tue Nov 28 13:14:10 2023]
Finished job 147.
159 of 632 steps (25%) done
Select jobs to execute...

[Tue Nov 28 13:14:10 2023]
Job 231: working on MYC_Brain
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_MYC_Brain.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_MYC_Brain.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 231 with external jobid 'Submitted batch job 10864441'.
[Tue Nov 28 13:14:11 2023]
Finished job 183.
160 of 632 steps (25%) done
Select jobs to execute...

[Tue Nov 28 13:14:11 2023]
Job 267: working on ASCL1_Lung
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ASCL1_Lung.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ASCL1_Lung.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 267 with external jobid 'Submitted batch job 10864443'.
[Tue Nov 28 13:14:12 2023]
Finished job 169.
161 of 632 steps (25%) done
Select jobs to execute...

[Tue Nov 28 13:14:12 2023]
Job 253: working on ASCL1_Skin
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ASCL1_Skin.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ASCL1_Skin.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 253 with external jobid 'Submitted batch job 10864444'.
[Tue Nov 28 13:14:13 2023]
Finished job 171.
162 of 632 steps (26%) done
Select jobs to execute...

[Tue Nov 28 13:14:13 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10864445'.
[Tue Nov 28 13:14:14 2023]
Finished job 189.
163 of 632 steps (26%) done
Select jobs to execute...

[Tue Nov 28 13:14:14 2023]
Job 273: working on SNAI2_Embryo
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_SNAI2_Embryo.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_SNAI2_Embryo.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 273 with external jobid 'Submitted batch job 10864450'.
[Tue Nov 28 13:14:15 2023]
Finished job 137.
164 of 632 steps (26%) done
Select jobs to execute...

[Tue Nov 28 13:14:15 2023]
Job 221: working on STAT4_Blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 221 with external jobid 'Submitted batch job 10864451'.
[Tue Nov 28 13:14:16 2023]
Finished job 172.
165 of 632 steps (26%) done
Select jobs to execute...

[Tue Nov 28 13:14:16 2023]
Job 256: working on STAT6_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT6_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT6_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 256 with external jobid 'Submitted batch job 10864452'.
[Tue Nov 28 13:14:17 2023]
Finished job 209.
166 of 632 steps (26%) done
Select jobs to execute...

[Tue Nov 28 13:14:17 2023]
Job 293: working on STAT6_Blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT6_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT6_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 293 with external jobid 'Submitted batch job 10864453'.
[Tue Nov 28 13:14:18 2023]
Finished job 138.
167 of 632 steps (26%) done
Select jobs to execute...

[Tue Nov 28 13:14:18 2023]
Job 222: working on STAT6_Cord-blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT6_Cord-blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT6_Cord-blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 222 with external jobid 'Submitted batch job 10864455'.
[Tue Nov 28 13:14:26 2023]
Finished job 83.
168 of 632 steps (27%) done
Select jobs to execute...

[Tue Nov 28 13:14:26 2023]
Job 167: working on tf=AR,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/AR_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor AR --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/AR_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_AR_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 167 with external jobid 'Submitted batch job 10864459'.
[Tue Nov 28 13:14:27 2023]
Finished job 97.
169 of 632 steps (27%) done
Select jobs to execute...

[Tue Nov 28 13:14:27 2023]
Job 181: working on tf=AR,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/predictor_files/AR_Embryonic-Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor AR --tissue Embryonic-Kidney --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/AR_Embryonic-Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_AR_Embryonic-Kidney.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 181 with external jobid 'Submitted batch job 10864461'.
[Tue Nov 28 13:14:28 2023]
Finished job 118.
170 of 632 steps (27%) done
Select jobs to execute...

[Tue Nov 28 13:14:28 2023]
Job 202: working on tf=AR,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/AR_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor AR --tissue Breast --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/AR_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_AR_Breast.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 202 with external jobid 'Submitted batch job 10864463'.
[Tue Nov 28 13:14:30 2023]
Finished job 73.
171 of 632 steps (27%) done
Select jobs to execute...

[Tue Nov 28 13:14:30 2023]
Job 157: working on tf=AR,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/AR_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor AR --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/AR_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_AR_Mammary-Gland.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 157 with external jobid 'Submitted batch job 10864464'.
[Tue Nov 28 13:14:31 2023]
Finished job 107.
172 of 632 steps (27%) done
Select jobs to execute...

[Tue Nov 28 13:14:31 2023]
Job 191: working on tf=AR,tissue=Ovary
Reason: Input files updated by another job: data/predictor_files/AR_Ovary.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor AR --tissue Ovary --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/AR_Ovary.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_AR_Ovary.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 191 with external jobid 'Submitted batch job 10864465'.
[Tue Nov 28 13:14:32 2023]
Finished job 196.
173 of 632 steps (27%) done
Select jobs to execute...

[Tue Nov 28 13:14:32 2023]
Job 280: working on HOXB13_Prostate
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HOXB13_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HOXB13_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 280 with external jobid 'Submitted batch job 10864466'.
[Tue Nov 28 13:14:33 2023]
Finished job 129.
174 of 632 steps (28%) done
Select jobs to execute...

[Tue Nov 28 13:14:33 2023]
Job 213: working on CDX2_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_CDX2_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_CDX2_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 213 with external jobid 'Submitted batch job 10864467'.
[Tue Nov 28 13:14:34 2023]
Finished job 41.
175 of 632 steps (28%) done
Select jobs to execute...

[Tue Nov 28 13:14:34 2023]
Job 46: working on tf=VDR,tissue=Blood
Reason: Input files updated by another job: data/homer_files/VDR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor VDR --tissue Blood --predicted_motif_file data/homer_files/VDR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/VDR_Blood --predictors_file data/predictor_files/VDR_Blood.predictors.txt --ground_truth_file data/predictor_files/VDR_Blood.ground_truth.txt --info_file data/predictor_files/VDR_Blood.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 46 with external jobid 'Submitted batch job 10864468'.

[Tue Nov 28 13:14:34 2023]
Job 111: working on tf=VDR,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/VDR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor VDR --tissue Prostate --predicted_motif_file data/homer_files/VDR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/VDR_Prostate --predictors_file data/predictor_files/VDR_Prostate.predictors.txt --ground_truth_file data/predictor_files/VDR_Prostate.ground_truth.txt --info_file data/predictor_files/VDR_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 111 with external jobid 'Submitted batch job 10864470'.

[Tue Nov 28 13:14:34 2023]
Job 57: working on tf=VDR,tissue=Colon
Reason: Input files updated by another job: data/homer_files/VDR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor VDR --tissue Colon --predicted_motif_file data/homer_files/VDR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/VDR_Colon --predictors_file data/predictor_files/VDR_Colon.predictors.txt --ground_truth_file data/predictor_files/VDR_Colon.ground_truth.txt --info_file data/predictor_files/VDR_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 57 with external jobid 'Submitted batch job 10864471'.
[Tue Nov 28 13:14:35 2023]
Finished job 24.
176 of 632 steps (28%) done
Select jobs to execute...

[Tue Nov 28 13:14:35 2023]
Job 89: working on tf=GRHL2,tissue=Colon
Reason: Input files updated by another job: data/homer_files/GRHL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GRHL2 --tissue Colon --predicted_motif_file data/homer_files/GRHL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GRHL2_Colon --predictors_file data/predictor_files/GRHL2_Colon.predictors.txt --ground_truth_file data/predictor_files/GRHL2_Colon.ground_truth.txt --info_file data/predictor_files/GRHL2_Colon.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 89 with external jobid 'Submitted batch job 10864472'.

[Tue Nov 28 13:14:36 2023]
Job 120: working on tf=GRHL2,tissue=Breast
Reason: Input files updated by another job: data/homer_files/GRHL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GRHL2 --tissue Breast --predicted_motif_file data/homer_files/GRHL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GRHL2_Breast --predictors_file data/predictor_files/GRHL2_Breast.predictors.txt --ground_truth_file data/predictor_files/GRHL2_Breast.ground_truth.txt --info_file data/predictor_files/GRHL2_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 120 with external jobid 'Submitted batch job 10864473'.

[Tue Nov 28 13:14:36 2023]
Job 69: working on tf=GRHL2,tissue=Bronchia
Reason: Input files updated by another job: data/homer_files/GRHL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GRHL2 --tissue Bronchia --predicted_motif_file data/homer_files/GRHL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GRHL2_Bronchia --predictors_file data/predictor_files/GRHL2_Bronchia.predictors.txt --ground_truth_file data/predictor_files/GRHL2_Bronchia.ground_truth.txt --info_file data/predictor_files/GRHL2_Bronchia.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 69 with external jobid 'Submitted batch job 10864474'.

[Tue Nov 28 13:14:36 2023]
Job 121: working on tf=GRHL2,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/GRHL2/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor GRHL2 --tissue Prostate --predicted_motif_file data/homer_files/GRHL2/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/GRHL2_Prostate --predictors_file data/predictor_files/GRHL2_Prostate.predictors.txt --ground_truth_file data/predictor_files/GRHL2_Prostate.ground_truth.txt --info_file data/predictor_files/GRHL2_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 121 with external jobid 'Submitted batch job 10864475'.
[Tue Nov 28 13:14:36 2023]
Finished job 37.
177 of 632 steps (28%) done
Select jobs to execute...

[Tue Nov 28 13:14:36 2023]
Job 102: working on tf=PR,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/PR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor PR --tissue Prostate --predicted_motif_file data/homer_files/PR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/PR_Prostate --predictors_file data/predictor_files/PR_Prostate.predictors.txt --ground_truth_file data/predictor_files/PR_Prostate.ground_truth.txt --info_file data/predictor_files/PR_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 102 with external jobid 'Submitted batch job 10864476'.

[Tue Nov 28 13:14:36 2023]
Job 84: working on tf=PR,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/homer_files/PR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor PR --tissue Umbilical-Vein --predicted_motif_file data/homer_files/PR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/PR_Umbilical-Vein --predictors_file data/predictor_files/PR_Umbilical-Vein.predictors.txt --ground_truth_file data/predictor_files/PR_Umbilical-Vein.ground_truth.txt --info_file data/predictor_files/PR_Umbilical-Vein.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 84 with external jobid 'Submitted batch job 10864477'.

[Tue Nov 28 13:14:36 2023]
Job 65: working on tf=PR,tissue=Mammary-Gland
Reason: Input files updated by another job: data/homer_files/PR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor PR --tissue Mammary-Gland --predicted_motif_file data/homer_files/PR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/PR_Mammary-Gland --predictors_file data/predictor_files/PR_Mammary-Gland.predictors.txt --ground_truth_file data/predictor_files/PR_Mammary-Gland.ground_truth.txt --info_file data/predictor_files/PR_Mammary-Gland.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 65 with external jobid 'Submitted batch job 10864478'.

[Tue Nov 28 13:14:36 2023]
Job 109: working on tf=PR,tissue=Breast
Reason: Input files updated by another job: data/homer_files/PR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor PR --tissue Breast --predicted_motif_file data/homer_files/PR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/PR_Breast --predictors_file data/predictor_files/PR_Breast.predictors.txt --ground_truth_file data/predictor_files/PR_Breast.ground_truth.txt --info_file data/predictor_files/PR_Breast.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 109 with external jobid 'Submitted batch job 10864479'.
[Tue Nov 28 13:14:56 2023]
Finished job 26.
178 of 632 steps (28%) done
Select jobs to execute...

[Tue Nov 28 13:14:56 2023]
Job 115: working on tf=ZNF382,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/homer_files/ZNF382/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor ZNF382 --tissue Embryonic-Kidney --predicted_motif_file data/homer_files/ZNF382/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/ZNF382_Embryonic-Kidney --predictors_file data/predictor_files/ZNF382_Embryonic-Kidney.predictors.txt --ground_truth_file data/predictor_files/ZNF382_Embryonic-Kidney.ground_truth.txt --info_file data/predictor_files/ZNF382_Embryonic-Kidney.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 115 with external jobid 'Submitted batch job 10864489'.
[Tue Nov 28 13:15:31 2023]
Finished job 167.
179 of 632 steps (28%) done
Select jobs to execute...

[Tue Nov 28 13:15:31 2023]
Job 251: working on AR_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_AR_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_AR_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 251 with external jobid 'Submitted batch job 10864504'.
[Tue Nov 28 13:15:32 2023]
Finished job 181.
180 of 632 steps (28%) done
Select jobs to execute...

[Tue Nov 28 13:15:32 2023]
Job 265: working on AR_Embryonic-Kidney
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_AR_Embryonic-Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_AR_Embryonic-Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 265 with external jobid 'Submitted batch job 10864505'.
[Tue Nov 28 13:15:33 2023]
Finished job 202.
181 of 632 steps (29%) done
Select jobs to execute...

[Tue Nov 28 13:15:33 2023]
Job 286: working on AR_Breast
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_AR_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_AR_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 286 with external jobid 'Submitted batch job 10864506'.
[Tue Nov 28 13:15:34 2023]
Finished job 157.
182 of 632 steps (29%) done
Select jobs to execute...

[Tue Nov 28 13:15:34 2023]
Job 241: working on AR_Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_AR_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_AR_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 241 with external jobid 'Submitted batch job 10864507'.
[Tue Nov 28 13:15:35 2023]
Finished job 191.
183 of 632 steps (29%) done
Select jobs to execute...

[Tue Nov 28 13:15:35 2023]
Job 275: working on AR_Ovary
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_AR_Ovary.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_AR_Ovary.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 275 with external jobid 'Submitted batch job 10864508'.
[Tue Nov 28 13:15:39 2023]
Finished job 111.
184 of 632 steps (29%) done
Select jobs to execute...

[Tue Nov 28 13:15:39 2023]
Job 195: working on tf=VDR,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/VDR_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor VDR --tissue Prostate --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/VDR_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_VDR_Prostate.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 195 with external jobid 'Submitted batch job 10864509'.
[Tue Nov 28 13:15:40 2023]
Finished job 57.
185 of 632 steps (29%) done
Select jobs to execute...

[Tue Nov 28 13:15:40 2023]
Job 141: working on tf=VDR,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/VDR_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor VDR --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/VDR_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_VDR_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 141 with external jobid 'Submitted batch job 10864511'.
[Tue Nov 28 13:15:41 2023]
Finished job 89.
186 of 632 steps (29%) done
Select jobs to execute...

[Tue Nov 28 13:15:41 2023]
Job 173: working on tf=GRHL2,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/GRHL2_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GRHL2 --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/GRHL2_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 173 with external jobid 'Submitted batch job 10864512'.
[Tue Nov 28 13:15:42 2023]
Finished job 120.
187 of 632 steps (30%) done
Select jobs to execute...

[Tue Nov 28 13:15:42 2023]
Job 204: working on tf=GRHL2,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/GRHL2_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GRHL2 --tissue Breast --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/GRHL2_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Breast.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 204 with external jobid 'Submitted batch job 10864513'.
[Tue Nov 28 13:15:43 2023]
Finished job 69.
188 of 632 steps (30%) done
Select jobs to execute...

[Tue Nov 28 13:15:43 2023]
Job 153: working on tf=GRHL2,tissue=Bronchia
Reason: Input files updated by another job: data/predictor_files/GRHL2_Bronchia.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GRHL2 --tissue Bronchia --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/GRHL2_Bronchia.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Bronchia.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 153 with external jobid 'Submitted batch job 10864514'.
[Tue Nov 28 13:15:44 2023]
Finished job 121.
189 of 632 steps (30%) done
Select jobs to execute...

[Tue Nov 28 13:15:44 2023]
Job 205: working on tf=GRHL2,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/GRHL2_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor GRHL2 --tissue Prostate --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/GRHL2_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Prostate.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 205 with external jobid 'Submitted batch job 10864516'.
[Tue Nov 28 13:15:45 2023]
Finished job 102.
190 of 632 steps (30%) done
Select jobs to execute...

[Tue Nov 28 13:15:45 2023]
Job 186: working on tf=PR,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/PR_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor PR --tissue Prostate --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/PR_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_PR_Prostate.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 186 with external jobid 'Submitted batch job 10864518'.
[Tue Nov 28 13:15:46 2023]
Finished job 84.
191 of 632 steps (30%) done
Select jobs to execute...

[Tue Nov 28 13:15:46 2023]
Job 168: working on tf=PR,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/predictor_files/PR_Umbilical-Vein.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor PR --tissue Umbilical-Vein --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/PR_Umbilical-Vein.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_PR_Umbilical-Vein.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 168 with external jobid 'Submitted batch job 10864519'.
[Tue Nov 28 13:16:29 2023]
Finished job 115.
192 of 632 steps (30%) done
Select jobs to execute...

[Tue Nov 28 13:16:29 2023]
Job 199: working on tf=ZNF382,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/predictor_files/ZNF382_Embryonic-Kidney.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor ZNF382 --tissue Embryonic-Kidney --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/ZNF382_Embryonic-Kidney.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_ZNF382_Embryonic-Kidney.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 199 with external jobid 'Submitted batch job 10864535'.
[Tue Nov 28 13:16:44 2023]
Finished job 195.
193 of 632 steps (31%) done
Select jobs to execute...

[Tue Nov 28 13:16:44 2023]
Job 279: working on VDR_Prostate
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_VDR_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_VDR_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 279 with external jobid 'Submitted batch job 10864543'.
[Tue Nov 28 13:16:45 2023]
Finished job 141.
194 of 632 steps (31%) done
Select jobs to execute...

[Tue Nov 28 13:16:45 2023]
Job 225: working on VDR_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_VDR_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_VDR_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 225 with external jobid 'Submitted batch job 10864544'.
[Tue Nov 28 13:16:46 2023]
Finished job 173.
195 of 632 steps (31%) done
Select jobs to execute...

[Tue Nov 28 13:16:46 2023]
Job 257: working on GRHL2_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 257 with external jobid 'Submitted batch job 10864546'.
[Tue Nov 28 13:16:47 2023]
Finished job 204.
196 of 632 steps (31%) done
Select jobs to execute...

[Tue Nov 28 13:16:47 2023]
Job 288: working on GRHL2_Breast
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 288 with external jobid 'Submitted batch job 10864548'.
[Tue Nov 28 13:16:48 2023]
Finished job 153.
197 of 632 steps (31%) done
Select jobs to execute...

[Tue Nov 28 13:16:48 2023]
Job 237: working on GRHL2_Bronchia
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Bronchia.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Bronchia.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 237 with external jobid 'Submitted batch job 10864550'.
[Tue Nov 28 13:16:49 2023]
Finished job 205.
198 of 632 steps (31%) done
Select jobs to execute...

[Tue Nov 28 13:16:49 2023]
Job 289: working on GRHL2_Prostate
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_GRHL2_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 289 with external jobid 'Submitted batch job 10864551'.
[Tue Nov 28 13:16:50 2023]
Finished job 186.
199 of 632 steps (31%) done
Select jobs to execute...

[Tue Nov 28 13:16:50 2023]
Job 270: working on PR_Prostate
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_PR_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_PR_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 270 with external jobid 'Submitted batch job 10864552'.
[Tue Nov 28 13:16:51 2023]
Finished job 168.
200 of 632 steps (32%) done
Select jobs to execute...

[Tue Nov 28 13:16:51 2023]
Job 252: working on PR_Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_PR_Umbilical-Vein.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_PR_Umbilical-Vein.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 252 with external jobid 'Submitted batch job 10864553'.
[Tue Nov 28 13:17:19 2023]
Finished job 46.
201 of 632 steps (32%) done
Select jobs to execute...

[Tue Nov 28 13:17:19 2023]
Job 130: working on tf=VDR,tissue=Blood
Reason: Input files updated by another job: data/predictor_files/VDR_Blood.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor VDR --tissue Blood --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/VDR_Blood.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_VDR_Blood.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 130 with external jobid 'Submitted batch job 10864570'.
[Tue Nov 28 13:17:20 2023]
Finished job 65.
202 of 632 steps (32%) done
Select jobs to execute...

[Tue Nov 28 13:17:20 2023]
Job 149: working on tf=PR,tissue=Mammary-Gland
Reason: Input files updated by another job: data/predictor_files/PR_Mammary-Gland.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor PR --tissue Mammary-Gland --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/PR_Mammary-Gland.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_PR_Mammary-Gland.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 149 with external jobid 'Submitted batch job 10864571'.
[Tue Nov 28 13:17:21 2023]
Finished job 109.
203 of 632 steps (32%) done
Select jobs to execute...

[Tue Nov 28 13:17:21 2023]
Job 193: working on tf=PR,tissue=Breast
Reason: Input files updated by another job: data/predictor_files/PR_Breast.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor PR --tissue Breast --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/PR_Breast.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_PR_Breast.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 193 with external jobid 'Submitted batch job 10864572'.
[Tue Nov 28 13:18:02 2023]
Finished job 199.
204 of 632 steps (32%) done
Select jobs to execute...

[Tue Nov 28 13:18:02 2023]
Job 283: working on ZNF382_Embryonic-Kidney
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ZNF382_Embryonic-Kidney.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ZNF382_Embryonic-Kidney.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 283 with external jobid 'Submitted batch job 10864588'.
[Tue Nov 28 13:18:20 2023]
Finished job 130.
205 of 632 steps (32%) done
Select jobs to execute...

[Tue Nov 28 13:18:20 2023]
Job 214: working on VDR_Blood
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_VDR_Blood.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_VDR_Blood.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 214 with external jobid 'Submitted batch job 10864592'.
[Tue Nov 28 13:18:21 2023]
Finished job 149.
206 of 632 steps (33%) done
Select jobs to execute...

[Tue Nov 28 13:18:21 2023]
Job 233: working on PR_Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_PR_Mammary-Gland.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_PR_Mammary-Gland.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 233 with external jobid 'Submitted batch job 10864594'.
[Tue Nov 28 13:18:22 2023]
Finished job 193.
207 of 632 steps (33%) done
Select jobs to execute...

[Tue Nov 28 13:18:22 2023]
Job 277: working on PR_Breast
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_PR_Breast.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_PR_Breast.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 277 with external jobid 'Submitted batch job 10864597'.
[Tue Nov 28 13:27:19 2023]
Finished job 44.
208 of 632 steps (33%) done
Select jobs to execute...

[Tue Nov 28 13:27:19 2023]
Job 128: working on tf=TCF4,tissue=Colon
Reason: Input files updated by another job: data/predictor_files/TCF4_Colon.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor TCF4 --tissue Colon --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/TCF4_Colon.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_TCF4_Colon.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 128 with external jobid 'Submitted batch job 10864855'.
[Tue Nov 28 13:27:31 2023]
Finished job 128.
209 of 632 steps (33%) done
Select jobs to execute...

[Tue Nov 28 13:27:31 2023]
Job 212: working on TCF4_Colon
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_TCF4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_TCF4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 212 with external jobid 'Submitted batch job 10864859'.
[Tue Nov 28 13:33:32 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10863918

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10863918, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.
Select jobs to execute...

[Tue Nov 28 13:33:32 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10864959'.
[Tue Nov 28 13:50:19 2023]
Error in rule create_training_set:
    jobid: 127
    input: data/homer_files/AR/merged_motif_file.txt
    output: data/predictor_files/AR_Prostate.predictors.txt, data/predictor_files/AR_Prostate.ground_truth.txt, data/predictor_files/AR_Prostate.info.txt.gz
    shell:
        
        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor AR --tissue Prostate --predicted_motif_file data/homer_files/AR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/AR_Prostate --predictors_file data/predictor_files/AR_Prostate.predictors.txt --ground_truth_file data/predictor_files/AR_Prostate.ground_truth.txt --info_file data/predictor_files/AR_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10864292

Error executing rule create_training_set on cluster (jobid: 127, external: Submitted batch job 10864292, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.create_training_set.127.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 127.
Select jobs to execute...

[Tue Nov 28 13:50:19 2023]
Job 127: working on tf=AR,tissue=Prostate
Reason: Input files updated by another job: data/homer_files/AR/merged_motif_file.txt


        /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_training_sets_bb.R --transcription_factor AR --tissue Prostate --predicted_motif_file data/homer_files/AR/merged_motif_file.txt --bedfiles_directory /project2/haky/Data/TFXcan/cistrome/raw/human_factor --bedlinks_directory data/bed_links/AR_Prostate --predictors_file data/predictor_files/AR_Prostate.predictors.txt --ground_truth_file data/predictor_files/AR_Prostate.ground_truth.txt --info_file data/predictor_files/AR_Prostate.info.txt.gz --cistrome_metadata_file /project2/haky/Data/TFXcan/cistrome/raw/human_factor_full_QC.txt; sleep 5
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: caslake
sbatch: QOS-Flag: caslake
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 127 with external jobid 'Submitted batch job 10866155'.
[Tue Nov 28 13:56:44 2023]
Finished job 230.
210 of 632 steps (33%) done
Select jobs to execute...

[Tue Nov 28 13:56:45 2023]
Job 314: working on tf=HIF1A,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 314 with external jobid 'Submitted batch job 10866389'.
[Tue Nov 28 13:59:52 2023]
Finished job 258.
211 of 632 steps (33%) done
Select jobs to execute...

[Tue Nov 28 13:59:52 2023]
Job 342: working on tf=HIF1A,tissue=Kidney
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 342 with external jobid 'Submitted batch job 10866562'.
[Tue Nov 28 14:00:07 2023]
Finished job 314.
212 of 632 steps (34%) done
Select jobs to execute...

[Tue Nov 28 14:00:07 2023]
Job 398: preparing tf=HIF1A,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: data/predictor_files/HIF1A_Umbilical-Vein.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HIF1A_Umbilical-Vein.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HIF1A_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/HIF1A_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 398 with external jobid 'Submitted batch job 10866565'.
[Tue Nov 28 14:01:26 2023]
Finished job 292.
213 of 632 steps (34%) done
Select jobs to execute...

[Tue Nov 28 14:01:26 2023]
Job 376: working on tf=HIF1A,tissue=Bone
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Bone.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 376 with external jobid 'Submitted batch job 10866628'.
[Tue Nov 28 14:01:39 2023]
Finished job 398.
214 of 632 steps (34%) done
Select jobs to execute...

[Tue Nov 28 14:01:39 2023]
Job 482: training on tf=HIF1A,tissue=Umbilical-Vein training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_HIF1A_Umbilical-Vein_2023-11-14/aggByCollect_HIF1A_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 482 with external jobid 'Submitted batch job 10866689'.
[Tue Nov 28 14:02:59 2023]
Finished job 266.
215 of 632 steps (34%) done
Select jobs to execute...

[Tue Nov 28 14:02:59 2023]
Job 350: working on tf=HIF1A,tissue=Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 350 with external jobid 'Submitted batch job 10866693'.
[Tue Nov 28 14:03:12 2023]
Finished job 482.
216 of 632 steps (34%) done
Select jobs to execute...

[Tue Nov 28 14:03:12 2023]
Job 566: evaluating on tf=HIF1A,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Umbilical-Vein.prepared.csv.gz, output/models/cistrome_HIF1A_Umbilical-Vein_2023-11-14/aggByCollect_HIF1A_Umbilical-Vein.logistic.rds, output/models/cistrome_HIF1A_Umbilical-Vein_2023-11-14/aggByCollect_HIF1A_Umbilical-Vein.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HIF1A_Umbilical-Vein_2023-11-14/aggByCollect_HIF1A_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_HIF1A_Umbilical-Vein_2023-11-14/aggByCollect_HIF1A_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_HIF1A_Umbilical-Vein_2023-11-14/aggByCollect_HIF1A_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 566 with external jobid 'Submitted batch job 10866695'.
[Tue Nov 28 14:03:14 2023]
Finished job 376.
217 of 632 steps (34%) done
Select jobs to execute...

[Tue Nov 28 14:03:14 2023]
Job 460: preparing tf=HIF1A,tissue=Bone training and test data
Reason: Input files updated by another job: data/predictor_files/HIF1A_Bone.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HIF1A_Bone.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HIF1A_Bone.csv.gz --ground_truth_file data/predictor_files/HIF1A_Bone.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Bone.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Bone.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 460 with external jobid 'Submitted batch job 10866696'.
[Tue Nov 28 14:03:15 2023]
Finished job 342.
218 of 632 steps (34%) done
Select jobs to execute...

[Tue Nov 28 14:03:15 2023]
Job 426: preparing tf=HIF1A,tissue=Kidney training and test data
Reason: Input files updated by another job: data/predictor_files/HIF1A_Kidney.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HIF1A_Kidney.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HIF1A_Kidney.csv.gz --ground_truth_file data/predictor_files/HIF1A_Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 426 with external jobid 'Submitted batch job 10866697'.
[Tue Nov 28 14:04:34 2023]
Finished job 285.
219 of 632 steps (35%) done
Select jobs to execute...

[Tue Nov 28 14:04:34 2023]
Job 369: working on tf=HIF1A,tissue=Lung
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 369 with external jobid 'Submitted batch job 10866728'.
[Tue Nov 28 14:04:45 2023]
Finished job 566.
220 of 632 steps (35%) done
[Tue Nov 28 14:04:46 2023]
Finished job 460.
221 of 632 steps (35%) done
Select jobs to execute...

[Tue Nov 28 14:04:46 2023]
Job 544: training on tf=HIF1A,tissue=Bone training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Bone.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Bone.prepared.csv.gz --rds_file output/models/cistrome_HIF1A_Bone_2023-11-14/aggByCollect_HIF1A_Bone --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 544 with external jobid 'Submitted batch job 10866760'.
[Tue Nov 28 14:04:47 2023]
Finished job 426.
222 of 632 steps (35%) done
Select jobs to execute...
[Tue Nov 28 14:06:18 2023]
Finished job 544.
223 of 632 steps (35%) done

[Tue Nov 28 14:06:18 2023]
Job 510: training on tf=HIF1A,tissue=Kidney training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Kidney.prepared.csv.gz --rds_file output/models/cistrome_HIF1A_Kidney_2023-11-14/aggByCollect_HIF1A_Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 510 with external jobid 'Submitted batch job 10867013'.

[Tue Nov 28 14:06:19 2023]
Job 628: evaluating on tf=HIF1A,tissue=Bone training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Bone.prepared.csv.gz, output/models/cistrome_HIF1A_Bone_2023-11-14/aggByCollect_HIF1A_Bone.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Bone.prepared.csv.gz, output/models/cistrome_HIF1A_Bone_2023-11-14/aggByCollect_HIF1A_Bone.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HIF1A_Bone_2023-11-14/aggByCollect_HIF1A_Bone.linear.rds --logistic_model output/models/cistrome_HIF1A_Bone_2023-11-14/aggByCollect_HIF1A_Bone.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Bone.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Bone.prepared.csv.gz --eval_output output/models_eval/cistrome_HIF1A_Bone_2023-11-14/aggByCollect_HIF1A_Bone
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 628 with external jobid 'Submitted batch job 10867014'.
[Tue Nov 28 14:07:49 2023]
Finished job 510.
224 of 632 steps (35%) done
Select jobs to execute...

[Tue Nov 28 14:07:49 2023]
Job 594: evaluating on tf=HIF1A,tissue=Kidney training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Kidney.prepared.csv.gz, output/models/cistrome_HIF1A_Kidney_2023-11-14/aggByCollect_HIF1A_Kidney.linear.rds, output/models/cistrome_HIF1A_Kidney_2023-11-14/aggByCollect_HIF1A_Kidney.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HIF1A_Kidney_2023-11-14/aggByCollect_HIF1A_Kidney.linear.rds --logistic_model output/models/cistrome_HIF1A_Kidney_2023-11-14/aggByCollect_HIF1A_Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_HIF1A_Kidney_2023-11-14/aggByCollect_HIF1A_Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 594 with external jobid 'Submitted batch job 10867075'.
[Tue Nov 28 14:07:50 2023]
Finished job 628.
225 of 632 steps (36%) done
[Tue Nov 28 14:07:51 2023]
Finished job 369.
226 of 632 steps (36%) done
Select jobs to execute...

[Tue Nov 28 14:07:51 2023]
Job 453: preparing tf=HIF1A,tissue=Lung training and test data
Reason: Input files updated by another job: data/predictor_files/HIF1A_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HIF1A_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HIF1A_Lung.csv.gz --ground_truth_file data/predictor_files/HIF1A_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 453 with external jobid 'Submitted batch job 10867076'.
[Tue Nov 28 14:09:10 2023]
Finished job 281.
227 of 632 steps (36%) done
Select jobs to execute...

[Tue Nov 28 14:09:10 2023]
Job 365: working on tf=HIF1A,tissue=Cervix
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 365 with external jobid 'Submitted batch job 10867080'.
[Tue Nov 28 14:09:21 2023]
Finished job 594.
228 of 632 steps (36%) done
[Tue Nov 28 14:09:22 2023]
Finished job 453.
229 of 632 steps (36%) done
Select jobs to execute...

[Tue Nov 28 14:09:22 2023]
Job 537: training on tf=HIF1A,tissue=Lung training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Lung.prepared.csv.gz --rds_file output/models/cistrome_HIF1A_Lung_2023-11-14/aggByCollect_HIF1A_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 537 with external jobid 'Submitted batch job 10867082'.
[Tue Nov 28 14:09:24 2023]
Finished job 350.
230 of 632 steps (36%) done
Select jobs to execute...

[Tue Nov 28 14:09:24 2023]
Job 434: preparing tf=HIF1A,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: data/predictor_files/HIF1A_Mammary-Gland.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HIF1A_Mammary-Gland.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HIF1A_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/HIF1A_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 434 with external jobid 'Submitted batch job 10867083'.
[Tue Nov 28 14:10:52 2023]
Finished job 537.
231 of 632 steps (37%) done
Select jobs to execute...

[Tue Nov 28 14:10:53 2023]
Job 621: evaluating on tf=HIF1A,tissue=Lung training and test data
Reason: Input files updated by another job: output/models/cistrome_HIF1A_Lung_2023-11-14/aggByCollect_HIF1A_Lung.logistic.rds, output/models/cistrome_HIF1A_Lung_2023-11-14/aggByCollect_HIF1A_Lung.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Lung.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HIF1A_Lung_2023-11-14/aggByCollect_HIF1A_Lung.linear.rds --logistic_model output/models/cistrome_HIF1A_Lung_2023-11-14/aggByCollect_HIF1A_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_HIF1A_Lung_2023-11-14/aggByCollect_HIF1A_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 621 with external jobid 'Submitted batch job 10867089'.
[Tue Nov 28 14:10:53 2023]
Finished job 434.
232 of 632 steps (37%) done
Select jobs to execute...

[Tue Nov 28 14:10:54 2023]
Job 518: training on tf=HIF1A,tissue=Mammary-Gland training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_HIF1A_Mammary-Gland_2023-11-14/aggByCollect_HIF1A_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 518 with external jobid 'Submitted batch job 10867090'.
[Tue Nov 28 14:12:02 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10864118

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10864118, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.
Select jobs to execute...

[Tue Nov 28 14:12:03 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10867094'.
[Tue Nov 28 14:12:23 2023]
Finished job 621.
233 of 632 steps (37%) done
[Tue Nov 28 14:12:25 2023]
Finished job 365.
234 of 632 steps (37%) done
Select jobs to execute...

[Tue Nov 28 14:12:26 2023]
Job 449: preparing tf=HIF1A,tissue=Cervix training and test data
Reason: Input files updated by another job: data/predictor_files/HIF1A_Cervix.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HIF1A_Cervix.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HIF1A_Cervix.csv.gz --ground_truth_file data/predictor_files/HIF1A_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 449 with external jobid 'Submitted batch job 10867152'.
[Tue Nov 28 14:13:53 2023]
Finished job 449.
235 of 632 steps (37%) done
Select jobs to execute...
[Tue Nov 28 14:16:50 2023]
Finished job 518.
236 of 632 steps (37%) done

[Tue Nov 28 14:16:50 2023]
Job 602: evaluating on tf=HIF1A,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Mammary-Gland.prepared.csv.gz, output/models/cistrome_HIF1A_Mammary-Gland_2023-11-14/aggByCollect_HIF1A_Mammary-Gland.logistic.rds, output/models/cistrome_HIF1A_Mammary-Gland_2023-11-14/aggByCollect_HIF1A_Mammary-Gland.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HIF1A_Mammary-Gland_2023-11-14/aggByCollect_HIF1A_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_HIF1A_Mammary-Gland_2023-11-14/aggByCollect_HIF1A_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_HIF1A_Mammary-Gland_2023-11-14/aggByCollect_HIF1A_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 602 with external jobid 'Submitted batch job 10867448'.

[Tue Nov 28 14:16:50 2023]
Job 533: training on tf=HIF1A,tissue=Cervix training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Cervix.prepared.csv.gz --rds_file output/models/cistrome_HIF1A_Cervix_2023-11-14/aggByCollect_HIF1A_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 533 with external jobid 'Submitted batch job 10867449'.
[Tue Nov 28 14:18:18 2023]
Finished job 602.
237 of 632 steps (38%) done
[Tue Nov 28 14:18:19 2023]
Finished job 533.
238 of 632 steps (38%) done
Select jobs to execute...

[Tue Nov 28 14:18:19 2023]
Job 617: evaluating on tf=HIF1A,tissue=Cervix training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Cervix.prepared.csv.gz, output/models/cistrome_HIF1A_Cervix_2023-11-14/aggByCollect_HIF1A_Cervix.logistic.rds, output/models/cistrome_HIF1A_Cervix_2023-11-14/aggByCollect_HIF1A_Cervix.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HIF1A_Cervix_2023-11-14/aggByCollect_HIF1A_Cervix.linear.rds --logistic_model output/models/cistrome_HIF1A_Cervix_2023-11-14/aggByCollect_HIF1A_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HIF1A_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HIF1A_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_HIF1A_Cervix_2023-11-14/aggByCollect_HIF1A_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 617 with external jobid 'Submitted batch job 10867468'.
[Tue Nov 28 14:19:47 2023]
Finished job 617.
239 of 632 steps (38%) done
[Tue Nov 28 14:25:38 2023]
Finished job 127.
240 of 632 steps (38%) done
Select jobs to execute...

[Tue Nov 28 14:25:38 2023]
Job 211: working on tf=AR,tissue=Prostate
Reason: Input files updated by another job: data/predictor_files/AR_Prostate.predictors.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/create_enformer_config.R --dataset cistrome --transcription_factor AR --tissue Prostate --base_directives config/enformer_base.yaml --project_directory data --predictors_file data/predictor_files/AR_Prostate.predictors.txt --model /project2/haky/Data/enformer/raw --fasta_file /project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta --parameters_file data/prediction_parameters/enformer_parameters_cistrome_AR_Prostate.json --date 2023-11-14
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 211 with external jobid 'Submitted batch job 10867593'.
[Tue Nov 28 14:27:03 2023]
Finished job 211.
241 of 632 steps (38%) done
Select jobs to execute...

[Tue Nov 28 14:27:04 2023]
Job 295: working on AR_Prostate
Reason: Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_AR_Prostate.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_AR_Prostate.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 295 with external jobid 'Submitted batch job 10867648'.
[Tue Nov 28 14:29:38 2023]
Finished job 244.
242 of 632 steps (38%) done
Select jobs to execute...

[Tue Nov 28 14:29:38 2023]
Job 328: working on tf=ERG,tissue=Breast
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ERG_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 328 with external jobid 'Submitted batch job 10867745'.
[Tue Nov 28 14:34:04 2023]
Finished job 268.
243 of 632 steps (38%) done
Select jobs to execute...

[Tue Nov 28 14:34:04 2023]
Job 352: working on tf=FLI1,tissue=Brain
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FLI1_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 352 with external jobid 'Submitted batch job 10868042'.
[Tue Nov 28 14:35:31 2023]
Finished job 238.
244 of 632 steps (39%) done
Select jobs to execute...

[Tue Nov 28 14:35:31 2023]
Job 322: working on tf=FLI1,tissue=Blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FLI1_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 322 with external jobid 'Submitted batch job 10868244'.
[Tue Nov 28 14:35:48 2023]
Finished job 328.
245 of 632 steps (39%) done
Select jobs to execute...

[Tue Nov 28 14:35:48 2023]
Job 412: preparing tf=ERG,tissue=Breast training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_ERG_Breast.csv.gz, data/predictor_files/ERG_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ERG_Breast.csv.gz --ground_truth_file data/predictor_files/ERG_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ERG_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 412 with external jobid 'Submitted batch job 10868312'.
[Tue Nov 28 14:37:13 2023]
Finished job 412.
246 of 632 steps (39%) done
Select jobs to execute...

[Tue Nov 28 14:37:13 2023]
Job 496: training on tf=ERG,tissue=Breast training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ERG_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Breast.prepared.csv.gz --rds_file output/models/cistrome_ERG_Breast_2023-11-14/aggByCollect_ERG_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 496 with external jobid 'Submitted batch job 10868727'.
[Tue Nov 28 14:37:15 2023]
Finished job 352.
247 of 632 steps (39%) done
Select jobs to execute...

[Tue Nov 28 14:37:15 2023]
Job 436: preparing tf=FLI1,tissue=Brain training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FLI1_Brain.csv.gz, data/predictor_files/FLI1_Brain.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FLI1_Brain.csv.gz --ground_truth_file data/predictor_files/FLI1_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 436 with external jobid 'Submitted batch job 10868728'.
[Tue Nov 28 14:38:27 2023]
Finished job 220.
248 of 632 steps (39%) done
Select jobs to execute...

[Tue Nov 28 14:38:27 2023]
Job 304: working on tf=FLI1,tissue=Cord-blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FLI1_Cord-blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 304 with external jobid 'Submitted batch job 10868735'.
[Tue Nov 28 14:38:40 2023]
Finished job 496.
249 of 632 steps (39%) done
Select jobs to execute...

[Tue Nov 28 14:38:40 2023]
Job 580: evaluating on tf=ERG,tissue=Breast training and test data
Reason: Input files updated by another job: output/models/cistrome_ERG_Breast_2023-11-14/aggByCollect_ERG_Breast.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_ERG_Breast.prepared.csv.gz, output/models/cistrome_ERG_Breast_2023-11-14/aggByCollect_ERG_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_ERG_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ERG_Breast_2023-11-14/aggByCollect_ERG_Breast.linear.rds --logistic_model output/models/cistrome_ERG_Breast_2023-11-14/aggByCollect_ERG_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ERG_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_ERG_Breast_2023-11-14/aggByCollect_ERG_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 580 with external jobid 'Submitted batch job 10868736'.
[Tue Nov 28 14:38:41 2023]
Finished job 436.
250 of 632 steps (40%) done
Select jobs to execute...

[Tue Nov 28 14:38:41 2023]
Job 520: training on tf=FLI1,tissue=Brain training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Brain.prepared.csv.gz --rds_file output/models/cistrome_FLI1_Brain_2023-11-14/aggByCollect_FLI1_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 520 with external jobid 'Submitted batch job 10868737'.
[Tue Nov 28 14:40:07 2023]
Finished job 580.
251 of 632 steps (40%) done
[Tue Nov 28 14:40:08 2023]
Finished job 520.
252 of 632 steps (40%) done
Select jobs to execute...

[Tue Nov 28 14:40:08 2023]
Job 604: evaluating on tf=FLI1,tissue=Brain training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Brain.prepared.csv.gz, output/models/cistrome_FLI1_Brain_2023-11-14/aggByCollect_FLI1_Brain.linear.rds, output/models/cistrome_FLI1_Brain_2023-11-14/aggByCollect_FLI1_Brain.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FLI1_Brain_2023-11-14/aggByCollect_FLI1_Brain.linear.rds --logistic_model output/models/cistrome_FLI1_Brain_2023-11-14/aggByCollect_FLI1_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_FLI1_Brain_2023-11-14/aggByCollect_FLI1_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 604 with external jobid 'Submitted batch job 10868907'.
[Tue Nov 28 14:40:10 2023]
Finished job 322.
253 of 632 steps (40%) done
Select jobs to execute...

[Tue Nov 28 14:40:10 2023]
Job 406: preparing tf=FLI1,tissue=Blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FLI1_Blood.csv.gz, data/predictor_files/FLI1_Blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FLI1_Blood.csv.gz --ground_truth_file data/predictor_files/FLI1_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 406 with external jobid 'Submitted batch job 10868908'.
[Tue Nov 28 14:41:35 2023]
Finished job 604.
254 of 632 steps (40%) done
[Tue Nov 28 14:41:35 2023]
Finished job 406.
255 of 632 steps (40%) done
Select jobs to execute...

[Tue Nov 28 14:41:35 2023]
Job 490: training on tf=FLI1,tissue=Blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Blood.prepared.csv.gz --rds_file output/models/cistrome_FLI1_Blood_2023-11-14/aggByCollect_FLI1_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 490 with external jobid 'Submitted batch job 10868914'.
[Tue Nov 28 14:41:36 2023]
Finished job 304.
256 of 632 steps (41%) done
Select jobs to execute...

[Tue Nov 28 14:41:36 2023]
Job 388: preparing tf=FLI1,tissue=Cord-blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FLI1_Cord-blood.csv.gz, data/predictor_files/FLI1_Cord-blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FLI1_Cord-blood.csv.gz --ground_truth_file data/predictor_files/FLI1_Cord-blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Cord-blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Cord-blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 388 with external jobid 'Submitted batch job 10868915'.
[Tue Nov 28 14:43:01 2023]
Finished job 490.
257 of 632 steps (41%) done
Select jobs to execute...

[Tue Nov 28 14:43:01 2023]
Job 574: evaluating on tf=FLI1,tissue=Blood training and test data
Reason: Input files updated by another job: output/models/cistrome_FLI1_Blood_2023-11-14/aggByCollect_FLI1_Blood.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Blood.prepared.csv.gz, output/models/cistrome_FLI1_Blood_2023-11-14/aggByCollect_FLI1_Blood.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FLI1_Blood_2023-11-14/aggByCollect_FLI1_Blood.linear.rds --logistic_model output/models/cistrome_FLI1_Blood_2023-11-14/aggByCollect_FLI1_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_FLI1_Blood_2023-11-14/aggByCollect_FLI1_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 574 with external jobid 'Submitted batch job 10868925'.
[Tue Nov 28 14:43:02 2023]
Finished job 388.
258 of 632 steps (41%) done
Select jobs to execute...

[Tue Nov 28 14:43:02 2023]
Job 472: training on tf=FLI1,tissue=Cord-blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Cord-blood.prepared.csv.gz --rds_file output/models/cistrome_FLI1_Cord-blood_2023-11-14/aggByCollect_FLI1_Cord-blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 472 with external jobid 'Submitted batch job 10868926'.
[Tue Nov 28 14:44:26 2023]
Finished job 574.
259 of 632 steps (41%) done
[Tue Nov 28 14:44:27 2023]
Finished job 472.
260 of 632 steps (41%) done
Select jobs to execute...

[Tue Nov 28 14:44:27 2023]
Job 556: evaluating on tf=FLI1,tissue=Cord-blood training and test data
Reason: Input files updated by another job: output/models/cistrome_FLI1_Cord-blood_2023-11-14/aggByCollect_FLI1_Cord-blood.logistic.rds, output/models/cistrome_FLI1_Cord-blood_2023-11-14/aggByCollect_FLI1_Cord-blood.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Cord-blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FLI1_Cord-blood_2023-11-14/aggByCollect_FLI1_Cord-blood.linear.rds --logistic_model output/models/cistrome_FLI1_Cord-blood_2023-11-14/aggByCollect_FLI1_Cord-blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Cord-blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Cord-blood.prepared.csv.gz --eval_output output/models_eval/cistrome_FLI1_Cord-blood_2023-11-14/aggByCollect_FLI1_Cord-blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 556 with external jobid 'Submitted batch job 10868943'.
[Tue Nov 28 14:45:51 2023]
Finished job 556.
261 of 632 steps (41%) done
[Tue Nov 28 14:47:02 2023]
Finished job 242.
262 of 632 steps (41%) done
Select jobs to execute...

[Tue Nov 28 14:47:02 2023]
Job 326: working on tf=FLI1,tissue=Pleura
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FLI1_Pleura.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 326 with external jobid 'Submitted batch job 10868975'.
[Tue Nov 28 14:52:47 2023]
Finished job 326.
263 of 632 steps (42%) done
Select jobs to execute...

[Tue Nov 28 14:52:47 2023]
Job 410: preparing tf=FLI1,tissue=Pleura training and test data
Reason: Input files updated by another job: data/predictor_files/FLI1_Pleura.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FLI1_Pleura.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FLI1_Pleura.csv.gz --ground_truth_file data/predictor_files/FLI1_Pleura.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Pleura.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Pleura.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 410 with external jobid 'Submitted batch job 10869064'.
[Tue Nov 28 14:53:35 2023]
Finished job 248.
264 of 632 steps (42%) done
Select jobs to execute...

[Tue Nov 28 14:53:35 2023]
Job 332: working on tf=HOXB13,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HOXB13_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 332 with external jobid 'Submitted batch job 10869084'.
[Tue Nov 28 14:53:58 2023]
Finished job 236.
265 of 632 steps (42%) done
Select jobs to execute...

[Tue Nov 28 14:53:58 2023]
Job 320: working on tf=FLI1,tissue=Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FLI1_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 320 with external jobid 'Submitted batch job 10869086'.
[Tue Nov 28 14:54:10 2023]
Finished job 410.
266 of 632 steps (42%) done
Select jobs to execute...

[Tue Nov 28 14:54:10 2023]
Job 494: training on tf=FLI1,tissue=Pleura training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Pleura.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Pleura.prepared.csv.gz --rds_file output/models/cistrome_FLI1_Pleura_2023-11-14/aggByCollect_FLI1_Pleura --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 494 with external jobid 'Submitted batch job 10869095'.
[Tue Nov 28 14:55:34 2023]
Finished job 494.
267 of 632 steps (42%) done
Select jobs to execute...

[Tue Nov 28 14:55:34 2023]
Job 578: evaluating on tf=FLI1,tissue=Pleura training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Pleura.prepared.csv.gz, output/models/cistrome_FLI1_Pleura_2023-11-14/aggByCollect_FLI1_Pleura.linear.rds, output/models/cistrome_FLI1_Pleura_2023-11-14/aggByCollect_FLI1_Pleura.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Pleura.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FLI1_Pleura_2023-11-14/aggByCollect_FLI1_Pleura.linear.rds --logistic_model output/models/cistrome_FLI1_Pleura_2023-11-14/aggByCollect_FLI1_Pleura.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Pleura.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Pleura.prepared.csv.gz --eval_output output/models_eval/cistrome_FLI1_Pleura_2023-11-14/aggByCollect_FLI1_Pleura
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 578 with external jobid 'Submitted batch job 10869194'.
[Tue Nov 28 14:56:56 2023]
Finished job 578.
268 of 632 steps (42%) done
[Tue Nov 28 14:58:08 2023]
Finished job 224.
269 of 632 steps (43%) done
Select jobs to execute...

[Tue Nov 28 14:58:08 2023]
Job 308: working on tf=FLI1,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FLI1_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 308 with external jobid 'Submitted batch job 10869214'.
[Tue Nov 28 14:58:21 2023]
Finished job 332.
270 of 632 steps (43%) done
Select jobs to execute...

[Tue Nov 28 14:58:21 2023]
Job 416: preparing tf=HOXB13,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_HOXB13_Colon.csv.gz, data/predictor_files/HOXB13_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HOXB13_Colon.csv.gz --ground_truth_file data/predictor_files/HOXB13_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HOXB13_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 416 with external jobid 'Submitted batch job 10869215'.
[Tue Nov 28 14:59:42 2023]
Finished job 416.
271 of 632 steps (43%) done
Select jobs to execute...

[Tue Nov 28 14:59:42 2023]
Job 500: training on tf=HOXB13,tissue=Colon training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Colon.prepared.csv.gz --rds_file output/models/cistrome_HOXB13_Colon_2023-11-14/aggByCollect_HOXB13_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 500 with external jobid 'Submitted batch job 10869253'.
[Tue Nov 28 14:59:44 2023]
Finished job 320.
272 of 632 steps (43%) done
Select jobs to execute...

[Tue Nov 28 14:59:44 2023]
Job 404: preparing tf=FLI1,tissue=Bone-Marrow training and test data
Reason: Input files updated by another job: data/predictor_files/FLI1_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FLI1_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FLI1_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/FLI1_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 404 with external jobid 'Submitted batch job 10869256'.
[Tue Nov 28 15:01:04 2023]
Finished job 500.
273 of 632 steps (43%) done
Select jobs to execute...

[Tue Nov 28 15:01:04 2023]
Job 584: evaluating on tf=HOXB13,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_HOXB13_Colon.prepared.csv.gz, output/models/cistrome_HOXB13_Colon_2023-11-14/aggByCollect_HOXB13_Colon.linear.rds, output/models/cistrome_HOXB13_Colon_2023-11-14/aggByCollect_HOXB13_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HOXB13_Colon_2023-11-14/aggByCollect_HOXB13_Colon.linear.rds --logistic_model output/models/cistrome_HOXB13_Colon_2023-11-14/aggByCollect_HOXB13_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HOXB13_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_HOXB13_Colon_2023-11-14/aggByCollect_HOXB13_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 584 with external jobid 'Submitted batch job 10869271'.
[Tue Nov 28 15:01:05 2023]
Finished job 404.
274 of 632 steps (43%) done
Select jobs to execute...

[Tue Nov 28 15:01:05 2023]
Job 488: training on tf=FLI1,tissue=Bone-Marrow training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_FLI1_Bone-Marrow_2023-11-14/aggByCollect_FLI1_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 488 with external jobid 'Submitted batch job 10869272'.
[Tue Nov 28 15:02:26 2023]
Finished job 584.
275 of 632 steps (44%) done
[Tue Nov 28 15:03:35 2023]
Finished job 239.
276 of 632 steps (44%) done
Select jobs to execute...

[Tue Nov 28 15:03:35 2023]
Job 323: working on tf=ERG,tissue=Blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ERG_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 323 with external jobid 'Submitted batch job 10869291'.
[Tue Nov 28 15:03:49 2023]
Finished job 488.
277 of 632 steps (44%) done
Select jobs to execute...

[Tue Nov 28 15:03:49 2023]
Job 572: evaluating on tf=FLI1,tissue=Bone-Marrow training and test data
Reason: Input files updated by another job: output/models/cistrome_FLI1_Bone-Marrow_2023-11-14/aggByCollect_FLI1_Bone-Marrow.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Bone-Marrow.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Bone-Marrow.prepared.csv.gz, output/models/cistrome_FLI1_Bone-Marrow_2023-11-14/aggByCollect_FLI1_Bone-Marrow.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FLI1_Bone-Marrow_2023-11-14/aggByCollect_FLI1_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_FLI1_Bone-Marrow_2023-11-14/aggByCollect_FLI1_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_FLI1_Bone-Marrow_2023-11-14/aggByCollect_FLI1_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 572 with external jobid 'Submitted batch job 10869292'.
[Tue Nov 28 15:05:09 2023]
Finished job 572.
278 of 632 steps (44%) done
[Tue Nov 28 15:10:31 2023]
Finished job 308.
279 of 632 steps (44%) done
Select jobs to execute...

[Tue Nov 28 15:10:32 2023]
Job 392: preparing tf=FLI1,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FLI1_Umbilical-Vein.csv.gz, data/predictor_files/FLI1_Umbilical-Vein.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FLI1_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/FLI1_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 392 with external jobid 'Submitted batch job 10869307'.
[Tue Nov 28 15:13:11 2023]
Finished job 392.
280 of 632 steps (44%) done
Select jobs to execute...

[Tue Nov 28 15:13:11 2023]
Job 476: training on tf=FLI1,tissue=Umbilical-Vein training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_FLI1_Umbilical-Vein_2023-11-14/aggByCollect_FLI1_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 476 with external jobid 'Submitted batch job 10869357'.
[Tue Nov 28 15:17:12 2023]
Finished job 323.
281 of 632 steps (44%) done
Select jobs to execute...

[Tue Nov 28 15:17:12 2023]
Job 407: preparing tf=ERG,tissue=Blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_ERG_Blood.csv.gz, data/predictor_files/ERG_Blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ERG_Blood.csv.gz --ground_truth_file data/predictor_files/ERG_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ERG_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 407 with external jobid 'Submitted batch job 10869423'.
[Tue Nov 28 15:18:32 2023]
Finished job 476.
282 of 632 steps (45%) done
Select jobs to execute...

[Tue Nov 28 15:18:32 2023]
Job 560: evaluating on tf=FLI1,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: output/models/cistrome_FLI1_Umbilical-Vein_2023-11-14/aggByCollect_FLI1_Umbilical-Vein.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Umbilical-Vein.prepared.csv.gz, output/models/cistrome_FLI1_Umbilical-Vein_2023-11-14/aggByCollect_FLI1_Umbilical-Vein.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FLI1_Umbilical-Vein_2023-11-14/aggByCollect_FLI1_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_FLI1_Umbilical-Vein_2023-11-14/aggByCollect_FLI1_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_FLI1_Umbilical-Vein_2023-11-14/aggByCollect_FLI1_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 560 with external jobid 'Submitted batch job 10869472'.
[Tue Nov 28 15:19:51 2023]
Finished job 560.
283 of 632 steps (45%) done
[Tue Nov 28 15:19:52 2023]
Finished job 407.
284 of 632 steps (45%) done
Select jobs to execute...

[Tue Nov 28 15:19:52 2023]
Job 491: training on tf=ERG,tissue=Blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ERG_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Blood.prepared.csv.gz --rds_file output/models/cistrome_ERG_Blood_2023-11-14/aggByCollect_ERG_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 491 with external jobid 'Submitted batch job 10869487'.
[Tue Nov 28 15:22:04 2023]
Finished job 250.
285 of 632 steps (45%) done
Select jobs to execute...

[Tue Nov 28 15:22:04 2023]
Job 334: working on tf=JUN,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 334 with external jobid 'Submitted batch job 10869515'.
[Tue Nov 28 15:23:50 2023]
Finished job 491.
286 of 632 steps (45%) done
Select jobs to execute...

[Tue Nov 28 15:23:50 2023]
Job 575: evaluating on tf=ERG,tissue=Blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_ERG_Blood.prepared.csv.gz, output/models/cistrome_ERG_Blood_2023-11-14/aggByCollect_ERG_Blood.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_ERG_Blood.prepared.csv.gz, output/models/cistrome_ERG_Blood_2023-11-14/aggByCollect_ERG_Blood.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ERG_Blood_2023-11-14/aggByCollect_ERG_Blood.linear.rds --logistic_model output/models/cistrome_ERG_Blood_2023-11-14/aggByCollect_ERG_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ERG_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_ERG_Blood_2023-11-14/aggByCollect_ERG_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 575 with external jobid 'Submitted batch job 10869630'.
[Tue Nov 28 15:25:08 2023]
Finished job 575.
287 of 632 steps (45%) done
[Tue Nov 28 15:27:34 2023]
Finished job 269.
288 of 632 steps (46%) done
Select jobs to execute...

[Tue Nov 28 15:27:35 2023]
Job 353: working on tf=FLI1,tissue=Muscle
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FLI1_Muscle.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 353 with external jobid 'Submitted batch job 10869704'.
[Tue Nov 28 15:27:45 2023]
Finished job 334.
289 of 632 steps (46%) done
Select jobs to execute...

[Tue Nov 28 15:27:46 2023]
Job 418: preparing tf=JUN,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_JUN_Colon.csv.gz, data/predictor_files/JUN_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Colon.csv.gz --ground_truth_file data/predictor_files/JUN_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 418 with external jobid 'Submitted batch job 10869705'.
[Tue Nov 28 15:29:04 2023]
Finished job 418.
290 of 632 steps (46%) done
Select jobs to execute...

[Tue Nov 28 15:29:04 2023]
Job 502: training on tf=JUN,tissue=Colon training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Colon.prepared.csv.gz --rds_file output/models/cistrome_JUN_Colon_2023-11-14/aggByCollect_JUN_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 502 with external jobid 'Submitted batch job 10869792'.
[Tue Nov 28 15:30:22 2023]
Finished job 502.
291 of 632 steps (46%) done
Select jobs to execute...

[Tue Nov 28 15:30:22 2023]
Job 586: evaluating on tf=JUN,tissue=Colon training and test data
Reason: Input files updated by another job: output/models/cistrome_JUN_Colon_2023-11-14/aggByCollect_JUN_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_JUN_Colon.prepared.csv.gz, output/models/cistrome_JUN_Colon_2023-11-14/aggByCollect_JUN_Colon.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_JUN_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Colon_2023-11-14/aggByCollect_JUN_Colon.linear.rds --logistic_model output/models/cistrome_JUN_Colon_2023-11-14/aggByCollect_JUN_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Colon_2023-11-14/aggByCollect_JUN_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 586 with external jobid 'Submitted batch job 10869899'.
[Tue Nov 28 15:31:40 2023]
Finished job 586.
292 of 632 steps (46%) done
[Tue Nov 28 15:33:51 2023]
Finished job 259.
293 of 632 steps (46%) done
Select jobs to execute...

[Tue Nov 28 15:33:51 2023]
Job 343: working on tf=JUN,tissue=Embryo
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 343 with external jobid 'Submitted batch job 10870216'.
[Tue Nov 28 15:36:20 2023]
Finished job 261.
294 of 632 steps (47%) done
Select jobs to execute...

[Tue Nov 28 15:36:20 2023]
Job 345: working on tf=JUN,tissue=Liver
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 345 with external jobid 'Submitted batch job 10870415'.
[Tue Nov 28 15:36:21 2023]
Finished job 216.
295 of 632 steps (47%) done
Select jobs to execute...

[Tue Nov 28 15:36:21 2023]
Job 300: working on tf=JUN,tissue=Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 300 with external jobid 'Submitted batch job 10870416'.
[Tue Nov 28 15:36:51 2023]
Finished job 343.
296 of 632 steps (47%) done
Select jobs to execute...

[Tue Nov 28 15:36:51 2023]
Job 427: preparing tf=JUN,tissue=Embryo training and test data
Reason: Input files updated by another job: data/predictor_files/JUN_Embryo.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_JUN_Embryo.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Embryo.csv.gz --ground_truth_file data/predictor_files/JUN_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 427 with external jobid 'Submitted batch job 10870429'.
[Tue Nov 28 15:38:06 2023]
Finished job 427.
297 of 632 steps (47%) done
Select jobs to execute...

[Tue Nov 28 15:38:06 2023]
Job 511: training on tf=JUN,tissue=Embryo training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Embryo.prepared.csv.gz --rds_file output/models/cistrome_JUN_Embryo_2023-11-14/aggByCollect_JUN_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 511 with external jobid 'Submitted batch job 10870456'.
[Tue Nov 28 15:38:56 2023]
Finished job 260.
298 of 632 steps (47%) done
Select jobs to execute...

[Tue Nov 28 15:38:56 2023]
Job 344: working on tf=JUN,tissue=Cervix
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 344 with external jobid 'Submitted batch job 10870463'.
[Tue Nov 28 15:39:02 2023]
Finished job 274.
299 of 632 steps (47%) done
Select jobs to execute...

[Tue Nov 28 15:39:02 2023]
Job 358: working on tf=TCF4,tissue=Embryo
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_TCF4_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 358 with external jobid 'Submitted batch job 10870464'.
[Tue Nov 28 15:39:23 2023]
Finished job 511.
300 of 632 steps (47%) done
Select jobs to execute...

[Tue Nov 28 15:39:23 2023]
Job 595: evaluating on tf=JUN,tissue=Embryo training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_JUN_Embryo.prepared.csv.gz, output/models/cistrome_JUN_Embryo_2023-11-14/aggByCollect_JUN_Embryo.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_JUN_Embryo.prepared.csv.gz, output/models/cistrome_JUN_Embryo_2023-11-14/aggByCollect_JUN_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Embryo_2023-11-14/aggByCollect_JUN_Embryo.linear.rds --logistic_model output/models/cistrome_JUN_Embryo_2023-11-14/aggByCollect_JUN_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Embryo_2023-11-14/aggByCollect_JUN_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 595 with external jobid 'Submitted batch job 10870469'.
[Tue Nov 28 15:41:37 2023]
Finished job 271.
301 of 632 steps (48%) done
Select jobs to execute...

[Tue Nov 28 15:41:38 2023]
Job 355: working on tf=CDX2,tissue=Embryo
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CDX2_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 355 with external jobid 'Submitted batch job 10870642'.
[Tue Nov 28 15:48:28 2023]
Finished job 300.
302 of 632 steps (48%) done
Select jobs to execute...

[Tue Nov 28 15:48:28 2023]
Job 384: preparing tf=JUN,tissue=Bone-Marrow training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_JUN_Bone-Marrow.csv.gz, data/predictor_files/JUN_Bone-Marrow.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/JUN_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 384 with external jobid 'Submitted batch job 10870917'.
[Tue Nov 28 15:49:30 2023]
Finished job 353.
303 of 632 steps (48%) done
Select jobs to execute...

[Tue Nov 28 15:49:30 2023]
Job 437: preparing tf=FLI1,tissue=Muscle training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FLI1_Muscle.csv.gz, data/predictor_files/FLI1_Muscle.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FLI1_Muscle.csv.gz --ground_truth_file data/predictor_files/FLI1_Muscle.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Muscle.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Muscle.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 437 with external jobid 'Submitted batch job 10870929'.
[Tue Nov 28 15:49:42 2023]
Finished job 595.
304 of 632 steps (48%) done
[Tue Nov 28 15:49:45 2023]
Finished job 345.
305 of 632 steps (48%) done
Select jobs to execute...

[Tue Nov 28 15:49:45 2023]
Job 429: preparing tf=JUN,tissue=Liver training and test data
Reason: Input files updated by another job: data/predictor_files/JUN_Liver.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_JUN_Liver.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Liver.csv.gz --ground_truth_file data/predictor_files/JUN_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 429 with external jobid 'Submitted batch job 10870931'.
[Tue Nov 28 15:51:01 2023]
Finished job 358.
306 of 632 steps (48%) done
Select jobs to execute...

[Tue Nov 28 15:51:01 2023]
Job 442: preparing tf=TCF4,tissue=Embryo training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_TCF4_Embryo.csv.gz, data/predictor_files/TCF4_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_TCF4_Embryo.csv.gz --ground_truth_file data/predictor_files/TCF4_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_TCF4_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 442 with external jobid 'Submitted batch job 10870944'.
[Tue Nov 28 15:51:55 2023]
Finished job 282.
307 of 632 steps (49%) done
Select jobs to execute...

[Tue Nov 28 15:51:55 2023]
Job 366: working on tf=FOXO1,tissue=Tonsil
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Tonsil.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 366 with external jobid 'Submitted batch job 10870999'.
[Tue Nov 28 15:52:13 2023]
Finished job 442.
308 of 632 steps (49%) done
Select jobs to execute...

[Tue Nov 28 15:52:13 2023]
Job 526: training on tf=TCF4,tissue=Embryo training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Embryo.prepared.csv.gz --rds_file output/models/cistrome_TCF4_Embryo_2023-11-14/aggByCollect_TCF4_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 526 with external jobid 'Submitted batch job 10871000'.
[Tue Nov 28 15:52:16 2023]
Finished job 384.
309 of 632 steps (49%) done
Select jobs to execute...
[Tue Nov 28 15:52:17 2023]
Finished job 355.
310 of 632 steps (49%) done

[Tue Nov 28 15:52:17 2023]
Job 439: preparing tf=CDX2,tissue=Embryo training and test data
Reason: Input files updated by another job: data/predictor_files/CDX2_Embryo.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_CDX2_Embryo.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CDX2_Embryo.csv.gz --ground_truth_file data/predictor_files/CDX2_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CDX2_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 439 with external jobid 'Submitted batch job 10871001'.
[Tue Nov 28 15:53:29 2023]
Finished job 526.
311 of 632 steps (49%) done
Select jobs to execute...

[Tue Nov 28 15:53:29 2023]
Job 468: training on tf=JUN,tissue=Bone-Marrow training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_JUN_Bone-Marrow_2023-11-14/aggByCollect_JUN_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 468 with external jobid 'Submitted batch job 10871042'.

[Tue Nov 28 15:53:30 2023]
Job 610: evaluating on tf=TCF4,tissue=Embryo training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_TCF4_Embryo.prepared.csv.gz, output/models/cistrome_TCF4_Embryo_2023-11-14/aggByCollect_TCF4_Embryo.logistic.rds, output/models/cistrome_TCF4_Embryo_2023-11-14/aggByCollect_TCF4_Embryo.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_TCF4_Embryo_2023-11-14/aggByCollect_TCF4_Embryo.linear.rds --logistic_model output/models/cistrome_TCF4_Embryo_2023-11-14/aggByCollect_TCF4_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_TCF4_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_TCF4_Embryo_2023-11-14/aggByCollect_TCF4_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 610 with external jobid 'Submitted batch job 10871043'.
[Tue Nov 28 15:53:30 2023]
Finished job 439.
312 of 632 steps (49%) done
Select jobs to execute...
[Tue Nov 28 15:53:32 2023]
Finished job 429.
313 of 632 steps (50%) done
[Tue Nov 28 15:53:33 2023]
Finished job 344.
314 of 632 steps (50%) done

[Tue Nov 28 15:53:33 2023]
Job 428: preparing tf=JUN,tissue=Cervix training and test data
Reason: Input files updated by another job: data/predictor_files/JUN_Cervix.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_JUN_Cervix.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Cervix.csv.gz --ground_truth_file data/predictor_files/JUN_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 428 with external jobid 'Submitted batch job 10871044'.
[Tue Nov 28 15:54:27 2023]
Finished job 294.
315 of 632 steps (50%) done
Select jobs to execute...

[Tue Nov 28 15:54:27 2023]
Job 378: working on tf=FOXO1,tissue=Cord-blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Cord-blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 378 with external jobid 'Submitted batch job 10871102'.
[Tue Nov 28 15:54:32 2023]
Finished job 235.
316 of 632 steps (50%) done
Select jobs to execute...

[Tue Nov 28 15:54:32 2023]
Job 319: working on tf=ERG,tissue=Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ERG_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 319 with external jobid 'Submitted batch job 10871109'.
[Tue Nov 28 15:54:34 2023]
Finished job 437.
317 of 632 steps (50%) done
Select jobs to execute...
[Tue Nov 28 15:54:45 2023]
Finished job 610.
318 of 632 steps (50%) done
[Tue Nov 28 15:55:37 2023]
Finished job 276.
319 of 632 steps (50%) done

[Tue Nov 28 15:55:37 2023]
Job 360: working on tf=JUN,tissue=Coronary-artery-smooth-muscle
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Coronary-artery-smooth-muscle.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 360 with external jobid 'Submitted batch job 10871160'.
[Tue Nov 28 15:55:43 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10864282

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10864282, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 15:55:43 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10871161'.
[Tue Nov 28 15:56:00 2023]
Finished job 428.
320 of 632 steps (51%) done
Select jobs to execute...
[Tue Nov 28 15:56:03 2023]
Finished job 366.
321 of 632 steps (51%) done

[Tue Nov 28 15:56:04 2023]
Job 450: preparing tf=FOXO1,tissue=Tonsil training and test data
Reason: Input files updated by another job: data/predictor_files/FOXO1_Tonsil.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_FOXO1_Tonsil.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXO1_Tonsil.csv.gz --ground_truth_file data/predictor_files/FOXO1_Tonsil.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Tonsil.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Tonsil.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 450 with external jobid 'Submitted batch job 10871169'.
[Tue Nov 28 15:57:09 2023]
Finished job 450.
322 of 632 steps (51%) done
Select jobs to execute...
[Tue Nov 28 15:57:13 2023]
Finished job 378.
323 of 632 steps (51%) done

[Tue Nov 28 15:57:14 2023]
Job 462: preparing tf=FOXO1,tissue=Cord-blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXO1_Cord-blood.csv.gz, data/predictor_files/FOXO1_Cord-blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXO1_Cord-blood.csv.gz --ground_truth_file data/predictor_files/FOXO1_Cord-blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Cord-blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Cord-blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 462 with external jobid 'Submitted batch job 10871222'.
[Tue Nov 28 15:58:21 2023]
Finished job 462.
324 of 632 steps (51%) done
Select jobs to execute...
[Tue Nov 28 15:58:24 2023]
Finished job 468.
325 of 632 steps (51%) done

[Tue Nov 28 15:58:24 2023]
Job 521: training on tf=FLI1,tissue=Muscle training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Muscle.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Muscle.prepared.csv.gz --rds_file output/models/cistrome_FLI1_Muscle_2023-11-14/aggByCollect_FLI1_Muscle --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 521 with external jobid 'Submitted batch job 10871282'.

[Tue Nov 28 15:58:24 2023]
Job 552: evaluating on tf=JUN,tissue=Bone-Marrow training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_JUN_Bone-Marrow.prepared.csv.gz, output/models/cistrome_JUN_Bone-Marrow_2023-11-14/aggByCollect_JUN_Bone-Marrow.logistic.rds, output/models/cistrome_JUN_Bone-Marrow_2023-11-14/aggByCollect_JUN_Bone-Marrow.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_JUN_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Bone-Marrow_2023-11-14/aggByCollect_JUN_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_JUN_Bone-Marrow_2023-11-14/aggByCollect_JUN_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Bone-Marrow_2023-11-14/aggByCollect_JUN_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 552 with external jobid 'Submitted batch job 10871283'.
[Tue Nov 28 15:59:32 2023]
Finished job 552.
326 of 632 steps (52%) done
Select jobs to execute...
[Tue Nov 28 16:00:23 2023]
Finished job 262.
327 of 632 steps (52%) done

[Tue Nov 28 16:00:23 2023]
Job 346: working on tf=JUN,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 346 with external jobid 'Submitted batch job 10871317'.
[Tue Nov 28 16:01:35 2023]
Finished job 263.
328 of 632 steps (52%) done
Select jobs to execute...

[Tue Nov 28 16:01:35 2023]
Job 347: working on tf=JUN,tissue=Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 347 with external jobid 'Submitted batch job 10871338'.
[Tue Nov 28 16:02:16 2023]
Finished job 223.
329 of 632 steps (52%) done
Select jobs to execute...

[Tue Nov 28 16:02:16 2023]
Job 307: working on tf=MYC,tissue=Embryo
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 307 with external jobid 'Submitted batch job 10871357'.
[Tue Nov 28 16:04:36 2023]
Finished job 226.
330 of 632 steps (52%) done
Select jobs to execute...

[Tue Nov 28 16:04:36 2023]
Job 310: working on tf=MYC,tissue=Cervix
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Cervix.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 310 with external jobid 'Submitted batch job 10871487'.
[Tue Nov 28 16:06:55 2023]
Finished job 240.
331 of 632 steps (52%) done
Select jobs to execute...

[Tue Nov 28 16:06:55 2023]
Job 324: working on tf=MYC,tissue=Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 324 with external jobid 'Submitted batch job 10871666'.
[Tue Nov 28 16:07:38 2023]
Finished job 347.
332 of 632 steps (53%) done
Select jobs to execute...

[Tue Nov 28 16:07:38 2023]
Job 431: preparing tf=JUN,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: data/predictor_files/JUN_Mammary-Gland.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_JUN_Mammary-Gland.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/JUN_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 431 with external jobid 'Submitted batch job 10871726'.
[Tue Nov 28 16:07:40 2023]
Finished job 521.
333 of 632 steps (53%) done
Select jobs to execute...

[Tue Nov 28 16:07:41 2023]
Job 605: evaluating on tf=FLI1,tissue=Muscle training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Muscle.prepared.csv.gz, output/models/cistrome_FLI1_Muscle_2023-11-14/aggByCollect_FLI1_Muscle.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Muscle.prepared.csv.gz, output/models/cistrome_FLI1_Muscle_2023-11-14/aggByCollect_FLI1_Muscle.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FLI1_Muscle_2023-11-14/aggByCollect_FLI1_Muscle.linear.rds --logistic_model output/models/cistrome_FLI1_Muscle_2023-11-14/aggByCollect_FLI1_Muscle.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FLI1_Muscle.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FLI1_Muscle.prepared.csv.gz --eval_output output/models_eval/cistrome_FLI1_Muscle_2023-11-14/aggByCollect_FLI1_Muscle
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 605 with external jobid 'Submitted batch job 10871727'.

[Tue Nov 28 16:07:41 2023]
Job 513: training on tf=JUN,tissue=Liver training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Liver.prepared.csv.gz --rds_file output/models/cistrome_JUN_Liver_2023-11-14/aggByCollect_JUN_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 513 with external jobid 'Submitted batch job 10871728'.
[Tue Nov 28 16:08:04 2023]
Finished job 245.
334 of 632 steps (53%) done
Select jobs to execute...

[Tue Nov 28 16:08:04 2023]
Job 329: working on tf=MYC,tissue=Breast
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 329 with external jobid 'Submitted batch job 10871742'.
[Tue Nov 28 16:08:28 2023]
Finished job 243.
335 of 632 steps (53%) done
Select jobs to execute...

[Tue Nov 28 16:08:28 2023]
Job 327: working on tf=JUN,tissue=Lung
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 327 with external jobid 'Submitted batch job 10871752'.
[Tue Nov 28 16:08:51 2023]
Finished job 307.
336 of 632 steps (53%) done
Select jobs to execute...

[Tue Nov 28 16:08:51 2023]
Job 391: preparing tf=MYC,tissue=Embryo training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MYC_Embryo.csv.gz, data/predictor_files/MYC_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Embryo.csv.gz --ground_truth_file data/predictor_files/MYC_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 391 with external jobid 'Submitted batch job 10871763'.
[Tue Nov 28 16:09:16 2023]
Finished job 228.
337 of 632 steps (53%) done
Select jobs to execute...

[Tue Nov 28 16:09:16 2023]
Job 312: working on tf=MYC,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 312 with external jobid 'Submitted batch job 10871774'.
[Tue Nov 28 16:10:27 2023]
Finished job 284.
338 of 632 steps (53%) done
Select jobs to execute...

[Tue Nov 28 16:10:27 2023]
Job 368: working on tf=MYC,tissue=Foreskin
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Foreskin.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 368 with external jobid 'Submitted batch job 10871801'.
[Tue Nov 28 16:11:13 2023]
Finished job 310.
339 of 632 steps (54%) done
Select jobs to execute...

[Tue Nov 28 16:11:14 2023]
Job 394: preparing tf=MYC,tissue=Cervix training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Cervix.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Cervix.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Cervix.csv.gz --ground_truth_file data/predictor_files/MYC_Cervix.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Cervix.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Cervix.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 394 with external jobid 'Submitted batch job 10871812'.
[Tue Nov 28 16:11:38 2023]
Finished job 232.
340 of 632 steps (54%) done
Select jobs to execute...

[Tue Nov 28 16:11:38 2023]
Job 316: working on tf=MYC,tissue=Lung
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 316 with external jobid 'Submitted batch job 10871819'.
[Tue Nov 28 16:11:39 2023]
Finished job 234.
341 of 632 steps (54%) done
Select jobs to execute...

[Tue Nov 28 16:11:39 2023]
Job 318: working on tf=MYC,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Embryonic-Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 318 with external jobid 'Submitted batch job 10871820'.
[Tue Nov 28 16:11:40 2023]
Finished job 290.
342 of 632 steps (54%) done
Select jobs to execute...

[Tue Nov 28 16:11:40 2023]
Job 374: working on tf=MYC,tissue=Prostate
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 374 with external jobid 'Submitted batch job 10871823'.
[Tue Nov 28 16:12:27 2023]
Finished job 324.
343 of 632 steps (54%) done
Select jobs to execute...

[Tue Nov 28 16:12:27 2023]
Job 408: preparing tf=MYC,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MYC_Mammary-Gland.csv.gz, data/predictor_files/MYC_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/MYC_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 408 with external jobid 'Submitted batch job 10871838'.
[Tue Nov 28 16:13:33 2023]
Finished job 431.
344 of 632 steps (54%) done
Select jobs to execute...
[Tue Nov 28 16:13:39 2023]
Finished job 360.
345 of 632 steps (55%) done

[Tue Nov 28 16:13:39 2023]
Job 444: preparing tf=JUN,tissue=Coronary-artery-smooth-muscle training and test data
Reason: Input files updated by another job: data/predictor_files/JUN_Coronary-artery-smooth-muscle.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.csv.gz --ground_truth_file data/predictor_files/JUN_Coronary-artery-smooth-muscle.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 444 with external jobid 'Submitted batch job 10871903'.
[Tue Nov 28 16:14:02 2023]
Finished job 264.
346 of 632 steps (55%) done
Select jobs to execute...

[Tue Nov 28 16:14:02 2023]
Job 348: working on tf=MYC,tissue=Bone
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Bone.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 348 with external jobid 'Submitted batch job 10871953'.
[Tue Nov 28 16:14:03 2023]
Finished job 229.
347 of 632 steps (55%) done
Select jobs to execute...

[Tue Nov 28 16:14:03 2023]
Job 313: working on tf=MYC,tissue=Skin
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Skin.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 313 with external jobid 'Submitted batch job 10871954'.
[Tue Nov 28 16:14:46 2023]
Finished job 605.
348 of 632 steps (55%) done
Select jobs to execute...
[Tue Nov 28 16:14:47 2023]
Finished job 513.
349 of 632 steps (55%) done

[Tue Nov 28 16:14:47 2023]
Job 512: training on tf=JUN,tissue=Cervix training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Cervix.prepared.csv.gz --rds_file output/models/cistrome_JUN_Cervix_2023-11-14/aggByCollect_JUN_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 512 with external jobid 'Submitted batch job 10871983'.

[Tue Nov 28 16:14:47 2023]
Job 597: evaluating on tf=JUN,tissue=Liver training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Liver.prepared.csv.gz, output/models/cistrome_JUN_Liver_2023-11-14/aggByCollect_JUN_Liver.linear.rds, output/models/cistrome_JUN_Liver_2023-11-14/aggByCollect_JUN_Liver.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_JUN_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Liver_2023-11-14/aggByCollect_JUN_Liver.linear.rds --logistic_model output/models/cistrome_JUN_Liver_2023-11-14/aggByCollect_JUN_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Liver_2023-11-14/aggByCollect_JUN_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 597 with external jobid 'Submitted batch job 10871984'.
[Tue Nov 28 16:15:13 2023]
Finished job 287.
350 of 632 steps (55%) done
Select jobs to execute...

[Tue Nov 28 16:15:13 2023]
Job 371: working on tf=MYC,tissue=LNCaP-cells
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_LNCaP-cells.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 371 with external jobid 'Submitted batch job 10871992'.
[Tue Nov 28 16:15:14 2023]
Finished job 227.
351 of 632 steps (56%) done
Select jobs to execute...

[Tue Nov 28 16:15:14 2023]
Job 311: working on tf=MYC,tissue=Liver
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Liver.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 311 with external jobid 'Submitted batch job 10871993'.
[Tue Nov 28 16:15:57 2023]
Finished job 391.
352 of 632 steps (56%) done
Select jobs to execute...
[Tue Nov 28 16:15:59 2023]
Finished job 329.
353 of 632 steps (56%) done

[Tue Nov 28 16:15:59 2023]
Job 413: preparing tf=MYC,tissue=Breast training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Breast.csv.gz --ground_truth_file data/predictor_files/MYC_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 413 with external jobid 'Submitted batch job 10872048'.
[Tue Nov 28 16:16:24 2023]
Finished job 215.
354 of 632 steps (56%) done
Select jobs to execute...

[Tue Nov 28 16:16:24 2023]
Job 299: working on tf=MYC,tissue=Blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 299 with external jobid 'Submitted batch job 10872104'.
[Tue Nov 28 16:17:10 2023]
Finished job 346.
355 of 632 steps (56%) done
Select jobs to execute...

[Tue Nov 28 16:17:10 2023]
Job 430: preparing tf=JUN,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_JUN_Umbilical-Vein.csv.gz, data/predictor_files/JUN_Umbilical-Vein.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/JUN_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 430 with external jobid 'Submitted batch job 10872111'.
[Tue Nov 28 16:17:33 2023]
Finished job 217.
356 of 632 steps (56%) done
Select jobs to execute...

[Tue Nov 28 16:17:33 2023]
Job 301: working on tf=MYC,tissue=Bone-Marrow
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Bone-Marrow.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 301 with external jobid 'Submitted batch job 10872117'.
[Tue Nov 28 16:17:34 2023]
Finished job 247.
357 of 632 steps (56%) done
Select jobs to execute...

[Tue Nov 28 16:17:34 2023]
Job 331: working on tf=MYC,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 331 with external jobid 'Submitted batch job 10872118'.
[Tue Nov 28 16:18:06 2023]
Finished job 512.
358 of 632 steps (57%) done
Select jobs to execute...

[Tue Nov 28 16:18:06 2023]
Job 515: training on tf=JUN,tissue=Mammary-Gland training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_JUN_Mammary-Gland_2023-11-14/aggByCollect_JUN_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 515 with external jobid 'Submitted batch job 10872128'.

[Tue Nov 28 16:18:06 2023]
Job 596: evaluating on tf=JUN,tissue=Cervix training and test data
Reason: Input files updated by another job: output/models/cistrome_JUN_Cervix_2023-11-14/aggByCollect_JUN_Cervix.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_JUN_Cervix.prepared.csv.gz, output/models/cistrome_JUN_Cervix_2023-11-14/aggByCollect_JUN_Cervix.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_JUN_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Cervix_2023-11-14/aggByCollect_JUN_Cervix.linear.rds --logistic_model output/models/cistrome_JUN_Cervix_2023-11-14/aggByCollect_JUN_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Cervix_2023-11-14/aggByCollect_JUN_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 596 with external jobid 'Submitted batch job 10872129'.
[Tue Nov 28 16:18:14 2023]
Finished job 394.
359 of 632 steps (57%) done
Select jobs to execute...
[Tue Nov 28 16:18:18 2023]
Finished job 368.
360 of 632 steps (57%) done

[Tue Nov 28 16:18:18 2023]
Job 452: preparing tf=MYC,tissue=Foreskin training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Foreskin.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Foreskin.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Foreskin.csv.gz --ground_truth_file data/predictor_files/MYC_Foreskin.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Foreskin.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Foreskin.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 452 with external jobid 'Submitted batch job 10872130'.
[Tue Nov 28 16:18:19 2023]
Finished job 312.
361 of 632 steps (57%) done
Select jobs to execute...

[Tue Nov 28 16:18:19 2023]
Job 396: preparing tf=MYC,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MYC_Umbilical-Vein.csv.gz, data/predictor_files/MYC_Umbilical-Vein.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/MYC_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 396 with external jobid 'Submitted batch job 10872131'.
[Tue Nov 28 16:18:43 2023]
Finished job 231.
362 of 632 steps (57%) done
Select jobs to execute...

[Tue Nov 28 16:18:43 2023]
Job 315: working on tf=MYC,tissue=Brain
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_MYC_Brain.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 315 with external jobid 'Submitted batch job 10872140'.
[Tue Nov 28 16:19:26 2023]
Finished job 316.
363 of 632 steps (57%) done
Select jobs to execute...

[Tue Nov 28 16:19:26 2023]
Job 400: preparing tf=MYC,tissue=Lung training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Lung.csv.gz --ground_truth_file data/predictor_files/MYC_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 400 with external jobid 'Submitted batch job 10872161'.
[Tue Nov 28 16:19:54 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10864445

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10864445, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 16:19:54 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10872174'.
[Tue Nov 28 16:20:19 2023]
Finished job 515.
364 of 632 steps (58%) done
Select jobs to execute...

[Tue Nov 28 16:20:19 2023]
Job 534: training on tf=FOXO1,tissue=Tonsil training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Tonsil.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Tonsil.prepared.csv.gz --rds_file output/models/cistrome_FOXO1_Tonsil_2023-11-14/aggByCollect_FOXO1_Tonsil --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 534 with external jobid 'Submitted batch job 10872182'.

[Tue Nov 28 16:20:19 2023]
Job 599: evaluating on tf=JUN,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: output/models/cistrome_JUN_Mammary-Gland_2023-11-14/aggByCollect_JUN_Mammary-Gland.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_JUN_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_JUN_Mammary-Gland.prepared.csv.gz, output/models/cistrome_JUN_Mammary-Gland_2023-11-14/aggByCollect_JUN_Mammary-Gland.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Mammary-Gland_2023-11-14/aggByCollect_JUN_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_JUN_Mammary-Gland_2023-11-14/aggByCollect_JUN_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Mammary-Gland_2023-11-14/aggByCollect_JUN_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 599 with external jobid 'Submitted batch job 10872183'.
[Tue Nov 28 16:20:35 2023]
Finished job 408.
365 of 632 steps (58%) done
Select jobs to execute...
[Tue Nov 28 16:20:36 2023]
Finished job 318.
366 of 632 steps (58%) done

[Tue Nov 28 16:20:36 2023]
Job 402: preparing tf=MYC,tissue=Embryonic-Kidney training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Embryonic-Kidney.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Embryonic-Kidney.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Embryonic-Kidney.csv.gz --ground_truth_file data/predictor_files/MYC_Embryonic-Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryonic-Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Embryonic-Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 402 with external jobid 'Submitted batch job 10872186'.
[Tue Nov 28 16:21:25 2023]
Finished job 534.
367 of 632 steps (58%) done
Select jobs to execute...

[Tue Nov 28 16:21:25 2023]
Job 618: evaluating on tf=FOXO1,tissue=Tonsil training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Tonsil.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Tonsil.prepared.csv.gz, output/models/cistrome_FOXO1_Tonsil_2023-11-14/aggByCollect_FOXO1_Tonsil.logistic.rds, output/models/cistrome_FOXO1_Tonsil_2023-11-14/aggByCollect_FOXO1_Tonsil.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXO1_Tonsil_2023-11-14/aggByCollect_FOXO1_Tonsil.linear.rds --logistic_model output/models/cistrome_FOXO1_Tonsil_2023-11-14/aggByCollect_FOXO1_Tonsil.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Tonsil.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Tonsil.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXO1_Tonsil_2023-11-14/aggByCollect_FOXO1_Tonsil
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 618 with external jobid 'Submitted batch job 10872343'.

[Tue Nov 28 16:21:26 2023]
Job 492: training on tf=MYC,tissue=Mammary-Gland training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_MYC_Mammary-Gland_2023-11-14/aggByCollect_MYC_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 492 with external jobid 'Submitted batch job 10872344'.
[Tue Nov 28 16:21:45 2023]
Finished job 374.
368 of 632 steps (58%) done
Select jobs to execute...

[Tue Nov 28 16:21:45 2023]
Job 458: preparing tf=MYC,tissue=Prostate training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MYC_Prostate.csv.gz, data/predictor_files/MYC_Prostate.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Prostate.csv.gz --ground_truth_file data/predictor_files/MYC_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 458 with external jobid 'Submitted batch job 10872368'.
[Tue Nov 28 16:22:11 2023]
Finished job 273.
369 of 632 steps (58%) done
Select jobs to execute...

[Tue Nov 28 16:22:11 2023]
Job 357: working on tf=SNAI2,tissue=Embryo
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_SNAI2_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 357 with external jobid 'Submitted batch job 10872374'.
[Tue Nov 28 16:22:34 2023]
Finished job 492.
370 of 632 steps (59%) done
Select jobs to execute...

[Tue Nov 28 16:22:34 2023]
Job 576: evaluating on tf=MYC,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: output/models/cistrome_MYC_Mammary-Gland_2023-11-14/aggByCollect_MYC_Mammary-Gland.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Mammary-Gland.prepared.csv.gz, output/models/cistrome_MYC_Mammary-Gland_2023-11-14/aggByCollect_MYC_Mammary-Gland.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Mammary-Gland_2023-11-14/aggByCollect_MYC_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_MYC_Mammary-Gland_2023-11-14/aggByCollect_MYC_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Mammary-Gland_2023-11-14/aggByCollect_MYC_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 576 with external jobid 'Submitted batch job 10872386'.

[Tue Nov 28 16:22:34 2023]
Job 523: training on tf=CDX2,tissue=Embryo training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Embryo.prepared.csv.gz --rds_file output/models/cistrome_CDX2_Embryo_2023-11-14/aggByCollect_CDX2_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 523 with external jobid 'Submitted batch job 10872387'.
[Tue Nov 28 16:22:54 2023]
Finished job 348.
371 of 632 steps (59%) done
Select jobs to execute...

[Tue Nov 28 16:22:54 2023]
Job 432: preparing tf=MYC,tissue=Bone training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MYC_Bone.csv.gz, data/predictor_files/MYC_Bone.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Bone.csv.gz --ground_truth_file data/predictor_files/MYC_Bone.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Bone.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 432 with external jobid 'Submitted batch job 10872455'.
[Tue Nov 28 16:22:58 2023]
Finished job 319.
372 of 632 steps (59%) done
Select jobs to execute...

[Tue Nov 28 16:22:58 2023]
Job 403: preparing tf=ERG,tissue=Bone-Marrow training and test data
Reason: Input files updated by another job: data/predictor_files/ERG_Bone-Marrow.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_ERG_Bone-Marrow.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ERG_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/ERG_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ERG_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 403 with external jobid 'Submitted batch job 10872463'.
[Tue Nov 28 16:23:43 2023]
Finished job 523.
373 of 632 steps (59%) done
Select jobs to execute...

[Tue Nov 28 16:23:43 2023]
Job 607: evaluating on tf=CDX2,tissue=Embryo training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Embryo.prepared.csv.gz, output/models/cistrome_CDX2_Embryo_2023-11-14/aggByCollect_CDX2_Embryo.linear.rds, output/models/cistrome_CDX2_Embryo_2023-11-14/aggByCollect_CDX2_Embryo.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_CDX2_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CDX2_Embryo_2023-11-14/aggByCollect_CDX2_Embryo.linear.rds --logistic_model output/models/cistrome_CDX2_Embryo_2023-11-14/aggByCollect_CDX2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CDX2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_CDX2_Embryo_2023-11-14/aggByCollect_CDX2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 607 with external jobid 'Submitted batch job 10872472'.

[Tue Nov 28 16:23:43 2023]
Job 478: training on tf=MYC,tissue=Cervix training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Cervix.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Cervix.prepared.csv.gz --rds_file output/models/cistrome_MYC_Cervix_2023-11-14/aggByCollect_MYC_Cervix --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 478 with external jobid 'Submitted batch job 10872473'.
[Tue Nov 28 16:24:02 2023]
Finished job 597.
374 of 632 steps (59%) done
Select jobs to execute...
[Tue Nov 28 16:24:05 2023]
Finished job 444.
375 of 632 steps (59%) done
[Tue Nov 28 16:24:53 2023]
Finished job 478.
376 of 632 steps (59%) done

[Tue Nov 28 16:24:53 2023]
Job 528: training on tf=JUN,tissue=Coronary-artery-smooth-muscle training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.prepared.csv.gz --rds_file output/models/cistrome_JUN_Coronary-artery-smooth-muscle_2023-11-14/aggByCollect_JUN_Coronary-artery-smooth-muscle --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 528 with external jobid 'Submitted batch job 10872527'.

[Tue Nov 28 16:24:54 2023]
Job 562: evaluating on tf=MYC,tissue=Cervix training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Cervix.prepared.csv.gz, output/models/cistrome_MYC_Cervix_2023-11-14/aggByCollect_MYC_Cervix.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Cervix.prepared.csv.gz, output/models/cistrome_MYC_Cervix_2023-11-14/aggByCollect_MYC_Cervix.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Cervix_2023-11-14/aggByCollect_MYC_Cervix.linear.rds --logistic_model output/models/cistrome_MYC_Cervix_2023-11-14/aggByCollect_MYC_Cervix.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Cervix.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Cervix.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Cervix_2023-11-14/aggByCollect_MYC_Cervix
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 562 with external jobid 'Submitted batch job 10872528'.
[Tue Nov 28 16:25:11 2023]
Finished job 413.
377 of 632 steps (60%) done
Select jobs to execute...
[Tue Nov 28 16:25:13 2023]
Finished job 371.
378 of 632 steps (60%) done

[Tue Nov 28 16:25:13 2023]
Job 455: preparing tf=MYC,tissue=LNCaP-cells training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_LNCaP-cells.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_LNCaP-cells.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_LNCaP-cells.csv.gz --ground_truth_file data/predictor_files/MYC_LNCaP-cells.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_LNCaP-cells.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_LNCaP-cells.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 455 with external jobid 'Submitted batch job 10872530'.
[Tue Nov 28 16:25:15 2023]
Finished job 313.
379 of 632 steps (60%) done
Select jobs to execute...

[Tue Nov 28 16:25:15 2023]
Job 397: preparing tf=MYC,tissue=Skin training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Skin.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Skin.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Skin.csv.gz --ground_truth_file data/predictor_files/MYC_Skin.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Skin.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Skin.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 397 with external jobid 'Submitted batch job 10872531'.
[Tue Nov 28 16:25:16 2023]
Finished job 327.
380 of 632 steps (60%) done
Select jobs to execute...

[Tue Nov 28 16:25:17 2023]
Job 411: preparing tf=JUN,tissue=Lung training and test data
Reason: Input files updated by another job: data/predictor_files/JUN_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_JUN_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Lung.csv.gz --ground_truth_file data/predictor_files/JUN_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 411 with external jobid 'Submitted batch job 10872532'.
[Tue Nov 28 16:26:24 2023]
Finished job 299.
381 of 632 steps (60%) done
Select jobs to execute...

[Tue Nov 28 16:26:24 2023]
Job 383: preparing tf=MYC,tissue=Blood training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Blood.csv.gz --ground_truth_file data/predictor_files/MYC_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 383 with external jobid 'Submitted batch job 10872567'.
[Tue Nov 28 16:26:25 2023]
Finished job 311.
382 of 632 steps (60%) done
Select jobs to execute...

[Tue Nov 28 16:26:25 2023]
Job 395: preparing tf=MYC,tissue=Liver training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Liver.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Liver.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Liver.csv.gz --ground_truth_file data/predictor_files/MYC_Liver.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Liver.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Liver.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 395 with external jobid 'Submitted batch job 10872572'.
[Tue Nov 28 16:27:26 2023]
Finished job 400.
383 of 632 steps (61%) done
Select jobs to execute...
[Tue Nov 28 16:27:29 2023]
Finished job 596.
384 of 632 steps (61%) done
[Tue Nov 28 16:27:30 2023]
Finished job 452.
385 of 632 steps (61%) done
[Tue Nov 28 16:27:30 2023]
Finished job 396.
386 of 632 steps (61%) done
[Tue Nov 28 16:27:32 2023]
Finished job 430.
387 of 632 steps (61%) done
[Tue Nov 28 16:27:33 2023]
Finished job 301.
388 of 632 steps (61%) done

[Tue Nov 28 16:27:33 2023]
Job 385: preparing tf=MYC,tissue=Bone-Marrow training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MYC_Bone-Marrow.csv.gz, data/predictor_files/MYC_Bone-Marrow.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Bone-Marrow.csv.gz --ground_truth_file data/predictor_files/MYC_Bone-Marrow.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone-Marrow.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Bone-Marrow.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 385 with external jobid 'Submitted batch job 10872638'.
[Tue Nov 28 16:27:34 2023]
Finished job 331.
389 of 632 steps (62%) done
Select jobs to execute...

[Tue Nov 28 16:27:35 2023]
Job 415: preparing tf=MYC,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_MYC_Colon.csv.gz, data/predictor_files/MYC_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Colon.csv.gz --ground_truth_file data/predictor_files/MYC_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 415 with external jobid 'Submitted batch job 10872639'.
[Tue Nov 28 16:28:25 2023]
Finished job 562.
390 of 632 steps (62%) done
Select jobs to execute...
[Tue Nov 28 16:28:29 2023]
Finished job 607.
391 of 632 steps (62%) done
[Tue Nov 28 16:28:30 2023]
Finished job 576.
392 of 632 steps (62%) done
[Tue Nov 28 16:28:31 2023]
Finished job 432.
393 of 632 steps (62%) done
[Tue Nov 28 16:28:33 2023]
Finished job 618.
394 of 632 steps (62%) done
[Tue Nov 28 16:28:34 2023]
Finished job 458.
395 of 632 steps (62%) done
[Tue Nov 28 16:28:36 2023]
Finished job 599.
396 of 632 steps (63%) done
[Tue Nov 28 16:28:37 2023]
Finished job 402.
397 of 632 steps (63%) done
[Tue Nov 28 16:29:24 2023]
Finished job 385.
398 of 632 steps (63%) done
[Tue Nov 28 16:29:26 2023]
Finished job 383.
399 of 632 steps (63%) done
[Tue Nov 28 16:29:27 2023]
Finished job 395.
400 of 632 steps (63%) done
[Tue Nov 28 16:29:29 2023]
Finished job 455.
401 of 632 steps (63%) done
[Tue Nov 28 16:29:30 2023]
Finished job 397.
402 of 632 steps (64%) done
[Tue Nov 28 16:29:33 2023]
Finished job 357.
403 of 632 steps (64%) done

[Tue Nov 28 16:29:33 2023]
Job 441: preparing tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_SNAI2_Embryo.csv.gz, data/predictor_files/SNAI2_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_SNAI2_Embryo.csv.gz --ground_truth_file data/predictor_files/SNAI2_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 441 with external jobid 'Submitted batch job 10872776'.
[Tue Nov 28 16:29:35 2023]
Finished job 315.
404 of 632 steps (64%) done
Select jobs to execute...

[Tue Nov 28 16:29:35 2023]
Job 399: preparing tf=MYC,tissue=Brain training and test data
Reason: Input files updated by another job: data/predictor_files/MYC_Brain.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_MYC_Brain.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_MYC_Brain.csv.gz --ground_truth_file data/predictor_files/MYC_Brain.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Brain.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Brain.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 399 with external jobid 'Submitted batch job 10872778'.
[Tue Nov 28 16:30:20 2023]
Finished job 441.
405 of 632 steps (64%) done
Select jobs to execute...
[Tue Nov 28 16:30:21 2023]
Finished job 399.
406 of 632 steps (64%) done
[Tue Nov 28 16:30:22 2023]
Finished job 415.
407 of 632 steps (64%) done
[Tue Nov 28 16:30:24 2023]
Finished job 411.
408 of 632 steps (65%) done
[Tue Nov 28 16:30:56 2023]
Finished job 219.
409 of 632 steps (65%) done

[Tue Nov 28 16:30:56 2023]
Job 303: working on tf=JUN,tissue=Breast
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_JUN_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 303 with external jobid 'Submitted batch job 10872793'.
[Tue Nov 28 16:32:00 2023]
Finished job 403.
410 of 632 steps (65%) done
Select jobs to execute...
[Tue Nov 28 16:33:12 2023]
Finished job 256.
411 of 632 steps (65%) done

[Tue Nov 28 16:33:12 2023]
Job 340: working on tf=STAT6,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT6_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 340 with external jobid 'Submitted batch job 10872814'.
[Tue Nov 28 16:34:43 2023]
Finished job 253.
412 of 632 steps (65%) done
Select jobs to execute...

[Tue Nov 28 16:34:43 2023]
Job 337: working on tf=ASCL1,tissue=Skin
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ASCL1_Skin.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 337 with external jobid 'Submitted batch job 10872821'.
[Tue Nov 28 16:35:04 2023]
Finished job 340.
413 of 632 steps (65%) done
Select jobs to execute...

[Tue Nov 28 16:35:04 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10872829'.
[Tue Nov 28 16:35:31 2023]
Finished job 293.
414 of 632 steps (66%) done
Select jobs to execute...

[Tue Nov 28 16:35:31 2023]
Job 377: working on tf=STAT6,tissue=Blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT6_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 377 with external jobid 'Submitted batch job 10872834'.
[Tue Nov 28 16:36:35 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10872829

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10872829, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.
Select jobs to execute...

[Tue Nov 28 16:36:35 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10872853'.
[Tue Nov 28 16:36:39 2023]
Finished job 528.
415 of 632 steps (66%) done
Select jobs to execute...

[Tue Nov 28 16:36:39 2023]
Job 487: training on tf=ERG,tissue=Bone-Marrow training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ERG_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_ERG_Bone-Marrow_2023-11-14/aggByCollect_ERG_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 487 with external jobid 'Submitted batch job 10872854'.

[Tue Nov 28 16:36:40 2023]
Job 612: evaluating on tf=JUN,tissue=Coronary-artery-smooth-muscle training and test data
Reason: Input files updated by another job: output/models/cistrome_JUN_Coronary-artery-smooth-muscle_2023-11-14/aggByCollect_JUN_Coronary-artery-smooth-muscle.linear.rds, output/models/cistrome_JUN_Coronary-artery-smooth-muscle_2023-11-14/aggByCollect_JUN_Coronary-artery-smooth-muscle.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Coronary-artery-smooth-muscle_2023-11-14/aggByCollect_JUN_Coronary-artery-smooth-muscle.linear.rds --logistic_model output/models/cistrome_JUN_Coronary-artery-smooth-muscle_2023-11-14/aggByCollect_JUN_Coronary-artery-smooth-muscle.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Coronary-artery-smooth-muscle.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Coronary-artery-smooth-muscle_2023-11-14/aggByCollect_JUN_Coronary-artery-smooth-muscle
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 612 with external jobid 'Submitted batch job 10872855'.
[Tue Nov 28 16:37:24 2023]
Finished job 377.
416 of 632 steps (66%) done
Select jobs to execute...

[Tue Nov 28 16:37:24 2023]
Job 461: preparing tf=STAT6,tissue=Blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Blood.csv.gz, data/predictor_files/STAT6_Blood.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Blood.csv.gz --ground_truth_file data/predictor_files/STAT6_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 461 with external jobid 'Submitted batch job 10872876'.
[Tue Nov 28 16:38:08 2023]
Finished job 461.
417 of 632 steps (66%) done
Select jobs to execute...
[Tue Nov 28 16:38:09 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10872853

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10872853, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.

[Tue Nov 28 16:38:09 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10872885'.
[Tue Nov 28 16:38:57 2023]
Finished job 612.
418 of 632 steps (66%) done
Select jobs to execute...
[Tue Nov 28 16:38:58 2023]
Finished job 337.
419 of 632 steps (66%) done

[Tue Nov 28 16:38:58 2023]
Job 421: preparing tf=ASCL1,tissue=Skin training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_ASCL1_Skin.csv.gz, data/predictor_files/ASCL1_Skin.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ASCL1_Skin.csv.gz --ground_truth_file data/predictor_files/ASCL1_Skin.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Skin.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ASCL1_Skin.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 421 with external jobid 'Submitted batch job 10872902'.
[Tue Nov 28 16:39:27 2023]
Finished job 278.
420 of 632 steps (66%) done
Select jobs to execute...

[Tue Nov 28 16:39:27 2023]
Job 362: working on tf=FOXO1,tissue=Endometrium
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Endometrium.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 362 with external jobid 'Submitted batch job 10872906'.
[Tue Nov 28 16:39:41 2023]
Finished job 421.
421 of 632 steps (67%) done
Select jobs to execute...
[Tue Nov 28 16:39:43 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10872885

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10872885, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.

[Tue Nov 28 16:39:43 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10872909'.
[Tue Nov 28 16:41:10 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10872909

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10872909, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.
Select jobs to execute...

[Tue Nov 28 16:41:10 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10872913'.
[Tue Nov 28 16:42:38 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10872913

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10872913, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.
Select jobs to execute...

[Tue Nov 28 16:42:38 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10872999'.
[Tue Nov 28 16:44:07 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10872999

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10872999, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.
Select jobs to execute...

[Tue Nov 28 16:44:07 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10873160'.
[Tue Nov 28 16:44:09 2023]
Finished job 487.
422 of 632 steps (67%) done
Select jobs to execute...

[Tue Nov 28 16:44:09 2023]
Job 514: training on tf=JUN,tissue=Umbilical-Vein training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_JUN_Umbilical-Vein_2023-11-14/aggByCollect_JUN_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 514 with external jobid 'Submitted batch job 10873161'.

[Tue Nov 28 16:44:09 2023]
Job 571: evaluating on tf=ERG,tissue=Bone-Marrow training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_ERG_Bone-Marrow.prepared.csv.gz, output/models/cistrome_ERG_Bone-Marrow_2023-11-14/aggByCollect_ERG_Bone-Marrow.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_ERG_Bone-Marrow.prepared.csv.gz, output/models/cistrome_ERG_Bone-Marrow_2023-11-14/aggByCollect_ERG_Bone-Marrow.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ERG_Bone-Marrow_2023-11-14/aggByCollect_ERG_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_ERG_Bone-Marrow_2023-11-14/aggByCollect_ERG_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ERG_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_ERG_Bone-Marrow_2023-11-14/aggByCollect_ERG_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 571 with external jobid 'Submitted batch job 10873162'.
[Tue Nov 28 16:45:36 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10873160

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10873160, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.
Select jobs to execute...

[Tue Nov 28 16:45:36 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10873243'.
[Tue Nov 28 16:45:38 2023]
Finished job 571.
423 of 632 steps (67%) done
Select jobs to execute...
[Tue Nov 28 16:47:05 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10873243

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10873243, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.

[Tue Nov 28 16:47:05 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10873316'.
[Tue Nov 28 16:48:33 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10873316

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10873316, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.
Select jobs to execute...

[Tue Nov 28 16:48:33 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10873358'.
[Tue Nov 28 16:50:01 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10873358

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10873358, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 424.
Select jobs to execute...

[Tue Nov 28 16:50:01 2023]
Job 424: preparing tf=STAT6,tissue=Colon training and test data
Reason: Missing output files: data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz; Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 424 with external jobid 'Submitted batch job 10873529'.
[Tue Nov 28 16:50:46 2023]
Finished job 514.
424 of 632 steps (67%) done
Select jobs to execute...

[Tue Nov 28 16:50:46 2023]
Job 598: evaluating on tf=JUN,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_JUN_Umbilical-Vein.prepared.csv.gz, output/models/cistrome_JUN_Umbilical-Vein_2023-11-14/aggByCollect_JUN_Umbilical-Vein.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_JUN_Umbilical-Vein.prepared.csv.gz, output/models/cistrome_JUN_Umbilical-Vein_2023-11-14/aggByCollect_JUN_Umbilical-Vein.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Umbilical-Vein_2023-11-14/aggByCollect_JUN_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_JUN_Umbilical-Vein_2023-11-14/aggByCollect_JUN_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Umbilical-Vein_2023-11-14/aggByCollect_JUN_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 598 with external jobid 'Submitted batch job 10873628'.

[Tue Nov 28 16:50:47 2023]
Job 495: training on tf=JUN,tissue=Lung training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Lung.prepared.csv.gz --rds_file output/models/cistrome_JUN_Lung_2023-11-14/aggByCollect_JUN_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 495 with external jobid 'Submitted batch job 10873629'.
[Tue Nov 28 16:50:48 2023]
Finished job 303.
425 of 632 steps (67%) done
Select jobs to execute...

[Tue Nov 28 16:50:48 2023]
Job 387: preparing tf=JUN,tissue=Breast training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_JUN_Breast.csv.gz, data/predictor_files/JUN_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_JUN_Breast.csv.gz --ground_truth_file data/predictor_files/JUN_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 387 with external jobid 'Submitted batch job 10873630'.
[Tue Nov 28 16:51:32 2023]
Error in rule prepare_training_data:
    jobid: 424
    input: data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz, data/predictor_files/STAT6_Colon.ground_truth.txt
    output: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Colon.csv.gz --ground_truth_file data/predictor_files/STAT6_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Colon.prepared.csv.gz
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10873529

Error executing rule prepare_training_data on cluster (jobid: 424, external: Submitted batch job 10873529, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.prepare_training_data.424.sh). For error details see the cluster log and the log files of the involved rule(s).
Select jobs to execute...
[Tue Nov 28 16:52:14 2023]
Finished job 598.
426 of 632 steps (67%) done
[Tue Nov 28 16:54:24 2023]
Finished job 495.
427 of 632 steps (68%) done

[Tue Nov 28 16:54:24 2023]
Job 579: evaluating on tf=JUN,tissue=Lung training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Lung.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_JUN_Lung.prepared.csv.gz, output/models/cistrome_JUN_Lung_2023-11-14/aggByCollect_JUN_Lung.logistic.rds, output/models/cistrome_JUN_Lung_2023-11-14/aggByCollect_JUN_Lung.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Lung_2023-11-14/aggByCollect_JUN_Lung.linear.rds --logistic_model output/models/cistrome_JUN_Lung_2023-11-14/aggByCollect_JUN_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Lung_2023-11-14/aggByCollect_JUN_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 579 with external jobid 'Submitted batch job 10873787'.

[Tue Nov 28 16:54:24 2023]
Job 505: training on tf=ASCL1,tissue=Skin training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Skin.prepared.csv.gz --rds_file output/models/cistrome_ASCL1_Skin_2023-11-14/aggByCollect_ASCL1_Skin --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 505 with external jobid 'Submitted batch job 10873788'.
[Tue Nov 28 16:55:07 2023]
Finished job 579.
428 of 632 steps (68%) done
Select jobs to execute...
[Tue Nov 28 16:55:08 2023]
Finished job 505.
429 of 632 steps (68%) done

[Tue Nov 28 16:55:08 2023]
Job 497: training on tf=MYC,tissue=Breast training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Breast.prepared.csv.gz --rds_file output/models/cistrome_MYC_Breast_2023-11-14/aggByCollect_MYC_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 497 with external jobid 'Submitted batch job 10873792'.

[Tue Nov 28 16:55:08 2023]
Job 589: evaluating on tf=ASCL1,tissue=Skin training and test data
Reason: Input files updated by another job: output/models/cistrome_ASCL1_Skin_2023-11-14/aggByCollect_ASCL1_Skin.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_ASCL1_Skin.prepared.csv.gz, output/models/cistrome_ASCL1_Skin_2023-11-14/aggByCollect_ASCL1_Skin.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ASCL1_Skin_2023-11-14/aggByCollect_ASCL1_Skin.linear.rds --logistic_model output/models/cistrome_ASCL1_Skin_2023-11-14/aggByCollect_ASCL1_Skin.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Skin.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ASCL1_Skin.prepared.csv.gz --eval_output output/models_eval/cistrome_ASCL1_Skin_2023-11-14/aggByCollect_ASCL1_Skin
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 589 with external jobid 'Submitted batch job 10873793'.
[Tue Nov 28 16:55:09 2023]
Finished job 387.
430 of 632 steps (68%) done
Select jobs to execute...
[Tue Nov 28 16:55:10 2023]
Finished job 362.
431 of 632 steps (68%) done

[Tue Nov 28 16:55:10 2023]
Job 446: preparing tf=FOXO1,tissue=Endometrium training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_FOXO1_Endometrium.csv.gz, data/predictor_files/FOXO1_Endometrium.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_FOXO1_Endometrium.csv.gz --ground_truth_file data/predictor_files/FOXO1_Endometrium.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Endometrium.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Endometrium.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 446 with external jobid 'Submitted batch job 10873794'.
[Tue Nov 28 16:55:51 2023]
Finished job 497.
432 of 632 steps (68%) done
Select jobs to execute...

[Tue Nov 28 16:55:51 2023]
Job 581: evaluating on tf=MYC,tissue=Breast training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MYC_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Breast.prepared.csv.gz, output/models/cistrome_MYC_Breast_2023-11-14/aggByCollect_MYC_Breast.logistic.rds, output/models/cistrome_MYC_Breast_2023-11-14/aggByCollect_MYC_Breast.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Breast_2023-11-14/aggByCollect_MYC_Breast.linear.rds --logistic_model output/models/cistrome_MYC_Breast_2023-11-14/aggByCollect_MYC_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Breast_2023-11-14/aggByCollect_MYC_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 581 with external jobid 'Submitted batch job 10873798'.

[Tue Nov 28 16:55:52 2023]
Job 471: training on tf=JUN,tissue=Breast training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_JUN_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Breast.prepared.csv.gz --rds_file output/models/cistrome_JUN_Breast_2023-11-14/aggByCollect_JUN_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 471 with external jobid 'Submitted batch job 10873799'.
[Tue Nov 28 16:55:52 2023]
Finished job 589.
433 of 632 steps (69%) done
Select jobs to execute...
[Tue Nov 28 16:56:34 2023]
Finished job 581.
434 of 632 steps (69%) done
[Tue Nov 28 16:58:00 2023]
Finished job 446.
435 of 632 steps (69%) done
[Tue Nov 28 16:59:53 2023]
Finished job 218.
436 of 632 steps (69%) done

[Tue Nov 28 16:59:53 2023]
Job 302: working on tf=ERG,tissue=Prostate
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ERG_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 302 with external jobid 'Submitted batch job 10874091'.
[Tue Nov 28 17:02:26 2023]
Finished job 251.
437 of 632 steps (69%) done
Select jobs to execute...

[Tue Nov 28 17:02:26 2023]
Job 335: working on tf=AR,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_AR_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 335 with external jobid 'Submitted batch job 10874174'.
[Tue Nov 28 17:03:31 2023]
Finished job 471.
438 of 632 steps (69%) done
Select jobs to execute...

[Tue Nov 28 17:03:31 2023]
Job 530: training on tf=FOXO1,tissue=Endometrium training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Endometrium.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Endometrium.prepared.csv.gz --rds_file output/models/cistrome_FOXO1_Endometrium_2023-11-14/aggByCollect_FOXO1_Endometrium --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 530 with external jobid 'Submitted batch job 10874477'.

[Tue Nov 28 17:03:31 2023]
Job 555: evaluating on tf=JUN,tissue=Breast training and test data
Reason: Input files updated by another job: output/models/cistrome_JUN_Breast_2023-11-14/aggByCollect_JUN_Breast.linear.rds, output/models/cistrome_JUN_Breast_2023-11-14/aggByCollect_JUN_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_JUN_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_JUN_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_JUN_Breast_2023-11-14/aggByCollect_JUN_Breast.linear.rds --logistic_model output/models/cistrome_JUN_Breast_2023-11-14/aggByCollect_JUN_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_JUN_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_JUN_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_JUN_Breast_2023-11-14/aggByCollect_JUN_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 555 with external jobid 'Submitted batch job 10874478'.
[Tue Nov 28 17:04:12 2023]
Finished job 335.
439 of 632 steps (69%) done
Select jobs to execute...

[Tue Nov 28 17:04:12 2023]
Job 419: preparing tf=AR,tissue=Colon training and test data
Reason: Input files updated by another job: data/predictor_files/AR_Colon.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_AR_Colon.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_AR_Colon.csv.gz --ground_truth_file data/predictor_files/AR_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 419 with external jobid 'Submitted batch job 10874542'.
[Tue Nov 28 17:04:52 2023]
Finished job 419.
440 of 632 steps (70%) done
Select jobs to execute...
[Tue Nov 28 17:04:54 2023]
Finished job 555.
441 of 632 steps (70%) done
[Tue Nov 28 17:09:34 2023]
Finished job 530.
442 of 632 steps (70%) done

[Tue Nov 28 17:09:34 2023]
Job 614: evaluating on tf=FOXO1,tissue=Endometrium training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Endometrium.prepared.csv.gz, output/models/cistrome_FOXO1_Endometrium_2023-11-14/aggByCollect_FOXO1_Endometrium.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Endometrium.prepared.csv.gz, output/models/cistrome_FOXO1_Endometrium_2023-11-14/aggByCollect_FOXO1_Endometrium.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXO1_Endometrium_2023-11-14/aggByCollect_FOXO1_Endometrium.linear.rds --logistic_model output/models/cistrome_FOXO1_Endometrium_2023-11-14/aggByCollect_FOXO1_Endometrium.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Endometrium.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Endometrium.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXO1_Endometrium_2023-11-14/aggByCollect_FOXO1_Endometrium
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 614 with external jobid 'Submitted batch job 10874953'.

[Tue Nov 28 17:09:34 2023]
Job 484: training on tf=MYC,tissue=Lung training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Lung.prepared.csv.gz --rds_file output/models/cistrome_MYC_Lung_2023-11-14/aggByCollect_MYC_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 484 with external jobid 'Submitted batch job 10874954'.
[Tue Nov 28 17:10:15 2023]
Finished job 484.
443 of 632 steps (70%) done
Select jobs to execute...

[Tue Nov 28 17:10:15 2023]
Job 568: evaluating on tf=MYC,tissue=Lung training and test data
Reason: Input files updated by another job: output/models/cistrome_MYC_Lung_2023-11-14/aggByCollect_MYC_Lung.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Lung.prepared.csv.gz, output/models/cistrome_MYC_Lung_2023-11-14/aggByCollect_MYC_Lung.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Lung_2023-11-14/aggByCollect_MYC_Lung.linear.rds --logistic_model output/models/cistrome_MYC_Lung_2023-11-14/aggByCollect_MYC_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Lung_2023-11-14/aggByCollect_MYC_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 568 with external jobid 'Submitted batch job 10875096'.

[Tue Nov 28 17:10:15 2023]
Job 499: training on tf=MYC,tissue=Colon training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Colon.prepared.csv.gz --rds_file output/models/cistrome_MYC_Colon_2023-11-14/aggByCollect_MYC_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 499 with external jobid 'Submitted batch job 10875097'.
[Tue Nov 28 17:10:55 2023]
Finished job 568.
444 of 632 steps (70%) done
Select jobs to execute...
[Tue Nov 28 17:10:56 2023]
Finished job 499.
445 of 632 steps (70%) done

[Tue Nov 28 17:10:56 2023]
Job 467: training on tf=MYC,tissue=Blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Blood.prepared.csv.gz --rds_file output/models/cistrome_MYC_Blood_2023-11-14/aggByCollect_MYC_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 467 with external jobid 'Submitted batch job 10875166'.

[Tue Nov 28 17:10:56 2023]
Job 583: evaluating on tf=MYC,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MYC_Colon.prepared.csv.gz, output/models/cistrome_MYC_Colon_2023-11-14/aggByCollect_MYC_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Colon.prepared.csv.gz, output/models/cistrome_MYC_Colon_2023-11-14/aggByCollect_MYC_Colon.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Colon_2023-11-14/aggByCollect_MYC_Colon.linear.rds --logistic_model output/models/cistrome_MYC_Colon_2023-11-14/aggByCollect_MYC_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Colon_2023-11-14/aggByCollect_MYC_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 583 with external jobid 'Submitted batch job 10875167'.
[Tue Nov 28 17:10:57 2023]
Finished job 614.
446 of 632 steps (71%) done
Select jobs to execute...
[Tue Nov 28 17:11:37 2023]
Finished job 467.
447 of 632 steps (71%) done

[Tue Nov 28 17:11:37 2023]
Job 481: training on tf=MYC,tissue=Skin training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Skin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Skin.prepared.csv.gz --rds_file output/models/cistrome_MYC_Skin_2023-11-14/aggByCollect_MYC_Skin --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 481 with external jobid 'Submitted batch job 10875177'.

[Tue Nov 28 17:11:37 2023]
Job 551: evaluating on tf=MYC,tissue=Blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MYC_Blood.prepared.csv.gz, output/models/cistrome_MYC_Blood_2023-11-14/aggByCollect_MYC_Blood.logistic.rds, output/models/cistrome_MYC_Blood_2023-11-14/aggByCollect_MYC_Blood.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Blood_2023-11-14/aggByCollect_MYC_Blood.linear.rds --logistic_model output/models/cistrome_MYC_Blood_2023-11-14/aggByCollect_MYC_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Blood_2023-11-14/aggByCollect_MYC_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 551 with external jobid 'Submitted batch job 10875178'.
[Tue Nov 28 17:11:38 2023]
Finished job 583.
448 of 632 steps (71%) done
Select jobs to execute...
[Tue Nov 28 17:12:18 2023]
Finished job 481.
449 of 632 steps (71%) done

[Tue Nov 28 17:12:18 2023]
Job 565: evaluating on tf=MYC,tissue=Skin training and test data
Reason: Input files updated by another job: output/models/cistrome_MYC_Skin_2023-11-14/aggByCollect_MYC_Skin.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Skin.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Skin.prepared.csv.gz, output/models/cistrome_MYC_Skin_2023-11-14/aggByCollect_MYC_Skin.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Skin_2023-11-14/aggByCollect_MYC_Skin.linear.rds --logistic_model output/models/cistrome_MYC_Skin_2023-11-14/aggByCollect_MYC_Skin.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Skin.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Skin.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Skin_2023-11-14/aggByCollect_MYC_Skin
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 565 with external jobid 'Submitted batch job 10875208'.

[Tue Nov 28 17:12:18 2023]
Job 539: training on tf=MYC,tissue=LNCaP-cells training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_LNCaP-cells.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_LNCaP-cells.prepared.csv.gz --rds_file output/models/cistrome_MYC_LNCaP-cells_2023-11-14/aggByCollect_MYC_LNCaP-cells --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 539 with external jobid 'Submitted batch job 10875209'.
[Tue Nov 28 17:12:19 2023]
Finished job 551.
450 of 632 steps (71%) done
Select jobs to execute...
[Tue Nov 28 17:12:59 2023]
Finished job 565.
451 of 632 steps (71%) done
[Tue Nov 28 17:13:00 2023]
Finished job 539.
452 of 632 steps (72%) done

[Tue Nov 28 17:13:00 2023]
Job 516: training on tf=MYC,tissue=Bone training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone.prepared.csv.gz --rds_file output/models/cistrome_MYC_Bone_2023-11-14/aggByCollect_MYC_Bone --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 516 with external jobid 'Submitted batch job 10875216'.

[Tue Nov 28 17:13:01 2023]
Job 623: evaluating on tf=MYC,tissue=LNCaP-cells training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_LNCaP-cells.prepared.csv.gz, output/models/cistrome_MYC_LNCaP-cells_2023-11-14/aggByCollect_MYC_LNCaP-cells.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_LNCaP-cells.prepared.csv.gz, output/models/cistrome_MYC_LNCaP-cells_2023-11-14/aggByCollect_MYC_LNCaP-cells.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_LNCaP-cells_2023-11-14/aggByCollect_MYC_LNCaP-cells.linear.rds --logistic_model output/models/cistrome_MYC_LNCaP-cells_2023-11-14/aggByCollect_MYC_LNCaP-cells.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_LNCaP-cells.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_LNCaP-cells.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_LNCaP-cells_2023-11-14/aggByCollect_MYC_LNCaP-cells
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 623 with external jobid 'Submitted batch job 10875217'.
[Tue Nov 28 17:13:40 2023]
Finished job 516.
453 of 632 steps (72%) done
Select jobs to execute...

[Tue Nov 28 17:13:40 2023]
Job 469: training on tf=MYC,tissue=Bone-Marrow training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone-Marrow.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone-Marrow.prepared.csv.gz --rds_file output/models/cistrome_MYC_Bone-Marrow_2023-11-14/aggByCollect_MYC_Bone-Marrow --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 469 with external jobid 'Submitted batch job 10875227'.

[Tue Nov 28 17:13:41 2023]
Job 600: evaluating on tf=MYC,tissue=Bone training and test data
Reason: Input files updated by another job: output/models/cistrome_MYC_Bone_2023-11-14/aggByCollect_MYC_Bone.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Bone.prepared.csv.gz, output/models/cistrome_MYC_Bone_2023-11-14/aggByCollect_MYC_Bone.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Bone_2023-11-14/aggByCollect_MYC_Bone.linear.rds --logistic_model output/models/cistrome_MYC_Bone_2023-11-14/aggByCollect_MYC_Bone.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Bone.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Bone_2023-11-14/aggByCollect_MYC_Bone
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 600 with external jobid 'Submitted batch job 10875228'.
[Tue Nov 28 17:13:41 2023]
Finished job 623.
454 of 632 steps (72%) done
Select jobs to execute...
[Tue Nov 28 17:14:04 2023]
Finished job 267.
455 of 632 steps (72%) done

[Tue Nov 28 17:14:05 2023]
Job 351: working on tf=ASCL1,tissue=Lung
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ASCL1_Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 351 with external jobid 'Submitted batch job 10875232'.
[Tue Nov 28 17:14:22 2023]
Finished job 469.
456 of 632 steps (72%) done
Select jobs to execute...

[Tue Nov 28 17:14:22 2023]
Job 545: training on tf=STAT6,tissue=Blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Blood.prepared.csv.gz --rds_file output/models/cistrome_STAT6_Blood_2023-11-14/aggByCollect_STAT6_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 545 with external jobid 'Submitted batch job 10875238'.

[Tue Nov 28 17:14:22 2023]
Job 553: evaluating on tf=MYC,tissue=Bone-Marrow training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone-Marrow.prepared.csv.gz, output/models/cistrome_MYC_Bone-Marrow_2023-11-14/aggByCollect_MYC_Bone-Marrow.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Bone-Marrow.prepared.csv.gz, output/models/cistrome_MYC_Bone-Marrow_2023-11-14/aggByCollect_MYC_Bone-Marrow.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Bone-Marrow_2023-11-14/aggByCollect_MYC_Bone-Marrow.linear.rds --logistic_model output/models/cistrome_MYC_Bone-Marrow_2023-11-14/aggByCollect_MYC_Bone-Marrow.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Bone-Marrow.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Bone-Marrow.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Bone-Marrow_2023-11-14/aggByCollect_MYC_Bone-Marrow
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 553 with external jobid 'Submitted batch job 10875239'.
[Tue Nov 28 17:14:22 2023]
Finished job 600.
457 of 632 steps (72%) done
Select jobs to execute...
[Tue Nov 28 17:15:03 2023]
Finished job 545.
458 of 632 steps (72%) done

[Tue Nov 28 17:15:03 2023]
Job 629: evaluating on tf=STAT6,tissue=Blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Blood.prepared.csv.gz, output/models/cistrome_STAT6_Blood_2023-11-14/aggByCollect_STAT6_Blood.linear.rds, output/models/cistrome_STAT6_Blood_2023-11-14/aggByCollect_STAT6_Blood.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT6_Blood_2023-11-14/aggByCollect_STAT6_Blood.linear.rds --logistic_model output/models/cistrome_STAT6_Blood_2023-11-14/aggByCollect_STAT6_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT6_Blood_2023-11-14/aggByCollect_STAT6_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 629 with external jobid 'Submitted batch job 10875249'.

[Tue Nov 28 17:15:03 2023]
Job 486: training on tf=MYC,tissue=Embryonic-Kidney training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryonic-Kidney.prepared.csv.gz --rds_file output/models/cistrome_MYC_Embryonic-Kidney_2023-11-14/aggByCollect_MYC_Embryonic-Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 486 with external jobid 'Submitted batch job 10875250'.
[Tue Nov 28 17:15:04 2023]
Finished job 553.
459 of 632 steps (73%) done
Select jobs to execute...
[Tue Nov 28 17:15:44 2023]
Finished job 629.
460 of 632 steps (73%) done
[Tue Nov 28 17:15:45 2023]
Finished job 486.
461 of 632 steps (73%) done

[Tue Nov 28 17:15:45 2023]
Job 570: evaluating on tf=MYC,tissue=Embryonic-Kidney training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MYC_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_MYC_Embryonic-Kidney_2023-11-14/aggByCollect_MYC_Embryonic-Kidney.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_MYC_Embryonic-Kidney_2023-11-14/aggByCollect_MYC_Embryonic-Kidney.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Embryonic-Kidney_2023-11-14/aggByCollect_MYC_Embryonic-Kidney.linear.rds --logistic_model output/models/cistrome_MYC_Embryonic-Kidney_2023-11-14/aggByCollect_MYC_Embryonic-Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryonic-Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Embryonic-Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Embryonic-Kidney_2023-11-14/aggByCollect_MYC_Embryonic-Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 570 with external jobid 'Submitted batch job 10875259'.

[Tue Nov 28 17:15:45 2023]
Job 483: training on tf=MYC,tissue=Brain training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Brain.prepared.csv.gz --rds_file output/models/cistrome_MYC_Brain_2023-11-14/aggByCollect_MYC_Brain --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 483 with external jobid 'Submitted batch job 10875260'.
[Tue Nov 28 17:16:25 2023]
Finished job 570.
462 of 632 steps (73%) done
Select jobs to execute...
[Tue Nov 28 17:16:26 2023]
Finished job 483.
463 of 632 steps (73%) done

[Tue Nov 28 17:16:26 2023]
Job 479: training on tf=MYC,tissue=Liver training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Liver.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Liver.prepared.csv.gz --rds_file output/models/cistrome_MYC_Liver_2023-11-14/aggByCollect_MYC_Liver --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 479 with external jobid 'Submitted batch job 10875366'.

[Tue Nov 28 17:16:26 2023]
Job 567: evaluating on tf=MYC,tissue=Brain training and test data
Reason: Input files updated by another job: output/models/cistrome_MYC_Brain_2023-11-14/aggByCollect_MYC_Brain.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Brain.prepared.csv.gz, output/models/cistrome_MYC_Brain_2023-11-14/aggByCollect_MYC_Brain.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Brain.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Brain_2023-11-14/aggByCollect_MYC_Brain.linear.rds --logistic_model output/models/cistrome_MYC_Brain_2023-11-14/aggByCollect_MYC_Brain.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Brain.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Brain.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Brain_2023-11-14/aggByCollect_MYC_Brain
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 567 with external jobid 'Submitted batch job 10875367'.
[Tue Nov 28 17:17:06 2023]
Finished job 479.
464 of 632 steps (73%) done
Select jobs to execute...

[Tue Nov 28 17:17:06 2023]
Job 563: evaluating on tf=MYC,tissue=Liver training and test data
Reason: Input files updated by another job: output/models/cistrome_MYC_Liver_2023-11-14/aggByCollect_MYC_Liver.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Liver.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Liver.prepared.csv.gz, output/models/cistrome_MYC_Liver_2023-11-14/aggByCollect_MYC_Liver.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Liver_2023-11-14/aggByCollect_MYC_Liver.linear.rds --logistic_model output/models/cistrome_MYC_Liver_2023-11-14/aggByCollect_MYC_Liver.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Liver.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Liver.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Liver_2023-11-14/aggByCollect_MYC_Liver
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 563 with external jobid 'Submitted batch job 10875370'.

[Tue Nov 28 17:17:06 2023]
Job 546: training on tf=FOXO1,tissue=Cord-blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Cord-blood.prepared.csv.gz --rds_file output/models/cistrome_FOXO1_Cord-blood_2023-11-14/aggByCollect_FOXO1_Cord-blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 546 with external jobid 'Submitted batch job 10875371'.
[Tue Nov 28 17:17:07 2023]
Finished job 567.
465 of 632 steps (74%) done
Select jobs to execute...
[Tue Nov 28 17:17:47 2023]
Finished job 563.
466 of 632 steps (74%) done
[Tue Nov 28 17:17:48 2023]
Finished job 546.
467 of 632 steps (74%) done

[Tue Nov 28 17:17:48 2023]
Job 480: training on tf=MYC,tissue=Umbilical-Vein training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_MYC_Umbilical-Vein_2023-11-14/aggByCollect_MYC_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 480 with external jobid 'Submitted batch job 10875439'.

[Tue Nov 28 17:17:48 2023]
Job 630: evaluating on tf=FOXO1,tissue=Cord-blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Cord-blood.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Cord-blood.prepared.csv.gz, output/models/cistrome_FOXO1_Cord-blood_2023-11-14/aggByCollect_FOXO1_Cord-blood.linear.rds, output/models/cistrome_FOXO1_Cord-blood_2023-11-14/aggByCollect_FOXO1_Cord-blood.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_FOXO1_Cord-blood_2023-11-14/aggByCollect_FOXO1_Cord-blood.linear.rds --logistic_model output/models/cistrome_FOXO1_Cord-blood_2023-11-14/aggByCollect_FOXO1_Cord-blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_FOXO1_Cord-blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_FOXO1_Cord-blood.prepared.csv.gz --eval_output output/models_eval/cistrome_FOXO1_Cord-blood_2023-11-14/aggByCollect_FOXO1_Cord-blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 630 with external jobid 'Submitted batch job 10875440'.
[Tue Nov 28 17:17:50 2023]
Finished job 302.
468 of 632 steps (74%) done
Select jobs to execute...

[Tue Nov 28 17:17:50 2023]
Job 386: preparing tf=ERG,tissue=Prostate training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_ERG_Prostate.csv.gz, data/predictor_files/ERG_Prostate.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ERG_Prostate.csv.gz --ground_truth_file data/predictor_files/ERG_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ERG_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 386 with external jobid 'Submitted batch job 10875441'.
[Tue Nov 28 17:18:28 2023]
Finished job 480.
469 of 632 steps (74%) done
Select jobs to execute...

[Tue Nov 28 17:18:28 2023]
Job 564: evaluating on tf=MYC,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: output/models/cistrome_MYC_Umbilical-Vein_2023-11-14/aggByCollect_MYC_Umbilical-Vein.logistic.rds, output/models/cistrome_MYC_Umbilical-Vein_2023-11-14/aggByCollect_MYC_Umbilical-Vein.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Umbilical-Vein.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Umbilical-Vein_2023-11-14/aggByCollect_MYC_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_MYC_Umbilical-Vein_2023-11-14/aggByCollect_MYC_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Umbilical-Vein_2023-11-14/aggByCollect_MYC_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 564 with external jobid 'Submitted batch job 10875596'.

[Tue Nov 28 17:18:28 2023]
Job 475: training on tf=MYC,tissue=Embryo training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryo.prepared.csv.gz --rds_file output/models/cistrome_MYC_Embryo_2023-11-14/aggByCollect_MYC_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 475 with external jobid 'Submitted batch job 10875597'.
[Tue Nov 28 17:18:29 2023]
Finished job 630.
470 of 632 steps (74%) done
Select jobs to execute...
[Tue Nov 28 17:19:09 2023]
Finished job 564.
471 of 632 steps (75%) done
[Tue Nov 28 17:19:10 2023]
Finished job 475.
472 of 632 steps (75%) done

[Tue Nov 28 17:19:10 2023]
Job 542: training on tf=MYC,tissue=Prostate training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Prostate.prepared.csv.gz --rds_file output/models/cistrome_MYC_Prostate_2023-11-14/aggByCollect_MYC_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 542 with external jobid 'Submitted batch job 10875625'.

[Tue Nov 28 17:19:10 2023]
Job 559: evaluating on tf=MYC,tissue=Embryo training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_MYC_Embryo.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryo.prepared.csv.gz, output/models/cistrome_MYC_Embryo_2023-11-14/aggByCollect_MYC_Embryo.logistic.rds, output/models/cistrome_MYC_Embryo_2023-11-14/aggByCollect_MYC_Embryo.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Embryo_2023-11-14/aggByCollect_MYC_Embryo.linear.rds --logistic_model output/models/cistrome_MYC_Embryo_2023-11-14/aggByCollect_MYC_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Embryo_2023-11-14/aggByCollect_MYC_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 559 with external jobid 'Submitted batch job 10875626'.
[Tue Nov 28 17:19:50 2023]
Finished job 542.
473 of 632 steps (75%) done
Select jobs to execute...

[Tue Nov 28 17:19:50 2023]
Job 626: evaluating on tf=MYC,tissue=Prostate training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Prostate.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Prostate.prepared.csv.gz, output/models/cistrome_MYC_Prostate_2023-11-14/aggByCollect_MYC_Prostate.logistic.rds, output/models/cistrome_MYC_Prostate_2023-11-14/aggByCollect_MYC_Prostate.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Prostate_2023-11-14/aggByCollect_MYC_Prostate.linear.rds --logistic_model output/models/cistrome_MYC_Prostate_2023-11-14/aggByCollect_MYC_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Prostate_2023-11-14/aggByCollect_MYC_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 626 with external jobid 'Submitted batch job 10875652'.

[Tue Nov 28 17:19:50 2023]
Job 503: training on tf=AR,tissue=Colon training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Colon.prepared.csv.gz --rds_file output/models/cistrome_AR_Colon_2023-11-14/aggByCollect_AR_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 503 with external jobid 'Submitted batch job 10875653'.
[Tue Nov 28 17:19:51 2023]
Finished job 559.
474 of 632 steps (75%) done
Select jobs to execute...
[Tue Nov 28 17:20:31 2023]
Finished job 626.
475 of 632 steps (75%) done
[Tue Nov 28 17:20:32 2023]
Finished job 503.
476 of 632 steps (75%) done

[Tue Nov 28 17:20:32 2023]
Job 536: training on tf=MYC,tissue=Foreskin training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_MYC_Foreskin.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Foreskin.prepared.csv.gz --rds_file output/models/cistrome_MYC_Foreskin_2023-11-14/aggByCollect_MYC_Foreskin --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 536 with external jobid 'Submitted batch job 10875686'.

[Tue Nov 28 17:20:32 2023]
Job 587: evaluating on tf=AR,tissue=Colon training and test data
Reason: Input files updated by another job: output/models/cistrome_AR_Colon_2023-11-14/aggByCollect_AR_Colon.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_AR_Colon.prepared.csv.gz, output/models/cistrome_AR_Colon_2023-11-14/aggByCollect_AR_Colon.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_AR_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_AR_Colon_2023-11-14/aggByCollect_AR_Colon.linear.rds --logistic_model output/models/cistrome_AR_Colon_2023-11-14/aggByCollect_AR_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_AR_Colon_2023-11-14/aggByCollect_AR_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 587 with external jobid 'Submitted batch job 10875687'.
[Tue Nov 28 17:21:12 2023]
Finished job 536.
477 of 632 steps (75%) done
Select jobs to execute...

[Tue Nov 28 17:21:12 2023]
Job 620: evaluating on tf=MYC,tissue=Foreskin training and test data
Reason: Input files updated by another job: output/models/cistrome_MYC_Foreskin_2023-11-14/aggByCollect_MYC_Foreskin.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_MYC_Foreskin.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_MYC_Foreskin.prepared.csv.gz, output/models/cistrome_MYC_Foreskin_2023-11-14/aggByCollect_MYC_Foreskin.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_MYC_Foreskin_2023-11-14/aggByCollect_MYC_Foreskin.linear.rds --logistic_model output/models/cistrome_MYC_Foreskin_2023-11-14/aggByCollect_MYC_Foreskin.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_MYC_Foreskin.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_MYC_Foreskin.prepared.csv.gz --eval_output output/models_eval/cistrome_MYC_Foreskin_2023-11-14/aggByCollect_MYC_Foreskin
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 620 with external jobid 'Submitted batch job 10875704'.

[Tue Nov 28 17:21:12 2023]
Job 525: training on tf=SNAI2,tissue=Embryo training data
Reason: Missing output files: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --rds_file output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 525 with external jobid 'Submitted batch job 10875705'.
[Tue Nov 28 17:21:13 2023]
Finished job 587.
478 of 632 steps (76%) done
[Tue Nov 28 17:21:53 2023]
Finished job 620.
479 of 632 steps (76%) done
[Tue Nov 28 17:21:54 2023]
Finished job 525.
480 of 632 steps (76%) done
Select jobs to execute...

[Tue Nov 28 17:21:54 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10875730'.
[Tue Nov 28 17:21:55 2023]
Finished job 386.
481 of 632 steps (76%) done
Select jobs to execute...

[Tue Nov 28 17:21:55 2023]
Job 470: training on tf=ERG,tissue=Prostate training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ERG_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Prostate.prepared.csv.gz --rds_file output/models/cistrome_ERG_Prostate_2023-11-14/aggByCollect_ERG_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 470 with external jobid 'Submitted batch job 10875731'.
[Tue Nov 28 17:23:14 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10875730

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10875730, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:23:14 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10875758'.
[Tue Nov 28 17:24:34 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10875758

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10875758, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:24:34 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10875798'.
[Tue Nov 28 17:25:42 2023]
Finished job 272.
482 of 632 steps (76%) done
Select jobs to execute...

[Tue Nov 28 17:25:42 2023]
Job 356: working on tf=OTX2,tissue=Embryo
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_OTX2_Embryo.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 356 with external jobid 'Submitted batch job 10875849'.
[Tue Nov 28 17:25:55 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10875798

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10875798, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:25:55 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10875850'.
[Tue Nov 28 17:27:14 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10875850

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10875850, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:27:14 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10875908'.
[Tue Nov 28 17:28:34 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10875908

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10875908, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:28:34 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10875946'.
[Tue Nov 28 17:29:55 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10875946

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10875946, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:29:55 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10875976'.
[Tue Nov 28 17:29:58 2023]
Finished job 351.
483 of 632 steps (76%) done
Select jobs to execute...

[Tue Nov 28 17:29:58 2023]
Job 435: preparing tf=ASCL1,tissue=Lung training and test data
Reason: Input files updated by another job: data/predictor_files/ASCL1_Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_ASCL1_Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ASCL1_Lung.csv.gz --ground_truth_file data/predictor_files/ASCL1_Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ASCL1_Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 435 with external jobid 'Submitted batch job 10875977'.
[Tue Nov 28 17:31:15 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10875976

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10875976, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:31:15 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10876104'.
[Tue Nov 28 17:31:58 2023]
Finished job 470.
484 of 632 steps (77%) done
Select jobs to execute...

[Tue Nov 28 17:31:58 2023]
Job 554: evaluating on tf=ERG,tissue=Prostate training and test data
Reason: Input files updated by another job: output/models/cistrome_ERG_Prostate_2023-11-14/aggByCollect_ERG_Prostate.linear.rds, output/models/cistrome_ERG_Prostate_2023-11-14/aggByCollect_ERG_Prostate.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_ERG_Prostate.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_ERG_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ERG_Prostate_2023-11-14/aggByCollect_ERG_Prostate.linear.rds --logistic_model output/models/cistrome_ERG_Prostate_2023-11-14/aggByCollect_ERG_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ERG_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ERG_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_ERG_Prostate_2023-11-14/aggByCollect_ERG_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 554 with external jobid 'Submitted batch job 10876161'.
[Tue Nov 28 17:32:36 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10876104

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10876104, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:32:36 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10876392'.
[Tue Nov 28 17:32:37 2023]
Finished job 435.
485 of 632 steps (77%) done
Select jobs to execute...

[Tue Nov 28 17:32:37 2023]
Job 519: training on tf=ASCL1,tissue=Lung training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Lung.prepared.csv.gz --rds_file output/models/cistrome_ASCL1_Lung_2023-11-14/aggByCollect_ASCL1_Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 519 with external jobid 'Submitted batch job 10876393'.
[Tue Nov 28 17:33:17 2023]
Finished job 554.
486 of 632 steps (77%) done
[Tue Nov 28 17:33:55 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10876392

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10876392, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:33:55 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10876432'.
[Tue Nov 28 17:34:23 2023]
Finished job 291.
487 of 632 steps (77%) done
Select jobs to execute...

[Tue Nov 28 17:34:23 2023]
Job 375: working on tf=NEUROG2,tissue=Fetal-Lung
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_NEUROG2_Fetal-Lung.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 375 with external jobid 'Submitted batch job 10876452'.
[Tue Nov 28 17:35:13 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10876432

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10876432, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 609.
Select jobs to execute...

[Tue Nov 28 17:35:13 2023]
Job 609: evaluating on tf=SNAI2,tissue=Embryo training and test data
Reason: Missing output files: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz; Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 609 with external jobid 'Submitted batch job 10876509'.
[Tue Nov 28 17:36:31 2023]
Error in rule evaluate_TFPred:
    jobid: 609
    input: output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds, output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz
    output: output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.test_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.train_eval.txt.gz, output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.test_eval.txt.gz
    shell:
        
            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.linear.rds --logistic_model output/models/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_SNAI2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_SNAI2_Embryo_2023-11-14/aggByCollect_SNAI2_Embryo
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10876509

Error executing rule evaluate_TFPred on cluster (jobid: 609, external: Submitted batch job 10876509, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.evaluate_TFPred.609.sh). For error details see the cluster log and the log files of the involved rule(s).
[Tue Nov 28 17:38:52 2023]
Finished job 280.
488 of 632 steps (77%) done
Select jobs to execute...

[Tue Nov 28 17:38:52 2023]
Job 364: working on tf=HOXB13,tissue=Prostate
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_HOXB13_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 364 with external jobid 'Submitted batch job 10877038'.
[Tue Nov 28 17:39:06 2023]
Finished job 519.
489 of 632 steps (77%) done
Select jobs to execute...

[Tue Nov 28 17:39:06 2023]
Job 603: evaluating on tf=ASCL1,tissue=Lung training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Lung.prepared.csv.gz, output/models/cistrome_ASCL1_Lung_2023-11-14/aggByCollect_ASCL1_Lung.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_ASCL1_Lung.prepared.csv.gz, output/models/cistrome_ASCL1_Lung_2023-11-14/aggByCollect_ASCL1_Lung.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ASCL1_Lung_2023-11-14/aggByCollect_ASCL1_Lung.linear.rds --logistic_model output/models/cistrome_ASCL1_Lung_2023-11-14/aggByCollect_ASCL1_Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ASCL1_Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ASCL1_Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_ASCL1_Lung_2023-11-14/aggByCollect_ASCL1_Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 603 with external jobid 'Submitted batch job 10877049'.
[Tue Nov 28 17:40:20 2023]
Finished job 603.
490 of 632 steps (78%) done
[Tue Nov 28 17:48:35 2023]
Finished job 279.
491 of 632 steps (78%) done
Select jobs to execute...

[Tue Nov 28 17:48:35 2023]
Job 363: working on tf=VDR,tissue=Prostate
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_VDR_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 363 with external jobid 'Submitted batch job 10877772'.
[Tue Nov 28 17:48:46 2023]
Finished job 275.
492 of 632 steps (78%) done
Select jobs to execute...

[Tue Nov 28 17:48:46 2023]
Job 359: working on tf=AR,tissue=Ovary
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_AR_Ovary.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 359 with external jobid 'Submitted batch job 10877779'.
[Tue Nov 28 17:50:29 2023]
Finished job 257.
493 of 632 steps (78%) done
Select jobs to execute...

[Tue Nov 28 17:50:29 2023]
Job 341: working on tf=GRHL2,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GRHL2_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 341 with external jobid 'Submitted batch job 10878099'.
[Tue Nov 28 17:52:06 2023]
Finished job 363.
494 of 632 steps (78%) done
Select jobs to execute...

[Tue Nov 28 17:52:06 2023]
Job 447: preparing tf=VDR,tissue=Prostate training and test data
Reason: Input files updated by another job: data/predictor_files/VDR_Prostate.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_VDR_Prostate.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_VDR_Prostate.csv.gz --ground_truth_file data/predictor_files/VDR_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_VDR_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 447 with external jobid 'Submitted batch job 10878387'.
[Tue Nov 28 17:52:47 2023]
Finished job 356.
495 of 632 steps (78%) done
Select jobs to execute...

[Tue Nov 28 17:52:47 2023]
Job 440: preparing tf=OTX2,tissue=Embryo training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_OTX2_Embryo.csv.gz, data/predictor_files/OTX2_Embryo.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_OTX2_Embryo.csv.gz --ground_truth_file data/predictor_files/OTX2_Embryo.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_OTX2_Embryo.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_OTX2_Embryo.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 440 with external jobid 'Submitted batch job 10878485'.
[Tue Nov 28 17:53:34 2023]
Finished job 225.
496 of 632 steps (78%) done
Select jobs to execute...

[Tue Nov 28 17:53:34 2023]
Job 309: working on tf=VDR,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_VDR_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 309 with external jobid 'Submitted batch job 10878599'.
[Tue Nov 28 17:54:36 2023]
Finished job 341.
497 of 632 steps (79%) done
Select jobs to execute...

[Tue Nov 28 17:54:36 2023]
Job 425: preparing tf=GRHL2,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GRHL2_Colon.csv.gz, data/predictor_files/GRHL2_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GRHL2_Colon.csv.gz --ground_truth_file data/predictor_files/GRHL2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 425 with external jobid 'Submitted batch job 10878780'.
[Tue Nov 28 17:55:13 2023]
Finished job 447.
498 of 632 steps (79%) done
Select jobs to execute...

[Tue Nov 28 17:55:13 2023]
Job 531: training on tf=VDR,tissue=Prostate training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_VDR_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Prostate.prepared.csv.gz --rds_file output/models/cistrome_VDR_Prostate_2023-11-14/aggByCollect_VDR_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 531 with external jobid 'Submitted batch job 10878865'.
[Tue Nov 28 17:55:51 2023]
Finished job 359.
499 of 632 steps (79%) done
Select jobs to execute...

[Tue Nov 28 17:55:51 2023]
Job 443: preparing tf=AR,tissue=Ovary training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_AR_Ovary.csv.gz, data/predictor_files/AR_Ovary.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_AR_Ovary.csv.gz --ground_truth_file data/predictor_files/AR_Ovary.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Ovary.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Ovary.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 443 with external jobid 'Submitted batch job 10878944'.
[Tue Nov 28 17:56:25 2023]
Finished job 531.
500 of 632 steps (79%) done
Select jobs to execute...

[Tue Nov 28 17:56:25 2023]
Job 615: evaluating on tf=VDR,tissue=Prostate training and test data
Reason: Input files updated by another job: output/models/cistrome_VDR_Prostate_2023-11-14/aggByCollect_VDR_Prostate.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_VDR_Prostate.prepared.csv.gz, output/models/cistrome_VDR_Prostate_2023-11-14/aggByCollect_VDR_Prostate.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_VDR_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_VDR_Prostate_2023-11-14/aggByCollect_VDR_Prostate.linear.rds --logistic_model output/models/cistrome_VDR_Prostate_2023-11-14/aggByCollect_VDR_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_VDR_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_VDR_Prostate_2023-11-14/aggByCollect_VDR_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 615 with external jobid 'Submitted batch job 10879027'.
[Tue Nov 28 17:57:41 2023]
Finished job 309.
501 of 632 steps (79%) done
Select jobs to execute...

[Tue Nov 28 17:57:42 2023]
Job 393: preparing tf=VDR,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_VDR_Colon.csv.gz, data/predictor_files/VDR_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_VDR_Colon.csv.gz --ground_truth_file data/predictor_files/VDR_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_VDR_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 393 with external jobid 'Submitted batch job 10879346'.
[Tue Nov 28 17:58:18 2023]
Finished job 425.
502 of 632 steps (79%) done
Select jobs to execute...

[Tue Nov 28 17:58:18 2023]
Job 509: training on tf=GRHL2,tissue=Colon training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Colon.prepared.csv.gz --rds_file output/models/cistrome_GRHL2_Colon_2023-11-14/aggByCollect_GRHL2_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 509 with external jobid 'Submitted batch job 10879465'.
[Tue Nov 28 17:58:20 2023]
Finished job 440.
503 of 632 steps (80%) done
Select jobs to execute...
[Tue Nov 28 17:58:52 2023]
Finished job 509.
504 of 632 steps (80%) done

[Tue Nov 28 17:58:52 2023]
Job 593: evaluating on tf=GRHL2,tissue=Colon training and test data
Reason: Input files updated by another job: output/models/cistrome_GRHL2_Colon_2023-11-14/aggByCollect_GRHL2_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Colon.prepared.csv.gz, output/models/cistrome_GRHL2_Colon_2023-11-14/aggByCollect_GRHL2_Colon.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GRHL2_Colon_2023-11-14/aggByCollect_GRHL2_Colon.linear.rds --logistic_model output/models/cistrome_GRHL2_Colon_2023-11-14/aggByCollect_GRHL2_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_GRHL2_Colon_2023-11-14/aggByCollect_GRHL2_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 593 with external jobid 'Submitted batch job 10879572'.

[Tue Nov 28 17:58:53 2023]
Job 524: training on tf=OTX2,tissue=Embryo training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_OTX2_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_OTX2_Embryo.prepared.csv.gz --rds_file output/models/cistrome_OTX2_Embryo_2023-11-14/aggByCollect_OTX2_Embryo --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 524 with external jobid 'Submitted batch job 10879573'.
[Tue Nov 28 17:58:53 2023]
Finished job 393.
505 of 632 steps (80%) done
Select jobs to execute...
[Tue Nov 28 17:58:54 2023]
Finished job 615.
506 of 632 steps (80%) done
[Tue Nov 28 17:58:56 2023]
Finished job 443.
507 of 632 steps (80%) done
[Tue Nov 28 17:58:56 2023]
Finished job 364.
508 of 632 steps (80%) done

[Tue Nov 28 17:58:57 2023]
Job 448: preparing tf=HOXB13,tissue=Prostate training and test data
Reason: Input files updated by another job: data/predictor_files/HOXB13_Prostate.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_HOXB13_Prostate.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_HOXB13_Prostate.csv.gz --ground_truth_file data/predictor_files/HOXB13_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_HOXB13_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 448 with external jobid 'Submitted batch job 10879581'.
[Tue Nov 28 17:59:29 2023]
Finished job 593.
509 of 632 steps (81%) done
Select jobs to execute...
[Tue Nov 28 18:02:17 2023]
Finished job 375.
510 of 632 steps (81%) done

[Tue Nov 28 18:02:17 2023]
Job 459: preparing tf=NEUROG2,tissue=Fetal-Lung training and test data
Reason: Input files updated by another job: data/predictor_files/NEUROG2_Fetal-Lung.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_NEUROG2_Fetal-Lung.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_NEUROG2_Fetal-Lung.csv.gz --ground_truth_file data/predictor_files/NEUROG2_Fetal-Lung.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_NEUROG2_Fetal-Lung.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_NEUROG2_Fetal-Lung.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 459 with external jobid 'Submitted batch job 10880103'.
[Tue Nov 28 18:03:23 2023]
Finished job 448.
511 of 632 steps (81%) done
Select jobs to execute...
[Tue Nov 28 18:05:46 2023]
Finished job 265.
512 of 632 steps (81%) done

[Tue Nov 28 18:05:46 2023]
Job 349: working on tf=AR,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_AR_Embryonic-Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 349 with external jobid 'Submitted batch job 10880555'.
[Tue Nov 28 18:06:35 2023]
Finished job 459.
513 of 632 steps (81%) done
Select jobs to execute...
[Tue Nov 28 18:07:24 2023]
Finished job 221.
514 of 632 steps (81%) done

[Tue Nov 28 18:07:24 2023]
Job 305: working on tf=STAT4,tissue=Blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT4_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 305 with external jobid 'Submitted batch job 10880738'.
[Tue Nov 28 18:08:10 2023]
Finished job 524.
515 of 632 steps (81%) done
Select jobs to execute...

[Tue Nov 28 18:08:10 2023]
Job 608: evaluating on tf=OTX2,tissue=Embryo training and test data
Reason: Input files updated by another job: output/models/cistrome_OTX2_Embryo_2023-11-14/aggByCollect_OTX2_Embryo.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_OTX2_Embryo.prepared.csv.gz, output/models/cistrome_OTX2_Embryo_2023-11-14/aggByCollect_OTX2_Embryo.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_OTX2_Embryo.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_OTX2_Embryo_2023-11-14/aggByCollect_OTX2_Embryo.linear.rds --logistic_model output/models/cistrome_OTX2_Embryo_2023-11-14/aggByCollect_OTX2_Embryo.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_OTX2_Embryo.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_OTX2_Embryo.prepared.csv.gz --eval_output output/models_eval/cistrome_OTX2_Embryo_2023-11-14/aggByCollect_OTX2_Embryo
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 608 with external jobid 'Submitted batch job 10880806'.

[Tue Nov 28 18:08:10 2023]
Job 532: training on tf=HOXB13,tissue=Prostate training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Prostate.prepared.csv.gz --rds_file output/models/cistrome_HOXB13_Prostate_2023-11-14/aggByCollect_HOXB13_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 532 with external jobid 'Submitted batch job 10880807'.
[Tue Nov 28 18:09:43 2023]
Finished job 608.
516 of 632 steps (82%) done
Select jobs to execute...
[Tue Nov 28 18:12:03 2023]
Finished job 270.
517 of 632 steps (82%) done

[Tue Nov 28 18:12:03 2023]
Job 354: working on tf=PR,tissue=Prostate
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_PR_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 354 with external jobid 'Submitted batch job 10881235'.
[Tue Nov 28 18:13:40 2023]
Finished job 222.
518 of 632 steps (82%) done
Select jobs to execute...

[Tue Nov 28 18:13:40 2023]
Job 306: working on tf=STAT6,tissue=Cord-blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_STAT6_Cord-blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 306 with external jobid 'Submitted batch job 10881414'.
[Tue Nov 28 18:14:24 2023]
Finished job 354.
519 of 632 steps (82%) done
Select jobs to execute...

[Tue Nov 28 18:14:24 2023]
Job 438: preparing tf=PR,tissue=Prostate training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_PR_Prostate.csv.gz, data/predictor_files/PR_Prostate.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PR_Prostate.csv.gz --ground_truth_file data/predictor_files/PR_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PR_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 438 with external jobid 'Submitted batch job 10881441'.
[Tue Nov 28 18:14:54 2023]
Finished job 438.
520 of 632 steps (82%) done
Select jobs to execute...
[Tue Nov 28 18:15:41 2023]
Finished job 252.
521 of 632 steps (82%) done

[Tue Nov 28 18:15:41 2023]
Job 336: working on tf=PR,tissue=Umbilical-Vein
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_PR_Umbilical-Vein.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 336 with external jobid 'Submitted batch job 10881501'.
[Tue Nov 28 18:16:42 2023]
Finished job 289.
522 of 632 steps (83%) done
Select jobs to execute...

[Tue Nov 28 18:16:42 2023]
Job 373: working on tf=GRHL2,tissue=Prostate
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GRHL2_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 373 with external jobid 'Submitted batch job 10881540'.
[Tue Nov 28 18:17:15 2023]
Finished job 213.
523 of 632 steps (83%) done
Select jobs to execute...

[Tue Nov 28 18:17:15 2023]
Job 297: working on tf=CDX2,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_CDX2_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 297 with external jobid 'Submitted batch job 10881561'.
[Tue Nov 28 18:17:58 2023]
Finished job 336.
524 of 632 steps (83%) done
Select jobs to execute...

[Tue Nov 28 18:17:58 2023]
Job 420: preparing tf=PR,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: data/predictor_files/PR_Umbilical-Vein.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_PR_Umbilical-Vein.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PR_Umbilical-Vein.csv.gz --ground_truth_file data/predictor_files/PR_Umbilical-Vein.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Umbilical-Vein.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PR_Umbilical-Vein.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 420 with external jobid 'Submitted batch job 10881591'.
[Tue Nov 28 18:21:28 2023]
Finished job 373.
525 of 632 steps (83%) done
Select jobs to execute...

[Tue Nov 28 18:21:28 2023]
Job 457: preparing tf=GRHL2,tissue=Prostate training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GRHL2_Prostate.csv.gz, data/predictor_files/GRHL2_Prostate.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GRHL2_Prostate.csv.gz --ground_truth_file data/predictor_files/GRHL2_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 457 with external jobid 'Submitted batch job 10881738'.
[Tue Nov 28 18:25:00 2023]
Finished job 532.
526 of 632 steps (83%) done
Select jobs to execute...

[Tue Nov 28 18:25:00 2023]
Job 543: training on tf=NEUROG2,tissue=Fetal-Lung training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_NEUROG2_Fetal-Lung.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_NEUROG2_Fetal-Lung.prepared.csv.gz --rds_file output/models/cistrome_NEUROG2_Fetal-Lung_2023-11-14/aggByCollect_NEUROG2_Fetal-Lung --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 543 with external jobid 'Submitted batch job 10881892'.

[Tue Nov 28 18:25:00 2023]
Job 616: evaluating on tf=HOXB13,tissue=Prostate training and test data
Reason: Input files updated by another job: output/models/cistrome_HOXB13_Prostate_2023-11-14/aggByCollect_HOXB13_Prostate.logistic.rds, output/models/cistrome_HOXB13_Prostate_2023-11-14/aggByCollect_HOXB13_Prostate.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Prostate.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_HOXB13_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_HOXB13_Prostate_2023-11-14/aggByCollect_HOXB13_Prostate.linear.rds --logistic_model output/models/cistrome_HOXB13_Prostate_2023-11-14/aggByCollect_HOXB13_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_HOXB13_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_HOXB13_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_HOXB13_Prostate_2023-11-14/aggByCollect_HOXB13_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 616 with external jobid 'Submitted batch job 10881893'.
[Tue Nov 28 18:27:20 2023]
Finished job 283.
527 of 632 steps (83%) done
Select jobs to execute...

[Tue Nov 28 18:27:20 2023]
Job 367: working on tf=ZNF382,tissue=Embryonic-Kidney
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_ZNF382_Embryonic-Kidney.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 367 with external jobid 'Submitted batch job 10882003'.
[Tue Nov 28 18:28:19 2023]
Finished job 237.
528 of 632 steps (84%) done
Select jobs to execute...

[Tue Nov 28 18:28:19 2023]
Job 321: working on tf=GRHL2,tissue=Bronchia
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GRHL2_Bronchia.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 321 with external jobid 'Submitted batch job 10882041'.
[Tue Nov 28 18:28:40 2023]
Finished job 349.
529 of 632 steps (84%) done
Select jobs to execute...

[Tue Nov 28 18:28:41 2023]
Job 433: preparing tf=AR,tissue=Embryonic-Kidney training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_AR_Embryonic-Kidney.csv.gz, data/predictor_files/AR_Embryonic-Kidney.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_AR_Embryonic-Kidney.csv.gz --ground_truth_file data/predictor_files/AR_Embryonic-Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Embryonic-Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Embryonic-Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 433 with external jobid 'Submitted batch job 10882059'.
[Tue Nov 28 18:29:08 2023]
Finished job 420.
530 of 632 steps (84%) done
Select jobs to execute...
[Tue Nov 28 18:29:38 2023]
Finished job 457.
531 of 632 steps (84%) done
[Tue Nov 28 18:29:46 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10864959

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10864959, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.

[Tue Nov 28 18:29:46 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10882102'.
[Tue Nov 28 18:30:37 2023]
Finished job 616.
532 of 632 steps (84%) done
Select jobs to execute...
[Tue Nov 28 18:31:40 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10867094

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10867094, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.

[Tue Nov 28 18:31:41 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10882279'.
[Tue Nov 28 18:34:09 2023]
Finished job 367.
533 of 632 steps (84%) done
Select jobs to execute...

[Tue Nov 28 18:34:09 2023]
Job 451: preparing tf=ZNF382,tissue=Embryonic-Kidney training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_ZNF382_Embryonic-Kidney.csv.gz, data/predictor_files/ZNF382_Embryonic-Kidney.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_ZNF382_Embryonic-Kidney.csv.gz --ground_truth_file data/predictor_files/ZNF382_Embryonic-Kidney.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_ZNF382_Embryonic-Kidney.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_ZNF382_Embryonic-Kidney.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 451 with external jobid 'Submitted batch job 10882418'.
[Tue Nov 28 18:34:23 2023]
Finished job 543.
534 of 632 steps (84%) done
Select jobs to execute...

[Tue Nov 28 18:34:23 2023]
Job 627: evaluating on tf=NEUROG2,tissue=Fetal-Lung training and test data
Reason: Input files updated by another job: output/models/cistrome_NEUROG2_Fetal-Lung_2023-11-14/aggByCollect_NEUROG2_Fetal-Lung.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_NEUROG2_Fetal-Lung.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_NEUROG2_Fetal-Lung.prepared.csv.gz, output/models/cistrome_NEUROG2_Fetal-Lung_2023-11-14/aggByCollect_NEUROG2_Fetal-Lung.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_NEUROG2_Fetal-Lung_2023-11-14/aggByCollect_NEUROG2_Fetal-Lung.linear.rds --logistic_model output/models/cistrome_NEUROG2_Fetal-Lung_2023-11-14/aggByCollect_NEUROG2_Fetal-Lung.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_NEUROG2_Fetal-Lung.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_NEUROG2_Fetal-Lung.prepared.csv.gz --eval_output output/models_eval/cistrome_NEUROG2_Fetal-Lung_2023-11-14/aggByCollect_NEUROG2_Fetal-Lung
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 627 with external jobid 'Submitted batch job 10882448'.

[Tue Nov 28 18:34:23 2023]
Job 541: training on tf=GRHL2,tissue=Prostate training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Prostate.prepared.csv.gz --rds_file output/models/cistrome_GRHL2_Prostate_2023-11-14/aggByCollect_GRHL2_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 541 with external jobid 'Submitted batch job 10882449'.
[Tue Nov 28 18:34:55 2023]
Finished job 305.
535 of 632 steps (85%) done
Select jobs to execute...

[Tue Nov 28 18:34:55 2023]
Job 389: preparing tf=STAT4,tissue=Blood training and test data
Reason: Input files updated by another job: data/predictor_files/STAT4_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT4_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT4_Blood.csv.gz --ground_truth_file data/predictor_files/STAT4_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT4_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT4_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 389 with external jobid 'Submitted batch job 10882490'.
[Tue Nov 28 18:35:18 2023]
Finished job 541.
536 of 632 steps (85%) done
Select jobs to execute...

[Tue Nov 28 18:35:18 2023]
Job 625: evaluating on tf=GRHL2,tissue=Prostate training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Prostate.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Prostate.prepared.csv.gz, output/models/cistrome_GRHL2_Prostate_2023-11-14/aggByCollect_GRHL2_Prostate.logistic.rds, output/models/cistrome_GRHL2_Prostate_2023-11-14/aggByCollect_GRHL2_Prostate.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GRHL2_Prostate_2023-11-14/aggByCollect_GRHL2_Prostate.linear.rds --logistic_model output/models/cistrome_GRHL2_Prostate_2023-11-14/aggByCollect_GRHL2_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_GRHL2_Prostate_2023-11-14/aggByCollect_GRHL2_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 625 with external jobid 'Submitted batch job 10882525'.

[Tue Nov 28 18:35:18 2023]
Job 527: training on tf=AR,tissue=Ovary training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Ovary.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Ovary.prepared.csv.gz --rds_file output/models/cistrome_AR_Ovary_2023-11-14/aggByCollect_AR_Ovary --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 527 with external jobid 'Submitted batch job 10882527'.
[Tue Nov 28 18:36:16 2023]
Finished job 527.
537 of 632 steps (85%) done
Select jobs to execute...

[Tue Nov 28 18:36:16 2023]
Job 477: training on tf=VDR,tissue=Colon training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_VDR_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Colon.prepared.csv.gz --rds_file output/models/cistrome_VDR_Colon_2023-11-14/aggByCollect_VDR_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 477 with external jobid 'Submitted batch job 10882575'.

[Tue Nov 28 18:36:16 2023]
Job 611: evaluating on tf=AR,tissue=Ovary training and test data
Reason: Input files updated by another job: output/models/cistrome_AR_Ovary_2023-11-14/aggByCollect_AR_Ovary.linear.rds, output/models/cistrome_AR_Ovary_2023-11-14/aggByCollect_AR_Ovary.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_AR_Ovary.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_AR_Ovary.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_AR_Ovary_2023-11-14/aggByCollect_AR_Ovary.linear.rds --logistic_model output/models/cistrome_AR_Ovary_2023-11-14/aggByCollect_AR_Ovary.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Ovary.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Ovary.prepared.csv.gz --eval_output output/models_eval/cistrome_AR_Ovary_2023-11-14/aggByCollect_AR_Ovary
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 611 with external jobid 'Submitted batch job 10882576'.
[Tue Nov 28 18:37:16 2023]
Finished job 477.
538 of 632 steps (85%) done
Select jobs to execute...

[Tue Nov 28 18:37:16 2023]
Job 522: training on tf=PR,tissue=Prostate training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_PR_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Prostate.prepared.csv.gz --rds_file output/models/cistrome_PR_Prostate_2023-11-14/aggByCollect_PR_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 522 with external jobid 'Submitted batch job 10882633'.

[Tue Nov 28 18:37:16 2023]
Job 561: evaluating on tf=VDR,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_VDR_Colon.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_VDR_Colon.prepared.csv.gz, output/models/cistrome_VDR_Colon_2023-11-14/aggByCollect_VDR_Colon.linear.rds, output/models/cistrome_VDR_Colon_2023-11-14/aggByCollect_VDR_Colon.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_VDR_Colon_2023-11-14/aggByCollect_VDR_Colon.linear.rds --logistic_model output/models/cistrome_VDR_Colon_2023-11-14/aggByCollect_VDR_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_VDR_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_VDR_Colon_2023-11-14/aggByCollect_VDR_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 561 with external jobid 'Submitted batch job 10882634'.
[Tue Nov 28 18:37:47 2023]
Finished job 522.
539 of 632 steps (85%) done
Select jobs to execute...

[Tue Nov 28 18:37:47 2023]
Job 606: evaluating on tf=PR,tissue=Prostate training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_PR_Prostate.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PR_Prostate.prepared.csv.gz, output/models/cistrome_PR_Prostate_2023-11-14/aggByCollect_PR_Prostate.linear.rds, output/models/cistrome_PR_Prostate_2023-11-14/aggByCollect_PR_Prostate.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_PR_Prostate_2023-11-14/aggByCollect_PR_Prostate.linear.rds --logistic_model output/models/cistrome_PR_Prostate_2023-11-14/aggByCollect_PR_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_PR_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_PR_Prostate_2023-11-14/aggByCollect_PR_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 606 with external jobid 'Submitted batch job 10882688'.

[Tue Nov 28 18:37:47 2023]
Job 504: training on tf=PR,tissue=Umbilical-Vein training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_PR_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Umbilical-Vein.prepared.csv.gz --rds_file output/models/cistrome_PR_Umbilical-Vein_2023-11-14/aggByCollect_PR_Umbilical-Vein --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 504 with external jobid 'Submitted batch job 10882689'.
[Tue Nov 28 18:38:20 2023]
Finished job 504.
540 of 632 steps (85%) done
Select jobs to execute...

[Tue Nov 28 18:38:20 2023]
Job 588: evaluating on tf=PR,tissue=Umbilical-Vein training and test data
Reason: Input files updated by another job: output/models/cistrome_PR_Umbilical-Vein_2023-11-14/aggByCollect_PR_Umbilical-Vein.linear.rds, output/models/cistrome_PR_Umbilical-Vein_2023-11-14/aggByCollect_PR_Umbilical-Vein.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_PR_Umbilical-Vein.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_PR_Umbilical-Vein.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_PR_Umbilical-Vein_2023-11-14/aggByCollect_PR_Umbilical-Vein.linear.rds --logistic_model output/models/cistrome_PR_Umbilical-Vein_2023-11-14/aggByCollect_PR_Umbilical-Vein.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Umbilical-Vein.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_PR_Umbilical-Vein.prepared.csv.gz --eval_output output/models_eval/cistrome_PR_Umbilical-Vein_2023-11-14/aggByCollect_PR_Umbilical-Vein
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 588 with external jobid 'Submitted batch job 10882737'.
[Tue Nov 28 18:39:01 2023]
Finished job 433.
541 of 632 steps (86%) done
Select jobs to execute...

[Tue Nov 28 18:39:01 2023]
Job 517: training on tf=AR,tissue=Embryonic-Kidney training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Embryonic-Kidney.prepared.csv.gz --rds_file output/models/cistrome_AR_Embryonic-Kidney_2023-11-14/aggByCollect_AR_Embryonic-Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 517 with external jobid 'Submitted batch job 10882800'.
[Tue Nov 28 18:39:15 2023]
Finished job 451.
542 of 632 steps (86%) done
Select jobs to execute...
[Tue Nov 28 18:40:36 2023]
Finished job 627.
543 of 632 steps (86%) done
[Tue Nov 28 18:41:43 2023]
Finished job 306.
544 of 632 steps (86%) done

[Tue Nov 28 18:41:43 2023]
Job 390: preparing tf=STAT6,tissue=Cord-blood training and test data
Reason: Input files updated by another job: data/predictor_files/STAT6_Cord-blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_STAT6_Cord-blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_STAT6_Cord-blood.csv.gz --ground_truth_file data/predictor_files/STAT6_Cord-blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Cord-blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Cord-blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 390 with external jobid 'Submitted batch job 10883057'.
[Tue Nov 28 18:42:08 2023]
Finished job 611.
545 of 632 steps (86%) done
Select jobs to execute...
[Tue Nov 28 18:42:09 2023]
Finished job 625.
546 of 632 steps (86%) done
[Tue Nov 28 18:42:37 2023]
Finished job 606.
547 of 632 steps (87%) done
[Tue Nov 28 18:42:38 2023]
Finished job 561.
548 of 632 steps (87%) done
[Tue Nov 28 18:43:05 2023]
Finished job 588.
549 of 632 steps (87%) done
[Tue Nov 28 18:44:01 2023]
Finished job 321.
550 of 632 steps (87%) done

[Tue Nov 28 18:44:01 2023]
Job 405: preparing tf=GRHL2,tissue=Bronchia training and test data
Reason: Input files updated by another job: data/predictor_files/GRHL2_Bronchia.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_GRHL2_Bronchia.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GRHL2_Bronchia.csv.gz --ground_truth_file data/predictor_files/GRHL2_Bronchia.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Bronchia.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Bronchia.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 405 with external jobid 'Submitted batch job 10883155'.
[Tue Nov 28 18:44:25 2023]
Finished job 389.
551 of 632 steps (87%) done
Select jobs to execute...
[Tue Nov 28 18:46:29 2023]
Finished job 405.
552 of 632 steps (87%) done
[Tue Nov 28 18:46:33 2023]
Finished job 297.
553 of 632 steps (88%) done

[Tue Nov 28 18:46:34 2023]
Job 381: preparing tf=CDX2,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_CDX2_Colon.csv.gz, data/predictor_files/CDX2_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_CDX2_Colon.csv.gz --ground_truth_file data/predictor_files/CDX2_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_CDX2_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 381 with external jobid 'Submitted batch job 10883259'.
[Tue Nov 28 18:46:54 2023]
Finished job 390.
554 of 632 steps (88%) done
Select jobs to execute...
[Tue Nov 28 18:50:45 2023]
Finished job 381.
555 of 632 steps (88%) done
[Tue Nov 28 18:53:08 2023]
Finished job 288.
556 of 632 steps (88%) done

[Tue Nov 28 18:53:08 2023]
Job 372: working on tf=GRHL2,tissue=Breast
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_GRHL2_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 372 with external jobid 'Submitted batch job 10883609'.
[Tue Nov 28 18:53:09 2023]
Finished job 286.
557 of 632 steps (88%) done
Select jobs to execute...

[Tue Nov 28 18:53:09 2023]
Job 370: working on tf=AR,tissue=Breast
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_AR_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 370 with external jobid 'Submitted batch job 10883610'.
[Tue Nov 28 18:54:53 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10872174

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10872174, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 18:54:53 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10883701'.
[Tue Nov 28 18:54:54 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10871161

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10871161, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 18:54:54 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10883702'.
[Tue Nov 28 18:56:22 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10882102

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10882102, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.
Select jobs to execute...

[Tue Nov 28 18:56:22 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10883781'.
[Tue Nov 28 18:56:44 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10882279

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10882279, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.
Select jobs to execute...

[Tue Nov 28 18:56:44 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10883808'.
[Tue Nov 28 18:58:08 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10883701

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10883701, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 18:58:08 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10883878'.
[Tue Nov 28 18:58:09 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10883702

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10883702, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 18:58:09 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10883880'.
[Tue Nov 28 18:58:12 2023]
Finished job 517.
558 of 632 steps (88%) done
Select jobs to execute...

[Tue Nov 28 18:58:12 2023]
Job 474: training on tf=STAT6,tissue=Cord-blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Cord-blood.prepared.csv.gz --rds_file output/models/cistrome_STAT6_Cord-blood_2023-11-14/aggByCollect_STAT6_Cord-blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 474 with external jobid 'Submitted batch job 10883888'.

[Tue Nov 28 18:58:12 2023]
Job 601: evaluating on tf=AR,tissue=Embryonic-Kidney training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_AR_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_AR_Embryonic-Kidney_2023-11-14/aggByCollect_AR_Embryonic-Kidney.logistic.rds, output/models/cistrome_AR_Embryonic-Kidney_2023-11-14/aggByCollect_AR_Embryonic-Kidney.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_AR_Embryonic-Kidney_2023-11-14/aggByCollect_AR_Embryonic-Kidney.linear.rds --logistic_model output/models/cistrome_AR_Embryonic-Kidney_2023-11-14/aggByCollect_AR_Embryonic-Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Embryonic-Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Embryonic-Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_AR_Embryonic-Kidney_2023-11-14/aggByCollect_AR_Embryonic-Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 601 with external jobid 'Submitted batch job 10883890'.
[Tue Nov 28 18:59:40 2023]
Finished job 601.
559 of 632 steps (88%) done
Select jobs to execute...
[Tue Nov 28 18:59:42 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10883781

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10883781, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.

[Tue Nov 28 18:59:42 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10883979'.
[Tue Nov 28 19:00:04 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10883808

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10883808, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.
Select jobs to execute...

[Tue Nov 28 19:00:04 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10884008'.
[Tue Nov 28 19:01:30 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10883878

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10883878, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 19:01:30 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10884091'.
[Tue Nov 28 19:01:31 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10883880

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10883880, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 19:01:31 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10884092'.
[Tue Nov 28 19:02:59 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10883979

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10883979, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.
Select jobs to execute...

[Tue Nov 28 19:02:59 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10884353'.
[Tue Nov 28 19:03:22 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884008

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10884008, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.
Select jobs to execute...

[Tue Nov 28 19:03:22 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10884368'.
[Tue Nov 28 19:03:31 2023]
Finished job 241.
560 of 632 steps (89%) done
Select jobs to execute...

[Tue Nov 28 19:03:31 2023]
Job 325: working on tf=AR,tissue=Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_AR_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 325 with external jobid 'Submitted batch job 10884373'.
[Tue Nov 28 19:04:49 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884091

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10884091, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 19:04:49 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10884438'.
[Tue Nov 28 19:04:50 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884092

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10884092, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 19:04:50 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10884439'.
[Tue Nov 28 19:05:34 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884353

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10884353, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.
Select jobs to execute...

[Tue Nov 28 19:05:34 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10884472'.
[Tue Nov 28 19:06:38 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884438

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10884438, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 19:06:38 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10884525'.
[Tue Nov 28 19:06:40 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884368

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10884368, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.
Select jobs to execute...

[Tue Nov 28 19:06:40 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10884527'.
[Tue Nov 28 19:07:02 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884439

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10884439, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 19:07:02 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10884542'.
[Tue Nov 28 19:07:30 2023]
Finished job 214.
561 of 632 steps (89%) done
Select jobs to execute...

[Tue Nov 28 19:07:30 2023]
Job 298: working on tf=VDR,tissue=Blood
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_VDR_Blood.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 298 with external jobid 'Submitted batch job 10884561'.
[Tue Nov 28 19:08:09 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884472

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10884472, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.
Select jobs to execute...

[Tue Nov 28 19:08:09 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10884587'.
[Tue Nov 28 19:08:30 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884525

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10884525, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 19:08:30 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10884605'.
[Tue Nov 28 19:08:53 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884527

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10884527, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.
Select jobs to execute...

[Tue Nov 28 19:08:53 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10884616'.
[Tue Nov 28 19:09:15 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884542

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10884542, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 19:09:15 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10884644'.
[Tue Nov 28 19:09:38 2023]
Finished job 474.
562 of 632 steps (89%) done
Select jobs to execute...

[Tue Nov 28 19:09:38 2023]
Job 473: training on tf=STAT4,tissue=Blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT4_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT4_Blood.prepared.csv.gz --rds_file output/models/cistrome_STAT4_Blood_2023-11-14/aggByCollect_STAT4_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 473 with external jobid 'Submitted batch job 10884656'.

[Tue Nov 28 19:09:38 2023]
Job 558: evaluating on tf=STAT6,tissue=Cord-blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Cord-blood.prepared.csv.gz, output/models/cistrome_STAT6_Cord-blood_2023-11-14/aggByCollect_STAT6_Cord-blood.linear.rds, output/models/cistrome_STAT6_Cord-blood_2023-11-14/aggByCollect_STAT6_Cord-blood.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Cord-blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT6_Cord-blood_2023-11-14/aggByCollect_STAT6_Cord-blood.linear.rds --logistic_model output/models/cistrome_STAT6_Cord-blood_2023-11-14/aggByCollect_STAT6_Cord-blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT6_Cord-blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT6_Cord-blood.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT6_Cord-blood_2023-11-14/aggByCollect_STAT6_Cord-blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 558 with external jobid 'Submitted batch job 10884657'.
[Tue Nov 28 19:10:00 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884587

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10884587, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.
Select jobs to execute...

[Tue Nov 28 19:10:00 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10884677'.
[Tue Nov 28 19:10:23 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884605

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10884605, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 19:10:23 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10884690'.
[Tue Nov 28 19:11:07 2023]
Finished job 558.
563 of 632 steps (89%) done
Select jobs to execute...
[Tue Nov 28 19:11:09 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884616

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10884616, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.

[Tue Nov 28 19:11:09 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10884727'.
[Tue Nov 28 19:11:31 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884644

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10884644, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 19:11:31 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10884739'.
[Tue Nov 28 19:11:33 2023]
Finished job 372.
564 of 632 steps (89%) done
Select jobs to execute...

[Tue Nov 28 19:11:33 2023]
Job 456: preparing tf=GRHL2,tissue=Breast training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_GRHL2_Breast.csv.gz, data/predictor_files/GRHL2_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_GRHL2_Breast.csv.gz --ground_truth_file data/predictor_files/GRHL2_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 456 with external jobid 'Submitted batch job 10884741'.
[Tue Nov 28 19:11:53 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884677

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10884677, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.
Select jobs to execute...

[Tue Nov 28 19:11:53 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10884761'.
[Tue Nov 28 19:12:37 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884690

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10884690, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 19:12:37 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10884785'.
[Tue Nov 28 19:13:21 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884727

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10884727, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.
Select jobs to execute...

[Tue Nov 28 19:13:21 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10884807'.
[Tue Nov 28 19:13:42 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884739

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10884739, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 19:13:42 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10884819'.
[Tue Nov 28 19:14:26 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884761

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10884761, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 249.
Select jobs to execute...

[Tue Nov 28 19:14:26 2023]
Job 249: working on HIF1A_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 249 with external jobid 'Submitted batch job 10884841'.
[Tue Nov 28 19:14:27 2023]
Finished job 456.
565 of 632 steps (89%) done
Select jobs to execute...
[Tue Nov 28 19:15:08 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884807

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10884807, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 246.

[Tue Nov 28 19:15:08 2023]
Job 246: working on ERG_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 246 with external jobid 'Submitted batch job 10884864'.
[Tue Nov 28 19:15:09 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884785

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10884785, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 255.
Select jobs to execute...

[Tue Nov 28 19:15:09 2023]
Job 255: working on STAT4_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 255 with external jobid 'Submitted batch job 10884866'.
[Tue Nov 28 19:16:12 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884819

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10884819, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
Trying to restart job 254.
Select jobs to execute...

[Tue Nov 28 19:16:12 2023]
Job 254: working on FOXO1_Colon
Reason: Missing output files: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json; Input files updated by another job: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json


            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 254 with external jobid 'Submitted batch job 10884897'.
[Tue Nov 28 19:16:52 2023]
Error in rule predict_with_enformer:
    jobid: 246
    input: data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_ERG_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_ERG_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884864

Error executing rule predict_with_enformer on cluster (jobid: 246, external: Submitted batch job 10884864, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.246.sh). For error details see the cluster log and the log files of the involved rule(s).
Select jobs to execute...
[Tue Nov 28 19:16:54 2023]
Error in rule predict_with_enformer:
    jobid: 249
    input: data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_HIF1A_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_HIF1A_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884841

Error executing rule predict_with_enformer on cluster (jobid: 249, external: Submitted batch job 10884841, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.249.sh). For error details see the cluster log and the log files of the involved rule(s).
[Tue Nov 28 19:17:52 2023]
Error in rule predict_with_enformer:
    jobid: 255
    input: data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_STAT4_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_STAT4_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884866

Error executing rule predict_with_enformer on cluster (jobid: 255, external: Submitted batch job 10884866, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.255.sh). For error details see the cluster log and the log files of the involved rule(s).
[Tue Nov 28 19:18:28 2023]
Error in rule predict_with_enformer:
    jobid: 254
    input: data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
    output: data/prediction_parameters/aggregation_config_cistrome_FOXO1_Colon.json
    shell:
        
            python3 /beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py --parameters data/prediction_parameters/enformer_parameters_cistrome_FOXO1_Colon.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 10884897

Error executing rule predict_with_enformer on cluster (jobid: 254, external: Submitted batch job 10884897, jobscript: /project2/haky/temi/projects/TFPred-snakemake/.snakemake/tmp.3cgl72ow/snakejob.predict_with_enformer.254.sh). For error details see the cluster log and the log files of the involved rule(s).
[Tue Nov 28 19:18:29 2023]
Finished job 473.
566 of 632 steps (90%) done

[Tue Nov 28 19:18:29 2023]
Job 465: training on tf=CDX2,tissue=Colon training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Colon.prepared.csv.gz --rds_file output/models/cistrome_CDX2_Colon_2023-11-14/aggByCollect_CDX2_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 465 with external jobid 'Submitted batch job 10884965'.

[Tue Nov 28 19:18:29 2023]
Job 557: evaluating on tf=STAT4,tissue=Blood training and test data
Reason: Input files updated by another job: output/models/cistrome_STAT4_Blood_2023-11-14/aggByCollect_STAT4_Blood.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_STAT4_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_STAT4_Blood.prepared.csv.gz, output/models/cistrome_STAT4_Blood_2023-11-14/aggByCollect_STAT4_Blood.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_STAT4_Blood_2023-11-14/aggByCollect_STAT4_Blood.linear.rds --logistic_model output/models/cistrome_STAT4_Blood_2023-11-14/aggByCollect_STAT4_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_STAT4_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_STAT4_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_STAT4_Blood_2023-11-14/aggByCollect_STAT4_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 557 with external jobid 'Submitted batch job 10884967'.
[Tue Nov 28 19:19:41 2023]
Finished job 557.
567 of 632 steps (90%) done
Select jobs to execute...
[Tue Nov 28 19:19:46 2023]
Finished job 233.
568 of 632 steps (90%) done

[Tue Nov 28 19:19:46 2023]
Job 317: working on tf=PR,tissue=Mammary-Gland
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_PR_Mammary-Gland.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 317 with external jobid 'Submitted batch job 10885005'.
[Tue Nov 28 19:21:59 2023]
Finished job 298.
569 of 632 steps (90%) done
Select jobs to execute...

[Tue Nov 28 19:21:59 2023]
Job 382: preparing tf=VDR,tissue=Blood training and test data
Reason: Input files updated by another job: data/predictor_files/VDR_Blood.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_VDR_Blood.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_VDR_Blood.csv.gz --ground_truth_file data/predictor_files/VDR_Blood.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Blood.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_VDR_Blood.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 382 with external jobid 'Submitted batch job 10885079'.
[Tue Nov 28 19:22:34 2023]
Finished job 370.
570 of 632 steps (90%) done
Select jobs to execute...

[Tue Nov 28 19:22:34 2023]
Job 454: preparing tf=AR,tissue=Breast training and test data
Reason: Input files updated by another job: data/predictor_files/AR_Breast.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_AR_Breast.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_AR_Breast.csv.gz --ground_truth_file data/predictor_files/AR_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 454 with external jobid 'Submitted batch job 10885101'.
[Tue Nov 28 19:24:14 2023]
Finished job 382.
571 of 632 steps (90%) done
Select jobs to execute...
[Tue Nov 28 19:26:38 2023]
Finished job 454.
572 of 632 steps (91%) done
[Tue Nov 28 19:29:10 2023]
Finished job 465.
573 of 632 steps (91%) done

[Tue Nov 28 19:29:10 2023]
Job 549: evaluating on tf=CDX2,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_CDX2_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Colon.prepared.csv.gz, output/models/cistrome_CDX2_Colon_2023-11-14/aggByCollect_CDX2_Colon.logistic.rds, output/models/cistrome_CDX2_Colon_2023-11-14/aggByCollect_CDX2_Colon.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_CDX2_Colon_2023-11-14/aggByCollect_CDX2_Colon.linear.rds --logistic_model output/models/cistrome_CDX2_Colon_2023-11-14/aggByCollect_CDX2_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_CDX2_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_CDX2_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_CDX2_Colon_2023-11-14/aggByCollect_CDX2_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 549 with external jobid 'Submitted batch job 10885253'.

[Tue Nov 28 19:29:10 2023]
Job 538: training on tf=AR,tissue=Breast training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Breast.prepared.csv.gz --rds_file output/models/cistrome_AR_Breast_2023-11-14/aggByCollect_AR_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 538 with external jobid 'Submitted batch job 10885254'.
[Tue Nov 28 19:30:28 2023]
Finished job 549.
574 of 632 steps (91%) done
Select jobs to execute...
[Tue Nov 28 19:34:04 2023]
Finished job 325.
575 of 632 steps (91%) done

[Tue Nov 28 19:34:05 2023]
Job 409: preparing tf=AR,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_AR_Mammary-Gland.csv.gz, data/predictor_files/AR_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_AR_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/AR_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 409 with external jobid 'Submitted batch job 10885291'.
[Tue Nov 28 19:35:02 2023]
Finished job 295.
576 of 632 steps (91%) done
Select jobs to execute...

[Tue Nov 28 19:35:02 2023]
Job 379: working on tf=AR,tissue=Prostate
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_AR_Prostate.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 379 with external jobid 'Submitted batch job 10885296'.
[Tue Nov 28 19:37:17 2023]
Finished job 317.
577 of 632 steps (91%) done
Select jobs to execute...

[Tue Nov 28 19:37:17 2023]
Job 401: preparing tf=PR,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_PR_Mammary-Gland.csv.gz, data/predictor_files/PR_Mammary-Gland.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PR_Mammary-Gland.csv.gz --ground_truth_file data/predictor_files/PR_Mammary-Gland.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Mammary-Gland.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PR_Mammary-Gland.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 401 with external jobid 'Submitted batch job 10885302'.
[Tue Nov 28 19:38:05 2023]
Finished job 409.
578 of 632 steps (91%) done
Select jobs to execute...
[Tue Nov 28 19:40:23 2023]
Finished job 538.
579 of 632 steps (92%) done

[Tue Nov 28 19:40:23 2023]
Job 493: training on tf=AR,tissue=Mammary-Gland training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_AR_Mammary-Gland_2023-11-14/aggByCollect_AR_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 493 with external jobid 'Submitted batch job 10885308'.

[Tue Nov 28 19:40:23 2023]
Job 622: evaluating on tf=AR,tissue=Breast training and test data
Reason: Input files updated by another job: output/models/cistrome_AR_Breast_2023-11-14/aggByCollect_AR_Breast.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_AR_Breast.prepared.csv.gz, output/models/cistrome_AR_Breast_2023-11-14/aggByCollect_AR_Breast.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_AR_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_AR_Breast_2023-11-14/aggByCollect_AR_Breast.linear.rds --logistic_model output/models/cistrome_AR_Breast_2023-11-14/aggByCollect_AR_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_AR_Breast_2023-11-14/aggByCollect_AR_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 622 with external jobid 'Submitted batch job 10885309'.
[Tue Nov 28 19:41:22 2023]
Finished job 401.
580 of 632 steps (92%) done
Select jobs to execute...
[Tue Nov 28 19:41:36 2023]
Finished job 622.
581 of 632 steps (92%) done
[Tue Nov 28 19:50:17 2023]
Finished job 493.
582 of 632 steps (92%) done

[Tue Nov 28 19:50:17 2023]
Job 577: evaluating on tf=AR,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Mammary-Gland.prepared.csv.gz, output/models/cistrome_AR_Mammary-Gland_2023-11-14/aggByCollect_AR_Mammary-Gland.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_AR_Mammary-Gland.prepared.csv.gz, output/models/cistrome_AR_Mammary-Gland_2023-11-14/aggByCollect_AR_Mammary-Gland.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_AR_Mammary-Gland_2023-11-14/aggByCollect_AR_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_AR_Mammary-Gland_2023-11-14/aggByCollect_AR_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_AR_Mammary-Gland_2023-11-14/aggByCollect_AR_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 577 with external jobid 'Submitted batch job 10885360'.

[Tue Nov 28 19:50:17 2023]
Job 485: training on tf=PR,tissue=Mammary-Gland training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_PR_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Mammary-Gland.prepared.csv.gz --rds_file output/models/cistrome_PR_Mammary-Gland_2023-11-14/aggByCollect_PR_Mammary-Gland --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 485 with external jobid 'Submitted batch job 10885361'.
[Tue Nov 28 19:51:26 2023]
Finished job 577.
583 of 632 steps (92%) done
Select jobs to execute...
[Tue Nov 28 19:53:38 2023]
Finished job 379.
584 of 632 steps (92%) done

[Tue Nov 28 19:53:38 2023]
Job 463: preparing tf=AR,tissue=Prostate training and test data
Reason: Input files updated by another job: data/predictor_files/AR_Prostate.ground_truth.txt, data/aggregation_folder/cistrome_aggByCollect_AR_Prostate.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_AR_Prostate.csv.gz --ground_truth_file data/predictor_files/AR_Prostate.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Prostate.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Prostate.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 463 with external jobid 'Submitted batch job 10885598'.
[Tue Nov 28 19:54:45 2023]
Finished job 277.
585 of 632 steps (93%) done
Select jobs to execute...

[Tue Nov 28 19:54:45 2023]
Job 361: working on tf=PR,tissue=Breast
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_PR_Breast.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 361 with external jobid 'Submitted batch job 10885676'.
[Tue Nov 28 19:57:44 2023]
Finished job 463.
586 of 632 steps (93%) done
Select jobs to execute...
[Tue Nov 28 20:02:57 2023]
Finished job 485.
587 of 632 steps (93%) done

[Tue Nov 28 20:02:58 2023]
Job 569: evaluating on tf=PR,tissue=Mammary-Gland training and test data
Reason: Input files updated by another job: output/models/cistrome_PR_Mammary-Gland_2023-11-14/aggByCollect_PR_Mammary-Gland.linear.rds, output/models/cistrome_PR_Mammary-Gland_2023-11-14/aggByCollect_PR_Mammary-Gland.logistic.rds, data/aggregation_folder/train_cistrome_aggByCollect_PR_Mammary-Gland.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_PR_Mammary-Gland.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_PR_Mammary-Gland_2023-11-14/aggByCollect_PR_Mammary-Gland.linear.rds --logistic_model output/models/cistrome_PR_Mammary-Gland_2023-11-14/aggByCollect_PR_Mammary-Gland.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Mammary-Gland.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_PR_Mammary-Gland.prepared.csv.gz --eval_output output/models_eval/cistrome_PR_Mammary-Gland_2023-11-14/aggByCollect_PR_Mammary-Gland
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 569 with external jobid 'Submitted batch job 10886510'.

[Tue Nov 28 20:02:58 2023]
Job 547: training on tf=AR,tissue=Prostate training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Prostate.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Prostate.prepared.csv.gz --rds_file output/models/cistrome_AR_Prostate_2023-11-14/aggByCollect_AR_Prostate --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 547 with external jobid 'Submitted batch job 10886511'.
[Tue Nov 28 20:04:14 2023]
Finished job 569.
588 of 632 steps (93%) done
Select jobs to execute...
[Tue Nov 28 20:05:28 2023]
Finished job 212.
589 of 632 steps (93%) done

[Tue Nov 28 20:05:28 2023]
Job 296: working on tf=TCF4,tissue=Colon
Reason: Input files updated by another job: data/prediction_parameters/aggregation_config_cistrome_TCF4_Colon.json

sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 296 with external jobid 'Submitted batch job 10886829'.
[Tue Nov 28 20:17:05 2023]
Finished job 547.
590 of 632 steps (93%) done
Select jobs to execute...

[Tue Nov 28 20:17:05 2023]
Job 540: training on tf=GRHL2,tissue=Breast training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Breast.prepared.csv.gz --rds_file output/models/cistrome_GRHL2_Breast_2023-11-14/aggByCollect_GRHL2_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 540 with external jobid 'Submitted batch job 10887750'.

[Tue Nov 28 20:17:06 2023]
Job 631: evaluating on tf=AR,tissue=Prostate training and test data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_AR_Prostate.prepared.csv.gz, output/models/cistrome_AR_Prostate_2023-11-14/aggByCollect_AR_Prostate.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_AR_Prostate.prepared.csv.gz, output/models/cistrome_AR_Prostate_2023-11-14/aggByCollect_AR_Prostate.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_AR_Prostate_2023-11-14/aggByCollect_AR_Prostate.linear.rds --logistic_model output/models/cistrome_AR_Prostate_2023-11-14/aggByCollect_AR_Prostate.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_AR_Prostate.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_AR_Prostate.prepared.csv.gz --eval_output output/models_eval/cistrome_AR_Prostate_2023-11-14/aggByCollect_AR_Prostate
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 631 with external jobid 'Submitted batch job 10887751'.
[Tue Nov 28 20:18:22 2023]
Finished job 631.
591 of 632 steps (94%) done
Select jobs to execute...
[Tue Nov 28 20:25:11 2023]
Finished job 540.
592 of 632 steps (94%) done

[Tue Nov 28 20:25:11 2023]
Job 489: training on tf=GRHL2,tissue=Bronchia training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Bronchia.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Bronchia.prepared.csv.gz --rds_file output/models/cistrome_GRHL2_Bronchia_2023-11-14/aggByCollect_GRHL2_Bronchia --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 489 with external jobid 'Submitted batch job 10888507'.

[Tue Nov 28 20:25:11 2023]
Job 624: evaluating on tf=GRHL2,tissue=Breast training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Breast.prepared.csv.gz, output/models/cistrome_GRHL2_Breast_2023-11-14/aggByCollect_GRHL2_Breast.logistic.rds, output/models/cistrome_GRHL2_Breast_2023-11-14/aggByCollect_GRHL2_Breast.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GRHL2_Breast_2023-11-14/aggByCollect_GRHL2_Breast.linear.rds --logistic_model output/models/cistrome_GRHL2_Breast_2023-11-14/aggByCollect_GRHL2_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_GRHL2_Breast_2023-11-14/aggByCollect_GRHL2_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 624 with external jobid 'Submitted batch job 10888508'.
[Tue Nov 28 20:26:03 2023]
Finished job 624.
593 of 632 steps (94%) done
Select jobs to execute...
[Tue Nov 28 20:31:27 2023]
Finished job 489.
594 of 632 steps (94%) done

[Tue Nov 28 20:31:27 2023]
Job 466: training on tf=VDR,tissue=Blood training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_VDR_Blood.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Blood.prepared.csv.gz --rds_file output/models/cistrome_VDR_Blood_2023-11-14/aggByCollect_VDR_Blood --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 466 with external jobid 'Submitted batch job 10888908'.

[Tue Nov 28 20:31:27 2023]
Job 573: evaluating on tf=GRHL2,tissue=Bronchia training and test data
Reason: Input files updated by another job: output/models/cistrome_GRHL2_Bronchia_2023-11-14/aggByCollect_GRHL2_Bronchia.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Bronchia.prepared.csv.gz, output/models/cistrome_GRHL2_Bronchia_2023-11-14/aggByCollect_GRHL2_Bronchia.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Bronchia.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_GRHL2_Bronchia_2023-11-14/aggByCollect_GRHL2_Bronchia.linear.rds --logistic_model output/models/cistrome_GRHL2_Bronchia_2023-11-14/aggByCollect_GRHL2_Bronchia.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_GRHL2_Bronchia.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_GRHL2_Bronchia.prepared.csv.gz --eval_output output/models_eval/cistrome_GRHL2_Bronchia_2023-11-14/aggByCollect_GRHL2_Bronchia
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 573 with external jobid 'Submitted batch job 10888909'.
[Tue Nov 28 20:32:19 2023]
Finished job 573.
595 of 632 steps (94%) done
Select jobs to execute...
[Tue Nov 28 20:33:33 2023]
Finished job 361.
596 of 632 steps (94%) done

[Tue Nov 28 20:33:33 2023]
Job 445: preparing tf=PR,tissue=Breast training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_PR_Breast.csv.gz, data/predictor_files/PR_Breast.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_PR_Breast.csv.gz --ground_truth_file data/predictor_files/PR_Breast.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Breast.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_PR_Breast.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 445 with external jobid 'Submitted batch job 10888926'.
[Tue Nov 28 20:37:45 2023]
Finished job 445.
597 of 632 steps (94%) done
Select jobs to execute...
[Tue Nov 28 20:40:40 2023]
Finished job 466.
598 of 632 steps (95%) done

[Tue Nov 28 20:40:40 2023]
Job 529: training on tf=PR,tissue=Breast training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_PR_Breast.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Breast.prepared.csv.gz --rds_file output/models/cistrome_PR_Breast_2023-11-14/aggByCollect_PR_Breast --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 529 with external jobid 'Submitted batch job 10889113'.

[Tue Nov 28 20:40:41 2023]
Job 550: evaluating on tf=VDR,tissue=Blood training and test data
Reason: Input files updated by another job: data/aggregation_folder/test_cistrome_aggByCollect_VDR_Blood.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_VDR_Blood.prepared.csv.gz, output/models/cistrome_VDR_Blood_2023-11-14/aggByCollect_VDR_Blood.linear.rds, output/models/cistrome_VDR_Blood_2023-11-14/aggByCollect_VDR_Blood.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_VDR_Blood_2023-11-14/aggByCollect_VDR_Blood.linear.rds --logistic_model output/models/cistrome_VDR_Blood_2023-11-14/aggByCollect_VDR_Blood.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_VDR_Blood.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_VDR_Blood.prepared.csv.gz --eval_output output/models_eval/cistrome_VDR_Blood_2023-11-14/aggByCollect_VDR_Blood
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 550 with external jobid 'Submitted batch job 10889114'.
[Tue Nov 28 20:41:28 2023]
Finished job 550.
599 of 632 steps (95%) done
Select jobs to execute...
[Tue Nov 28 20:43:09 2023]
Finished job 296.
600 of 632 steps (95%) done

[Tue Nov 28 20:43:09 2023]
Job 380: preparing tf=TCF4,tissue=Colon training and test data
Reason: Input files updated by another job: data/aggregation_folder/cistrome_aggByCollect_TCF4_Colon.csv.gz, data/predictor_files/TCF4_Colon.ground_truth.txt


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_test_split.R --data_file data/aggregation_folder/cistrome_aggByCollect_TCF4_Colon.csv.gz --ground_truth_file data/predictor_files/TCF4_Colon.ground_truth.txt --aggregation_method aggByCollect --train_prepared_file data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Colon.prepared.csv.gz --test_prepared_file data/aggregation_folder/test_cistrome_aggByCollect_TCF4_Colon.prepared.csv.gz
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 380 with external jobid 'Submitted batch job 10889162'.
[Tue Nov 28 20:47:11 2023]
Finished job 380.
601 of 632 steps (95%) done
Select jobs to execute...
[Tue Nov 28 20:51:21 2023]
Finished job 529.
602 of 632 steps (95%) done

[Tue Nov 28 20:51:21 2023]
Job 613: evaluating on tf=PR,tissue=Breast training and test data
Reason: Input files updated by another job: output/models/cistrome_PR_Breast_2023-11-14/aggByCollect_PR_Breast.linear.rds, data/aggregation_folder/test_cistrome_aggByCollect_PR_Breast.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_PR_Breast.prepared.csv.gz, output/models/cistrome_PR_Breast_2023-11-14/aggByCollect_PR_Breast.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_PR_Breast_2023-11-14/aggByCollect_PR_Breast.linear.rds --logistic_model output/models/cistrome_PR_Breast_2023-11-14/aggByCollect_PR_Breast.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_PR_Breast.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_PR_Breast.prepared.csv.gz --eval_output output/models_eval/cistrome_PR_Breast_2023-11-14/aggByCollect_PR_Breast
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 613 with external jobid 'Submitted batch job 10889648'.

[Tue Nov 28 20:51:22 2023]
Job 464: training on tf=TCF4,tissue=Colon training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Colon.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Colon.prepared.csv.gz --rds_file output/models/cistrome_TCF4_Colon_2023-11-14/aggByCollect_TCF4_Colon --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 464 with external jobid 'Submitted batch job 10889649'.
[Tue Nov 28 20:52:37 2023]
Finished job 613.
603 of 632 steps (95%) done
Select jobs to execute...
[Tue Nov 28 21:10:29 2023]
Finished job 464.
604 of 632 steps (96%) done

[Tue Nov 28 21:10:30 2023]
Job 548: evaluating on tf=TCF4,tissue=Colon training and test data
Reason: Input files updated by another job: output/models/cistrome_TCF4_Colon_2023-11-14/aggByCollect_TCF4_Colon.logistic.rds, data/aggregation_folder/test_cistrome_aggByCollect_TCF4_Colon.prepared.csv.gz, data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Colon.prepared.csv.gz, output/models/cistrome_TCF4_Colon_2023-11-14/aggByCollect_TCF4_Colon.linear.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_TCF4_Colon_2023-11-14/aggByCollect_TCF4_Colon.linear.rds --logistic_model output/models/cistrome_TCF4_Colon_2023-11-14/aggByCollect_TCF4_Colon.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_TCF4_Colon.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_TCF4_Colon.prepared.csv.gz --eval_output output/models_eval/cistrome_TCF4_Colon_2023-11-14/aggByCollect_TCF4_Colon
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 548 with external jobid 'Submitted batch job 10890890'.

[Tue Nov 28 21:10:30 2023]
Job 535: training on tf=ZNF382,tissue=Embryonic-Kidney training data
Reason: Input files updated by another job: data/aggregation_folder/train_cistrome_aggByCollect_ZNF382_Embryonic-Kidney.prepared.csv.gz


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/train_enet.R --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ZNF382_Embryonic-Kidney.prepared.csv.gz --rds_file output/models/cistrome_ZNF382_Embryonic-Kidney_2023-11-14/aggByCollect_ZNF382_Embryonic-Kidney --nfolds 5; sleep 12
        
sbatch: Verify job submission ...
sbatch: Using a shared partition ...
sbatch: Partition: bigmem
sbatch: QOS-Flag: bigmem
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 535 with external jobid 'Submitted batch job 10890891'.
[Tue Nov 28 21:11:13 2023]
Finished job 535.
605 of 632 steps (96%) done
Select jobs to execute...

[Tue Nov 28 21:11:13 2023]
Job 619: evaluating on tf=ZNF382,tissue=Embryonic-Kidney training and test data
Reason: Input files updated by another job: output/models/cistrome_ZNF382_Embryonic-Kidney_2023-11-14/aggByCollect_ZNF382_Embryonic-Kidney.linear.rds, data/aggregation_folder/train_cistrome_aggByCollect_ZNF382_Embryonic-Kidney.prepared.csv.gz, data/aggregation_folder/test_cistrome_aggByCollect_ZNF382_Embryonic-Kidney.prepared.csv.gz, output/models/cistrome_ZNF382_Embryonic-Kidney_2023-11-14/aggByCollect_ZNF382_Embryonic-Kidney.logistic.rds


            /beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript workflow/src/evaluate_enet.R --linear_model output/models/cistrome_ZNF382_Embryonic-Kidney_2023-11-14/aggByCollect_ZNF382_Embryonic-Kidney.linear.rds --logistic_model output/models/cistrome_ZNF382_Embryonic-Kidney_2023-11-14/aggByCollect_ZNF382_Embryonic-Kidney.logistic.rds --train_data_file data/aggregation_folder/train_cistrome_aggByCollect_ZNF382_Embryonic-Kidney.prepared.csv.gz --test_data_file data/aggregation_folder/test_cistrome_aggByCollect_ZNF382_Embryonic-Kidney.prepared.csv.gz --eval_output output/models_eval/cistrome_ZNF382_Embryonic-Kidney_2023-11-14/aggByCollect_ZNF382_Embryonic-Kidney
        
sbatch: Verify job submission ...
sbatch: Partition: beagle3
sbatch: QOS-Flag: beagle3
sbatch: Account: pi-haky
sbatch: Verification: ***PASSED***
Submitted job 619 with external jobid 'Submitted batch job 10890926'.
[Tue Nov 28 21:11:35 2023]
Finished job 619.
606 of 632 steps (96%) done
[Tue Nov 28 21:11:55 2023]
Finished job 548.
607 of 632 steps (96%) done
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2023-11-28T125628.823973.snakemake.log
84 valid TF-tissue pairs were found.
